[{"content":"【六步提问法】 第一步：现象确认 目的：确认和GPT处于同一讨论语境（对现象的认识达成一致）\n提问模板：你知道xxx吗？（用地域、时间、学科类别进行限定）\n你知道中国的一种教育现象，叫”鸡娃“吗？ 如果不知道，直接投喂资源，可以直接发几篇相关文章让它学习\n第二步：学术概念化 提问模板：关于xx，在xx领域会用什么概念进行研究？\n关于”鸡娃“，在教育学会用什么概念进行研究呢？ 第三步：定位优质资源 （1）聚焦感兴趣的学术概念 提问模板：关于xxx，请推荐5篇引用率较高的英文文献并介绍\n家长涉入有哪些类型，请推荐5篇引用率较高的英文文献并介绍 （2）换提问方式 提问模板：请推荐关于xxx的高被引文献、综述文献、按时间或按主题、特定期刊的文献\n关于家长涉入研究，有哪些综述文献，要求是英文，推荐五篇 （3）要求GPT总结文献 提问模板：请用1500字总结这五篇文献的内容，包括背景、问题、方法、分析、案例、结论六个方面\n如果发现了有趣的子概念或者相关概念，可以继续追问\n控制型家长涉入研究，推荐三篇论文 第四步：对比分析 跨学科对比、跨地域对比、跨时间对比、概念之间对比、理论与现实对比\n提问模板：\n（1）将aa与bb进行比较，列出五个方面；\n（2）关于xxx，十年前和现在有什么不同；\n（3）中国和美国在xxx方面有什么不同。\n第五步：启示分析 提问模板：\n（1）这三个案例对于xxxx（问题）有哪些启示，请从xxxx四个方面给出建议\n（2）关于xxx的研究，能够给英文文献提供什么新方向——论文最后一部分的启发、建议\n第六步：写初稿 先定标题 提问模板：\n（1）我想研究xxx，你可以根据我们上面的聊天内容，帮我生成三篇论文的标题吗？\n再定大纲 （2）请帮我就《xxxx》这个标题生成论文大纲\n再逐个部分写出来，记得检查文献真伪，假的替换为真的 （3）文献综述部分，请帮我写500字，加上参考文献和学者观点。\n","date":"2023-09-03T00:01:08+08:00","permalink":"https://linjianshu.github.io/p/cg/","title":"CG"},{"content":"智能优化混合算法是一种以某类优化算法为基础,融合其他智能算法或理论的混合算法,可用于求解各种工程问题最优解.\n智能算法在工程领域(如系统控制、生产调度、人工智能、模式识别等)的迅速推广和应用，作为一个重要的科学分支，智能优化算法激励人们从更广泛的生物或自然现象寻求启发，以构造新的只能算法或对算法不断地进行改进，从而更好地解决工程中存在的多数复杂问题。优势主要表现在：\n算法原理简单，易于推广和应用 良好的算法收敛性和搜索速度，优化问题较易取得满意结果 Chapter1 绪论\n智能优化算法即一种按照某规则或思想进行的搜索过程，用以得到满足用户要求的问题的解。\n遗传算法于1975年由美国密歇根大学的J.Holland教授等人受生物进化论的启发而提出[1]。遗传算法是以自然界中的生物进化过程为背景，将生物进化过程中的繁殖、选择、杂交、变异和竞争等概念引入算法中。它的基本思想来源于自然界中的生物从低级、简单，发展到高级、复杂，乃至进化成人类这样的一个漫长进化过程，并借鉴了达尔文提出的物竞天择、优胜劣汰、适者生存的自然法则。遗传算法的本质是一种对问题进行高效全局搜索的方法，它在搜索过程中有效的利用已有信息来自动获取和积累有关搜索空间的知识，并自适应地控制搜索方向使其最终走向最优解。\n遗传算法已经在数据挖掘、生产调度、图像处理以及函数优化等领域去的了令人鼓舞的成就，证明了其良好的性能。近年来，遗传算法被应用于诸如复杂的多目标规划问题、人工生命以及神经网络问题、机器学习问题、智能控制等问题中。\n自然界中的生物遗传物质的主要载体是染色体，基因是控制生物性状的遗传物质的功能单位和结构单位，是染色体的主要组成部分，即多个基因组成染色体。在染色体中，基因所占据的位置称为基因座。同一个基因座，可能有的全部基因称为等位基因。染色体的特征即生物个体的性状就是由基因和基因座决定的。与此对应染色体有两种相应的表示模式，即基因型和表现型。所谓表现形式是指生五个题外在所表现出来的性状，而基因型则是指与表现型密切相关的基因组成。同一种基因型的生物个体在不同的外在环境条件作用下可以存在不同的表现型，因此表现型是基因型与外在环境条件下相互作用的结果。染色体带有特征的实体称为个体，个体的集合就是种群。该集合内，个体数称为群体的大小。一个个体对环境的适应程度称为适应度，生物学家使用适应度这个属于来衡量某个物种将获得更多的繁殖后代的机会；而对外在生存环境适应程度较低的物种，其放置后代的机会就会相对较少，甚至逐渐走向灭绝。复制、选择、交叉和变异是自然界中的生物不断向前进化的最重要的组成部分。\n自然遗传学说与人工遗传算法中所使用的基本概念和术语之间的对应关系\n染色体 解的编码 基因 解中的每一个分量的特征 基因座 特性值 个体 解 种群 选定的一组解(解的个数为种群的规模) 适应度 适应度函数值 复制 根据适应度函数值选取的一组解的操作 选择 以一定概率从种群中选择若干个解的操作 交叉 通过交配原则产生一组新解的过程 变异 通过突变原则产生一组新解的过程 执行遗传算法时必须包含两个数据转换操作，一是表现型到基因型的转换，二是基因型到表现型的转换。前者是指把实际问题中的参数或解转换成遗传算法问题中的染色体或个体。这个过程定义为编码操作；后者是对前者的一个相反操作，即把遗传算法中的染色体或者个体转换为实际问题中的解或参数，这个过程叫做译码操作。当产生初始种群之后，就按照适者生存和优胜劣汰的原理，在每一代中根据每个个体的适应度函数值大小来挑选个体，并仿照自然遗传学说中的遗传算子来进行交叉和变异，并产生出代表新的解集的种群。以此类推逐代进化并产生出越来越优异的近似解，最后一代种群中的最优个体经过解码操作，就可以作为待解决问题的近似最优解。\n计算开始时，先将种群随机初始化，产生出一定数目的N个个体，并计算每个个体的适应度函数值，第一代初始种群就产生了。算法按照适应度值选择个体参与交叉编译运算，父代要通过基因重组（交叉）而产生子代，所有的子代按一定概率进行变异操作，然后子代的适应度值又被重新计算，从而产生新的下一代种群。如此反复，直到满足优化准则为止。\n近些年来，国内学者也发表了大量关于遗传算法的文章，如2004年，杨晓梅、曾建潮[5]为改善当时求解车间调度问题中的遗传算法的性能,提高搜索最优调度解的速度,并借鉴遗传算法的生物学基础,提出了基于多个体交叉的遗传算法。该算法在执行遗传过程中充分利用个体自身的优良性质，对不可行的调度解根据多个体修补原则进行修补改正，以此就可保证遗传后代的合法性和种群多样性，能够显著缩短最优调度解的搜索时间。在2005年，王凌、张亮[6]针对有限缓冲区的流水线调度问题,提出了一种基于多搜索模式的遗传算法,该算法使用多个交叉和变异操作来对解空间进行探索和改良,并采用面向有向图的领域结构来增强局部搜索性能。在2007年，吴尔飞、金烨等[7]针对当前研究较少的双边装配线平衡问题,研究双边装配中具有操作方位约束的任务,以及在工位上分配任务的操作顺序与平衡结果具有直接关系等特点,提出了相对应的符合该问题特性的遗传算法。该算法采用基于序列、任务机器分配方位相组合的编码方法，并改进了更加可行的交叉与变异算子，使最优解搜索过程仅在可行解的空间内进行，提高了搜索效率，节约了搜索时间。在2009年，莫巨华、黄敏、王兴伟[8]为实现系统的最优化设计，致力于研究以满足顾客满意率要求为主要约束的多目标规划，并提出了一种改进的遗传算法与过程仿真相结合的求解方法。在该求解方法中，多目标规划通过加权平均转化为单目标规划。\n遗传算法是一种模拟生物界的自然选择和自然遗传机制的随机搜索算法。在遗传算法提出之前，为解决各种优化问题，许多优化算法已经被提出，例如梯度法、单纯形法、动态规划法等。这些优化算法有各自的有点，也有各自的适用范围，同时又有各自的限制因素。遗传算法与这些传统的优化算法有很大的不同，大多数古典的优化算法是对一个单一的度量函数（评估函数）进行梯度或较高次统计，然后产生一个具有确定性的试验解序列。相反，遗传算法并不依赖于梯度信息，而是通过模拟自然界的进化过程来对最优解进行搜索，它利用某种编码技术，并作用于称为染色体的数字串上，对由这些串组成的群体的进化过程进行模拟。遗传算法通过有组织地、随机地交换信息来重新组合那些适应性较好的串，生成新的串并组成群体。\n遗传算法具有自组织性、自适应性和智能性。自然选择清楚了算法设计过程中的一个最大的障碍，即需要事先对问题的全部特点进行描述，并要说明针对问题的不同特点所应采取何种措施。遗传算法的这种自组织、自适应的特征，使它同时具有根据环境的变化而自动发现环境的特性和规律的能力，从而使遗传算法可以用来解决一些复杂的非结构化问题。 遗传算法具有并行性。遗传算法在种群中是按照并行方式进行搜索的，而不是在一个单点上进行寻优的，其并行性表现在两个方面： 遗传算法具有内在并行性，使它本身及其时候大规模并行，并适合在目前所有的并行机或分布式系统上进行并行的处理； 遗传算法具有内行并行性，由于它采用种群的方式来组织搜索，因此可以同时搜索解空间内的多个区域，并相互进行信息交流。许多传统的搜索方法都是从单点开始寻优的，因而在多峰函数优化中极容易陷入局部最优解。遗传算法是从一个种群开始进行搜索的，并且可以同时向不同的方向进行搜索，从而大大提高了遗传算法的全局搜索性能，并减少了陷入局部最优解的可能性。 遗传算法使用概率搜索技术。遗传算法在搜索过程中并不采用确定性规则，而采用概率的变迁规则来指引它的搜索方向，在优化过程中，使搜索的每一步都向最终结果靠近的机制或智能性称为搜索的探索性或启发性。传统搜索方法中从一个搜索点到另一个搜索点的转移有确定性的转移方法和转移关系，这种确定性也极有可能使搜索永远也达不到最优点，因而限制了算法的应用范围，制约了算法的应用效果。遗传算法以适应度数字作为标尺、以概率作为一种工具来指引搜索过程，虽然表面上看，遗传算法好像是一种盲目的搜索方法，但实际上它却是一种导向随机搜索方法。 遗传算法把决策变量的编码作为运算对象。 遗传算法直接把目标函数值作为搜索信息。传统的优化算法不仅需要利用目标函数值，并且还需要目标函数的导数值等其他一些辅助信息才能最终确定下一步的搜索方向和搜索范围，无需使用目标函数的导数值及其他一些辅助信息。这个特性使得遗传算法在很多目标函数无法求导或很难求导的优化问题，以及组合优化问题等应用中比较方便，因为它消除了导数求导这个障碍。另外，直接利用目标函数值或个体适应度值，也可使我们把搜索范围集中到适应度较高的那部分搜索空间中，从而大大提高了搜索的效率，节省了搜索时间。 ","date":"2022-12-25T10:46:00+08:00","permalink":"https://linjianshu.github.io/p/%E6%99%BA%E8%83%BD%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/","title":"智能优化算法笔记"},{"content":"并发vs并行 并发:多线程程序在一个核的cpu上运行\n并行:多线程程序在多个核的cpu上运行\ngo:充分发挥多核优势 高效运行\ngoroutine image-20221206101655826\r协程:用户态 轻量级线程 栈kb级别\n线程:内核态 线程上跑多个协程 栈mb级别\n快速打印demo\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { for i := 0; i \u0026lt; 5; i++ { //使用闭包 防止出问题 go func(j int) { hello(j) }(i) } time.Sleep(1 * time.Second) manyGoWait() } //优雅一点 使用等待组概念 没做完就会阻塞 做完就会通过信号来解除阻塞 func manyGoWait() { var wg sync.WaitGroup wg.Add(5) for i := 0; i \u0026lt; 5; i++ { go func(j int) { defer wg.Done() hello(j) }(i) } wg.Wait() } //快速打印 快速 func hello(i int) { println(\u0026#34;hello goroutine : \u0026#34; + fmt.Sprint(i)) } CSP:communicating sequential processes image-20221206101742614\r提倡通过信号而不是通过共享内存实现通信\nChannel make(chan 元素类型, [缓冲大小])\n无缓冲通道 同步通道 make(chan int) 有缓冲通道 make(chan int , 2) 生产消费模型 for循环的for range形式可用于从通道接收值，直到它关闭为止\nimage-20221206101901733\rchannel demo\npackage main func main() { CalSquare() } func CalSquare() { src := make(chan int) dest := make(chan int, 3) //生产者模型 go func() { //defer关闭生产者通道 defer close(src) for i := 0; i \u0026lt; 10; i++ { src \u0026lt;- i } }() //消费者模型 go func() { //defer关闭消费者通道 defer close(dest) //for range遍历生产者通道 for range可以一直遍历直到通道关闭 for i := range src { dest \u0026lt;- i * i } }() //for range遍历结果通道 for range可以一直遍历直到通道关闭 for i := range dest { println(i) } } 并发安全lock demo\npackage main import ( \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var ( x int64 lock sync.Mutex ) func main() { Add() } // Add 快速添加 重点在快速 不能简单串行 func Add() { x = 0 for i := 0; i \u0026lt; 5; i++ { go addWithoutLock() } time.Sleep(time.Second) println(\u0026#34;WithoutLock:\u0026#34;, x) x = 0 for i := 0; i \u0026lt; 5; i++ { go addWithLock() } time.Sleep(time.Second) println(\u0026#34;WithLock:\u0026#34;, x) } //通过锁来保护临界区代码段 保证对资源的独占式访问 func addWithLock() { for i := 0; i \u0026lt; 2000; i++ { lock.Lock() x += 1 lock.Unlock() } } //没有加锁 高并发场景下会造成重复添加 func addWithoutLock() { for i := 0; i \u0026lt; 2000; i++ { x += 1 } } WaitGroup image-20221206102844247\r计数器\n开启协程+1\n执行结束-1\n主协程阻塞直到计数器为0\n小结 Goroutine channel sync 依赖管理 image-20221206103155342\r工程项目不可能基于标准库0-1编码搭建\n管理依赖库\ngo依赖管理演进 image-20221206103325231\rGOPATH==\u0026gt;Go Vendor==\u0026gt;Go Module\n不同环境(项目)依赖的版本不同 控制依赖库的版本 GOPATH 环境变量$GOPATH image-20221206103447833\r项目代码直接依赖src下的代码\ngo get下载最新版本的包到src目录下\nimage-20221206103543806\r场景:A和B依赖于某一package的不同版本\n问题:无法实现package的多版本控制\nGo Vendor 项目目录下增加vendor文件夹 所有依赖包副本形式放在$ProjectRoot/vendor文件夹下 依赖寻址方式: vendor=\u0026gt;GOPATH image-20221206103716933\r通过每个项目引入一份依赖的副本 解决了多个项目需要同一个package依赖的冲突问题\nimage-20221206103829986\r问题:\n无法控制依赖的版本 更新项目有可能出现依赖冲突 导致编译出错 Go Module 通过go.mod文件管理依赖包版本 通过go get/go mod指令工具管理依赖包 终极目标:定义版本规则和管理项目依赖关系\n依赖管理三要素 配置文件 描述依赖 go.mod 中心仓库管理依赖库 Proxy 本地工具 go get/mod 依赖配置- go.mod image-20221206104345655\r依赖配置-version 语义化版本 ${MAJOR}.${MINOR}.${PATCH}\nMAJOR不同大版本 不同Major可以不兼容\nMINOR新增和功能更新 在major中需要做到兼容\nPATCH代码bug的修复\nV1.3.0\nV2.3.0\n基于commit伪版本 vx.0.0-yyyymmddhhmmss-abcdefgh1234\n时间戳-hash码前缀校验码\n依赖配置-indirect image-20221206104745233\r间接依赖就会以indirect标识出来\n依赖配置-incompatible image-20221206104908841\r主版本2+模块会在模块路径增加/vN后缀 对于没有go.mod文件并且主版本2+的依赖 会+incompatible标识 依赖配置-依赖图 image-20221206105035380\r依赖分发-回源 image-20221206105101648\r无法保证构建稳定性 增加/修改/删除软件版本 无法保证依赖可用性 删除软件 增加第三方压力 代码托管平台负载问题 依赖分发-Proxy image-20221206105225107\r依赖分发-变量GOPROXY\nGOPROXY=\u0026ldquo;https://proxy1.cn,https://proxy2.cn,direct\u0026rdquo;\n服务站点URL列表 direct表示源站 找不到依赖就回到源站搜索\nimage-20221206105429465\r工具-go get image-20221206105525614\r工具-go mod image-20221206105540671\r依赖管理三要素 配置文件 描述依赖 go.mod 中心仓库管理依赖库 Proxy 本地工具 go get/mod 小结 GO依赖管理演进 GO Module依赖管理方案 测试 image-20221206112256589\r回归测试 集成测试 功能维度 单元测试 单元测试 image-20221206183157928\r单元测试-规则 所有测试文件以_test.go结尾 image-20221206183419054\rfunc TestXxx(*testing.T) image-20221206183426143\r初始化逻辑放到TestMain中 image-20221206183433038\r单元测试-assert 使用testify包\ndemo\nmain.go\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;github.com/bytedance/gopkg/lang/fastrand\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) func main() { } func HelloTom() string { return \u0026#34;Tom\u0026#34; } func JudgePassLine(score int16) bool { if score \u0026gt;= 60 { return true } return false } // ReadFirstLine 这里要对系统文件进行强依赖 适合使用桩代码进行替换 func ReadFirstLine() string { open, err := os.Open(\u0026#34;E:\\\\project\\\\GOproject\\\\src\\\\log.txt\u0026#34;) defer open.Close() if err != nil { return \u0026#34;\u0026#34; } scanner := bufio.NewScanner(open) for scanner.Scan() { return scanner.Text() } return \u0026#34;\u0026#34; } func ProcessFirstLine() string { line := ReadFirstLine() destLine := strings.ReplaceAll(line, \u0026#34;11\u0026#34;, \u0026#34;00\u0026#34;) return destLine } var ServerIndex [10]int // InitServerIndex 模拟初始化10个服务器 func InitServerIndex() { for i := 0; i \u0026lt; 10; i++ { ServerIndex[i] = i + 100 } } // Select 模拟从初始化的服务器中随机挑选出一个服务器为前端提供服务 func Select() int { //rand是串行的 return ServerIndex[rand.Intn(10)] } // FastSelect 模拟从初始化的服务器中随机挑选出一个服务器为前端提供服务 func FastSelect() int { //fastRand进行了优化 return ServerIndex[fastrand.Intn(10)] } main_test.go\npackage main import ( \u0026#34;bou.ke/monkey\u0026#34; \u0026#34;github.com/magiconair/properties/assert\u0026#34; \u0026#34;testing\u0026#34; ) func TestHelloTom(t *testing.T) { //使用简单的!=来判断 output := HelloTom() expectedoutput := \u0026#34;Tom\u0026#34; if output != expectedoutput { t.Errorf(\u0026#34;Expected %s do not match actual %s\u0026#34;, expectedoutput, output) } } func TestJudgePassLineTrue(t *testing.T) { isPass := JudgePassLine(70) //使用testify包的assert来进行 assert.Equal(t, true, isPass) } //覆盖率测试 对各个分支进行测试 func TestJudgePassLineFalse(t *testing.T) { isPass := JudgePassLine(50) assert.Equal(t, false, isPass) } //直接的对系统文件的强依赖 可能导致无法正常测试 需要桩代码 func TestProcessFirstLine(t *testing.T) { firstLine := ProcessFirstLine() assert.Equal(t, \u0026#34;line00\u0026#34;, firstLine) } //mock 对readline 进行打桩测试 不再依赖本地文件 func TestProcessFirstLineWithMock(t *testing.T) { //patch对强依赖代码进行替换 monkey.Patch(ReadFirstLine, func() string { return \u0026#34;line110\u0026#34; }) //defer 别忘了进行卸载 defer monkey.Unpatch(ReadFirstLine) line := ProcessFirstLine() assert.Equal(t, \u0026#34;line000\u0026#34;, line) } //基准测试 串行 func BenchmarkSelect(b *testing.B) { //这个是准备 不能囊括进去 InitServerIndex() //重置 时间 b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { Select() } } func BenchmarkSelectParallel(b *testing.B) { InitServerIndex() b.ResetTimer() //并行测试 b.RunParallel(func(pb *testing.PB) { for pb.Next() { Select() } }) } func BenchmarkFastSelectParallel(b *testing.B) { InitServerIndex() b.ResetTimer() b.RunParallel(func(pb *testing.PB) { for pb.Next() { FastSelect() } }) } 单元测试-覆盖率 代码覆盖率\n衡量代码是否经过足够的测试\n评价项目的测试水准\n评估项目是否达到了高水准的测试等级\n单元测试-Tips 一般覆盖率:50%-60% 测试分支相互独立、全面覆盖 测试单元粒度足够小，函数单一职责 单元测试-依赖 image-20221206184449319\r外部依赖 =\u0026gt; 稳定\u0026amp;幂等\n单元测试-文件处理 image-20221206184652243\r单元测试-Mock 打桩:用打桩函数替换原函数\nimage-20221206184816946\rimage-20221206185058140\r基准测试 优化代码 需要对当前代码分析 内置的测试框架提供了基准测试的能力 基准测试-运行 image-20221206185305366\r小结\n单元测试 Mock测试 基准测试 项目实践\n需求描述\nimage-20221206185602280\r需求用例\nimage-20221206185640045\rER图\nimage-20221206185737269\r分层结构\nimage-20221206190545181\r数据层: 数据model 外部数据的增删改查 逻辑层: 业务entity 处理核心业务逻辑输出 视图层: 视图view 处理和外部的交互逻辑 组件工具\nimage-20221206191012515\rRepository\nimage-20221206191126882\rRepository-index\nimage-20221206191259858\r初始化话题数据索引\nfunc initTopicIndexMap(filePath string) error { open, err := os.Open(filePath + \u0026#34;topic\u0026#34;) if err != nil { return err } scanner := bufio.NewScanner(open) topicTmpMap := make(map[int64]*Topic) for scanner.Scan() { text := scanner.Text() var topic Topic err := json.Unmarshal([]byte(text), \u0026amp;topic) if err != nil { return err } topicTmpMap[topic.Id] = \u0026amp;topic } topicIndexMap = topicTmpMap return nil } 初始化post数据索引\nfunc initPostIndexMap(filePath string) error { open, err := os.Open(filePath + \u0026#34;post\u0026#34;) if err != nil { return err } scanner := bufio.NewScanner(open) postTmpMap := make(map[int64][]*Post) for scanner.Scan() { text := scanner.Text() var post Post err := json.Unmarshal([]byte(text), \u0026amp;post) if err != nil { return err } postTmpMap[post.ParentId] = append(postTmpMap[post.ParentId], \u0026amp;post) } postIndexMap = postTmpMap return nil } Repository-查询\ntype Topic struct { Id int64 `json:\u0026#34;id\u0026#34;` Title string `json:\u0026#34;title\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` CreateTime int64 `json:\u0026#34;create_time\u0026#34;` } type TopicDao struct { } var ( topicDao *TopicDao topicOnce sync.Once ) // NewTopicDaoInstance once 单例模式 func NewTopicDaoInstance() *TopicDao { topicOnce.Do( func() { topicDao = \u0026amp;TopicDao{} }) return topicDao } func (t *TopicDao) QueryTopicById(id int64) *Topic { return topicIndexMap[id] } Service\nimage-20221206191714621\rimage-20221206191740159\r准备数据\nimage-20221206192109921\rController\nimage-20221206192238283\rRouter\nimage-20221206192937467\r运行\nimage-20221206193047832\r小结\n项目拆解 代码设计 测试运行 课后实践\nimage-20221206193141620\r","date":"2022-12-06T10:06:21+08:00","permalink":"https://linjianshu.github.io/p/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E9%9D%92%E8%AE%AD%E8%90%A5-go%E8%AF%AD%E8%A8%80%E4%B8%8A%E6%89%8B-%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/","title":"字节跳动青训营 Go语言上手 工程实践"},{"content":"实习进度汇报 这几天在做什么: 数据持久化 pvc pv sc 学习 secret、configmap 用法并应用； 这些事情的进度: 1.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\nhttps://github.com/linjianshu/e-book-Gin\nhttps://github.com/linjianshu/client-go\n2.数据持久化 使用hostpath(不推荐 但是简单) statefulset.yaml文件\napiVersion: apps/v1 kind: StatefulSet metadata: name: my-mysql-statefulset spec: serviceName: my-mysql-service replicas: 3 selector: matchLabels: app: my-mysql template: metadata: labels: app: my-mysql spec: affinity: #节点的亲和性 好像是没有节点反亲和的 nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node #要求pod不允许运行在标签node=master的节点上 operator: NotIn values: - master #pod的反亲和性 podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \u0026#34;app\u0026#34; #要求pod不允许运行在已有pod标签为webapp的节点上 operator: In values: - \u0026#34;my-mysql\u0026#34; topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: my-mysql image: mysql:latest imagePullPolicy: IfNotPresent #IfNotPresent 仅本地没有镜像时才远程拉取 , Always永远都是远程拉取 , Never永远只是用本地镜像 本地没有则报错 args: - \u0026#34;--character-set-server=utf8\u0026#34; # 指定字符编码 - \u0026#34;--collation-server=utf8_general_ci\u0026#34; # 指定字符编码 env: - name: MYSQL_ROOT_PASSWORD # 指定root用户的用户名 value: \u0026#34;123456\u0026#34; - name: MYSQL_DATABASE # 新建的数据库 value: \u0026#34;datashare\u0026#34; volumeMounts: - name: data #与65行对应 mountPath: /var/lib/mysql #容器里面挂载的路径 volumes: - name: data #卷名字 hostPath: path: /data/mysql-data #节点上的路径 type: DirectoryOrCreate #指向一个目录 不存在自动创建 --- apiVersion: v1 kind: Service metadata: name: my-mysql-service spec: selector: app: my-mysql type: ClusterIP clusterIP: None ports: - port: 3306 targetPort: 3306 运行截图 image-20220820154026704\r进入容器创建student数据库\nimage-20220820154138057\r进入节点minikube-m03查看是否挂载成功\nimage-20220820154356207\r删除pod查看是否数据会丢失\nimage-20220820154606129\rimage-20220820154621624\r使用pvc-pv-sc SC storage class:将存储卷划分为不同的种类 例如SSD 普通磁盘 本地磁盘 按需使用\n云服务商会提供\napiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-storage provisioner: kubernetes.io/no-provisioner volumeBindingMode: WaitForFirstConsumer Persistent Volume PV:描述数据卷的具体信息 , 例如磁盘大小 访问模式 文档 类型\napiVersion: v1 kind: PersistentVolume metadata: name: mysqldata spec: capacity: storage: 2Gi volumeMode: Filesystem #Filesystem(文件系统) Block(块) accessModes: - ReadWriteOnce #卷可以被一个节点以读写方式挂载 persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /root/data nodeAffinity: required: #通过hostname 限定在某个节点创建存储卷 nodeSelectorTerms: - matchExpressions: - key: node operator: In values: - worker02 PVC persistent volume claim:对存储需求的一个申明 可以理解为一个申请单 系统根据这个申请单去找一个合适的PV 还可以根据PVC自动创建PV\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: mysqldata spec: accessModes: [\u0026#34;ReadWriteOnce\u0026#34;] storageClassName: \u0026#34;local-storage\u0026#34; resources: requests: storage: 2Gi 为什么要这么多层的抽象 更好的分工 运维人员负责提供好存储 开发人员不需要关注磁盘细节 只需要写一个申请单 方便云服务商提供不同类型 配置细节不需要开发者关注 只需要写一个申请单 动态创建 开发人员写好申请单后 供应商可以根据需求自动创建所需存储卷 本地磁盘示例 sta的yaml 使用pvc来挂载\napiVersion: apps/v1 kind: StatefulSet metadata: name: my-mysql-statefulset spec: serviceName: my-mysql-service replicas: 3 selector: matchLabels: app: my-mysql template: metadata: labels: app: my-mysql spec: affinity: #节点的亲和性 好像是没有节点反亲和的 nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node #要求pod不允许运行在标签node=master的节点上 operator: NotIn values: - master #pod的反亲和性 podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \u0026#34;app\u0026#34; #要求pod不允许运行在已有pod标签为webapp的节点上 operator: In values: - \u0026#34;my-mysql\u0026#34; topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: my-mysql image: mysql:latest imagePullPolicy: IfNotPresent #IfNotPresent 仅本地没有镜像时才远程拉取 , Always永远都是远程拉取 , Never永远只是用本地镜像 本地没有则报错 args: - \u0026#34;--character-set-server=utf8\u0026#34; # 指定字符编码 - \u0026#34;--collation-server=utf8_general_ci\u0026#34; # 指定字符编码 env: - name: MYSQL_ROOT_PASSWORD # 指定root用户的用户名 value: \u0026#34;123456\u0026#34; - name: MYSQL_DATABASE # 新建的数据库 value: \u0026#34;datashare\u0026#34; volumeMounts: - name: mysql-data #与71行对应 mountPath: /var/lib/mysql #容器里面挂载的路径 volumes: #local-storage 要通过pvc 前提是先创建pvc - name: mysql-data persistentVolumeClaim: claimName: mysqldata --- apiVersion: v1 kind: Service metadata: name: my-mysql-service spec: selector: app: my-mysql type: ClusterIP clusterIP: None ports: - port: 3306 targetPort: 3306 pv指定在worker02上的root/data目录上\n所以先进入worker02标签的节点里创建目录\nimage-20220820160940067\r创建sc pv pvc\nimage-20220820160958134\r创建sts 完成绑定\nimage-20220820161631815\r查看worker02的root/data路径下是否有数据挂载\nimage-20220820161800247\r3.学习 secret、configmap 用法并应用； configMap和secret\n数据库连接地址 这种可能根据部署环境变化的 不应该写死在代码里\nkubernetes为我们提供了configmap 可以方便的配置一些变量\nconfigMap.yaml apiVersion: v1 kind: ConfigMap metadata: # name: mongo-config name: mysql-config data: # mongoAddress: mongodb-0.mongodb:27017 mysqlAddress: mysql-0.mysql:3306 运行截图 image-20220820163855550\rsecret文件 一些重要数据 例如密码 token 可以放到secret中\n注意:数据要base64编码\nyaml文件 apiVersion: v1 kind: Secret metadata: # name: mongo-secret name: mysql-secret # Opaque 用户定义的任意数据类型 更多类型介绍 https://kubernetes.io/zh/docs/concepts/configuration/secret/#secret-types type: Opaque data: #数据要base64 mysql-username: cm9vdA== #root mysql-password: MTIzNDU2 #123456 运行截图 image-20220820164742646\r作为环境变量使用 statefulset.yaml\napiVersion: apps/v1 kind: StatefulSet metadata: name: my-mysql-statefulset spec: serviceName: my-mysql-service replicas: 2 selector: matchLabels: app: my-mysql template: metadata: labels: app: my-mysql spec: affinity: #节点的亲和性 好像是没有节点反亲和的 nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node #要求pod不允许运行在标签node=master的节点上 operator: NotIn values: - master #pod的反亲和性 podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \u0026#34;app\u0026#34; #要求pod不允许运行在已有pod标签为webapp的节点上 operator: In values: - \u0026#34;my-mysql\u0026#34; topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: my-mysql image: mysql:latest imagePullPolicy: IfNotPresent #IfNotPresent 仅本地没有镜像时才远程拉取 , Always永远都是远程拉取 , Never永远只是用本地镜像 本地没有则报错 args: - \u0026#34;--character-set-server=utf8\u0026#34; # 指定字符编码 - \u0026#34;--collation-server=utf8_general_ci\u0026#34; # 指定字符编码 env: - name: MYSQL_USER valueFrom: secretKeyRef: name: mysql-secret key: mysql-username - name: MYSQL_ROOT_PASSWORD # 指定root用户的用户名 valueFrom: secretKeyRef: name: mysql-secret key: mysql-password - name: MYSQL_DATABASE # 新建的数据库 value: \u0026#34;datashare\u0026#34; volumeMounts: - name: mysql-data #与71行对应 mountPath: /var/lib/mysql #容器里面挂载的路径 volumes: #local-storage 要通过pvc 前提是先创建pvc - name: mysql-data persistentVolumeClaim: claimName: mysqldata --- apiVersion: v1 kind: Service metadata: name: my-mysql-service spec: selector: app: my-mysql type: ClusterIP clusterIP: None ports: - port: 3306 targetPort: 3306 运行截图 image-20220820171448686\rdeployment.yaml\napiVersion: apps/v1 kind: Deployment metadata: name: e-book-gin labels: app: e-book-gin #deployment的标签 version: v1.0.0 spec: replicas: 6 #副本数量 selector: #pod标签选择器，匹配pod标签，默认使用pods的标签 定义标签选择器,部署需要管理的pod（带有该标签的的会被管理）需在pod 模板中定义 matchLabels: app: webapp version: v1.0.0 strategy: type: RollingUpdate #将现有pod替换为新pod的部署策略 滚动更新 template: #pod的定义 metadata: labels: app: webapp #与12行对应 version: v1.0.0 spec: affinity: #节点的亲和性 好像是没有节点反亲和的 nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node #要求pod不允许运行在标签node=master的节点上 operator: NotIn values: - master #pod的反亲和性 podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \u0026#34;app\u0026#34; #要求pod不允许运行在已有pod标签为webapp的节点上 operator: In values: - \u0026#34;webapp\u0026#34; topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - image: ccr.ccs.tencentyun.com/hfut-ie/e-book-gin:v3.0 #容器的镜像地址 name: e-book-gin #容器的名字 ports: - containerPort: 7777 #对service暴露端口 name: http env: - name: MYSQL_USER valueFrom: secretKeyRef: name: mysql-secret key: mysql-username - name: MYSQL_ROOT_PASSWORD # 指定root用户的用户名 valueFrom: secretKeyRef: name: mysql-secret key: mysql-password - name: MYSQL_ADDRESS valueFrom: configMapKeyRef: name: mysql-config key: mysqlAddress 运行截图\nimage-20220820172051739\r通过echo判断是否成功注入到环境变量中了\nimage-20220820180741127\rmysql也成功注入到环境变量中了\nimage-20220820181521581\r存在哪些问题: 不太清楚为什么挂载卷的目录会引起冲突\nimage-20220820171332000\r打算接下来做什么: helm和命名空间 ingress kubectl常用指令 kubectl exec -it e-book-gin-69b4df6cd9-mfrxt sh\nbin/bash进入不了就用sh\nkubectl get configmap\nkubectl get configmap mysql-config -o yaml\nkubectl get pvc\n","date":"2022-08-20T15:20:00+08:00","permalink":"https://linjianshu.github.io/p/20220819%E5%AE%9E%E4%B9%A0%E8%BF%9B%E5%BA%A6%E6%B1%87%E6%8A%A5/","title":"20220819实习进度汇报"},{"content":"实习进度汇报 这几天在做什么: 掌握 statefulset、deployment 用法，实现2副本高可用并将两个pod调度至不同node（反亲和） client-go 实现demo（创建deployment编排之前的docker镜像并运行）； 这些事情的进度: 1.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\nhttps://github.com/linjianshu/e-book-Gin\nhttps://github.com/linjianshu/client-go\n2.学习statefulset和deployment 反亲和操作 反亲和 先给不同的工作节点打上了label\nkubectl label nodes minikube-m02 node=worker01\nkubectl label nodes minikube-m03 node=worker02\nkubectl label nodes minikube node=master\napiVersion: apps/v1 kind: Deployment metadata: name: e-book-gin labels: app: e-book-gin #deployment的标签 version: v1.0.0 spec: replicas: 6 #副本数量 selector: #pod标签选择器，匹配pod标签，默认使用pods的标签 定义标签选择器,部署需要管理的pod（带有该标签的的会被管理）需在pod 模板中定义 matchLabels: app: webapp version: v1.0.0 strategy: type: RollingUpdate #将现有pod替换为新pod的部署策略 滚动更新 template: #pod的定义 metadata: labels: app: webapp #与12行对应 version: v1.0.0 spec: affinity: #节点的亲和性 好像是没有节点反亲和的 nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node #要求pod不允许运行在标签node=master的节点上 operator: NotIn values: - master #pod的反亲和性 podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \u0026#34;app\u0026#34; #要求pod不允许运行在已有pod标签为webapp的节点上 operator: In values: - \u0026#34;webapp\u0026#34; topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - image: ccr.ccs.tencentyun.com/hfut-ie/e-book-gin:v3.0 #容器的镜像地址 name: e-book-gin #容器的名字 ports: - containerPort: 7777 #对service暴露端口 name: http 3.client-go 实现demo 1.尝试create deployment web应用\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; v1 \u0026#34;k8s.io/api/apps/v1\u0026#34; v12 \u0026#34;k8s.io/api/core/v1\u0026#34; metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/client-go/kubernetes\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; \u0026#34;k8s.io/client-go/util/homedir\u0026#34; \u0026#34;path\u0026#34; ) func main() { var kubeconfig *string if home := homedir.HomeDir(); home != \u0026#34;\u0026#34; { kubeconfig = flag.String(\u0026#34;kubeconfig\u0026#34;, path.Join(home, \u0026#34;.kube\u0026#34;, \u0026#34;config\u0026#34;), \u0026#34;\u0026#34;) } else { kubeconfig = flag.String(\u0026#34;kubeconfig\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;) } config, err := clientcmd.BuildConfigFromFlags(\u0026#34;\u0026#34;, *kubeconfig) if err != nil { panic(err.Error()) } clientset, err := kubernetes.NewForConfig(config) if err != nil { panic(err.Error()) } nodeAffinity := \u0026amp;v12.NodeAffinity{RequiredDuringSchedulingIgnoredDuringExecution: \u0026amp;v12.NodeSelector{NodeSelectorTerms: []v12.NodeSelectorTerm{{ MatchExpressions: []v12.NodeSelectorRequirement{{ Key: \u0026#34;node\u0026#34;, Operator: \u0026#34;NotIn\u0026#34;, Values: []string{\u0026#34;master\u0026#34;}, }}, MatchFields: []v12.NodeSelectorRequirement{}, }}}} podAntiAffinity := \u0026amp;v12.PodAntiAffinity{RequiredDuringSchedulingIgnoredDuringExecution: []v12.PodAffinityTerm{{ LabelSelector: \u0026amp;metav1.LabelSelector{MatchLabels: map[string]string{}, MatchExpressions: []metav1.LabelSelectorRequirement{{Key: \u0026#34;app\u0026#34;, Operator: metav1.LabelSelectorOpIn, Values: []string{\u0026#34;webapp\u0026#34;}}}}, Namespaces: nil, TopologyKey: \u0026#34;kubernetes.io/hostname\u0026#34;, NamespaceSelector: nil, }}} deployment := \u0026amp;v1.Deployment{ TypeMeta: metav1.TypeMeta{Kind: \u0026#34;Deployment\u0026#34;, APIVersion: \u0026#34;apps/v1\u0026#34;}, ObjectMeta: metav1.ObjectMeta{Name: \u0026#34;e-book-gin\u0026#34;, Labels: map[string]string{\u0026#34;app\u0026#34;: \u0026#34;e-book-gin\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;v1.0.0\u0026#34;}}, Spec: v1.DeploymentSpec{ Replicas: int32Ptr(6), Selector: \u0026amp;metav1.LabelSelector{MatchLabels: map[string]string{\u0026#34;app\u0026#34;: \u0026#34;webapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;v1.0.0\u0026#34;}}, Strategy: v1.DeploymentStrategy{Type: v1.RollingUpdateDeploymentStrategyType}, Template: v12.PodTemplateSpec{metav1.ObjectMeta{Labels: map[string]string{\u0026#34;app\u0026#34;: \u0026#34;webapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;v1.0.0\u0026#34;}}, v12.PodSpec{Affinity: \u0026amp;v12.Affinity{NodeAffinity: nodeAffinity, PodAntiAffinity: podAntiAffinity}, Containers: []v12.Container{{Image: \u0026#34;ccr.ccs.tencentyun.com/hfut-ie/e-book-gin:v3.0\u0026#34;, Name: \u0026#34;e-book-gin\u0026#34;, Ports: []v12.ContainerPort{{ContainerPort: 7777, Name: \u0026#34;http\u0026#34;}}}}}}, }, Status: v1.DeploymentStatus{}, } dep, err := clientset.AppsV1().Deployments(metav1.NamespaceDefault).Create(context.TODO(), deployment, metav1.CreateOptions{}) if err != nil { panic(err.Error()) } fmt.Println(dep.Status) } func int32Ptr(i int32) *int32 { return \u0026amp;i } 存在哪些问题: core dns问题 nslookup找不到headless service的ip 打算接下来做什么: 持久化 pvc pv sc secret + configmap kubectl常用指令 minikube添加工作节点\nminikube node add\n打标签\nkubectl label nodes minikube-m02 node=worker01\nkubectl label nodes minikube-m03 node=worker02\nkubectl label nodes minikube node=master\n查看statefulset\nkubectl get sts\n查看标签\nkubectl get nodes \u0026ndash;show-labels\n查看hostname\nfor i in 0 1 2; do kubectl exec redis-statefulset-$i \u0026ndash; sh -c \u0026lsquo;hostname\u0026rsquo;; done\nnslookup redis-statefulset-0\n检测dns是否正常\n查看kube-system命名空间的pod状态\nkubectl get pods -n kube-system -o wide\n查看dnscore有没有问题\nkubectl logs -f coredns-65c54cc984-9wxzc -n kube-system\nk8s一些常用的小细节_永远在路上啊的博客-CSDN博客\nloop (coredns.io)\n[CoreDNS Error：FATAL] plugin/loop: Loop_你好阳光的技术博客_51CTO博客\n[插件 循环] 不适用于系统解析的运行 ·第 2087 期 ·科伦斯/科伦斯 ·GitHub\n修改配置 kubectl -n kube-system edit configmap coredns 删除loop 相关资料\nhttps://www.it610.com/article/1304836244370395136.htm\nhttps://zhuanlan.zhihu.com/p/405150555 亲和与反亲和\nhttps://blog.csdn.net/qq_39578545/article/details/125011953 yaml文件释义\nhttps://blog.csdn.net/yujia_666/article/details/116532953 topologyKeyhttps://blog.csdn.net/a772304419/article/details/110943111 亲和与反亲和\nhttps://blog.csdn.net/zhuchance/article/details/117995309 client-go创建deployment\n","date":"2022-08-12T09:18:55+08:00","permalink":"https://linjianshu.github.io/p/20220812%E5%AE%9E%E4%B9%A0%E8%BF%9B%E5%BA%A6%E6%B1%87%E6%8A%A5/","title":"20220812实习进度汇报"},{"content":"实习进度汇报 这几天在做什么: hugo 更新实习日记至github主页上 git代码管理 上传demo方便导师检查 以deployment和service方式部署应用 client-go的学习 这些事情的进度: 1.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\nhttps://github.com/linjianshu/e-book-Gin\nhttps://github.com/linjianshu/client-go\n3.以deployment和service方式部署应用 运行截图\ndeployment.yaml文件 web应用\napiVersion: apps/v1 kind: Deployment metadata: name: e-book-gin labels: app: e-book-gin version: v1.0.0 spec: replicas: 2 selector: matchLabels: app: e-book-gin version: v1.0.0 strategy: type: RollingUpdate template: metadata: labels: app: e-book-gin version: v1.0.0 spec: containers: - image: ccr.ccs.tencentyun.com/hfut-ie/e-book-gin:v3.0 #镜像 name: e-book-gin ports: - containerPort: 7777 name: e-book-gin service.yaml文件 apiVersion: v1 kind: Service metadata: # 服务名字 name: test-service spec: selector: # 对应pod的标签 app: e-book-gin # 默认 ClusterIP 集群内可访问 NodePort节点可访问 LoadBalancer 负载均衡模式 (需要负载均衡器才可用) type: NodePort ports: - port: 8080 #本 service端口 targetPort: 7777 #容器端口 nodePort: 31000 #节点端口 范围固定 从30000-32767 运行截图 deployment\nimage-20220806104916704\rpod\nimage-20220806104857355\rservice\nimage-20220806104827062\rimage-20220806105306455\rNodePort类型 需要节点nodePort: 31000访问 进入节点 curl验证\nimage-20220806105510785\r5.client-go的学习 rest-client获取pods信息 image-20220809151945441\rclient-set获取pods信息 image-20220809152042518\rdynamic-client获取pods信息 image-20220809152118760\rdiscover-client发现GVR资源 image-20220809152231368\rwatch demo image-20220809162701324\r存在哪些问题: client-go可以从k8s宿主机之外访问吗 使用自己电脑尝试连接腾讯云显示网络无法访问 ping ip没ping通 是需要额外做一些操作让网络先联通起来吗? image-20220809152608948\r打算接下来做什么: 掌握 statefulset、deployment 用法，实现2副本高可用并将两个pod调度至不同node（反亲和）； 学习 secret、configmap 用法并应用； client-go 实现demo（创建deployment编排之前的docker镜像并运行）； kubectl常用指令 kubectl get node\nkubectl run testapp \u0026ndash;image=ccr.ccs.tencentyun.com/hfut/e-book-gin:v1.0\nkubectl apply -f ./mysql.yaml\nkubectl get pod\nkubectl get deployment\nkubectl get pod -o wide\nkubectl describe pod [testapp]\nkubectl logs testapp \u0026ndash;previous\nkubectl delete pod my-mysql-6b8cf957fc-2sl59\nkubectl delete deploy/my-mysql\n伸缩副本 kubectl scale deployment test-k8s \u0026ndash;replicas=2\n查看历史版本 kubectl rollout history deployment [deployment]\n回到上个版本 kubectl rollout undo deployment [deployment]\n回退指定版本 kubectl rollout undo deployment test-k8s \u0026ndash;to-revision=2 删除部署 kubectl delete deployment test-k8s\n查看所有信息 kubectl get all\n重新部署 kubectl rullout restart deployment test-k8s\n命令修改镜像\nkubectl set image deployment test-k8s test-k8s=ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v2-with-error \u0026ndash;record\n暂停运行 去做想做的事情 比如修改其他的pod之类的 kubectl rollout pause deployment my-mysql\n恢复 kubectl rollout resume deployment my-mysql\n输出到文件 kubectl get deployment my-mysql -o yaml \u0026raquo; toyaml.yaml\nkubectl delete all \u0026ndash;all\nkubectl get service\nkubectl get svc\nkubectl api-versions\nkubectl api-resources\n","date":"2022-08-06T10:41:29+08:00","permalink":"https://linjianshu.github.io/p/20220806%E5%AE%9E%E4%B9%A0%E8%BF%9B%E5%BA%A6%E6%B1%87%E6%8A%A5/","title":"20220806实习进度汇报"},{"content":"实习进度汇报 这几天在做什么: hugo 更新实习日记至github主页上 git代码管理 上传demo方便导师检查 docker 数据卷挂载 部署有状态应用 容器通信 编译镜像推送至华为云镜像仓库 搭建minikube环境 k8s 以pod方式部署 mysql+web应用 这些事情的进度: 1.对demo编写dockerfile镜像编译 2.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\nhttps://github.com/linjianshu/e-bookNew/tree/master\n3.docker 数据卷挂载 部署有状态应用 容器通信 Dockerfile FROM golang:alpine AS builder LABEL stage=gobuilder ENV GO111MODULE=on \\ CGO_ENABLE=0 \\ GOOS=linux \\ GOARCH=amd64 \\ GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; ENV LANG C.UTF-8 RUN apk update --no-cache \u0026amp;\u0026amp; apk add --no-cache tzdata RUN #apt-get install -y mysql-server WORKDIR /build COPY . . EXPOSE 7777 RUN go build -ldflags=\u0026#34;-s -w\u0026#34; -o /app/main FROM alpine EXPOSE 3306 RUN apk update --no-cache \u0026amp;\u0026amp; apk add --no-cache ca-certificates COPY --from=builder /usr/share/zoneinfo/Asia/Shanghai /usr/share/zoneinfo/Asia/Shanghai ENV TZ Asia/Shanghai ENV LANG C.UTF-8 WORKDIR /app #COPY --from=builder /build/. /app/. COPY . /app/. COPY --from=builder /app/main /app/main EXPOSE 7777 CMD [\u0026#34;./main\u0026#34;] 挂载mysql 开放3310 默认密码123456 提高权限 后台运行 设定时区 docker run --privileged -d --name mysql84 -v /etc/mysql:/etc/mysql -v /var/lib/data/mysql:/var/lib/mysql -v /var/lib/mysql-files:/var/lib/mysql-files -p 3310:3306 -e TZ=Asia/Shanghai -e MYSQL_ROOT_PASSWORD=123456 mysql 问题解决方案: https://docs.docker.com/desktop/networking/\n我想从容器连接到主机上的服务 主机有一个不断变化的 IP 地址（如果您没有网络访问权限，则没有）。我们建议您连接到 host.docker.internal解析为主机使用的内部 IP 地址的特殊 DNS 名称。这是出于开发目的，不适用于 Docker Desktop 之外的生产环境。 您也可以使用gateway.docker.internal. 如果您的机器上安装了 Python，请使用以下说明作为示例，从容器连接到主机上的服务： 运行以下命令在端口 8000 上启动一个简单的 HTTP 服务器。 python -m http.server 8000 如果您已安装 Python 2.x，请运行python -m SimpleHTTPServer 8000. 现在，运行一个容器，安装curl，并尝试使用以下命令连接到主机： docker run --rm -it alpine sh apk add curl curl http://host.docker.internal:8000 exit 部署到华为云 供外网访问 http://124.220.207.169:7777/blog 来人 把书掏出来\n运行截图 image-20220802095017747\rimage-20220802095335957\r4.搭建minikube环境 又租了一台RAM\u0026gt;2GB的华为云服务器 搭建minikube\nminikube start --kubernetes-version=v1.23.3 --registry-mirror=https://bmtb46e4.mirror.aliyuncs.com --vm-driver=docker --base-image=\u0026#34;anjone/kicbase\u0026#34; --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers 运行截图 image-20220802095616280\r5.k8s 以pod方式部署 mysql+web应用 image-20220802095657532\rPod.yaml文件 web应用 apiVersion: v1 kind: Pod metadata: name: test-pod labels: name: test-pod spec: #定义容器 可以多个 containers: - name: test-pod #容器名字 image: ccr.ccs.tencentyun.com/hfut-ie/e-book-gin:v3.0 #镜像 ports: - containerPort: 7777 name: test-pod hostPort: 7777 # dnsPolicy: ClusterFirst # hostNetwork: true mysql.yaml文件 mysql3310 apiVersion: apps/v1 kind: Deployment metadata: name: my-mysql labels: app: my-mysql version: v1.0.0 spec: selector: matchLabels: app: my-mysql version: v1.0.0 strategy: type: RollingUpdate template: metadata: labels: app: my-mysql version: v1.0.0 spec: containers: - image: mysql:latest name: my-mysql args: # - \u0026#34;--ignore-db-dir=lost+found\u0026#34; - \u0026#34;--character-set-server=utf8\u0026#34; # 指定字符编码 - \u0026#34;--collation-server=utf8_general_ci\u0026#34; # 指定字符编码 env: - name: MYSQL_ROOT_PASSWORD # 指定root用户的用户名 value: \u0026#34;123456\u0026#34; # - name: MYSQL_PASSWORD # 新建用户的用户名 # value: \u0026#34;123456\u0026#34; # - name: MYSQL_USER # 新建的用户 # value: \u0026#34;ljs\u0026#34; - name: MYSQL_DATABASE # 新建的数据库 value: \u0026#34;datashare\u0026#34; ports: - containerPort: 3310 name: mysql volumeMounts: - name: data mountPath: /var/lib/mysql - name: config mountPath: /etc/mysql/mysql.conf.d/mysqld.cnf subPath: mysqld.cnf readOnly: False volumes: - name: data # persistentVolumeClaim: # claimName: mysql-pvc - name: config # configMap: # name: mysql-configmap 数据库连接字符串 尝试了好多次 最后使用ip地址:3306 连接宿主机本地数据库 image-20220802095955401\r运行截图 port-forward\nimage-20220802100528339\rcurl验证\nimage-20220802100555894\r存在哪些问题: pod理解还有点问题 请问pod内有一组容器 A B 容器A和B本身是一个docker文件系统吗? 那Pod也是一个docker文件系统嘛 是属于docker文件系统里套了两个docker文件系统吗? 使用kubectl port-forward 7777:7777如何后台跑 好像需要一直开着 使用kubectl port-forward 7777:7777 为什么不能通过公网ip:7777/index访问 只能通过本机localhost:7777/index跑 原来打算把pod里放了两个容器 一个是mysql端口3310 一个是web应用端口是7777 所以打算使用的数据库连接字符串是localhost 我认为pod之间应该是能够通信的 但是实际上解析不出来 我不太清楚是为啥 (是因为web应用程序解析localhost的时候 会认为是宿主机的localhost吗? 如果认为是pod的localhost的话 应该是能连的通的才对) image-20220802092832969\r上午实验的时候发现 如果pod里两个容器都是mysql 一个是3310 一个是3311的话 是可以通过 mysql -u root -P 3311 -h localhost -p123456来相互访问的 理论上 是要通过pod的IP来作为host 才能通才对 数据库容器和web应用容器通过一台宿主机连接 生产环境中是这么用的嘛 如果宿主机都不一致的话(web应用在A服务器上 mysql应用在B服务器上)应该怎么使用呢 是修改web应用中的数据库连接字符串吗 dockerfile是不是有点问题 目前dockerfile的逻辑是先build之后然后运行 但如果数据库连接不成功的话容器就启动不起来 也无法进入容器修改连接字符串重启容器 不知道应该怎么处理 打算接下来做什么: k8s学习 以service方式部署mysql+web应用 修改service的yaml 尝试数据挂载 client-go学习 过程记录(踩坑): docker run \u0026ndash;privileged -d \u0026ndash;name mysql84 -v /etc/mysql:/etc/mysql -v /var/lib/data/mysql:/var/lib/mysql -v /var/lib/mysql-files:/var/lib/mysql-files -p 3310:3306 -e TZ=Asia/Shanghai -e MYSQL_ROOT_PASSWORD=123456 mysql\nubuntu重装mysql 1、删除 mysql\nsudo apt-get autoremove \u0026ndash;purge mysql-server-5.0\nsudo apt-get remove mysql-server\nsudo apt-get autoremove mysql-server\nsudo apt-get remove mysql-common (非常重要)\n上面的其实有一些是多余的，建议还是按照顺序执行一遍\n清理残留数据\ndpkg -l |grep ^rc|awk \u0026lsquo;{print $2}\u0026rsquo; |sudo xargs dpkg -P\n2、安装 mysql\nsudo apt-get install mysql-server\n记得启动服务 设置密码\ndocker连接宿主机 https://docs.docker.com/desktop/networking/ 我想从容器连接到主机上的服务 主机有一个不断变化的 IP 地址（如果您没有网络访问权限，则没有）。我们建议您连接到 host.docker.internal解析为主机使用的内部 IP 地址的特殊 DNS 名称。这是出于开发目的，不适用于 Docker Desktop 之外的生产环境。\n您也可以使用gateway.docker.internal.\n如果您的机器上安装了 Python，请使用以下说明作为示例，从容器连接到主机上的服务：\n运行以下命令在端口 8000 上启动一个简单的 HTTP 服务器。\npython -m http.server 8000\n如果您已安装 Python 2.x，请运行python -m SimpleHTTPServer 8000.\n现在，运行一个容器，安装curl，并尝试使用以下命令连接到主机：\ndocker run \u0026ndash;rm -it alpine sh apk add curl curl http://host.docker.internal:8000 exit\nminikube版本和镜像问题 minikube start \u0026ndash;kubernetes-version=v1.23.3 \u0026ndash;base-image=\u0026ldquo;kicbase/stable:v0.0.32\u0026rdquo;\nminikube start \u0026ndash;kubernetes-version=v1.23.3 \u0026ndash;registry-mirror=https://bmtb46e4.mirror.aliyuncs.com \u0026ndash;vm-driver=docker \u0026ndash;base-image=\u0026ldquo;anjone/kicbase\u0026rdquo; \u0026ndash;image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers\nkubectl常用指令 kubectl get node\nkubectl run testapp \u0026ndash;image=ccr.ccs.tencentyun.com/hfut/e-book-gin:v1.0\nkubectl apply -f ./mysql.yaml\nkubectl get pod\nkubectl get deployment\nkubectl get pod -o wide\nkubectl describe pod [testapp]\nkubectl logs testapp \u0026ndash;previous\nkubectl delete pod my-mysql-6b8cf957fc-2sl59\nkubectl delete deploy/my-mysql\nssh突然连接不上问题 不要对etc/ssh目录盲目扩大权限 chmod 600 /etc/ssh/*key 使用ssh -t 查看问题 lsof -i:22 确定是否开着\ncentos8 重装mysql问题 1、卸载 之前是用yum安装的，现在通过yum去卸载yum remove -y mysql find / -name mysql 找到残留的文件，再通过rm -rf去删除对应的文件\n注意将所有有关的文件全部删除，不然会有问题！\n2、安装 yum update yum install mysql-server\nps -ef | grep mysql\nsystemctl start mysqld\nsystemctl enable mysqld\nsystemctl status mysqld\n3、修改root用户密码 修改root用户的密码。\nalter user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost\u0026rsquo; identified by \u0026lsquo;password\u0026rsquo;\n刷新权限\nflush privileges\n","date":"2022-08-02T09:16:05+08:00","permalink":"https://linjianshu.github.io/p/20220802%E5%AE%9E%E4%B9%A0%E8%BF%9B%E5%BA%A6%E6%B1%87%E6%8A%A5/","title":"20220802实习进度汇报"},{"content":"实习进度汇报 这几天在做什么: hugo 更新实习日记至github主页上 git代码管理 上传demo方便导师检查 docker复习 编译镜像推送至阿里云镜像仓库 k8s学习 (之前都没有接触过 学习的进度很慢) 尝试搭建minikube环境/云服务器搭建kubernetes集群/裸机搭建 三种方式 这些事情的进度: 1.对demo编写dockerfile镜像编译 2.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\nhttps://github.com/linjianshu/e-bookNew/tree/master\n3.编译镜像推送至阿里云镜像仓库 仓库地址(私有) https://cr.console.aliyun.com/repository/cn-hangzhou/hfutie/e-book/details\nimage-20220729153325022\rdocker登录阿里云账户 pull images到Ecs docker内运行 image-20220729153819033\r运行截图(乱码的问题暂时还没有解决) image-20220729153856705\r4.k8s学习 完全没有接触过 还在看学习资料ing😥\n5.尝试搭建本机wsl minikube环境/云服务器搭建kubernetes集群/裸机搭建 三种方式 还在搭建ing\n存在哪些问题: 编译镜像推送至docker hub 没推送上去 推到一半就卡住了(换成了推送至阿里云) k8s集群搭建问题(还在百度中) 打算接下来做什么: 容器技术学习 搭建k8s k8s学习 go web开发 (有时间进行修缮 功能:上传文件删除 文章审核等功能) docker利用dockerfile写数据卷挂载 把有数据库依赖的demo镜像编译 尝试缩小镜像大小 ","date":"2022-07-29T14:54:20+08:00","permalink":"https://linjianshu.github.io/p/20220729%E5%AE%9E%E4%B9%A0%E8%BF%9B%E5%BA%A6%E6%B1%87%E6%8A%A5/","title":"20220729实习进度汇报"},{"content":"Kubernetes学习文档 特性 灰度更新 不影响业务正常运转 高可用 不宕机 自动灾难恢复 一键回滚到历史版本 方便的伸缩扩展(应用伸缩,机器加减) 提供负载均衡 有一个完善的生态 不同的应用部署方案 image-20220728092456835\r传统部署方式: 应用直接在物理机上部署 机器资源分配不好控制 出现bug时 可能机器的大部分资源被某个应用占用 导致其他应用无法正常运行 无法做到应用隔离 虚拟机部署 在单个物理机上运行多个虚拟机 每个虚拟机都是完整独立的系统 性能损耗大 容器部署 所有容器共享主机的系统 轻量级的虚拟机 性能损耗小 资源隔离 CPU和内存可按需分配 什么时候需要Kubernetes 当应用只是跑在一台机器 直接一个docker+ docker-compose 就够了 方便轻松 当应用需要跑在3 4 台机器 依旧可以每台机器单独配置运行环境 + 负载均衡器 当应用访问数不断增加 机器逐渐增加到上百台 上千台 每次加机器 软件更新 版本回滚 就会变得非常麻烦 这时候就需要kubernetes 轻松管理百万千万机器的集群 kubernetes 可以为你提供集中式的管理集群机器的应用 加机器 版本升级 版本回滚都是一个命令就搞定的事情 不停机的灰度更新 确保高可用 高性能 搞扩展 kubernetes集群架构 master\n主节点 控制平台 不需要很高的性能 不跑任务 通常一个就行了 也可以开多个主节点来提高集群的可用度 worker\n工作节点 可以是虚拟机或物理计算机 任务都在这里跑 机器性能都需要好点 通常有很多个 可以不断加机器扩大集群 每个工作节点由主节点管理 重要概念pod\n豆荚 k8s调度 管理的最小单位 一个pod可以包含一个或多个容器 每个pod都有自己的虚拟IP 一个工作节点可以有多个pod 主节点会考量负载自动调度pod到哪个节点运行 image-20220728093657693\rkubernetes组件 kube-apiserver API服务器 公开了kubernetes API etcd 键值数据库 可以作为保存 kubernetes所有集群数据的后台数据库 kube-scheduler 调度pod到哪个节点运行 kube-controller 集群控制器 cloud-controller 与云服务商交互 image-20220728093942078\r安装kubernetes\nminikube安装 minikube start | minikube (k8s.io)\n安装\n环境变量配置\n启动集群\nminikube start 查看节点\nkubectl get node docker run \u0026ndash;privileged -d \u0026ndash;name mysql84 -v /etc/mysql:/etc/mysql -v /var/lib/data/mysql:/var/lib/mysql -v /var/lib/mysql-files:/var/lib/mysql-files -p 3310:3306 -e TZ=Asia/Shanghai -e MYSQL_ROOT_PASSWORD=123456 mysql\nubuntu重装mysql 1、删除 mysql\n1 sudo apt-get autoremove \u0026ndash;purge mysql-server-5.0\n2 sudo apt-get remove mysql-server\n3 sudo apt-get autoremove mysql-server\n4 sudo apt-get remove mysql-common (非常重要)\n上面的其实有一些是多余的，建议还是按照顺序执行一遍\n清理残留数据\ndpkg -l |grep ^rc|awk \u0026lsquo;{print $2}\u0026rsquo; |sudo xargs dpkg -P\n2、安装 mysql\n1 sudo apt-get install mysql-server\n记得启动服务 设置密码\nhttps://docs.docker.com/desktop/networking/ 我想从容器连接到主机上的服务 主机有一个不断变化的 IP 地址（如果您没有网络访问权限，则没有）。我们建议您连接到 host.docker.internal解析为主机使用的内部 IP 地址的特殊 DNS 名称。这是出于开发目的，不适用于 Docker Desktop 之外的生产环境。\n您也可以使用gateway.docker.internal.\n如果您的机器上安装了 Python，请使用以下说明作为示例，从容器连接到主机上的服务：\n运行以下命令在端口 8000 上启动一个简单的 HTTP 服务器。\npython -m http.server 8000\n如果您已安装 Python 2.x，请运行python -m SimpleHTTPServer 8000.\n现在，运行一个容器，安装curl，并尝试使用以下命令连接到主机：\ndocker run \u0026ndash;rm -it alpine sh apk add curl curl http://host.docker.internal:8000 exit\nminikube start \u0026ndash;kubernetes-version=v1.23.3 \u0026ndash;base-image=\u0026ldquo;kicbase/stable:v0.0.32\u0026rdquo;\nminikube start \u0026ndash;kubernetes-version=v1.23.3 \u0026ndash;registry-mirror=https://bmtb46e4.mirror.aliyuncs.com \u0026ndash;vm-driver=docker \u0026ndash;base-image=\u0026ldquo;anjone/kicbase\u0026rdquo; \u0026ndash;image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers\nkubectl get node\nkubectl run testapp \u0026ndash;image=ccr.ccs.tencentyun.com/hfut/e-book-gin:v1.0\nkubectl apply -f ./mysql.yaml\nkubectl get pod\nkubectl get deployment\nkubectl get pod -o wide\nkubectl describe pod [testapp]\nkubectl logs testapp \u0026ndash;previous\nkubectl delete pod my-mysql-6b8cf957fc-2sl59\nkubectl delete deploy/my-mysql\n不要对etc/ssh目录盲目扩大权限 chmod 600 /etc/ssh/*key 使用ssh -t 查看问题 lsof -i:22 确定是否开着\n1、卸载 之前是用yum安装的，现在通过yum去卸载yum remove -y mysql find / -name mysql 找到残留的文件，再通过rm -rf去删除对应的文件\n注意将所有有关的文件全部删除，不然会有问题！\n2、安装 yum update yum install mysql-server\nps -ef | grep mysql\nsystemctl start mysqld\nsystemctl enable mysqld\nsystemctl status mysqld\n3、修改root用户密码 修改root用户的密码。\nalter user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost\u0026rsquo; identified by \u0026lsquo;password\u0026rsquo;\n刷新权限\nflush privileges\n灰度更新\n先启动 启动成功再把之前的销毁\n伸缩副本 kubectl scale deployment test-k8s --replicas=2 查看历史版本 kubectl rollout history deployment [deployment] 回到上个版本 kubectl rollout undo deployment [deployment] 回退指定版本 kubectl rollout undo deployment test-k8s --to-revision=2 删除部署 kubectl delete deployment test-k8s 查看所有信息 kubectl get all 重新部署 kubectl rullout restart deployment test-k8s # 命令修改镜像，--record 表示把这个命令记录到操作历史中 kubectl set image deployment test-k8s test-k8s=ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v2-with-error --record 暂停运行 去做想做的事情 比如修改其他的pod之类的 kubectl rollout pause deployment my-mysql 恢复 kubectl rollout resume deployment my-mysql 输出到文件 kubectl get deployment my-mysql -o yaml \u0026gt;\u0026gt; toyaml.yaml kubectl delete all --all 可以将pod指定到某个节点进行运行 在yaml里指定 工作负载分类 deployment 适合无状态应用 所有POD等价 可以替代 statefulset 有状态的应用 适合数据库这种类型 daemonset 在每个节点上跑一个pod 可以用来做节点监控 节点日志收集等等 job \u0026amp; cronjob job用来表达一次性的任务 而cronjob会根据其时间规划反复运行 现存问题 每次只能访问一个pod 没有负载均衡自动转发到不同pod 访问还需要端口转发 pod重建之后ip变了 名字也变了 service 特性\nservice通过label关联对应的pod service生命周期不跟pod绑定 不会因为pod重新建立而改变IP 提供了负载均衡功能 自动转发流量到不同的pod 可对集群外部提供访问端口 集群内部可通过服务名字访问 image-20220806093538047\rservice.yaml\napiVersion: v1 kind: Service metadata: name: test-service spec: selector: app: test-pod # 默认 ClusterIP 集群内可访问 NodePort节点可访问 LoadBalancer 负载均衡模式 (需要负载均衡器才可用) type: NodePort ports: - port: 8080 #本 service端口 targetPort: 7777 #容器端口 nodePort: 31000 #节点端口 范围固定 从30000-32767 kubectl get service kubectl get svc type 可以有三种\nloadbalancer需要云服务提供商的支持 逻辑可以安装metallb测试 会额外生成一个IP对外提供服务\nnodeport需要进入节点访问 所以通过docker进入minikube 访问31000才能get到\nclusterIP 默认的 仅在集群内可用\nheadless 适合数据库 clusterip设置为none就变成headless 就不会分配ip 后续讲解具体用法\n","date":"2022-07-28T09:20:43+08:00","permalink":"https://linjianshu.github.io/p/kubernetes%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"Kubernetes学习文档"},{"content":"数字规律题 标序列号 把变量和序列号放在一起比较看看 公因式法 找出最小公因式 看看有无规律 对每一位数减去第一位数 替换掉第2\u0026hellip;.位 结合上面的看看有无规律 对每一位数同时加上/乘以/除以第一位数 结合上面看看有无规律 同时除以1/2/3 加法和减法可能性稍大 能否分成奇数和偶数数组 看增幅 是否有规律 +1 +2 +4 +8 等比或者等差 前两个和/积是后一个 类斐波那契数列 前一个数是后一个数的比例关系 图形推理题 是否间隔排列或者对称排列 寻找共同特征 顺时针/逆时针 变化 白*黑=白 重合的题目 对称与不对称 轴对称与中心对称 切割三角形 相交相切 一全一半 叠加 求同存异 相对位置 内部还是外部 ","date":"2022-07-23T11:52:38+08:00","permalink":"https://linjianshu.github.io/p/%E8%A1%8C%E4%B8%BA%E8%AE%A4%E7%9F%A5%E6%B5%8B%E8%AF%84%E6%8A%80%E5%B7%A7/","title":"行为认知测评技巧"},{"content":"实习进度汇报 这几天在做什么: hugo 更新实习日记至github主页上 git代码管理 上传demo方便导师检查 docker学习 对demo编写dockerfile镜像编译 编译镜像推送至docker hub k8s学习 (之前都没有接触过 学习的进度很慢) 这些事情的进度: 1.对demo编写dockerfile镜像编译 2.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\n3.对项目代码进行简单的git版本管理 增加dockerfile\nhttps://github.com/linjianshu/e-bookNew/tree/master\n4.编译镜像推送至docker hub https://hub.docker.com/repositories\n5.k8s学习 完全没有接触过 还在看学习资料ing😥\n存在哪些问题: 目前是自己安排任务给自己做 是已经学过的知识 但不知道有哪些知识企业用到的偏多 希望导师给一点意见 指定一下复习的重点或者提供方向 我可以自学新知识 镜像构建之后好大 尝试过降低但是无果 image-20220722012320673\rdocker build要好久 请问老师有缩短时间的方案吗 image-20220722012642439\r系统中文乱码 暂时还不知道怎么改成中文(通过dockerfile) image-20220722012530906\rimage-20220722012552117\r打算接下来做什么: 容器技术学习 mysql复习 听导师的安排继续学习 搭建k8s go web开发 (有时间进行修缮 功能:上传文件删除 文章审核等功能) docker利用dockerfile写数据卷挂载 把有数据库依赖的demo镜像编译 尝试缩小镜像大小 阿里云服务器运行镜像 ","date":"2022-07-22T01:13:49+08:00","permalink":"https://linjianshu.github.io/p/20220722%E5%AE%9E%E4%B9%A0%E8%BF%9B%E5%BA%A6%E6%B1%87%E6%8A%A5/","title":"20220722实习进度汇报"},{"content":"实习进度汇报 这几天在做什么: go web开发 (使用gorm框架增加论坛模块 用户登录权限模块) hugo 更新实习日记至github主页上 git代码管理 上传demo方便导师检查 linux中mysql重装(由于之前mysql被黑了) docker学习 之前老师的代码指点 已经做了修缮 不知道可不可行 已经列在main函数的TODO中了 这些事情的进度: 1.go web开发(使用gin框架 了解常用api) 了解了gorm框架常用知识点 CRUD 高级特性还没有了解 使用gorm操纵mysql数据库 部署至阿里云 供公网访问 (http://118.178.236.128:7777/index) 目前文件删除 博客删除和审核还没做 部分存在bug image-20220721015655812\r2.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\n3.对项目代码进行简单的git版本管理 https://github.com/linjianshu/e-book-Gin\n4.linux中mysql重装(由于之前mysql被黑了) 5.代码指点已做了修缮 不知道可不可行 存在哪些问题: 目前是自己安排任务给自己做 是已经学过的知识 但不知道有哪些知识企业用到的偏多 希望导师给一点意见 指定一下复习的重点或者提供方向 我可以自学新知识 部分存在bug 需要再进行完善 没有掌握web测试的技能 Db.Model(\u0026amp;Session{}).Where(\u0026ldquo;user_id = ?\u0026quot;,user.Id) 底层的sql语句会不会select * 呀? 框架会不会自动优化? 测试用的很别扭 还是得看数据库有没有数据多了或者少了 test的时候 有时候会对数据库进行新增删除和修改 是否需要掌握测试的东西 ? 比如桩代码和mono模拟测试之类的技能 ? 企业后端的岗位需要用到测试嘛? log那一块没有使用别人的库 自己写了一个是不是已经弄巧成拙了 麻烦老师指点一下 后续我改成别人的库优化一下 打算接下来做什么: 容器技术学习 mysql复习 听导师的安排继续学习 搭建k8s ","date":"2022-07-21T01:50:14+08:00","permalink":"https://linjianshu.github.io/p/20220720%E5%AE%9E%E4%B9%A0%E5%B7%A5%E4%BD%9C%E8%BF%9B%E5%BA%A6%E6%B1%87%E6%8A%A5/","title":"20220720实习工作进度汇报"},{"content":" 算法\n树 平衡二叉树 镜像二叉树 最低公共祖先 前序后续便利构造二叉树 节点和等于整数的路径 两个节点的最长距离 二叉查找树 链表 奇升偶降 如何有序 数组 二维数组旋转90° 2sum问题 位运算 动态规划 背包问题 0-1 背包问题 完全 排序 复杂度 冒泡 插入 归并 快排 希尔 堆排序 基数排序 桶排序 如何求中位数 大根堆与小根堆 优先队列 单调栈 单调队列 接雨水 最大矩形 滑动窗口 二分 DFS BFS 递归 回溯 LRU 辅助栈 并查集 堆栈\n内存中的堆、栈、静态区 ","date":"2022-07-18T16:34:40+08:00","permalink":"https://linjianshu.github.io/p/%E9%9D%A2%E8%AF%95%E8%96%84%E5%BC%B1%E5%A4%8D%E4%B9%A0/","title":"面试薄弱复习"},{"content":"实习进度汇报 这几天在做什么: go web开发 (使用gin框架重构上次的web程序) hugo 更新实习日记至github主页上 git代码管理 上传demo方便导师检查 linux更新了gosdk至1.18 这些事情的进度: 1.go web开发(使用gin框架 了解常用api) 了解了gin框架常用知识点 使用gin框架重构上次的demo 部署至阿里云 供公网访问 (http://118.178.236.128:7777/index) 目前仅完成查找和上传 删除还没做 1658112111377\r2.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\n3.对项目代码进行简单的git版本管理 https://github.com/linjianshu/e-book-Gin\n4.linux更新了go-sdk至1.18 gostudy网站中下载linux-amd64压缩包=\u0026gt;ecs中解压=\u0026gt;删除原先1.13的文件夹=\u0026gt;把解压的内容丢进去=\u0026gt;更新/etc/profile=\u0026gt;刷新profile source /etc/profile=\u0026gt;验证 go version\n不知道有没有简单的做法\n1658110937384\r存在哪些问题: 目前是自己安排任务给自己做 是已经学过的知识 但不知道有哪些知识企业用到的偏多 希望导师给一点意见 指定一下复习的重点或者提供方向 我可以自学新知识 gin框架通常配合前端什么技术呀?还是说直接使用gotemplate嘛? 下载功能可以实现 但是看日志发现调用了三次 最后一次才完成传输 前面两次是broken pipe 请问这个是什么原因呀? 1658109545148\r打算接下来做什么: 容器技术学习 mysql学习 听导师的安排继续学习 使用gorm和go操纵数据库 (浏览之前项目代码尝试手动构建被黑数据库表结构 尝试使用gorm重构sql 使用gin重构http调用) ","date":"2022-07-18T15:10:39+08:00","permalink":"https://linjianshu.github.io/p/%E5%AE%9E%E4%B9%A0%E5%B0%8F%E7%BB%9320220718/","title":"实习小结20220718"},{"content":" 实习进度汇报 这几天在做什么: go web开发 (使用gin框架重构上次的web程序) hugo 更新实习日记至github主页上 git代码管理 上传demo方便导师检查 linux更新了gosdk至1.18 这些事情的进度: 1.go web开发(使用gin框架 了解常用api) 了解了gin框架常用知识点 使用gin框架重构上次的demo 部署至阿里云 供公网访问 (http://118.178.236.128:7777/index) 目前仅完成查找和上传 删除还没做 1658112111377\r2.使用hugo更新实习日记至github主页 github主页 (linjianshu.github.io)\n3.对项目代码进行简单的git版本管理 https://github.com/linjianshu/e-book-Gin\n4.linux更新了go-sdk至1.18 gostudy网站中下载linux-amd64压缩包=\u0026gt;ecs中解压=\u0026gt;删除原先1.13的文件夹=\u0026gt;把解压的内容丢进去=\u0026gt;更新/etc/profile=\u0026gt;刷新profile source /etc/profile=\u0026gt;验证 go version\n不知道有没有简单的做法\n1658110937384\r存在哪些问题: 目前是自己安排任务给自己做 是已经学过的知识 但不知道有哪些知识企业用到的偏多 希望导师给一点意见 指定一下复习的重点或者提供方向 我可以自学新知识 gin框架通常配合前端什么技术呀?还是说直接使用gotemplate嘛? 下载功能可以实现 但是看日志发现调用了三次 最后一次才完成传输 前面两次是broken pipe 请问这个是什么原因呀? 1658109545148\r打算接下来做什么: 容器技术学习 mysql学习 听导师的安排继续学习 使用gorm和go操纵数据库 (浏览之前项目代码尝试手动构建被黑数据库表结构 尝试使用gorm重构sql 使用gin重构http调用) ","date":"2022-07-17T23:48:18+08:00","permalink":"https://linjianshu.github.io/p/%E5%AE%9E%E4%B9%A0%E5%B0%8F%E7%BB%9320220718/","title":"实习小结20220718"},{"content":"实习进度汇报 这几天在做什么: 环境搭建 restful api开发 go web开发 (原生api) hugo 更新实习日记至github主页上 git代码管理 上传demo方便导师检查 这些事情的进度: 1.环境搭建 windows端 安装了Go sdk和 GoLand IDE 配置好了环境变量 安装了docker 还未开始使用 1657867093520\rWSL-Linux端 ubuntu 安装了Go sdk 1657867136423\r阿里云ECS-Linux ubuntu 安装了Go sdk 1657867231001\r2.restful api开发 (在3中) 3.go web开发 复习了go web知识 简单编写go 文件服务器 部署至阿里云 供公网访问 (http://118.178.236.128:9876/index) 目前仅完成查找和上传 删除还没做 1657868172601\r4.对项目代码进行简单的git版本管理 https://github.com/linjianshu/e-bookNew\n存在哪些问题: 目前是自己安排任务给自己做 是已经学过的知识 但不知道有哪些知识企业用到的偏多 希望导师给一点意见 指定一下复习的重点或者提供方向 我可以自学新知识 GoLand进行goweb开发的时候 调试的时候打开html文件总会在src下打开 往往是page no found(因为文件在项目文件夹的根目录下而不是在src的根目录下 通常我的解决方案是1.直接go build然后打开生成的exe 但是这样做不了调试2.把项目的html拷贝到src的根目录下 这是IDE中的设置问题吗还是? vscode好像就可以直接编译运行出界面) 写的时候很潦草 导师能否给一些指导方案 或者优化方案或者编码规范 错误处理很难看 不知道应该怎么一层一层往上处理 经常性需要对err进行判断 对web应用的功能能否提一些简单的功能或者修改或者UI上的建议 我可以进一步慢慢完善 之前做的论坛web和其他的应用程序 底层依赖的云服务器mysql数据库给人黑了 导师知道怎么进行恢复嘛? 以后应该怎么防止被黑(被黑了之后 hacker直接把root权限给改了 现在新增不了数据库 删除不了这个数据库 之前没有做备份 好像通过bin-log还原不回来) 1657902600597\r1657902791284\r阿里云服务器里Go sdk版本是1.13 有些api使用不了如何更新至1.18 网上的解决方案是卸载掉重装🫥 有没有更好的方法 打算接下来做什么: 容器技术学习 mysql学习 听导师的安排继续学习 使用gorm和go操纵数据库 了解gin框架 使用gin重构文件管理web应用程序 ","date":"2022-07-15T15:10:39+08:00","permalink":"https://linjianshu.github.io/p/%E5%AE%9E%E4%B9%A0%E5%B0%8F%E7%BB%9320220714/","title":"实习小结20220714"},{"content":"Go模版与BootStrap3使用 Go模版看了老容易忘记,今天正好项目上工艺部门想要安全件的解析规则清单,我想着用.net开发还不如用Go模版+Bootstrap来个最佳实践得了.结果在公司多加班了半小时 : )\n成品样图 image-20220307001641199\r实现了搜索功能 隔行变色 其他的表头排序还在研究中\n文件结构 image-20220307001737794\rimage-20220307001747021\r简单的 一个main.go 一个html(bootstrap.html没用 作为参考) 几张图片拼凑拼凑\n实现步骤 连接数据库 oracle 构造结构体完成数据库的数据映射问题 image-20220307002353869\rpackage main import ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/mattn/go-oci8\u0026#34; \u0026#34;html/template\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;time\u0026#34; ) type Items struct { ROW_NUM string PART_CODE string PART_NAME string PART_MODEL_NO sql.NullString PART_PLATFORM string PART_ABB string RESERVE07 string } var DB *sql.DB func DBconnect() { var err error //go连接mysql实例 //数据库源信息 dsn := \u0026#34;隐藏\u0026#34; //连接数据库 DB, err = sql.Open(\u0026#34;oci8\u0026#34;, dsn) //不会校验用户名和密码是否正确 if err != nil { log.Fatal(err) } err = DB.Ping() if err != nil { time.Sleep(5 * time.Minute) DBconnect() } return } 根据Go Template语法书写html代码 image-20220307002733907\r使用简单的 range . 和 .Row_num的迭代和.方法 并使用了bootstrap的link\rimage-20220307002825445\r主函数解析模版 书写相应处理函数 回传数据完成渲染 image-20220307002922090\rt := template.Must(template.ParseFiles(\u0026#34;template.html\u0026#34;)) // FileServer返回一个使用FileSystem接口root提供文件访问服务的HTTP处理器 file, _ := exec.LookPath(os.Args[0]) //得到全路径，比如在windows下E:\\\\golang\\\\test\\\\a.exe path, _ := filepath.Abs(file) rst := filepath.Dir(path) http.Handle(\u0026#34;/\u0026#34;, http.FileServer(http.Dir(rst))) 主函数书写处理函数 处理界面跳转 发布端口监听服务 image-20220307002539437\r这个函数完成检索数据 并渲染到界面上的功能 t就是模版\nt := template.Must(template.ParseFiles(\u0026#34;template.html\u0026#34;)) //检索所有 http.HandleFunc(\u0026#34;/CheckPart\u0026#34;, func(writer http.ResponseWriter, request *http.Request) { DBconnect() s := make([]Items, 0) if DB == nil { fmt.Fprintln(writer, \u0026#34;sry , please try again ...\u0026#34;) return } rows, err2 := DB.Query(\u0026#34;select ROWNUM, PART_CODE ,PART_NAME ,PART_MODEL_NO,PART_PLATFORM ,PART_ABB ,case RESERVE07 when \u0026#39;是\u0026#39; then \u0026#39;默认规则\u0026#39; when \u0026#39;否\u0026#39; then \u0026#39;不解析\u0026#39; else Reserve07 end RESERVE07 from part where PART_NAME like \u0026#39;%AQJ%\u0026#39;\u0026#34;) if err2 != nil { fmt.Fprintln(writer, \u0026#34;sry , please try again ...\u0026#34;) return } for rows.Next() { i := new(Items) rows.Scan(\u0026amp;i.ROW_NUM, \u0026amp;i.PART_CODE, \u0026amp;i.PART_NAME, \u0026amp;i.PART_MODEL_NO, \u0026amp;i.PART_PLATFORM, \u0026amp;i.PART_ABB, \u0026amp;i.RESERVE07) s = append(s, *i) } err2 = t.Execute(writer, s) if err2 != nil { panic(err2) } }) //查询 http.HandleFunc(\u0026#34;/Search\u0026#34;, func(writer http.ResponseWriter, request *http.Request) { m := make(map[string]string) m[\u0026#34;默认规则\u0026#34;] = \u0026#34;是\u0026#34; m[\u0026#34;不解析\u0026#34;] = \u0026#34;否\u0026#34; request.ParseForm() value := request.FormValue(\u0026#34;keyword\u0026#34;) if v, ok := m[value]; ok { value = v } value = \u0026#34;%\u0026#34; + value + \u0026#34;%\u0026#34; DBconnect() s := make([]Items, 0) query, err := DB.Query(\u0026#34;select ROWNUM, PART_CODE ,PART_NAME ,PART_MODEL_NO,PART_PLATFORM ,PART_ABB ,case RESERVE07 when \u0026#39;是\u0026#39; then \u0026#39;默认规则\u0026#39; when \u0026#39;否\u0026#39; then \u0026#39;不解析\u0026#39; else Reserve07 end RESERVE07 from part where PART_NAME like \u0026#39;%AQJ%\u0026#39; and (part_code like :1 or part_name like :2 or part_model_no like :3 or part_platform like :4 or part_abb like :5 or reserve07 like :6)\u0026#34;, value, value, value, value, value, value) if err != nil { panic(err) return } for query.Next() { i := new(Items) query.Scan(\u0026amp;i.ROW_NUM, \u0026amp;i.PART_CODE, \u0026amp;i.PART_NAME, \u0026amp;i.PART_MODEL_NO, \u0026amp;i.PART_PLATFORM, \u0026amp;i.PART_ABB, \u0026amp;i.RESERVE07) s = append(s, *i) } err2 := t.Execute(writer, s) if err2 != nil { panic(err2) } }) //监听端口 发布服务 server := http.Server{ Addr: \u0026#34;:8081\u0026#34;, Handler: nil, TLSConfig: nil, ReadTimeout: 0, ReadHeaderTimeout: 0, WriteTimeout: 0, IdleTimeout: 0, MaxHeaderBytes: 0, TLSNextProto: nil, ConnState: nil, ErrorLog: nil, BaseContext: nil, ConnContext: nil, } log.Println(server.ListenAndServe()) ","date":"2022-03-06T23:56:51+08:00","permalink":"https://linjianshu.github.io/p/gotemplateandbootstrap3/","title":"GoTemplateAndBootStrap3"},{"content":"找工作相关 github.com\nimage-20220215111209406\rimage-20220215111227477\rimage-20220215111249762\rimage-20220215111421252\rimage-20220215111554764\rimage-20220215111730527\rimage-20220215111802867\rimage-20220215111813725\rimage-20220215111837478\rimage-20220215111846849\rimage-20220215112302045\rimage-20220215112349551\r","date":"2022-03-01T10:11:37+08:00","permalink":"https://linjianshu.github.io/p/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/","title":"找工作相关"},{"content":"leetBook_冲刺攻略 image-20220227100312893\r根据提示的数据范围推定时间复杂度 根据时间复杂度推定算法集合 根据题目特征确定算法\nimage-20220227100007364\r没有给出数据范围通常使用枚举 枚举通常是n~nlog(n)的时间复杂度 然后再确定算法集合\nimage-20220227100056863\rimage-20220228103152097\rimage-20220228103157567\r","date":"2022-02-28T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/leetbook_%E5%86%B2%E5%88%BA%E6%94%BB%E7%95%A5/","title":"leetBook_冲刺攻略"},{"content":"leetBook_数组和字符串 理解数组的 基本概念 及其 操作方式；\n理解 二维数组 的基本概念，熟悉二维数组的使用；\n了解 字符串 的概念以及字符串所具有的不同特性；\n理解字符串匹配中的 KMP 算法；\n能够运用 双指针 解决实际问题。\n数组简介 image-20220228130907972\r集合列表与数组 集合:由一个或多个确定的元素构成的整体\n集合里的元素类型不一定相同,集合里的元素没有顺序\n列表:一种数据项构成的有限序列,即按照一定的线性顺序,排列而成的数据项的集合\n列表的概念是在集合的特征上形成的,他具有顺序,且长度是可变的.\n列表最常见的形式有数组和链表;栈和队列是两种特殊类型的列表\n数组:列表的实现方式之一\n如何区分列表和数组:索引\n数组中的元素在内存中是连续存储的,且每个元素占用相同大小的内存\n相反,列表中的元素在内存中可能彼此相邻,也可能不相邻.比如链表的元素在内存中则不一定是连续的\n列表是集合的一种表现形式,在集合的特征上形成的;数组是列表的一种实现方式,链表是列表的另一种实现方式.\nimage-20220228131524791\r数组的操作 连续存储\n读取元素:按照索引访问 , o(1)\n查找元素:全数组遍历,o(n)\n插入元素:要挪位子,很麻烦.如果需要频繁地对数组元素进行插入操作，会造成时间的浪费。事实上，另一种数据结构，即链表可以有效解决这个问题。\n删除元素:删掉后,把后面的挪到前面,很麻烦.删除操作具有线性时间复杂度，即时间复杂度为 O(N)，N 为数组的长度。\n题目 寻找数组的中心索引 给你一个整数数组 nums ，请计算数组的 中心下标 。\n数组 中心下标 是数组的一个下标，其左侧所有元素相加的和等于右侧所有元素相加的和。\n如果中心下标位于数组最左端，那么左侧数之和视为 0 ，因为在下标的左侧不存在元素。这一点对于中心下标位于数组最右端同样适用。\n如果数组有多个中心下标，应该返回 最靠近左边 的那一个。如果数组不存在中心下标，返回 -1 。\n//前缀和 + 逐项遍历 func pivotIndex(nums []int) int { preSum := make([]int, len(nums)+1, len(nums)+1) preSum[0] = 0 for i := 0; i \u0026lt; len(nums); i++ { preSum[i+1] = nums[i] + preSum[i] } for i := 1; i \u0026lt; len(preSum); i++ { left := preSum[i-1] right := preSum[len(preSum)-1] - preSum[i] if left == right { return i - 1 } } return -1 } 搜索插入位置 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\n请必须使用时间复杂度为 O(log n) 的算法。\n//二分法 func searchInsert(nums []int, target int) int { left, right := 0, len(nums)-1 for left \u0026lt;= right { mid := left + (right-left)/2 if nums[mid] == target { return mid } else if nums[mid] \u0026gt; target { right = mid - 1 } else if nums[mid] \u0026lt; target { left = mid + 1 } } return left } 合并区间 以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。\n//不太会啊 数组有序问题 最好先排个序 思路可能会开阔一点 func merge1(intervals [][]int) [][]int { res := make([][]int, 0) sort.Slice(intervals, func(i, j int) bool { return intervals[i][0] \u0026lt; intervals[j][0] }) res = append(res, intervals[0]) for i := 1; i \u0026lt; len(intervals); i++ { //如果这个左端点 比 前一个的端点小 说明有重合 有重合还得判断这个的右端点是否会比前一个的右端点大 大的话才会覆盖 小的话顶多算子集 if intervals[i][0] \u0026lt;= res[len(res)-1][1] { if res[len(res)-1][1] \u0026lt; intervals[i][1] { res[len(res)-1][1] = intervals[i][1] } } else { res = append(res, intervals[i]) } } return res } 二维数组简介 二维数组 二维数组是一种结构较为特殊的数组,只是将数组中的每个元素变成了一堆数组.\nimage-20220228155559676\r二维数组的本质上仍然是一个一维数组,内部的一维数组仍然从索引0开始,我们可以将它看作一个矩阵,并处理矩阵的相关问题.\n题目 旋转矩阵 给你一幅由 N × N 矩阵表示的图像，其中每个像素的大小为 4 字节。请你设计一种算法，将图像旋转 90 度。\n不占用额外内存空间能否做到？\n//属实不会 二维数组翻转的话 根据对角线翻转 然后再横向翻转 多试一试 func rotate1(matrix [][]int) { //正对角线翻转 for i := 0; i \u0026lt; len(matrix); i++ { for j := 0; j \u0026lt;= i; j++ { matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j] } } //水平横向翻转 for i := 0; i \u0026lt; len(matrix); i++ { for j := 0; j \u0026lt; len(matrix[i])/2; j++ { matrix[i][j], matrix[i][len(matrix[i])-1-j] = matrix[i][len(matrix[i])-1-j], matrix[i][j] } } return } 零矩阵 编写一种算法，若M × N矩阵中某个元素为0，则将其所在的行与列清零。\n//使用数组作为桥梁 存一下 func rotate(matrix [][]int) { res := make([]int, 0, len(matrix)*len(matrix)) //代表列 for i := 0; i \u0026lt; len(matrix[0]); i++ { //代表行 for j := len(matrix) - 1; j \u0026gt;= 0; j-- { res = append(res, matrix[j][i]) } } index := 0 for i := 0; i \u0026lt; len(matrix); i++ { for j := 0; j \u0026lt; len(matrix[i]); j++ { matrix[i][j] = res[index] index++ } } return } func setZeroes1(matrix [][]int) { m := make(map[[2]int]bool) for i := 0; i \u0026lt; len(matrix); i++ { for j := 0; j \u0026lt; len(matrix[i]); j++ { if matrix[i][j] == 0 { m[[2]int{i, j}] = true } } } for ints := range m { for i := 0; i \u0026lt; len(matrix[ints[0]]); i++ { matrix[ints[0]][i] = 0 } for i := 0; i \u0026lt; len(matrix); i++ { matrix[i][ints[1]] = 0 } } } func setZeroes(matrix [][]int) { mRow := make(map[int]bool) mCol := make(map[int]bool) for i := 0; i \u0026lt; len(matrix); i++ { for j := 0; j \u0026lt; len(matrix[i]); j++ { if matrix[i][j] == 0 { mRow[i] = true mCol[j] = true } } } for i := 0; i \u0026lt; len(matrix); i++ { for j := 0; j \u0026lt; len(matrix[i]); j++ { if mRow[i] || mCol[j] { matrix[i][j] = 0 } } } } 对角线遍历 给你一个大小为 m x n 的矩阵 mat ，请以对角线遍历的顺序，用一个数组返回这个矩阵中的所有元素。\n//对角线的特征是 行索引和列索引和相等 可以利用和是奇数和偶数来判断 正向遍历还是反向遍历 func findDiagonalOrder(mat [][]int) []int { res := make([]int, 0, 0) if len(mat) == 1 { return mat[0] } if len(mat[0]) == 1 { for _, ints := range mat { res = append(res, ints[0]) } return res } sum := len(mat) + len(mat[0]) for i := 0; i \u0026lt;= sum; i++ { for j := 0; j \u0026lt;= i; j++ { if i%2 == 0 { if i-j \u0026gt;= 0 \u0026amp;\u0026amp; i-j \u0026lt; len(mat) \u0026amp;\u0026amp; j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; len(mat[0]) { res = append(res, mat[i-j][j]) } } else { if j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; len(mat) \u0026amp;\u0026amp; i-j \u0026gt;= 0 \u0026amp;\u0026amp; i-j \u0026lt; len(mat[0]) { res = append(res, mat[j][i-j]) } } } } return res } 字符串 字符串简介 字符串的基本操作对象通常是字符串整体或者其子串 I like leetcode 反向输出 更愿意接受Leetcode like I 而不是edocteel ekil I\n字符串的比较和连接操作相对复杂\n语言支持运算符重载 那么就可以对字符串进行==比较\n字符串进行连接操作,根据语言的不同效率不同\n​\tC++可以修改字符串 在连接操作的时候效率就比较高\n​\tJava Go 不能修改字符串 在连接操作的时候就会重新分配内存给新字符串 然后再拷贝就的字符串中的内容到新的内存地址中 这样就会造成效率下降\n因此如果需要连接 可以尝试使用stringbuilder数据结构 或者转换成[]byte切片进行连接或者修改\n","date":"2022-02-10T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/leetbook_%E6%95%B0%E7%BB%84%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"leetBook_数组和字符串"},{"content":"尚硅谷Go学习 进制： 对于整数，有四种表示方式：\n二进制 在golang中，不能直接使用二进制来表示一个整数，她沿用了c的特点 十进制 八进制 以数字0开头 十六进制 以0x或0X开头表示 此处A-F不区分大小写 进制转换 其他进制转十进制\n十进制转其他进制\n将该数不断除以其他进制的基数，直到商为0为止，然后将每步得到的余数倒过来，就是对应的二进制。 image-20211106093415401\r二进制转八进制、十六进制\n转八进制 三位一组，低位开始组合，转成八进制就可以了。 转十六进制 思维一组，低位开始组合，转成十六进制就可以了。 其他进制转二进制\n八进制、十六进制 每三位、四位转成二进制即可 位运算 运算符 \u0026amp;按位与 |按位或 ^按位异或 \u0026laquo;左移 \u0026raquo;右移\nimage-20211106094703255\r原码、反码、补码 二进制的最高位是符号位：0表示正数 1表示负数 正数的原码、反码、补码都一样 负数的反码=它的原码符号位不变，其他位取反 负数的补码=负数的反码+1 -1 原码[1000 0001] 反码[1111 1110] 补码[1111 1111] 0的反码补码都是0 在计算机运算的时候，都是以补码的方式来运算的 image-20211106100410526\r函数调用机制 image-20211106101741641\r回收栈\nimage-20211106101856688\r说明：\n在调用一个函数时，会给该函数分配一个新的空间，编译器会通过自身的处理让这个新的空间和其他的栈的空间区分开来 在每个函数对应的栈中，数据空间是独立的，不会混淆 当一个函数调用完毕（执行完毕）后，程序会销毁这个函数对应的栈空间 func main() { n1 := 10 test(n1) fmt.Println(\u0026#34;main() \u0026#34;, n1) sum := getSum(1,2) fmt.Println(\u0026#34;main sum = \u0026#34;, sum) fmt.Printf(\u0026#34;main sum %v\\n\u0026#34;,\u0026amp;sum) } func test(n1 int) { n1++ fmt.Println(\u0026#34;test() \u0026#34;, n1) } func getSum(n1, n2 int) int { sum := n1 + n2 fmt.Println(\u0026#34;get Sum = \u0026#34;,sum) //当函数又return语句时，就是将结果返回给调用者 //即谁调用我，我就返回给谁 fmt.Printf(\u0026#34;get sum %v\\n\u0026#34;,\u0026amp;sum) return sum } test() 11 main() 10 get Sum = 3 get sum 0xc00000a0d8 main sum = 3 main sum 0xc00000a0d0 进程 已完成，退出代码为 0 函数的递归调用 image-20211106104718001\r顶层栈执行完毕后销毁\nimage-20211106104802326\rimage-20211106104837444\rimage-20211106104910149\r总体流程\nimage-20211106105257021\r总结：\n执行一个函数时，就会创建一个新的受保护的独立空间（新函数栈） 函数的局部变量是独立的，不会相互影响 递归必须想退出递归的条件逼近，否则就是无限递归了，死龟 当一个函数执行完毕，或者遇到return，就会返回，遵守谁调用，就将结果返回给谁，同时当函数执行完毕或者返回时，该函数本身也会被系统销毁 ","date":"2021-12-13T09:17:59+08:00","permalink":"https://linjianshu.github.io/p/%E5%B0%9A%E7%A1%85%E8%B0%B7go%E5%AD%A6%E4%B9%A0/","title":"尚硅谷Go学习"},{"content":"Go web编程 Chapter_9 Go_Concurrency channel_message package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func thrower(c chan int) { for i := 0; i \u0026lt; 5; i++ { c \u0026lt;- i fmt.Println(\u0026#34;Threw \u0026gt;\u0026gt;\u0026#34;, i) } } func catcher(c chan int) { for i := 0; i \u0026lt; 5; i++ { num := \u0026lt;-c fmt.Println(\u0026#34;Caught \u0026lt;\u0026lt;\u0026#34;, num) } } func main() { c := make(chan int, 3) go thrower(c) go catcher(c) time.Sleep(100 * time.Millisecond) } channel_select package main import ( \u0026#34;fmt\u0026#34; ) func callerA(c chan string) { c \u0026lt;- \u0026#34;Hello World!\u0026#34; close(c) } func callerB(c chan string) { c \u0026lt;- \u0026#34;Hola Mundo!\u0026#34; close(c) } func main() { a, b := make(chan string), make(chan string) go callerA(a) go callerB(b) var msg string openA, openB := true, true for openA || openB { select { case msg, openA = \u0026lt;-a: if openA { fmt.Printf(\u0026#34;%s from A\\n\u0026#34;, msg) } case msg, openB = \u0026lt;-b: if openB { fmt.Printf(\u0026#34;%s from B\\n\u0026#34;, msg) } } } } // func main() { // a, b := make(chan string), make(chan string) // go callerA(a) // go callerB(b) // msg1, msg2 := \u0026#34;A\u0026#34;, \u0026#34;B\u0026#34; // for { // time.Sleep(1 * time.Microsecond) // // select { // case msg1 = \u0026lt;-a: // fmt.Printf(\u0026#34;%s from A\\n\u0026#34;, msg1) // case msg2 = \u0026lt;-b: // fmt.Printf(\u0026#34;%s from B\\n\u0026#34;, msg2) // // default: // // fmt.Println(\u0026#34;Default\u0026#34;) // } // if msg1 == \u0026#34;\u0026#34; \u0026amp;\u0026amp; msg2 == \u0026#34;\u0026#34; { // break // } // // } // } channel_shared package main import ( \u0026#34;fmt\u0026#34; // \u0026#34;math/rand\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; ) var DB Store type Store struct { hash map[string]string in chan [2]string out chan [2]string } func StoreInit() { DB = Store{ hash: make(map[string]string), in: make(chan [2]string), } go func() { for { a := \u0026lt;-DB.in DB.hash[a[0]] = a[1] } }() } func (store *Store) Get(key string) (value string, err error) { value = store.hash[key] return } func (store *Store) Add(key string, value string) (err error) { a := [2]string{key, value} store.in \u0026lt;- a // store.hash[key] = value return } func (store *Store) Set(key string, value string) (err error) { return } func (store *Store) Del(key string) (err error) { return } func (store *Store) Pop(key string) (value string, err error) { return } func main() { runtime.GOMAXPROCS(4) StoreInit() for i := 0; i \u0026lt; 10; i++ { go DB.Add(\u0026#34;a\u0026#34;, \u0026#34;A\u0026#34;) go DB.Add(\u0026#34;a\u0026#34;, \u0026#34;B\u0026#34;) go DB.Add(\u0026#34;a\u0026#34;, \u0026#34;C\u0026#34;) time.Sleep(1 * time.Microsecond) s, _ := DB.Get(\u0026#34;a\u0026#34;) fmt.Printf(\u0026#34;%s \u0026#34;, s) } } channel_wait package main import \u0026#34;fmt\u0026#34; import \u0026#34;time\u0026#34; func printNumbers(w chan bool) { for i := 0; i \u0026lt; 10; i++ { time.Sleep(1 * time.Microsecond) fmt.Printf(\u0026#34;%d \u0026#34;, i) } w \u0026lt;- true } func printLetters(w chan bool) { for i := \u0026#39;A\u0026#39;; i \u0026lt; \u0026#39;A\u0026#39;+10; i++ { time.Sleep(1 * time.Microsecond) fmt.Printf(\u0026#34;%c \u0026#34;, i) } w \u0026lt;- true } func main() { w1, w2 := make(chan bool), make(chan bool) go printNumbers(w1) go printLetters(w2) \u0026lt;-w1 \u0026lt;-w2 } goroutine package main // import \u0026#34;fmt\u0026#34; import \u0026#34;time\u0026#34; func printNumbers1() { for i := 0; i \u0026lt; 10; i++ { // fmt.Printf(\u0026#34;%d \u0026#34;, i) } } func printLetters1() { for i := \u0026#39;A\u0026#39;; i \u0026lt; \u0026#39;A\u0026#39;+10; i++ { // fmt.Printf(\u0026#34;%c \u0026#34;, i) } } func printNumbers2() { for i := 0; i \u0026lt; 10; i++ { time.Sleep(1 * time.Microsecond) // fmt.Printf(\u0026#34;%d \u0026#34;, i) } } func printLetters2() { for i := \u0026#39;A\u0026#39;; i \u0026lt; \u0026#39;A\u0026#39;+10; i++ { time.Sleep(1 * time.Microsecond) // fmt.Printf(\u0026#34;%c \u0026#34;, i) } } func print1() { printNumbers1() printLetters1() } func goPrint1() { go printNumbers1() go printLetters1() } func print2() { printNumbers2() printLetters2() } func goPrint2() { go printNumbers2() go printLetters2() } func main() { } ","date":"2021-11-28T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/go-web%E7%BC%96%E7%A8%8B-chapter9/","title":"Go Web编程 Chapter9"},{"content":"Go web编程 Chapter_7 Creating_Web_Servies json_creating_encoder package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) type Post struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author Author `json:\u0026#34;author\u0026#34;` Comments []Comment `json:\u0026#34;comments\u0026#34;` } type Author struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } type Comment struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author string `json:\u0026#34;author\u0026#34;` } func main() { post := Post{ Id: 1, Content: \u0026#34;Hello World!\u0026#34;, Author: Author{ Id: 2, Name: \u0026#34;Sau Sheong\u0026#34;, }, Comments: []Comment{ Comment{ Id: 1, Content: \u0026#34;Have a great day!\u0026#34;, Author: \u0026#34;Adam\u0026#34;, }, Comment{ Id: 2, Content: \u0026#34;How are you today?\u0026#34;, Author: \u0026#34;Betty\u0026#34;, }, }, } jsonFile, err := os.Create(\u0026#34;post.json\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error creating JSON file:\u0026#34;, err) return } jsonWriter := io.Writer(jsonFile) encoder := json.NewEncoder(jsonWriter) err = encoder.Encode(\u0026amp;post) if err != nil { fmt.Println(\u0026#34;Error encoding JSON to file:\u0026#34;, err) return } } post.json\n{\u0026#34;id\u0026#34;:1,\u0026#34;content\u0026#34;:\u0026#34;Hello World!\u0026#34;,\u0026#34;author\u0026#34;:{\u0026#34;id\u0026#34;:2,\u0026#34;name\u0026#34;:\u0026#34;Sau Sheong\u0026#34;},\u0026#34;comments\u0026#34;:[{\u0026#34;id\u0026#34;:1,\u0026#34;content\u0026#34;:\u0026#34;Have a great day!\u0026#34;,\u0026#34;author\u0026#34;:\u0026#34;Adam\u0026#34;},{\u0026#34;id\u0026#34;:2,\u0026#34;content\u0026#34;:\u0026#34;How are you today?\u0026#34;,\u0026#34;author\u0026#34;:\u0026#34;Betty\u0026#34;}]} json_creating_marshal package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; ) type Post struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author Author `json:\u0026#34;author\u0026#34;` Comments []Comment `json:\u0026#34;comments\u0026#34;` } type Author struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } type Comment struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author string `json:\u0026#34;author\u0026#34;` } func main() { post := Post{ Id: 1, Content: \u0026#34;Hello World!\u0026#34;, Author: Author{ Id: 2, Name: \u0026#34;Sau Sheong\u0026#34;, }, Comments: []Comment{ Comment{ Id: 1, Content: \u0026#34;Have a great day!\u0026#34;, Author: \u0026#34;Adam\u0026#34;, }, Comment{ Id: 2, Content: \u0026#34;How are you today?\u0026#34;, Author: \u0026#34;Betty\u0026#34;, }, }, } output, err := json.MarshalIndent(\u0026amp;post, \u0026#34;\u0026#34;, \u0026#34;\\t\\t\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error marshalling to JSON:\u0026#34;, err) return } err = ioutil.WriteFile(\u0026#34;post.json\u0026#34;, output, 0644) if err != nil { fmt.Println(\u0026#34;Error writing JSON to file:\u0026#34;, err) return } } post.json\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;content\u0026#34;: \u0026#34;Hello World!\u0026#34;, \u0026#34;author\u0026#34;: { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;Sau Sheong\u0026#34; }, \u0026#34;comments\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;content\u0026#34;: \u0026#34;Have a great day!\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Adam\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;content\u0026#34;: \u0026#34;How are you today?\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Betty\u0026#34; } ] } json_parsing_decoder package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) type Post struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author Author `json:\u0026#34;author\u0026#34;` Comments []Comment `json:\u0026#34;comments\u0026#34;` } type Author struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } type Comment struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author string `json:\u0026#34;author\u0026#34;` } func main() { jsonFile, err := os.Open(\u0026#34;post.json\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error opening JSON file:\u0026#34;, err) return } defer jsonFile.Close() decoder := json.NewDecoder(jsonFile) for { var post Post err := decoder.Decode(\u0026amp;post) if err == io.EOF { break } if err != nil { fmt.Println(\u0026#34;Error decoding JSON:\u0026#34;, err) return } fmt.Println(post) } } post.json\n{ \u0026#34;id\u0026#34; : 1, \u0026#34;content\u0026#34; : \u0026#34;Hello World!\u0026#34;, \u0026#34;author\u0026#34; : { \u0026#34;id\u0026#34; : 2, \u0026#34;name\u0026#34; : \u0026#34;Sau Sheong\u0026#34; }, \u0026#34;comments\u0026#34; : [ { \u0026#34;id\u0026#34; : 3, \u0026#34;content\u0026#34; : \u0026#34;Have a great day!\u0026#34;, \u0026#34;author\u0026#34; : \u0026#34;Adam\u0026#34; }, { \u0026#34;id\u0026#34; : 4, \u0026#34;content\u0026#34; : \u0026#34;How are you today?\u0026#34;, \u0026#34;author\u0026#34; : \u0026#34;Betty\u0026#34; } ] } json_parsing_unmarshal package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) type Post struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author Author `json:\u0026#34;author\u0026#34;` Comments []Comment `json:\u0026#34;comments\u0026#34;` } type Author struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } type Comment struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author string `json:\u0026#34;author\u0026#34;` } func main() { jsonFile, err := os.Open(\u0026#34;post.json\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error opening JSON file:\u0026#34;, err) return } defer jsonFile.Close() jsonData, err := ioutil.ReadAll(jsonFile) if err != nil { fmt.Println(\u0026#34;Error reading JSON data:\u0026#34;, err) return } fmt.Println(string(jsonData)) var post Post json.Unmarshal(jsonData, \u0026amp;post) fmt.Println(post.Id) fmt.Println(post.Content) fmt.Println(post.Author.Id) fmt.Println(post.Author.Name) fmt.Println(post.Comments[0].Id) fmt.Println(post.Comments[0].Content) fmt.Println(post.Comments[0].Author) } post.json\n{ \u0026#34;id\u0026#34; : 1, \u0026#34;content\u0026#34; : \u0026#34;Hello World!\u0026#34;, \u0026#34;author\u0026#34; : { \u0026#34;id\u0026#34; : 2, \u0026#34;name\u0026#34; : \u0026#34;Sau Sheong\u0026#34; }, \u0026#34;comments\u0026#34; : [ { \u0026#34;id\u0026#34; : 1, \u0026#34;content\u0026#34; : \u0026#34;Have a great day!\u0026#34;, \u0026#34;author\u0026#34; : \u0026#34;Adam\u0026#34; }, { \u0026#34;id\u0026#34; : 2, \u0026#34;content\u0026#34; : \u0026#34;How are you today?\u0026#34;, \u0026#34;author\u0026#34; : \u0026#34;Betty\u0026#34; } ] } web_service data.go\npackage main import ( \u0026#34;database/sql\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; ) var Db *sql.DB // connect to the Db func init() { var err error Db, err = sql.Open(\u0026#34;postgres\u0026#34;, \u0026#34;user=gwp dbname=gwp password=gwp sslmode=disable\u0026#34;) if err != nil { panic(err) } } // Get a single post func retrieve(id int) (post Post, err error) { post = Post{} err = Db.QueryRow(\u0026#34;select id, content, author from posts where id = $1\u0026#34;, id).Scan(\u0026amp;post.Id, \u0026amp;post.Content, \u0026amp;post.Author) return } // Create a new post func (post *Post) create() (err error) { statement := \u0026#34;insert into posts (content, author) values ($1, $2) returning id\u0026#34; stmt, err := Db.Prepare(statement) if err != nil { return } defer stmt.Close() err = stmt.QueryRow(post.Content, post.Author).Scan(\u0026amp;post.Id) return } // Update a post func (post *Post) update() (err error) { _, err = Db.Exec(\u0026#34;update posts set content = $2, author = $3 where id = $1\u0026#34;, post.Id, post.Content, post.Author) return } // Delete a post func (post *Post) delete() (err error) { _, err = Db.Exec(\u0026#34;delete from posts where id = $1\u0026#34;, post.Id) return } server.go\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;path\u0026#34; \u0026#34;strconv\u0026#34; ) type Post struct { Id int `json:\u0026#34;id\u0026#34;` Content string `json:\u0026#34;content\u0026#34;` Author string `json:\u0026#34;author\u0026#34;` } func main() { server := http.Server{ Addr: \u0026#34;:8080\u0026#34;, } http.HandleFunc(\u0026#34;/post/\u0026#34;, handleRequest) server.ListenAndServe() } // main handler function func handleRequest(w http.ResponseWriter, r *http.Request) { var err error switch r.Method { case \u0026#34;GET\u0026#34;: err = handleGet(w, r) case \u0026#34;POST\u0026#34;: err = handlePost(w, r) case \u0026#34;PUT\u0026#34;: err = handlePut(w, r) case \u0026#34;DELETE\u0026#34;: err = handleDelete(w, r) } if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } } // Retrieve a post // GET /post/1 func handleGet(w http.ResponseWriter, r *http.Request) (err error) { id, err := strconv.Atoi(path.Base(r.URL.Path)) if err != nil { return } post, err := retrieve(id) if err != nil { return } output, err := json.MarshalIndent(\u0026amp;post, \u0026#34;\u0026#34;, \u0026#34;\\t\\t\u0026#34;) if err != nil { return } w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) w.Write(output) return } // Create a post // POST /post/ func handlePost(w http.ResponseWriter, r *http.Request) (err error) { len := r.ContentLength body := make([]byte, len) r.Body.Read(body) var post Post json.Unmarshal(body, \u0026amp;post) err = post.create() if err != nil { return } w.WriteHeader(200) return } // Update a post // PUT /post/1 func handlePut(w http.ResponseWriter, r *http.Request) (err error) { id, err := strconv.Atoi(path.Base(r.URL.Path)) if err != nil { return } post, err := retrieve(id) if err != nil { return } len := r.ContentLength body := make([]byte, len) r.Body.Read(body) json.Unmarshal(body, \u0026amp;post) err = post.update() if err != nil { return } w.WriteHeader(200) return } // Delete a post // DELETE /post/1 func handleDelete(w http.ResponseWriter, r *http.Request) (err error) { id, err := strconv.Atoi(path.Base(r.URL.Path)) if err != nil { return } post, err := retrieve(id) if err != nil { return } err = post.delete() if err != nil { return } w.WriteHeader(200) return } curl_script\ncurl -i -X POST -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;content\u0026#34;:\u0026#34;My first post\u0026#34;,\u0026#34;author\u0026#34;:\u0026#34;Sau Sheong\u0026#34;}\u0026#39; http://127.0.0.1:8080/post/ curl -i -X DELETE http://127.0.0.1:8080/post/1 curl -i -X GET http://127.0.0.1:8080/post/1 curl -i -X PUT -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;content\u0026#34;:\u0026#34;Updated post\u0026#34;,\u0026#34;author\u0026#34;:\u0026#34;Sau Sheong\u0026#34;}\u0026#39; http://127.0.0.1:8080/post/1 sql\ndrop database gwp; create database gwp; drop user gwp; create user gwp with password \u0026#39;gwp\u0026#39;; grant all privileges on database gwp to gwp; drop table posts; create table posts ( id serial primary key, content text, author varchar(255) ); xml_creating_encoder package main import ( \u0026#34;encoding/xml\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) type Post struct { XMLName xml.Name `xml:\u0026#34;post\u0026#34;` Id string `xml:\u0026#34;id,attr\u0026#34;` Content string `xml:\u0026#34;content\u0026#34;` Author Author `xml:\u0026#34;author\u0026#34;` } type Author struct { Id string `xml:\u0026#34;id,attr\u0026#34;` Name string `xml:\u0026#34;,chardata\u0026#34;` } func main() { post := Post{ Id: \u0026#34;1\u0026#34;, Content: \u0026#34;Hello World!\u0026#34;, Author: Author{ Id: \u0026#34;2\u0026#34;, Name: \u0026#34;Sau Sheong\u0026#34;, }, } xmlFile, err := os.Create(\u0026#34;post.xml\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error creating XML file:\u0026#34;, err) return } encoder := xml.NewEncoder(xmlFile) encoder.Indent(\u0026#34;\u0026#34;, \u0026#34;\\t\u0026#34;) err = encoder.Encode(\u0026amp;post) if err != nil { fmt.Println(\u0026#34;Error encoding XML to file:\u0026#34;, err) return } } post.xml\n\u0026lt;post id=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;content\u0026gt;Hello World!\u0026lt;/content\u0026gt; \u0026lt;author id=\u0026#34;2\u0026#34;\u0026gt;Sau Sheong\u0026lt;/author\u0026gt; \u0026lt;/post\u0026gt; xml_creating_marshal package main import ( \u0026#34;encoding/xml\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; ) type Post struct { XMLName xml.Name `xml:\u0026#34;post\u0026#34;` Id string `xml:\u0026#34;id,attr\u0026#34;` Content string `xml:\u0026#34;content\u0026#34;` Author Author `xml:\u0026#34;author\u0026#34;` } type Author struct { Id string `xml:\u0026#34;id,attr\u0026#34;` Name string `xml:\u0026#34;,chardata\u0026#34;` } func main() { post := Post{ Id: \u0026#34;1\u0026#34;, Content: \u0026#34;Hello World!\u0026#34;, Author: Author{ Id: \u0026#34;2\u0026#34;, Name: \u0026#34;Sau Sheong\u0026#34;, }, } // output, err := xml.Marshal(\u0026amp;post) output, err := xml.MarshalIndent(\u0026amp;post, \u0026#34;\u0026#34;, \u0026#34;\\t\\t\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error marshalling to XML:\u0026#34;, err) return } err = ioutil.WriteFile(\u0026#34;post.xml\u0026#34;, []byte(xml.Header+string(output)), 0644) if err != nil { fmt.Println(\u0026#34;Error writing XML to file:\u0026#34;, err) return } } \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;post id=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;content\u0026gt;Hello World!\u0026lt;/content\u0026gt; \u0026lt;author id=\u0026#34;2\u0026#34;\u0026gt;Sau Sheong\u0026lt;/author\u0026gt; \u0026lt;/post\u0026gt; xml_parsing_decoder post.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;post id=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;content\u0026gt;Hello World!\u0026lt;/content\u0026gt; \u0026lt;author id=\u0026#34;2\u0026#34;\u0026gt;Sau Sheong\u0026lt;/author\u0026gt; \u0026lt;comments\u0026gt; \u0026lt;comment id=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;content\u0026gt;Have a great day!\u0026lt;/content\u0026gt; \u0026lt;author id=\u0026#34;3\u0026#34;\u0026gt;Adam\u0026lt;/author\u0026gt; \u0026lt;/comment\u0026gt; \u0026lt;comment id=\u0026#34;2\u0026#34;\u0026gt; \u0026lt;content\u0026gt;How are you today?\u0026lt;/content\u0026gt; \u0026lt;author id=\u0026#34;4\u0026#34;\u0026gt;Betty\u0026lt;/author\u0026gt; \u0026lt;/comment\u0026gt; \u0026lt;/comments\u0026gt; \u0026lt;/post\u0026gt; package main import ( \u0026#34;encoding/xml\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) type Post struct { XMLName xml.Name `xml:\u0026#34;post\u0026#34;` Id string `xml:\u0026#34;id,attr\u0026#34;` Content string `xml:\u0026#34;content\u0026#34;` Author Author `xml:\u0026#34;author\u0026#34;` Xml string `xml:\u0026#34;,innerxml\u0026#34;` Comments []Comment `xml:\u0026#34;comments\u0026gt;comment\u0026#34;` } type Author struct { Id string `xml:\u0026#34;id,attr\u0026#34;` Name string `xml:\u0026#34;,chardata\u0026#34;` } type Comment struct { Id string `xml:\u0026#34;id,attr\u0026#34;` Content string `xml:\u0026#34;content\u0026#34;` Author Author `xml:\u0026#34;author\u0026#34;` } func main() { xmlFile, err := os.Open(\u0026#34;post.xml\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error opening XML file:\u0026#34;, err) return } defer xmlFile.Close() decoder := xml.NewDecoder(xmlFile) for { t, err := decoder.Token() if err == io.EOF { break } if err != nil { fmt.Println(\u0026#34;Error decoding XML into tokens:\u0026#34;, err) return } switch se := t.(type) { case xml.StartElement: if se.Name.Local == \u0026#34;comment\u0026#34; { var comment Comment decoder.DecodeElement(\u0026amp;comment, \u0026amp;se) fmt.Println(comment) } } } } xml_parsing_unmarshal_1 post.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;post id=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;content\u0026gt;Hello World!\u0026lt;/content\u0026gt; \u0026lt;author id=\u0026#34;2\u0026#34;\u0026gt;Sau Sheong\u0026lt;/author\u0026gt; \u0026lt;/post\u0026gt; package main import ( \u0026#34;encoding/xml\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) type Post struct { XMLName xml.Name `xml:\u0026#34;post\u0026#34;` Id string `xml:\u0026#34;id,attr\u0026#34;` Content string `xml:\u0026#34;content\u0026#34;` Author Author `xml:\u0026#34;author\u0026#34;` Xml string `xml:\u0026#34;,innerxml\u0026#34;` } type Author struct { Id string `xml:\u0026#34;id,attr\u0026#34;` Name string `xml:\u0026#34;,chardata\u0026#34;` } func main() { xmlFile, err := os.Open(\u0026#34;post.xml\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error opening XML file:\u0026#34;, err) return } defer xmlFile.Close() xmlData, err := ioutil.ReadAll(xmlFile) if err != nil { fmt.Println(\u0026#34;Error reading XML data:\u0026#34;, err) return } var post Post xml.Unmarshal(xmlData, \u0026amp;post) fmt.Println(post) } xml_parsing_unmarshal_2 post.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;post id=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;content\u0026gt;Hello World!\u0026lt;/content\u0026gt; \u0026lt;author id=\u0026#34;2\u0026#34;\u0026gt;Sau Sheong\u0026lt;/author\u0026gt; \u0026lt;comments\u0026gt; \u0026lt;comment id=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;content\u0026gt;Have a great day!\u0026lt;/content\u0026gt; \u0026lt;author\u0026gt;Adam\u0026lt;/author\u0026gt; \u0026lt;/comment\u0026gt; \u0026lt;comment id=\u0026#34;2\u0026#34;\u0026gt; \u0026lt;content\u0026gt;How are you today?\u0026lt;/content\u0026gt; \u0026lt;author\u0026gt;Betty\u0026lt;/author\u0026gt; \u0026lt;/comment\u0026gt; \u0026lt;/comments\u0026gt; \u0026lt;/post\u0026gt; package main import ( \u0026#34;encoding/xml\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) type Post struct { XMLName xml.Name `xml:\u0026#34;post\u0026#34;` Id string `xml:\u0026#34;id,attr\u0026#34;` Content string `xml:\u0026#34;content\u0026#34;` Author Author `xml:\u0026#34;author\u0026#34;` Xml string `xml:\u0026#34;,innerxml\u0026#34;` Comments []Comment `xml:\u0026#34;comments\u0026gt;comment\u0026#34;` } type Author struct { Id string `xml:\u0026#34;id,attr\u0026#34;` Name string `xml:\u0026#34;,chardata\u0026#34;` } type Comment struct { Id string `xml:\u0026#34;id,attr\u0026#34;` Content string `xml:\u0026#34;content\u0026#34;` Author Author `xml:\u0026#34;author\u0026#34;` } func main() { xmlFile, err := os.Open(\u0026#34;post.xml\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error opening XML file:\u0026#34;, err) return } defer xmlFile.Close() xmlData, err := ioutil.ReadAll(xmlFile) if err != nil { fmt.Println(\u0026#34;Error reading XML data:\u0026#34;, err) return } var post Post xml.Unmarshal(xmlData, \u0026amp;post) fmt.Println(post.XMLName.Local) fmt.Println(post.Id) fmt.Println(post.Content) fmt.Println(post.Author) fmt.Println(post.Xml) fmt.Println(post.Author.Id) fmt.Println(post.Author.Name) fmt.Println(post.Comments) fmt.Println(post.Comments[0].Id) fmt.Println(post.Comments[0].Content) fmt.Println(post.Comments[0].Author) fmt.Println(post.Comments[1].Id) fmt.Println(post.Comments[1].Content) fmt.Println(post.Comments[1].Author) } ","date":"2021-11-20T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/go-web%E7%BC%96%E7%A8%8B-chapter7/","title":"Go Web编程 Chapter7"},{"content":"Go web编程 Chapter_6 Storing_Data csv_store package main import ( \u0026#34;encoding/csv\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; ) type Post struct { Id int Content string Author string } func main() { // creating a CSV file csvFile, err := os.Create(\u0026#34;posts.csv\u0026#34;) if err != nil { panic(err) } defer csvFile.Close() allPosts := []Post{ Post{Id: 1, Content: \u0026#34;Hello World!\u0026#34;, Author: \u0026#34;Sau Sheong\u0026#34;}, Post{Id: 2, Content: \u0026#34;Bonjour Monde!\u0026#34;, Author: \u0026#34;Pierre\u0026#34;}, Post{Id: 3, Content: \u0026#34;Hola Mundo!\u0026#34;, Author: \u0026#34;Pedro\u0026#34;}, Post{Id: 4, Content: \u0026#34;Greetings Earthlings!\u0026#34;, Author: \u0026#34;Sau Sheong\u0026#34;}, } writer := csv.NewWriter(csvFile) for _, post := range allPosts { line := []string{strconv.Itoa(post.Id), post.Content, post.Author} err := writer.Write(line) if err != nil { panic(err) } } writer.Flush() // reading a CSV file file, err := os.Open(\u0026#34;posts.csv\u0026#34;) if err != nil { panic(err) } defer file.Close() reader := csv.NewReader(file) reader.FieldsPerRecord = -1 record, err := reader.ReadAll() if err != nil { panic(err) } var posts []Post for _, item := range record { id, _ := strconv.ParseInt(item[0], 0, 0) post := Post{Id: int(id), Content: item[1], Author: item[2]} posts = append(posts, post) } fmt.Println(posts[0].Id) fmt.Println(posts[0].Content) fmt.Println(posts[0].Author) } gob_store package main import ( \u0026#34;bytes\u0026#34; \u0026#34;encoding/gob\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; ) type Post struct { Id int Content string Author string } // store data func store(data interface{}, filename string) { buffer := new(bytes.Buffer) encoder := gob.NewEncoder(buffer) err := encoder.Encode(data) if err != nil { panic(err) } err = ioutil.WriteFile(filename, buffer.Bytes(), 0600) if err != nil { panic(err) } } // load the data func load(data interface{}, filename string) { raw, err := ioutil.ReadFile(filename) if err != nil { panic(err) } buffer := bytes.NewBuffer(raw) dec := gob.NewDecoder(buffer) err = dec.Decode(data) if err != nil { panic(err) } } func main() { post := Post{Id: 1, Content: \u0026#34;Hello World!\u0026#34;, Author: \u0026#34;Sau Sheong\u0026#34;} store(post, \u0026#34;post1\u0026#34;) var postRead Post load(\u0026amp;postRead, \u0026#34;post1\u0026#34;) fmt.Println(postRead) } gorm_store package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/jinzhu/gorm\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; \u0026#34;time\u0026#34; ) type Post struct { Id int Content string Author string `sql:\u0026#34;not null\u0026#34;` Comments []Comment CreatedAt time.Time } type Comment struct { Id int Content string Author string `sql:\u0026#34;not null\u0026#34;` PostId int CreatedAt time.Time } var Db *gorm.DB // connect to the Db func init() { var err error Db, err = gorm.Open(\u0026#34;postgres\u0026#34;, \u0026#34;user=gwp dbname=gwp password=gwp sslmode=disable\u0026#34;) if err != nil { panic(err) } Db.AutoMigrate(\u0026amp;Post{}, \u0026amp;Comment{}) } func main() { post := Post{Content: \u0026#34;Hello World!\u0026#34;, Author: \u0026#34;Sau Sheong\u0026#34;} fmt.Println(post) // {0 Hello World! Sau Sheong [] 0001-01-01 00:00:00 +0000 UTC} // Create a post Db.Create(\u0026amp;post) fmt.Println(post) // {1 Hello World! Sau Sheong [] 2015-04-13 11:38:50.91815604 +0800 SGT} // Add a comment comment := Comment{Content: \u0026#34;Good post!\u0026#34;, Author: \u0026#34;Joe\u0026#34;} Db.Model(\u0026amp;post).Association(\u0026#34;Comments\u0026#34;).Append(comment) // Get comments from a post var readPost Post Db.Where(\u0026#34;author = $1\u0026#34;, \u0026#34;Sau Sheong\u0026#34;).First(\u0026amp;readPost) var comments []Comment Db.Model(\u0026amp;readPost).Related(\u0026amp;comments) fmt.Println(comments[0]) // {1 Good post! Joe 1 2015-04-13 11:38:50.920377 +0800 SGT} } map_store package main import ( \u0026#34;fmt\u0026#34; ) type Post struct { Id int Content string Author string } var PostById map[int]*Post var PostsByAuthor map[string][]*Post func store(post Post) { PostById[post.Id] = \u0026amp;post PostsByAuthor[post.Author] = append(PostsByAuthor[post.Author], \u0026amp;post) } func main() { PostById = make(map[int]*Post) PostsByAuthor = make(map[string][]*Post) post1 := Post{Id: 1, Content: \u0026#34;Hello World!\u0026#34;, Author: \u0026#34;Sau Sheong\u0026#34;} post2 := Post{Id: 2, Content: \u0026#34;Bonjour Monde!\u0026#34;, Author: \u0026#34;Pierre\u0026#34;} post3 := Post{Id: 3, Content: \u0026#34;Hola Mundo!\u0026#34;, Author: \u0026#34;Pedro\u0026#34;} post4 := Post{Id: 4, Content: \u0026#34;Greetings Earthlings!\u0026#34;, Author: \u0026#34;Sau Sheong\u0026#34;} store(post1) store(post2) store(post3) store(post4) fmt.Println(PostById[1]) fmt.Println(PostById[2]) for _, post := range PostsByAuthor[\u0026#34;Sau Sheong\u0026#34;] { fmt.Println(post) } for _, post := range PostsByAuthor[\u0026#34;Pedro\u0026#34;] { fmt.Println(post) } } read_write_files package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) func main() { data := []byte(\u0026#34;Hello World!\\n\u0026#34;) // write to file and read from file using WriteFile and ReadFile err := ioutil.WriteFile(\u0026#34;data1\u0026#34;, data, 0644) if err != nil { panic(err) } read1, _ := ioutil.ReadFile(\u0026#34;data1\u0026#34;) fmt.Print(string(read1)) // write to file and read from file using the File struct file1, _ := os.Create(\u0026#34;data2\u0026#34;) defer file1.Close() bytes, _ := file1.Write(data) fmt.Printf(\u0026#34;Wrote %d bytes to file\\n\u0026#34;, bytes) file2, _ := os.Open(\u0026#34;data2\u0026#34;) defer file2.Close() read2 := make([]byte, len(data)) bytes, _ = file2.Read(read2) fmt.Printf(\u0026#34;Read %d bytes from file\\n\u0026#34;, bytes) fmt.Println(string(read2)) } sql_store1 package main import ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; ) type Post struct { Id int Content string Author string } var Db *sql.DB // connect to the Db func init() { var err error Db, err = sql.Open(\u0026#34;postgres\u0026#34;, \u0026#34;user=gwp dbname=gwp password=gwp sslmode=disable\u0026#34;) if err != nil { panic(err) } } // get all posts func Posts(limit int) (posts []Post, err error) { rows, err := Db.Query(\u0026#34;select id, content, author from posts limit $1\u0026#34;, limit) if err != nil { return } for rows.Next() { post := Post{} err = rows.Scan(\u0026amp;post.Id, \u0026amp;post.Content, \u0026amp;post.Author) if err != nil { return } posts = append(posts, post) } rows.Close() return } // Get a single post func GetPost(id int) (post Post, err error) { post = Post{} err = Db.QueryRow(\u0026#34;select id, content, author from posts where id = $1\u0026#34;, id).Scan(\u0026amp;post.Id, \u0026amp;post.Content, \u0026amp;post.Author) return } // Create a new post func (post *Post) Create() (err error) { statement := \u0026#34;insert into posts (content, author) values ($1, $2) returning id\u0026#34; stmt, err := Db.Prepare(statement) if err != nil { return } defer stmt.Close() err = stmt.QueryRow(post.Content, post.Author).Scan(\u0026amp;post.Id) return } // Update a post func (post *Post) Update() (err error) { _, err = Db.Exec(\u0026#34;update posts set content = $2, author = $3 where id = $1\u0026#34;, post.Id, post.Content, post.Author) return } // Delete a post func (post *Post) Delete() (err error) { _, err = Db.Exec(\u0026#34;delete from posts where id = $1\u0026#34;, post.Id) return } // Delete all posts func DeleteAll() (err error) { _, err = Db.Exec(\u0026#34;delete from posts\u0026#34;) return } func main() { post := Post{Content: \u0026#34;Hello World!\u0026#34;, Author: \u0026#34;Sau Sheong\u0026#34;} // Create a post fmt.Println(post) // {0 Hello World! Sau Sheong} post.Create() fmt.Println(post) // {1 Hello World! Sau Sheong} // Get one post readPost, _ := GetPost(post.Id) fmt.Println(readPost) // {1 Hello World! Sau Sheong} // Update the post readPost.Content = \u0026#34;Bonjour Monde!\u0026#34; readPost.Author = \u0026#34;Pierre\u0026#34; readPost.Update() // Get all posts posts, _ := Posts(10) fmt.Println(posts) // [{1 Bonjour Monde! Pierre}] // Delete the post readPost.Delete() // Get all posts posts, _ = Posts(10) fmt.Println(posts) // [] // Delete all posts // DeleteAll() } setup.sql\ndrop table posts; create table posts ( id serial primary key, content text, author varchar(255) ); sql_store2 package main import ( \u0026#34;database/sql\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; ) type Post struct { Id int Content string Author string Comments []Comment } type Comment struct { Id int Content string Author string Post *Post } var Db *sql.DB // connect to the Db func init() { var err error Db, err = sql.Open(\u0026#34;postgres\u0026#34;, \u0026#34;user=gwp dbname=gwp password=gwp sslmode=disable\u0026#34;) if err != nil { panic(err) } } func (comment *Comment) Create() (err error) { if comment.Post == nil { err = errors.New(\u0026#34;Post not found\u0026#34;) return } err = Db.QueryRow(\u0026#34;insert into comments (content, author, post_id) values ($1, $2, $3) returning id\u0026#34;, comment.Content, comment.Author, comment.Post.Id).Scan(\u0026amp;comment.Id) return } // Get a single post func GetPost(id int) (post Post, err error) { post = Post{} post.Comments = []Comment{} err = Db.QueryRow(\u0026#34;select id, content, author from posts where id = $1\u0026#34;, id).Scan(\u0026amp;post.Id, \u0026amp;post.Content, \u0026amp;post.Author) rows, err := Db.Query(\u0026#34;select id, content, author from comments where post_id = $1\u0026#34;, id) if err != nil { return } for rows.Next() { comment := Comment{Post: \u0026amp;post} err = rows.Scan(\u0026amp;comment.Id, \u0026amp;comment.Content, \u0026amp;comment.Author) if err != nil { return } post.Comments = append(post.Comments, comment) } rows.Close() return } // Create a new post func (post *Post) Create() (err error) { err = Db.QueryRow(\u0026#34;insert into posts (content, author) values ($1, $2) returning id\u0026#34;, post.Content, post.Author).Scan(\u0026amp;post.Id) return } func main() { post := Post{Content: \u0026#34;Hello World!\u0026#34;, Author: \u0026#34;Sau Sheong\u0026#34;} post.Create() // Add a comment comment := Comment{Content: \u0026#34;Good post!\u0026#34;, Author: \u0026#34;Joe\u0026#34;, Post: \u0026amp;post} comment.Create() readPost, _ := GetPost(post.Id) fmt.Println(readPost) // {1 Hello World! Sau Sheong [{1 Good post! Joe 0xc20802a1c0}]} fmt.Println(readPost.Comments) // [{1 Good post! Joe 0xc20802a1c0}] fmt.Println(readPost.Comments[0].Post) // \u0026amp;{1 Hello World! Sau Sheong [{1 Good post! Joe 0xc20802a1c0}]} } setup.sql\ndrop table posts cascade; drop table comments; create table posts ( id serial primary key, content text, author varchar(255) ); create table comments ( id serial primary key, content text, author varchar(255), post_id integer references posts(id) ); sqlx_store package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/jmoiron/sqlx\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; ) type Post struct { Id int Content string AuthorName string `db: author` } var Db *sqlx.DB // connect to the Db func init() { var err error Db, err = sqlx.Open(\u0026#34;postgres\u0026#34;, \u0026#34;user=gwp dbname=gwp password=gwp sslmode=disable\u0026#34;) if err != nil { panic(err) } } // Get a single post func GetPost(id int) (post Post, err error) { post = Post{} err = Db.QueryRowx(\u0026#34;select id, content, author from posts where id = $1\u0026#34;, id).StructScan(\u0026amp;post) if err != nil { return } return } // Create a new post func (post *Post) Create() (err error) { err = Db.QueryRow(\u0026#34;insert into posts (content, author) values ($1, $2) returning id\u0026#34;, post.Content, post.AuthorName).Scan(\u0026amp;post.Id) return } func main() { post := Post{Content: \u0026#34;Hello World!\u0026#34;, AuthorName: \u0026#34;Sau Sheong\u0026#34;} post.Create() fmt.Println(post) // {1 Hello World! Sau Sheong}} } setup.sql\ndrop table posts; create table posts ( id serial primary key, content text, author varchar(255) ); ","date":"2021-11-12T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/go-web%E7%BC%96%E7%A8%8B-chapter6/","title":"Go Web编程 Chapter6"},{"content":"Go web编程 Chapter_5 Displaying_Content context_aware package main import ( \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { t, _ := template.ParseFiles(\u0026#34;tmpl.html\u0026#34;) content := `I asked: \u0026lt;i\u0026gt;\u0026#34;What\u0026#39;s up?\u0026#34;\u0026lt;/i\u0026gt;` t.Execute(w, content) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } tmpl.html\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt;{{ . }}\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;\u0026lt;a href=\u0026#34;/{{ . }}\u0026#34;\u0026gt;Path\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;\u0026lt;a href=\u0026#34;/?q={{ . }}\u0026#34;\u0026gt;Query\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;\u0026lt;a onclick=\u0026#34;f(\u0026#39;{{ . }}\u0026#39;)\u0026#34;\u0026gt;Onclick\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; costom_function package main import ( \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func formatDate(t time.Time) string { layout := \u0026#34;2006-01-02\u0026#34; return t.Format(layout) } func process(w http.ResponseWriter, r *http.Request) { funcMap := template.FuncMap{\u0026#34;fdate\u0026#34;: formatDate} t := template.New(\u0026#34;tmpl.html\u0026#34;).Funcs(funcMap) t, _ = t.ParseFiles(\u0026#34;tmpl.html\u0026#34;) t.Execute(w, time.Now()) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } tmpl.html\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt;The date/time is {{ . | fdate }}\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; include package main import ( \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { t, _ := template.ParseFiles(\u0026#34;t1.html\u0026#34;, \u0026#34;t2.html\u0026#34;) t.Execute(w, \u0026#34;Hello World!\u0026#34;) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } t1.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=9\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; This is t1.html before\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;This is the value of the dot in t1.html - [{{ . }}]\u0026lt;/div\u0026gt; \u0026lt;hr/\u0026gt; {{ template \u0026#34;t2.html\u0026#34; }} \u0026lt;hr/\u0026gt; \u0026lt;div\u0026gt; This is t1.html after\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; t2.html\n\u0026lt;div style=\u0026#34;background-color: yellow;\u0026#34;\u0026gt; This is t2.html\u0026lt;br/\u0026gt; This is the value of the dot in t2.html - [{{ . }}] \u0026lt;/div\u0026gt; iterator package main import ( \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { t, _ := template.ParseFiles(\u0026#34;tmpl.html\u0026#34;) daysOfWeek := []string{\u0026#34;Mon\u0026#34;, \u0026#34;Tue\u0026#34;, \u0026#34;Wed\u0026#34;, \u0026#34;Thu\u0026#34;, \u0026#34;Fri\u0026#34;, \u0026#34;Sat\u0026#34;, \u0026#34;Sun\u0026#34;} t.Execute(w, daysOfWeek) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } tmpl.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;ul\u0026gt; {{ range . }} \u0026lt;li\u0026gt;{{ . }}\u0026lt;/li\u0026gt; {{ end}} \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; nested1 package main import ( \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { t, _ := template.ParseFiles(\u0026#34;layout.html\u0026#34;) t.ExecuteTemplate(w, \u0026#34;layout\u0026#34;, \u0026#34;\u0026#34;) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } layout.html\n{{ define \u0026#34;layout\u0026#34; }} \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{ template \u0026#34;content\u0026#34; }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; {{ end }} {{ define \u0026#34;content\u0026#34; }} Hello World! {{ end }} nested2 package main import ( \u0026#34;html/template\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { rand.Seed(time.Now().Unix()) var t *template.Template if rand.Intn(10) \u0026gt; 5 { t, _ = template.ParseFiles(\u0026#34;layout.html\u0026#34;, \u0026#34;red_hello.html\u0026#34;) } else { t, _ = template.ParseFiles(\u0026#34;layout.html\u0026#34;, \u0026#34;blue_hello.html\u0026#34;) } t.ExecuteTemplate(w, \u0026#34;layout\u0026#34;, \u0026#34;\u0026#34;) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } blue_hello.html\n{{ define \u0026#34;content\u0026#34; }} \u0026lt;h1 style=\u0026#34;color: blue;\u0026#34;\u0026gt;Hello World!\u0026lt;/h1\u0026gt; {{ end }} layout.html\n{{ define \u0026#34;layout\u0026#34; }} \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{ template \u0026#34;content\u0026#34; }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; {{ end }} red_hello.html\n{{ define \u0026#34;content\u0026#34; }} \u0026lt;h1 style=\u0026#34;color: red;\u0026#34;\u0026gt;Hello World!\u0026lt;/h1\u0026gt; {{ end }} random_number package main import ( \u0026#34;html/template\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { t, _ := template.ParseFiles(\u0026#34;tmpl.html\u0026#34;) rand.Seed(time.Now().Unix()) t.Execute(w, rand.Intn(10) \u0026gt; 5) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } tmpl.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{ if . }} Number is greater than 5! {{ else }} Number is 5 or less! {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; set_dot package main import ( \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { t, _ := template.ParseFiles(\u0026#34;tmpl.html\u0026#34;) t.Execute(w, \u0026#34;hello\u0026#34;) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } tmpl.html\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt;The dot is {{ . }}\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; {{ with \u0026#34;world\u0026#34;}} Now the dot is set to {{ . }} {{ end }} \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;The dot is {{ . }} again\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; trigger_template package main import ( \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { t, _ := template.ParseFiles(\u0026#34;tmpl.html\u0026#34;) t.Execute(w, \u0026#34;Hello World!\u0026#34;) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } tmpl.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{ . }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; xss package main import ( \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;X-XSS-Protection\u0026#34;, \u0026#34;0\u0026#34;) t, _ := template.ParseFiles(\u0026#34;tmpl.html\u0026#34;) t.Execute(w, r.FormValue(\u0026#34;comment\u0026#34;)) t.Execute(w, template.HTML(r.FormValue(\u0026#34;comment\u0026#34;))) } func form(w http.ResponseWriter, r *http.Request) { t, _ := template.ParseFiles(\u0026#34;form.html\u0026#34;) t.Execute(w, nil) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) http.HandleFunc(\u0026#34;/\u0026#34;, form) server.ListenAndServe() } form.html\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;/process\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; Comment: \u0026lt;input name=\u0026#34;comment\u0026#34; type=\u0026#34;text\u0026#34; size=\u0026#34;50\u0026#34;\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;button id=\u0026#34;submit\u0026#34;\u0026gt;Submit\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; tmpl.html\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt;{{ . }}\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","date":"2021-10-31T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/go-web%E7%BC%96%E7%A8%8B-chapter5/","title":"Go Web编程 Chapter5"},{"content":"维保\n优化内存占用 提高sql执行效率 索引 性能分析 慢查询日志 多线程上传数据 以后要设定阀值 上传数据总量等于5w(估算)的时候,先上传,放置因为很久没上传的数据因为累积过多,导致一次性上传50w数据裂开 image-20211117085507371\r","date":"2021-10-28T10:24:40+08:00","permalink":"https://linjianshu.github.io/p/%E6%B4%BB%E8%BF%9E%E4%B8%8A%E7%BA%BF%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"活连上线学习文档"},{"content":"Go web编程 Chapter_4 Processing_Requests body package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func body(w http.ResponseWriter, r *http.Request) { len := r.ContentLength body := make([]byte, len) r.Body.Read(body) fmt.Fprintln(w, string(body)) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/body\u0026#34;, body) server.ListenAndServe() } cookie package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func setCookie(w http.ResponseWriter, r *http.Request) { c1 := http.Cookie{ Name: \u0026#34;first_cookie\u0026#34;, Value: \u0026#34;Go Web Programming\u0026#34;, HttpOnly: true, } c2 := http.Cookie{ Name: \u0026#34;second_cookie\u0026#34;, Value: \u0026#34;Manning Publications Co\u0026#34;, HttpOnly: true, } http.SetCookie(w, \u0026amp;c1) http.SetCookie(w, \u0026amp;c2) } func getCookie(w http.ResponseWriter, r *http.Request) { c1, err := r.Cookie(\u0026#34;first_cookie\u0026#34;) if err != nil { fmt.Fprintln(w, \u0026#34;Cannot get the first cookie\u0026#34;) } cs := r.Cookies() fmt.Fprintln(w, c1) fmt.Fprintln(w, cs) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/set_cookie\u0026#34;, setCookie) http.HandleFunc(\u0026#34;/get_cookie\u0026#34;, getCookie) server.ListenAndServe() } cookie_flash package main import ( \u0026#34;encoding/base64\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func setMessage(w http.ResponseWriter, r *http.Request) { msg := []byte(\u0026#34;Hello World!\u0026#34;) c := http.Cookie{ Name: \u0026#34;flash\u0026#34;, Value: base64.URLEncoding.EncodeToString(msg), } http.SetCookie(w, \u0026amp;c) } func showMessage(w http.ResponseWriter, r *http.Request) { c, err := r.Cookie(\u0026#34;flash\u0026#34;) if err != nil { if err == http.ErrNoCookie { fmt.Fprintln(w, \u0026#34;No message found\u0026#34;) } } else { rc := http.Cookie{ Name: \u0026#34;flash\u0026#34;, MaxAge: -1, Expires: time.Unix(1, 0), } http.SetCookie(w, \u0026amp;rc) val, _ := base64.URLEncoding.DecodeString(c.Value) fmt.Fprintln(w, string(val)) } } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/set_message\u0026#34;, setMessage) http.HandleFunc(\u0026#34;/show_message\u0026#34;, showMessage) server.ListenAndServe() } fileupload package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { r.ParseMultipartForm(1024) fileHeader := r.MultipartForm.File[\u0026#34;uploaded\u0026#34;][0] file, err := fileHeader.Open() if err == nil { data, err := ioutil.ReadAll(file) if err == nil { fmt.Fprintln(w, string(data)) } } } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } client.html网页\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;http://localhost:8080/process?hello=world\u0026amp;thread=123\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;hello\u0026#34; value=\u0026#34;sau sheong\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;post\u0026#34; value=\u0026#34;456\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;file\u0026#34; name=\u0026#34;uploaded\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; form package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { r.ParseForm() fmt.Fprintln(w, r.Form) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } client.html网页\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;http://127.0.0.1:8080/process?hello=world\u0026amp;thread=123\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;application/x-www-form-urlencoded\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;hello\u0026#34; value=\u0026#34;sau sheong\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;post\u0026#34; value=\u0026#34;456\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;/\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; formfile package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; ) func process(w http.ResponseWriter, r *http.Request) { file, _, err := r.FormFile(\u0026#34;uploaded\u0026#34;) if err == nil { data, err := ioutil.ReadAll(file) if err == nil { fmt.Fprintln(w, string(data)) } } } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/process\u0026#34;, process) server.ListenAndServe() } client.html网页\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;http://localhost:8080/process?hello=world\u0026amp;thread=123\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;hello\u0026#34; value=\u0026#34;sau sheong\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;post\u0026#34; value=\u0026#34;456\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;file\u0026#34; name=\u0026#34;uploaded\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; header package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func headers(w http.ResponseWriter, r *http.Request) { h := r.Header fmt.Fprintln(w, h) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/headers\u0026#34;, headers) server.ListenAndServe() } write package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) type Post struct { User string Threads []string } func writeExample(w http.ResponseWriter, r *http.Request) { str := `\u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;Go Web Programming\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;\u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;` w.Write([]byte(str)) } func writeHeaderExample(w http.ResponseWriter, r *http.Request) { w.WriteHeader(501) fmt.Fprintln(w, \u0026#34;No such service, try next door\u0026#34;) } func headerExample(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Location\u0026#34;, \u0026#34;http://google.com\u0026#34;) w.WriteHeader(302) } func jsonExample(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) post := \u0026amp;Post{ User: \u0026#34;Sau Sheong\u0026#34;, Threads: []string{\u0026#34;first\u0026#34;, \u0026#34;second\u0026#34;, \u0026#34;third\u0026#34;}, } json, _ := json.Marshal(post) w.Write(json) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/write\u0026#34;, writeExample) http.HandleFunc(\u0026#34;/writeheader\u0026#34;, writeHeaderExample) http.HandleFunc(\u0026#34;/redirect\u0026#34;, headerExample) http.HandleFunc(\u0026#34;/json\u0026#34;, jsonExample) server.ListenAndServe() } ","date":"2021-10-20T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/go-web%E7%BC%96%E7%A8%8B-chapter4/","title":"Go Web编程 Chapter4"},{"content":"Go web编程 Chapter_3 Handling_Requests chain_handler package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) type HelloHandler struct{} func (h HelloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello!\u0026#34;) } func log(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { fmt.Printf(\u0026#34;Handler called - %T\\n\u0026#34;, h) h.ServeHTTP(w, r) }) } func protect(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { // some code to make sure the user is authorized h.ServeHTTP(w, r) }) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } hello := HelloHandler{} http.Handle(\u0026#34;/hello\u0026#34;, protect(log(hello))) server.ListenAndServe() } chain_handlerfunc package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;runtime\u0026#34; ) func hello(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello!\u0026#34;) } func log(h http.HandlerFunc) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { name := runtime.FuncForPC(reflect.ValueOf(h).Pointer()).Name() fmt.Println(\u0026#34;Handler function called - \u0026#34; + name) h(w, r) } } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/hello\u0026#34;, log(hello)) server.ListenAndServe() } configurable package main import ( \u0026#34;net/http\u0026#34; ) func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, Handler: nil, } server.ListenAndServe() } gencert package main import ( \u0026#34;crypto/rand\u0026#34; \u0026#34;crypto/rsa\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;crypto/x509/pkix\u0026#34; \u0026#34;encoding/pem\u0026#34; \u0026#34;math/big\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) func main() { max := new(big.Int).Lsh(big.NewInt(1), 128) serialNumber, _ := rand.Int(rand.Reader, max) subject := pkix.Name{ Organization: []string{\u0026#34;Manning Publications Co.\u0026#34;}, OrganizationalUnit: []string{\u0026#34;Books\u0026#34;}, CommonName: \u0026#34;Go Web Programming\u0026#34;, } template := x509.Certificate{ SerialNumber: serialNumber, Subject: subject, NotBefore: time.Now(), NotAfter: time.Now().Add(365 * 24 * time.Hour), KeyUsage: x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature, ExtKeyUsage: []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth}, IPAddresses: []net.IP{net.ParseIP(\u0026#34;127.0.0.1\u0026#34;)}, } pk, _ := rsa.GenerateKey(rand.Reader, 2048) derBytes, _ := x509.CreateCertificate(rand.Reader, \u0026amp;template, \u0026amp;template, \u0026amp;pk.PublicKey, pk) certOut, _ := os.Create(\u0026#34;cert.pem\u0026#34;) pem.Encode(certOut, \u0026amp;pem.Block{Type: \u0026#34;CERTIFICATE\u0026#34;, Bytes: derBytes}) certOut.Close() keyOut, _ := os.Create(\u0026#34;key.pem\u0026#34;) pem.Encode(keyOut, \u0026amp;pem.Block{Type: \u0026#34;RSA PRIVATE KEY\u0026#34;, Bytes: x509.MarshalPKCS1PrivateKey(pk)}) keyOut.Close() } handler package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) type MyHandler struct{} func (h *MyHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello World!\u0026#34;) } func main() { handler := MyHandler{} server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, Handler: \u0026amp;handler, } server.ListenAndServe() } handlerfunc package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func hello(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello!\u0026#34;) } func world(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;World!\u0026#34;) } func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/hello\u0026#34;, hello) http.HandleFunc(\u0026#34;/world\u0026#34;, world) server.ListenAndServe() } httprouter package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/julienschmidt/httprouter\u0026#34; \u0026#34;net/http\u0026#34; ) func hello(w http.ResponseWriter, r *http.Request, p httprouter.Params) { fmt.Fprintf(w, \u0026#34;hello, %s!\\n\u0026#34;, p.ByName(\u0026#34;name\u0026#34;)) } func main() { mux := httprouter.New() mux.GET(\u0026#34;/hello/:name\u0026#34;, hello) server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, Handler: mux, } server.ListenAndServe() } https package main import ( \u0026#34;net/http\u0026#34; ) func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, Handler: nil, } server.ListenAndServeTLS(\u0026#34;cert.pem\u0026#34;, \u0026#34;key.pem\u0026#34;) } multihandler package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) type HelloHandler struct{} func (h *HelloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello!\u0026#34;) } type WorldHandler struct{} func (h *WorldHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;World!\u0026#34;) } func main() { hello := HelloHandler{} world := WorldHandler{} server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } http.Handle(\u0026#34;/hello\u0026#34;, \u0026amp;hello) http.Handle(\u0026#34;/world\u0026#34;, \u0026amp;world) server.ListenAndServe() } simplest package main import ( \u0026#34;net/http\u0026#34; ) func main() { http.ListenAndServe(\u0026#34;\u0026#34;, nil) } ","date":"2021-10-15T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/go-web%E7%BC%96%E7%A8%8B-chapter3/","title":"Go Web编程 Chapter3"},{"content":"Mysql高级学习文档 mysql的架构介绍 mysql简介 mysqllinux版安装 mysql配置文件 mysql逻辑架构介绍 mysql存储引擎 索引优化分析 性能下降sql慢是执行时间长还是等待时间长 常见通用的join查询 索引简介 性能分析 索引优化 查询截取分析 查询优化 慢查询日志 批量数据脚本 show profile 全局查询日志 mysql锁机制 锁的分类 主从复制 主从配置 mysql简介 高级mysql 完整的mysql优化\nmysql内核 sql优化攻城狮 mysql服务器的优化 各种参数常量设定 查询语句优化 主从复制 软硬件升级 容灾备份 sql编程 mysqllinux版的安装 image-20211012195826053\r#查看当前ubuntu版本 yourtreedad@yourtreedad:~$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.3 LTS Release: 20.04 Codename: focal yourtreedad@yourtreedad:~$ 准备工作\n#切换到root账户 yourtreedad@yourtreedad:~$ sudo passwd root New password: Retype new password: passwd: password updated successfully yourtreedad@yourtreedad:~$ su root Password: root@yourtreedad:/home/yourtreedad# #查看电脑里有没有mysql root@yourtreedad:/home/yourtreedad# service mysql status * MySQL is stopped. root@yourtreedad:/home/yourtreedad# mysql --version mysql Ver 8.0.26-0ubuntu0.20.04.2 for Linux on x86_64 ((Ubuntu)) root@yourtreedad:/home/yourtreedad# service mysql start * Starting MySQL database server mysqld su: warning: cannot change directory to /nonexistent: No such file or directory #那就彻底卸载了 root@yourtreedad:/home/yourtreedad# sudo apt-get remove mysql-* root@yourtreedad:/home/yourtreedad# sudo rm -rf /etc/mysql/ root@yourtreedad:/home/yourtreedad# dpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P dpkg: error: --purge needs at least one package name argument #如果出现这个错误 dpkg: error: --purge needs at least one package name argument，说明已经清空完毕了 #全部删除了 root@yourtreedad:/home/yourtreedad# service mysql status mysql: unrecognized service root@yourtreedad:/home/yourtreedad# mysql --version bash: /usr/bin/mysql: No such file or directory root@yourtreedad:/home/yourtreedad# #更新到最新 安装rpm root@yourtreedad:/opt# apt-get update root@yourtreedad:/home/yourtreedad# apt-get upgrade root@yourtreedad:/home/yourtreedad# apt-get install rpm #使用rpm判断当前系统是否安装过mysql root@yourtreedad:/home/yourtreedad# rpm -qa|grep -i mysql #安装mysql root@yourtreedad:/opt# sudo apt-get install mysql-server mysql-client #查看是否安装成功 root@yourtreedad:/# id yourtreedad uid=1000(yourtreedad) gid=1000(yourtreedad) groups=1000(yourtreedad),4(adm),20(dialout),24(cdrom),25(floppy),27(sudo),29(audio),30(dip),44(video),46(plugdev),117(netdev) root@yourtreedad:/# cat /etc/passwd|grep mysql mysql:x:112:119:MySQL Server,,,:/var/lib/mysql/:/bin/false root@yourtreedad:/# cat /etc/group|grep mysql mysql:x:119: root@yourtreedad:/# mysqladmin --version mysqladmin Ver 8.0.26-0ubuntu0.20.04.3 for Linux on x86_64 ((Ubuntu)) root@yourtreedad:/# root@yourtreedad:/# service mysql start root@yourtreedad:/# ps -ef|grep mysql mysql 18675 1 0 21:03 ? 00:00:00 /bin/sh /usr/bin/mysqld_safe mysql 18822 18675 0 21:03 ? 00:00:00 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib/mysql/plugin --log-error=/var/log/mysql/error.log --pid-file=yourtreedad.pid root 19055 16743 0 21:14 tty1 00:00:00 grep --color=auto mysql https://www.cnblogs.com/duolamengxiong/p/13650684.html\nmysql启停和自动运行 #查看运行时间 root@yourtreedad:/home/yourtreedad# top top - 21:17:30 up 1:21, 0 users, load average: 0.52, 0.58, 0.59 Tasks: 8 total, 1 running, 7 sleeping, 0 stopped, 0 zombie %Cpu(s): 4.0 us, 2.9 sy, 0.0 ni, 92.7 id, 0.0 wa, 0.4 hi, 0.0 si, 0.0 st MiB Mem : 32674.8 total, 21949.1 free, 10501.7 used, 224.0 buff/cache MiB Swap: 38400.2 total, 38322.8 free, 77.3 used. 22042.5 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 8944 328 288 S 0.0 0.0 0:00.18 init 16725 root 20 0 8952 232 184 S 0.0 0.0 0:00.00 init 16726 yourtre+ 20 0 18096 3588 3484 S 0.0 0.0 0:00.13 bash 18675 mysql 20 0 10656 812 780 S 0.0 0.0 0:00.10 mysqld_safe 18822 mysql 20 0 2603072 299920 20628 S 0.0 0.9 0:00.75 mysqld 19087 root 20 0 18412 2592 2568 S 0.0 0.0 0:00.03 su 19088 root 20 0 17008 2396 2304 S 0.0 0.0 0:00.07 bash 19201 root 20 0 18924 2152 1528 R 0.0 0.0 0:00.04 top #直接mysql 就进来了 root@yourtreedad:/home/yourtreedad# mysql Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 24 mysql默认没有密码,所以我们这里咩有输入密码就直接连上了\n设置登陆密码\nroot@yourtreedad:/home/yourtreedad# /usr/bin/mysqladmin -u root password 123456 mysqladmin: [Warning] Using a password on the command line interface can be insecure. Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety. image-20211012213458570\rmysql\u0026gt; create database student ; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; exit Bye root@yourtreedad:/var/lib/mysql# ls -l total 193956 -rw-r----- 1 mysql mysql 196608 Oct 12 21:33 \u0026#39;#ib_16384_0.dblwr\u0026#39; -rw-r----- 1 mysql mysql 8585216 Oct 12 20:19 \u0026#39;#ib_16384_1.dblwr\u0026#39; drwxr-x--- 1 mysql mysql 512 Oct 12 21:03 \u0026#39;#innodb_temp\u0026#39; -rw-r----- 1 mysql mysql 56 Oct 12 20:19 auto.cnf -rw-r----- 1 mysql mysql 12582912 Oct 12 21:33 ibdata1 -rw-r----- 1 mysql mysql 12582912 Oct 12 21:03 ibtmp1 drwxr-x--- 1 mysql mysql 512 Oct 12 20:19 mysql -rw-r----- 1 mysql mysql 25165824 Oct 12 21:33 mysql.ibd drwxr-x--- 1 mysql mysql 512 Oct 12 21:33 student drwxr-x--- 1 mysql mysql 512 Oct 12 20:19 sys 修改配置文件位置\nimage-20211012213843009\r弄好了重启mysql\nmysql\u0026gt; insert into user values (2,\u0026#39;张三\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from user ; +----+--------+ | id | name | +----+--------+ | 1 | z3 | | 2 | 张三 | +----+--------+ 2 rows in set (0.00 sec) #有时候字符集没弄好 要弄成utf-8 mysql\u0026gt; show variables like \u0026#39;%char%\u0026#39;; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8mb3 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.01 sec) 修改字符集和数据存储路径\n必须在字符集修改之后才能支持中文,之前的数据库好像不行\nmysql配置文件 二进制日志 log - bin 主从复制 错误日志 mysqlerror.error 查询日志log 默认关闭,记录查询的sql语句,如果开启会减低mysql的整体性能 数据文件 两个系统不一致 windows mysql5.0\\data目录下有很多库 linux 默认路径 /var/lib/mysql frm文件 存放表结构 myd文件 存放表数据 myi文件 存放表索引 mysql逻辑架构介绍 image-20211014205109147\r第一层:连接层 最上层是一些客户端和连接服务,包含本地sock通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信.主要完成一些类似于连接处理/授权认证及相关的安全方案.在该层上引入了线程池的概念,为通过认证安全接入的客户端提供线程.同样在该层上可以实现基于ssl的安全连接.服务器也会为安全接入的每个客户端验证它所具有的操作权限.\n第二层:数据库连接池 备份恢复安全集群容灾 存储过程 视图 触发器 解析器 优化器 缓存 第二层架构主要完成大多数的核心服务功能,如sql接口,并完成缓存的查询,sql的分析和优化以部分内置函数的执行.所有跨存储引擎的功能也在这一层实现,如过程/函数等.在该层,服务器会解析查询并创建相应的内部解析树,并对其完成相应的优化如确定查询表的顺序,是否利用索引等,最后生成相应的执行操作.如果是select语句,服务器还会查询内部的缓存,如果缓存空间足够大,这样在解决大量读操作的环境中能够很好的提升系统的性能.\n第三层:可插拔存储引擎 存储引擎层,存储引擎真正的负责了mysql中数据的存储和提取,服务器通过api与存储引擎进行通信.不同的存储引擎具有的功能不同,这样我们可以根据自己的实际需要进行选取.后面介绍myisam和innodb\n第四层:文件系统和文件日志 数据存储层,主要是将数据存储在运行于裸设备的文件系统上,并完成与存储引擎的交互\n和其他的数据库相比,mysql有点与众不同,它的架构可以在多种不同场景中应用并发挥良好作用.主要体现在存储引擎的架构上,插件式的存储引擎将查询处理和其他的系统任务以及数据的存储提取相分离.这种架构可以根据业务的需求和实际需要选择合适的存储引擎\nmysql存储引擎 mysql\u0026gt; show engines ; +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ | Engine | Support | Comment | Transactions | XA | Savepoints | +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ | MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO | | MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO | | CSV | YES | CSV storage engine | NO | NO | NO | | FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL | | PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO | | MyISAM | YES | MyISAM storage engine #查看存储引擎 mysql\u0026gt; show variables like \u0026#39;%storage_engine%\u0026#39; ; +---------------------------------+-----------+ | Variable_name | Value | +---------------------------------+-----------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | disabled_storage_engines | | | internal_tmp_mem_storage_engine | TempTable | +---------------------------------+-----------+ image-20211014211207589\rimage-20211014211324759\r索引优化 优化分析 性能下降sql慢/执行时间长/等待时间长\n查询语句写的烂 索引失效 单值 复合 #创建索引 mysql\u0026gt; create index idx_beauty_name on beauty(name); Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; create index idx_beauty_name_sex on beauty(name,sex); Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 #查看索引 mysql\u0026gt; show index from beauty ; +--------+------------+---------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +--------+------------+---------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | beauty | 0 | PRIMARY | 1 | id | A | 13 | NULL | NULL | | BTREE | | | YES | NULL | | beauty | 1 | idx_beauty_name | 1 | name | A | 12 | NULL | NULL | | BTREE | | | YES | NULL | | beauty | 1 | idx_beauty_name_sex | 1 | name | A | 12 | NULL | NULL | | BTREE | | | YES | NULL | | beauty | 1 | idx_beauty_name_sex | 2 | sex | A | 12 | NULL | NULL | YES | BTREE | | | YES | NULL | +--------+------------+---------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 关联查询太多join(设计缺陷或不得已的需求) 服务器调优以各个参数设置(缓冲/线程数) 常见的join查询 sql的执行顺序\n手写 select from join on where group by having order by limit 机读 from on join where group by having select dinstinct order by limit image-20211014213300494\rjoin 图\nimage-20211014213503395\rimage-20211014213909722\rmysql\u0026gt; CREATE TABLE tbl_dept ( -\u0026gt; id INT(11) NOT NULL AUTO_INCREMENT, -\u0026gt; deptName VARCHAR(30) DEFAULT NULL, -\u0026gt; locAdd VARCHAR(40) DEFAULT NULL, -\u0026gt; PRIMARY KEY (id) -\u0026gt; ) ENGINE INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; Query OK, 0 rows affected, 2 warnings (0.02 sec) mysql\u0026gt; CREATE TABLE tbl_emp ( -\u0026gt; id INT(11) NOT NULL AUTO_INCREMENT, -\u0026gt; name VARCHAR(20) DEFAULT NULL, -\u0026gt; deptld INT(11) DEFAULT NULL, -\u0026gt; PRIMARY KEY(id), -\u0026gt; KEY fk_dept_id(deptld) -\u0026gt; #CONSTRAINT fk_dept_id FOREIGNKEY(deptld) REFERENCES tbl_dept(id) -\u0026gt; )ENGINE INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; Query OK, 0 rows affected, 3 warnings (0.02 sec) mysql\u0026gt; select * from tbl_emp ; +----+------+--------+ | id | name | deptld | +----+------+--------+ | 1 | z3 | 1 | | 2 | z4 | 1 | | 3 | z5 | 1 | | 4 | w5 | 2 | | 5 | w6 | 2 | | 6 | s7 | 3 | | 7 | s8 | 4 | | 8 | s9 | 51 | +----+------+--------+ 8 rows in set (0.00 sec) mysql\u0026gt; select * from tbl_dept ; +----+----------+--------+ | id | deptName | locAdd | +----+----------+--------+ | 1 | RD | 11 | | 2 | HR | 12 | | 3 | MK | 13 | | 4 | MIS | 14 | | 5 | FD | 15 | +----+----------+--------+ 5 rows in set (0.00 sec) #内连接 就么有8员工 和 5部门 mysql\u0026gt; select e.* , d.* from tbl_emp e join tbl_dept d on e.deptld = d.id ; +----+------+--------+----+----------+--------+ | id | name | deptld | id | deptName | locAdd | +----+------+--------+----+----------+--------+ | 1 | z3 | 1 | 1 | RD | 11 | | 2 | z4 | 1 | 1 | RD | 11 | | 3 | z5 | 1 | 1 | RD | 11 | | 4 | w5 | 2 | 2 | HR | 12 | | 5 | w6 | 2 | 2 | HR | 12 | | 6 | s7 | 3 | 3 | MK | 13 | | 7 | s8 | 4 | 4 | MIS | 14 | +----+------+--------+----+----------+--------+ #左外连接 没有5部门 mysql\u0026gt; select e.* , d.* from tbl_emp e left join tbl_dept d on e.deptid = d.id ; +----+------+--------+------+----------+--------+ | id | name | deptid | id | deptName | locAdd | +----+------+--------+------+----------+--------+ | 1 | z3 | 1 | 1 | RD | 11 | | 2 | z4 | 1 | 1 | RD | 11 | | 3 | z5 | 1 | 1 | RD | 11 | | 4 | w5 | 2 | 2 | HR | 12 | | 5 | w6 | 2 | 2 | HR | 12 | | 6 | s7 | 3 | 3 | MK | 13 | | 7 | s8 | 4 | 4 | MIS | 14 | | 8 | s9 | 51 | NULL | NULL | NULL | +----+------+--------+------+----------+--------+ #右外连接 没有8员工 mysql\u0026gt; select e.* , d.* from tbl_emp e right join tbl_dept d on e.deptid = d.id ; +------+------+--------+----+----------+--------+ | id | name | deptid | id | deptName | locAdd | +------+------+--------+----+----------+--------+ | 1 | z3 | 1 | 1 | RD | 11 | | 2 | z4 | 1 | 1 | RD | 11 | | 3 | z5 | 1 | 1 | RD | 11 | | 4 | w5 | 2 | 2 | HR | 12 | | 5 | w6 | 2 | 2 | HR | 12 | | 6 | s7 | 3 | 3 | MK | 13 | | 7 | s8 | 4 | 4 | MIS | 14 | | NULL | NULL | NULL | 5 | FD | 15 | +------+------+--------+----+----------+--------+ #只有左边 只有8员工 mysql\u0026gt; select e.* , d.* from tbl_emp e left join tbl_dept d on e.deptid = d.id where d.id is null ; +----+------+--------+------+----------+--------+ | id | name | deptid | id | deptName | locAdd | +----+------+--------+------+----------+--------+ | 8 | s9 | 51 | NULL | NULL | NULL | +----+------+--------+------+----------+--------+ #只有右边 只有5部门 mysql\u0026gt; select e.* , d.* from tbl_emp e right join tbl_dept d on e.deptid = d.id where e.deptid is null ; +------+------+--------+----+----------+--------+ | id | name | deptid | id | deptName | locAdd | +------+------+--------+----+----------+--------+ | NULL | NULL | NULL | 5 | FD | 15 | +------+------+--------+----+----------+--------+ 1 row in set (0.00 sec) #全连接 都得有 mysql不支持outer join mysql\u0026gt; select e.* , d.* from tbl_emp e outer join tbl_dept d on e.deptid = d.id; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;outer join tbl_dept d on e.deptid = d.id\u0026#39; at line 1 #可以这么做 union默认去重 union all 就不会去重 mysql\u0026gt; select e.* , d.* from tbl_emp e left join tbl_dept d on e.deptid = d.id union select e.* , d.* from tbl_emp e right join tbl_dept d on e.deptid = d.id; +------+------+--------+------+----------+--------+ | id | name | deptid | id | deptName | locAdd | +------+------+--------+------+----------+--------+ | 1 | z3 | 1 | 1 | RD | 11 | | 2 | z4 | 1 | 1 | RD | 11 | | 3 | z5 | 1 | 1 | RD | 11 | | 4 | w5 | 2 | 2 | HR | 12 | | 5 | w6 | 2 | 2 | HR | 12 | | 6 | s7 | 3 | 3 | MK | 13 | | 7 | s8 | 4 | 4 | MIS | 14 | | 8 | s9 | 51 | NULL | NULL | NULL | | NULL | NULL | NULL | 5 | FD | 15 | +------+------+--------+------+----------+--------+ 9 rows in set (0.00 sec) #不要join重合的部分 要另外两半的 mysql\u0026gt; select e.* , d.* from tbl_emp e left join tbl_dept d on e.deptid = d.id where d.id is null union select e.* ,d.* from tbl_emp e right join tbl_dept d on e.deptid = d.id where e.deptid is null ; +------+------+--------+------+----------+--------+ | id | name | deptid | id | deptName | locAdd | +------+------+--------+------+----------+--------+ | 8 | s9 | 51 | NULL | NULL | NULL | | NULL | NULL | NULL | 5 | FD | 15 | +------+------+--------+------+----------+--------+ 2 rows in set (0.00 sec) 索引简介 是什么 mysql官方对索引的定义为:索引index是帮助mysql高效获取数据的数据结构.可以得到索引的本质:索引是数据结构.\n如果要查mysql这个单词,我们肯定需要定位到m字母,然后往下找到y字母,再找到剩下的sql\n如果没有索引,那么你可能需要a\u0026ndash;z,如果我想找到java开头的单词呢,或者oracle开头的单词呢\n你可以简单理解为 排好序的快速查找数据结构\n在数据之外,数据库系统还维护着满足特定查找算法的数据结构,这些数据结构以某种方式引用(指向)数据,这样就可以在这些数据结构上实现高级查找算法.这种数据结构,就是索引.下图就是一种可能的索引方式示例:\nimage-20211014224606584\r所以说索引是一种数据结构,如果要查7这本书,正常的遍历要第七次才能找到,时间复杂度为n,索引是利用平衡二叉树,或者B+树,也就是说不一定二叉可以多叉,这样至多log2n+1次就能索引到,故而提高了效率\n一般来说,索引本身也很大,不可能全部存储在内存中,因此索引往往以索引文件的形式存储在磁盘上\n索引不太适合删除和修改多的场景,因为删除数据的同时要删除索引,修改数据的同时要修改索引,索引为何会失效\n我们常说的索引,如果没有特别指明,都是指B树(多路搜索树,并不一定是二叉的)结构组织的索引.其中聚集索引,次要索引,覆盖索引,符合索引,前缀索引,唯一索引默认都是使用B+树索引,统称索引.当然,除了B+树这种类型的索引之外,还有哈希索引(hash index)等.\n优势 类似大学图书馆建书索引,提高数据检索的效率,降低数据库的IO成本 通过索引列对数据进行排序,降低数据排序的成本,降低了CPU的消耗 劣势 实际上索引也是一张表,该表保存了主键与索引字段,并指向实体表的记录,所以索引列也是要占用空间的 虽然索引大大提高了查询速度,同时却会降低更新表的速度,如对表进行insert/update/delete.因为更新表时,mysql不仅要保存数据,还要保存一下索引文件每次更新添加了索引列的字段,都会调整因为更新所带来的键值变化后的索引信息 索引只是提高效率的一个因素,如果你的mysql有大数据量的表,就需要花时间研究建立最优秀的索引,或优化查询 mysql索引分类 单值索引 即一个索引只包含单个列,一个表可以有多个单列索引 唯一索引 索引列的值必须唯一,但允许空值 复合索引 即一个索引包含多个列 基本语法 创建 create [unique] index indexName on tableName(columnName,\u0026hellip;) ; alter tableName add [unique] index [indexName] on (columnName(length)) ; 删除 drop index [indexName] on tableName ; 查看 show index from tableName ; 使用alter命令 alter table tbl_name add primary key (column_list) ; 该语句添加一个主键,这意味这索引值必须是唯一的,且不能为null alter table tbl_name add unique index_name (column_list) ; 这条语句创建索引的值必须是唯一的,除了null之外,null可能会出现多次 alter table tbl_name add index index_name (column_list) ; 添加普通索引,索引值可出现多次 alter table tbl_name add fulltext index_name (column_list) ; 该语句指定了索引为fulltext,用于全文索引 #主键外键唯一都是索引 我们这边讲的是那种普通索引 mysql\u0026gt; show index from tbl_emp ; +---------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +---------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | tbl_emp | 0 | PRIMARY | 1 | id | A | 8 | NULL | NULL | | BTREE | | | YES | NULL | | tbl_emp | 1 | fk_dept_id | 1 | deptid | A | 5 | NULL | NULL | YES | BTREE | | | YES | NULL | +---------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 2 rows in set (0.02 sec) mysql索引的结构 Btree索引 索引原理 hash索引 full-text全文索引 R-Tree索引 image-20211016093656515\r初始化介绍\n一颗B+树,浅蓝色的块我们称之为一个磁盘块,可以看到每个磁盘块包含了几个数据项(深蓝色所示)和指针(黄色所示),如磁盘块1包含数据项17和35,包含指针P1P2P3\nP1表示小于17的磁盘块,P2表示在17和35之间的磁盘块,P3表示大于35的磁盘块\n真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99\n非叶子节点不存储真实的数据,只存储指引搜索方向的数据项,如17、35并不真实存在与数据表中\n查找过程\n如果要查找数据项29,那么首先会把磁盘块1由磁盘加载到内存,此时发生一次IO,在内存中用二分查找确定29在17和35之间,锁定磁盘块1的P2指针,内存时间因为非常短(相比于磁盘的IO)可以忽略不计,通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存中,发生了第二次IO,29在26和30之间,锁定磁盘块3的P2指针,通过指针加载磁盘块8到内存,发生第三次IO,同时内存中做二分查找找到29,结束查询,总计三次IO\n真实情况\n3层的b+树可以表示上百万条的数据,如果上百万的数据查找只需要三次IO,性能提高将是巨大的,如果没有索引,每个数据项都要发生一次IO,那么总共需要百万次IO,显然成本非常非常高\n哪些情况需要创建索引 主键自动建立唯一索引 频繁作为查询条件的字段应该创建索引 查询中与其他表关联的字段,外键关系应该建立索引 频繁更新的字段不适合创建索引 因为每次更新不单单是更新了记录还会更新索引 where条件里用不到的字段不创建索引 单值/复合索引的选择问题 高并发下倾向创建组合索引 查询中排序的字段,排序字段若通过索引去访问将大大提高排序速度 查询中统计或者分组字段 哪些情况不要创建索引 表记录太少 经常增删改的表 提高了查询速度,同时却会降低更新表的速度,如对表进行insert/update和delete,因为更新表时,mysql不仅要保存数据,还要保存一下索引文件 数据重复且分布均匀的表字段,因此应该只为最经常查询和最经常排序的数据列创建索引. 注意,如果某个数据列包含许多重复的内容,为它建立索引就没有太大的实际效果 image-20211016095439966\r性能分析 msyql query optimizer 查询优化器 image-20211016095805682\rmysql常见瓶颈 CPU cpu在饱和的时候一般发生在数据装入内存或从磁盘上读取数据的时候 IO 磁盘IO瓶颈发生在装入数据远大于内存容量的时候 服务器硬件的性能瓶颈: top free iostat vmstat 来查看系统的性能状态 explain Explain 是什么(查看执行计划) 使用explain关键字可以模拟优化器执行sql查询语句,从而知道mysql是如何处理你的sql语句的.分析你的查询语句或是表结构的性能瓶颈 官网介绍 能干嘛 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 怎么玩 Explain + SQL语句 执行计划包含的信息 表头 id select_type table partitions type possible_keys key ken_len ref rows filtered extra 各字段解释 id select查询的序列号,包含一组数字,表示查询中执行select子句或操作表的顺序 三种情况 id相同,执行顺序由上到下\rimage-20211016101510820\rid不同,如果是子查询,id的序号会递增,id值越大优先级越高,越先被执行\rimage-20211016101830835\rid相同不同,同时存在\rimage-20211016102234339\rselect_type 有哪些 simple primary subquery dirived union union result 查询的类型,主要是用于区别普通查询/联合查询/子查询等的复杂查询 simple 简单的select查询,查询中不包含子查询或者union primary 查询中若包含任何复杂的子部分,最外层查询则被标记为 subquery 在select或where列表中包含了子查询 derived 在from列表中包含的子查询被标记为derived(衍生) mysql会递归执行这些子查询,把结果放在临时表里 union 若第二个select出现在union之后,则被标记为union;若union包含在from子句的子查询中,外层select 将被标记为derived(很正常嘛,union之后的结果作为临时表 所以被标记为derived) union result 从union表获取结果的select table 显示这一行的数据是关于那些表的 type all index range ref eq_ref const,system null 访问类型排列 显示查询使用了何种类型,最好到最差依次是 syste\u0026gt;const\u0026gt;eq_ref\u0026gt;ref\u0026gt;range\u0026gt;index\u0026gt;all\rimage-20211016110536099\rsystem 表只有一行记录(等于系统表),这是const类型的特例,平时不会出现,这个也可以忽略不计 const 表示通过索引一次就找到了,const用于比较primary key 或者 unique索引,因为只匹配了一行数据,所以很快,如将主键置于where列表中,mysql就能将该查询转换为一个常量\rimage-20211016110923813\req_ref 唯一性索引扫描,对于每个索引键,表中只有一条记录与之匹配.常用语主键或唯一索引扫描\rimage-20211016112628359\rref 非唯一性索引扫描,返回匹配某个单独值的所有行.本质上也是一种索引访问,他返回所有匹配某个单独值的行,然而,她可能会找到多个符合条件的行,所以他应该属于查找和扫描的混合体.\rimage-20211016113043870\rrange 只检索给定范围的行,使用一个索引来选择行. key列显示使用了哪个索引,一般就是在你的where语句中出现了between \u0026lt; \u0026gt; in 等的查询,这种范围扫描索引扫描比全表扫描要好,因为它只需要开始于索引的某一点,而结束于另一点,不用扫描全部索引\rimage-20211016113701811\rindex (full index san) index与all的区别为index类型只遍历索引树.这通常比all快,因为索引文件比数据文件小 也就是说虽然all和index都是读全表,但index是从索引中读取的,而all是从硬盘中读取的\rimage-20211016114028963\rall (full table scan) 将遍历全表以找到匹配的行\rimage-20211016114058619\r**注意:**一般来说,得保证查询至少打到range级别,最好能够达到ref possible_keys 用来判断索引用上没,索引失效没 显示可能应用在这张表中的索引,一个或多个.查询涉及到的字段上若存在索引,则该索引将被列出,但不一定被查询实际使用 key 实际使用的索引.如果为null,则没有使用索引 查询中若使用了覆盖索引,则该索引仅出现在key列表中 key_len 表示索引中使用的字节数,可通过该列计算查询中使用的索引的长度.在不损失精确性的情况下,长度越短越好 key_len显示的值为索引字段的最大可能长度,并非实际使用长度,即key_len是根据表定义计算而得,不是通过表内检索出的 同样的查询条件下,精度越小越好\rimage-20211016145227350\rref 显示索引的哪一列被使用了,如果可能的话,是一个常数.那些列或常量被用于查找索引列上的值\rimage-20211016145926736\rrows 根据表统计信息及索引选用情况,大致估算出找到所需的记录所需要读取的行数\rimage-20211016150445129\rextra 包含不适合在其他列中显示但十分重要的额外信息 extra信息 using filesort 说明mysql会对数据使用一个外部的索引排序,而不是按照表内的索引顺序进行读取 mysql中无法利用索引完成的排序操作称为文件排序 出现这个东西不好 如果可以尽快优化\rimage-20211016151320887\rusing temporary 使用了临时表保存中间结果,mysql在对查询结果排序时使用临时表.常见于排序order by和分组查询group by 使用临时表会损伤数据库性能 用完还要回收 这个很不好哦\rimage-20211016151757718\rusing index 表示相应的select操作中使用了覆盖索引covering index , 避免了访问了表的的数据行,效率不错! 如果同时出现using where ,表明索引被用来执行索引键值的查找 如果没有同时出现using where , 表明索引用来读取数据而非执行查找动作 覆盖索引 建了3个索引,查的也是3个 全覆盖 image-20211016152608867\rimage-20211016152333029\rusing where 表明使用了where条件 using join buffer 表明使用了连接缓存 impossible where 表明where子句的值总是false , 不能用来获取任何元组\rimage-20211016152746052\rselect tables optimized away 在没有groupby子句的情况下,基于索引优化min/max操作或者对于myisam存储引擎优化count(*)操作,不必等到执行阶段再进行计算,查询执行计划生成的阶段即完成优化. select distinct 优化distinct操作,在找到第一匹配的元组后立即停止查找同样值的操作 #使用explain关键字 进行性能分析 mysql\u0026gt; explain select * from tbl_emp ; +----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------+ | 1 | SIMPLE | tbl_emp | NULL | ALL | NULL | NULL | NULL | NULL | 8 | 100.00 | NULL | +----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------+ 1 row in set, 1 warning (0.01 sec) mysql\u0026gt; explain select * from tbl_emp a left join tbl_dept b on a.deptId = b.id union select * from tbl_emp a right join tbl_dept b on a.deptid = b.id ; +----+--------------+------------+------------+--------+---------------+------------+---------+----------------+------+----------+-----------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+--------------+------------+------------+--------+---------------+------------+---------+----------------+------+----------+-----------------+ | 1 | PRIMARY | a | NULL | ALL | NULL | NULL | NULL | NULL | 8 | 100.00 | NULL | | 1 | PRIMARY | b | NULL | eq_ref | PRIMARY | PRIMARY | 4 | girls.a.deptid | 1 | 100.00 | NULL | | 2 | UNION | b | NULL | ALL | NULL | NULL | NULL | NULL | 5 | 100.00 | NULL | | 2 | UNION | a | NULL | ref | fk_dept_id | fk_dept_id | 5 | girls.b.id | 1 | 100.00 | NULL | | NULL | UNION RESULT | \u0026lt;union1,2\u0026gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | NULL | Using temporary | +----+--------------+------------+------------+--------+---------------+------------+---------+----------------+------+----------+-----------------+ 5 rows in set, 1 warning (0.00 sec) 热身case image-20211016153657227\rimage-20211016153809882\r索引优化 索引分析\n单表\n两表\n三表\n索引失效(应该避免)\n一般性建议\n#建表 单表示例 mysql\u0026gt; CREATE TABLE IF NOT EXISTS `article`( -\u0026gt; `id` INT(10) UNSIGNED NOT NULL PRIMARY KEY AUTO_INCREMENT, -\u0026gt; `author_id` INT(10) UNSIGNED NOT NULL, -\u0026gt; `category_id` INT(10) UNSIGNED NOT NULL, -\u0026gt; `views` INT(10) UNSIGNED NOT NULL, -\u0026gt; `comments` INT(10) UNSIGNED NOT NULL, -\u0026gt; `title` VARBINARY(255) NOT NULL, -\u0026gt; `content` TEXT NOT NULL -\u0026gt; ); Query OK, 0 rows affected, 5 warnings (0.03 sec) mysql\u0026gt; mysql\u0026gt; INSERT INTO `article`(`author_id`,`category_id`,`views`,`comments`,`title`,`content`) VALUES -\u0026gt; (1,1,1,1,\u0026#39;1\u0026#39;,\u0026#39;1\u0026#39;), -\u0026gt; (2,2,2,2,\u0026#39;2\u0026#39;,\u0026#39;2\u0026#39;), -\u0026gt; (1,1,3,3,\u0026#39;3\u0026#39;,\u0026#39;3\u0026#39;); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from article; +----+-----------+-------------+-------+----------+--------------+---------+ | id | author_id | category_id | views | comments | title | content | +----+-----------+-------------+-------+----------+--------------+---------+ | 1 | 1 | 1 | 1 | 1 | 0x31 | 1 | | 2 | 2 | 2 | 2 | 2 | 0x32 | 2 | | 3 | 1 | 1 | 3 | 3 | 0x33 | 3 | +----+-----------+-------------+-------+----------+--------------+---------+ 3 rows in set (0.00 sec) #性能分析 type是all 说明是全表扫描 #显然 using filesort 也是最坏的情况 发生了文件内排序 mysql\u0026gt; explain select id,author_id from article where category_id = 1 and comments \u0026gt;1 order by views desc limit 1 ; +----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+ | 1 | SIMPLE | article | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where; Using filesort | +----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+ 1 row in set, 1 warning (0.00 sec) #如果创建的索引是ccv type 变成了range extra还是filesort 好了点 mysql\u0026gt; create index idx_ccv on article(category_id,comments,views) ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; explain select id,author_id from article where category_id = 1 and comments \u0026gt;1 order by views desc limit 1 ; +----+-------------+---------+------------+-------+---------------+---------+---------+------+------+----------+---------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+-------+---------------+---------+---------+------+------+----------+---------------------------------------+ | 1 | SIMPLE | article | NULL | range | idx_ccv | idx_ccv | 8 | NULL | 1 | 100.00 | Using index condition; Using filesort | +----+-------------+---------+------------+-------+---------------+---------+---------+------+------+----------+---------------------------------------+ 1 row in set, 1 warning (0.00 sec) #删除索引 mysql\u0026gt; drop index idx_ccv on article ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 image-20211016171713970\rmysql\u0026gt; create index idx_cv on article(category_id,views) ; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 #把范围的去掉 mysql\u0026gt; explain select id,author_id from article where category_id = 1 and comments \u0026gt;1 order by views desc limit 1 ; +----+-------------+---------+------------+------+---------------+--------+---------+-------+------+----------+----------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------------+------+---------------+--------+---------+-------+------+----------+----------------------------------+ | 1 | SIMPLE | article | NULL | ref | idx_cv | idx_cv | 4 | const | 2 | 33.33 | Using where; Backward index scan | +----+-------------+---------+------------+------+---------------+--------+---------+-------+------+----------+----------------------------------+ 1 row in set, 1 warning (0.00 sec) #两表 mysql\u0026gt; CREATE TABLE IF NOT EXISTS `class`( -\u0026gt; `id` INT(10) UNSIGNED NOT NULL AUTO_INCREMENT, -\u0026gt; `card` INT(10) UNSIGNED NOT NULL, -\u0026gt; PRIMARY KEY(`id`) -\u0026gt; ); Query OK, 0 rows affected, 2 warnings (0.03 sec) mysql\u0026gt; CREATE TABLE IF NOT EXISTS `book`( -\u0026gt; `bookid` INT(10) UNSIGNED NOT NULL AUTO_INCREMENT, -\u0026gt; `card` INT(10) UNSIGNED NOT NULL, -\u0026gt; PRIMARY KEY(`bookid`) -\u0026gt; ); Query OK, 0 rows affected, 2 warnings (0.01 sec) #分析 都是全表扫描 很几把恐怖 mysql\u0026gt; explain select * from book b right join class c on b.card = c.card ; +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+ | 1 | SIMPLE | c | NULL | ALL | NULL | NULL | NULL | NULL | 20 | 100.00 | NULL | | 1 | SIMPLE | b | NULL | ALL | NULL | NULL | NULL | NULL | 20 | 100.00 | Using where; Using join buffer (hash join) | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+ 2 rows in set, 1 warning (0.00 sec) #优化 先给右连接的左表定索引 同理 或者给左连接的右表定索引 mysql\u0026gt; alter table book add index Y(card) ; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 #type变成ref了 有点意思 using index 很好 mysql\u0026gt; explain select * from book b right join class c on b.card = c.card ; +----+-------------+-------+------------+------+---------------+------+---------+--------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+--------------+------+----------+-------------+ | 1 | SIMPLE | c | NULL | ALL | NULL | NULL | NULL | NULL | 20 | 100.00 | NULL | | 1 | SIMPLE | b | NULL | ref | Y | Y | 4 | girls.c.card | 1 | 100.00 | Using index | +----+-------------+-------+------------+------+---------------+------+---------+--------------+------+----------+-------------+ 2 rows in set, 1 warning (0.00 sec) #不知道给左边添加索引好还是给右边添加好 所以再试试 mysql\u0026gt; drop index Y on book ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 #添加索引 mysql\u0026gt; alter table class add index Y(card) ; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 #发现没有用 为啥呢 因为右连接 没有where的话右边是肯定是全都有的 加了索引有啥用啊 mysql\u0026gt; explain select * from book b right join class c on b.card = c.card ; +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------------------------+ | 1 | SIMPLE | c | NULL | index | NULL | Y | 4 | NULL | 20 | 100.00 | Using index | | 1 | SIMPLE | b | NULL | ALL | NULL | NULL | NULL | NULL | 20 | 100.00 | Using where; Using join buffer (hash join) | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------------------------+ 2 rows in set, 1 warning (0.00 sec) #删除索引 mysql\u0026gt; drop index Y on class ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 image-20211016174325936\r#三表 mysql\u0026gt; CREATE TABLE IF NOT EXISTS `phone`( -\u0026gt; `phoneid` INT(10) UNSIGNED NOT NULL AUTO_INCREMENT, -\u0026gt; `card` INT(10) UNSIGNED NOT NULL, -\u0026gt; PRIMARY KEY(`phoneid`) -\u0026gt; )ENGINE=INNODB; Query OK, 0 rows affected, 2 warnings (0.02 sec) #都是all 很差劲 20 mysql\u0026gt; explain select * from class left join book on class.card = book.card left join phone on phone.card = book.card ; +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+ | 1 | SIMPLE | class | NULL | ALL | NULL | NULL | NULL | NULL | 20 | 100.00 | NULL | | 1 | SIMPLE | book | NULL | ALL | NULL | NULL | NULL | NULL | 20 | 100.00 | Using where; Using join buffer (hash join) | | 1 | SIMPLE | phone | NULL | ALL | NULL | NULL | NULL | NULL | 20 | 100.00 | Using where; Using join buffer (hash join) | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+ 3 rows in set, 1 warning (0.00 sec) mysql\u0026gt; alter table phone add index z(card); Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; create index y on book(card) ; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; explain select * from class left join book on class.card = book.card left join phone on phone.card = book.card ; +----+-------------+-------+------------+------+---------------+------+---------+------------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+------------------+------+----------+-------------+ | 1 | SIMPLE | class | NULL | ALL | NULL | NULL | NULL | NULL | 20 | 100.00 | NULL | | 1 | SIMPLE | book | NULL | ref | y | y | 4 | girls.class.card | 1 | 100.00 | Using index | | 1 | SIMPLE | phone | NULL | ref | z | z | 4 | girls.book.card | 1 | 100.00 | Using index | +----+-------------+-------+------------+------+---------------+------+---------+------------------+------+----------+-------------+ 3 rows in set, 1 warning (0.00 sec) image-20211016193542297\r索引失效(应该避免) 全值匹配我最爱\n最佳左前缀法则\n如果索引了多列,要遵守最左前缀法则.指的是查询从索引的最左前列开始并且不跳过索引中的列\rimage-20211016195626235\r不在索引列上做任何操作(计算/函数/自动手动类型转换),会导致索引失效而转向全表扫描\n少计算\n#对索引列进行函数转换后会导致索引失效的问题 mysql\u0026gt; explain select * from staffs where left(name,4)= \u0026#39;July\u0026#39; ; +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | 1 | SIMPLE | staffs | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using where | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) 存储引擎不能使用索引中范围条件右边的列\n范围后面的索引都失效了 between and / in / like #都用到了 三个索引 140的长度 mysql\u0026gt; explain select * from staffs where name = \u0026#39;July\u0026#39; and age =25 and pos = \u0026#39;dev\u0026#39; ; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 140 | const,const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #用到了两个 因为范围后的索引失效了 78长度 说明第二个用到了 mysql\u0026gt; explain select * from staffs where name = \u0026#39;July\u0026#39; and age \u0026gt;25 and pos = \u0026#39;dev\u0026#39; ; +----+-------------+--------+------------+-------+-----------------------+-----------------------+---------+------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+-------+-----------------------+-----------------------+---------+------+------+----------+-----------------------+ | 1 | SIMPLE | staffs | NULL | range | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 78 | NULL | 1 | 33.33 | Using index condition | +----+-------------+--------+------------+-------+-----------------------+-----------------------+---------+------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec) 尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致)),减少select *\n#查找所有字段 mysql\u0026gt; explain select * from staffs where name = \u0026#39;July\u0026#39; and age =25 and pos = \u0026#39;dev\u0026#39; ; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 140 | const,const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #就只查找索引 索引覆盖 extra 变成 using index 是个好兆头 mysql\u0026gt; explain select name , age , pos from staffs where name = \u0026#39;July\u0026#39; and age =25 and pos=\u0026#39;manager\u0026#39; ; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 140 | const,const,const | 1 | 100.00 | Using index | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) image-20211016201217849\rmysql在使用不等于!= 或者 \u0026lt;\u0026gt;的时候无法使用索引 , 会导致全表扫描\nimage-20211016201756985\ris null , is not null 也无法使用索引 image-20211016202018668\rlike 以通配符开头 (\u0026rsquo;%abc\u0026hellip;\u0026rsquo;) mysql索引失效会变成全表扫描的操作\n只有把%写在右边才能避免索引失效 #索引失效 mysql\u0026gt; explain select * from staffs where name like \u0026#39;%July%\u0026#39; ; +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | 1 | SIMPLE | staffs | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) #放在左边也失效 毕竟不全表扫怎么知道是否找全了 mysql\u0026gt; explain select * from staffs where name like \u0026#39;%July\u0026#39; ; +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | 1 | SIMPLE | staffs | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) #没有失效 mysql\u0026gt; explain select * from staffs where name like \u0026#39;July%\u0026#39; ; +----+-------------+--------+------------+-------+-----------------------+-----------------------+---------+------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+-------+-----------------------+-----------------------+---------+------+------+----------+-----------------------+ | 1 | SIMPLE | staffs | NULL | range | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 74 | NULL | 1 | 100.00 | Using index condition | +----+-------------+--------+------------+-------+-----------------------+-----------------------+---------+------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec) 问题是解决like\u0026rsquo;%字符%\u0026lsquo;时索引不失效??? mysql\u0026gt; CREATE TABLE `tbl_user`( -\u0026gt; `id` INT(11) NOT NULL AUTO_INCREMENT, -\u0026gt; `NAME` VARCHAR(20) DEFAULT NULL, -\u0026gt; `age` INT(11) DEFAULT NULL, -\u0026gt; email VARCHAR(20) DEFAULT NULL, -\u0026gt; PRIMARY KEY (`id`) -\u0026gt; ) ENGINE =INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; Query OK, 0 rows affected, 3 warnings (0.03 sec) #用覆盖索引来解决 mysql\u0026gt; create index idx_user_nameAge on tbl_user(name,age) ; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 #index了 说明用到了 mysql\u0026gt; explain select name , age from tbl_user where name like \u0026#39;%aa%\u0026#39; ; +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | tbl_user | NULL | index | NULL | idx_user_nameAge | 68 | NULL | 4 | 25.00 | Using where; Using index | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) #index了 说明用到了 mysql\u0026gt; explain select id from tbl_user where name like \u0026#39;%aa%\u0026#39;; +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | tbl_user | NULL | index | NULL | idx_user_nameAge | 68 | NULL | 4 | 25.00 | Using where; Using index | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) #index了 说明用到了 mysql\u0026gt; explain select name from tbl_user where name like \u0026#39;%aa%\u0026#39;; +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | tbl_user | NULL | index | NULL | idx_user_nameAge | 68 | NULL | 4 | 25.00 | Using where; Using index | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) #index了 说明用到了 mysql\u0026gt; explain select age from tbl_user where name like \u0026#39;%aa%\u0026#39;; +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | tbl_user | NULL | index | NULL | idx_user_nameAge | 68 | NULL | 4 | 25.00 | Using where; Using index | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) #index了 说明用到了 mysql\u0026gt; explain select id,name from tbl_user where name like \u0026#39;%aa%\u0026#39;; +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | tbl_user | NULL | index | NULL | idx_user_nameAge | 68 | NULL | 4 | 25.00 | Using where; Using index | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) #index了 说明用到了 mysql\u0026gt; explain select id,name,age from tbl_user where name like \u0026#39;%aa%\u0026#39;; +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | tbl_user | NULL | index | NULL | idx_user_nameAge | 68 | NULL | 4 | 25.00 | Using where; Using index | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) #index了 说明用到了 mysql\u0026gt; explain select id,name,age from tbl_user where name like \u0026#39;%aa%\u0026#39;; +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | tbl_user | NULL | index | NULL | idx_user_nameAge | 68 | NULL | 4 | 25.00 | Using where; Using index | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) #index了 说明用到了 mysql\u0026gt; explain select name,age from tbl_user where name like \u0026#39;%aa%\u0026#39;; +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | tbl_user | NULL | index | NULL | idx_user_nameAge | 68 | NULL | 4 | 25.00 | Using where; Using index | +----+-------------+----------+------------+-------+---------------+------------------+---------+------+------+----------+--------------------------+ 1 row in set, 1 warning (0.00 sec) #没有覆盖到索引 ， 索引失效 mysql\u0026gt; explain select * from tbl_user where name like \u0026#39;%aa%\u0026#39; ; +----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------------+ | 1 | SIMPLE | tbl_user | NULL | ALL | NULL | NULL | NULL | NULL | 4 | 25.00 | Using where | +----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) #没有完全覆盖 索引失效 mysql\u0026gt; explain select id,name,age,email from tbl_user where name like \u0026#39;%aa%\u0026#39; ; +----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------------+ | 1 | SIMPLE | tbl_user | NULL | ALL | NULL | NULL | NULL | NULL | 4 | 25.00 | Using where | +----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) 字符串不加单引号索引失效\nmysql\u0026gt; select * from staffs where name = \u0026#39;2000\u0026#39; ; +----+------+-----+-----+---------------------+ | id | NAME | age | pos | add_time | +----+------+-----+-----+---------------------+ | 3 | 2000 | 23 | dev | 2021-10-16 19:38:15 | +----+------+-----+-----+---------------------+ 1 row in set (0.00 sec) #会发生隐式转换 mysql\u0026gt; select * from staffs where name =2000 ; +----+------+-----+-----+---------------------+ | id | NAME | age | pos | add_time | +----+------+-----+-----+---------------------+ | 3 | 2000 | 23 | dev | 2021-10-16 19:38:15 | +----+------+-----+-----+---------------------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select * from staffs where name =\u0026#39;2000\u0026#39; ; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 74 | const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #和第三个吻合 隐式自动转换 自动转换会导致索引失效 mysql\u0026gt; explain select * from staffs where name =2000 ; +----+-------------+--------+------------+------+-----------------------+------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+------+---------+------+------+----------+-------------+ | 1 | SIMPLE | staffs | NULL | ALL | idx_staffs_nameAgePos | NULL | NULL | NULL | 3 | 33.33 | Using where | +----+-------------+--------+------------+------+-----------------------+------+---------+------+------+----------+-------------+ 1 row in set, 3 warnings (0.00 sec) 少用or , 用它来连接时会索引失效 image-20211017095517319\r#建表 mysql\u0026gt; CREATE TABLE staffs( -\u0026gt; id INT PRIMARY KEY AUTO_INCREMENT, -\u0026gt; NAME VARCHAR(24) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;姓名\u0026#39;, -\u0026gt; age INT NOT NULL DEFAULT 0 COMMENT \u0026#39;年龄\u0026#39;, -\u0026gt; pos VARCHAR(20) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;职位\u0026#39;, -\u0026gt; add_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;入职时间\u0026#39; -\u0026gt; )CHARSET utf8 COMMENT \u0026#39;员工记录表\u0026#39;; Query OK, 0 rows affected, 1 warning (0.02 sec) #添加索引 mysql\u0026gt; ALTER TABLE staffs ADD INDEX idx_staffs_nameAgePos(name, age, pos); Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 #查看索引 mysql\u0026gt; show index from staffs ; +--------+------------+-----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +--------+------------+-----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | staffs | 0 | PRIMARY | 1 | id | A | 2 | NULL | NULL | | BTREE | | | YES | NULL | | staffs | 1 | idx_staffs_nameAgePos | 1 | NAME | A | 3 | NULL | NULL | | BTREE | | | YES | NULL | | staffs | 1 | idx_staffs_nameAgePos | 2 | age | A | 3 | NULL | NULL | | BTREE | | | YES | NULL | | staffs | 1 | idx_staffs_nameAgePos | 3 | pos | A | 3 | NULL | NULL | | BTREE | | | YES | NULL | +--------+------------+-----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ #挺好的哈 mysql\u0026gt; explain select * from staffs where name = \u0026#39;July\u0026#39; ; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 74 | const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #两个条件 key_len越来越大 mysql\u0026gt; explain select * from staffs where name = \u0026#39;July\u0026#39;and age = 25; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 78 | const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #三个条件 mysql\u0026gt; explain select * from staffs where name = \u0026#39;July\u0026#39; and age =25 and pos = \u0026#39;dev\u0026#39; ; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 140 | const,const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #问题来了 没有name 只用age和pos的时候变成了全表扫描 索引失效 mysql\u0026gt; explain select * from staffs where age =23 and pos = \u0026#39;dev\u0026#39; ; +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | 1 | SIMPLE | staffs | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) #没有name 只用pos变成了全表扫描 索引失效 mysql\u0026gt; explain select * from staffs where pos = \u0026#39;dev\u0026#39; ; +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ | 1 | SIMPLE | staffs | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where | +----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) #必须要有name 带头大哥不能死 最佳左前缀法则 mysql\u0026gt; explain select * from staffs where name = \u0026#39;July\u0026#39; ; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 74 | const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #虽然用到索引了 但是从索引的长度可以看出 只用了name这个索引 因为中间的age丢了 mysql\u0026gt; explain select * from staffs where name = \u0026#39;July\u0026#39; and pos = \u0026#39;dev\u0026#39; ; +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-----------------------+ | 1 | SIMPLE | staffs | NULL | ref | idx_staffs_nameAgePos | idx_staffs_nameAgePos | 74 | const | 1 | 33.33 | Using index condition | +----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec) image-20211017095823171\rimage-20211017100150557\r可能有点小问题,到时候勘误一下\n练习一下\nmysql\u0026gt; CREATE TABLE test03( -\u0026gt; id int primary key not null auto_increment, -\u0026gt; c1 char(10), -\u0026gt; c2 char(10), -\u0026gt; c3 char(10), -\u0026gt; c4 char(10), -\u0026gt; c5 char(10) -\u0026gt; ); Query OK, 0 rows affected (0.05 sec) mysql\u0026gt; select * from test03; +----+------+------+------+------+------+ | id | c1 | c2 | c3 | c4 | c5 | +----+------+------+------+------+------+ | 1 | a1 | a2 | a3 | a4 | a5 | | 2 | b1 | b2 | b3 | b4 | b5 | | 3 | c1 | c2 | c3 | c4 | c5 | | 4 | d1 | d2 | d3 | d4 | d5 | | 5 | e1 | e2 | e3 | e4 | e5 | +----+------+------+------+------+------+ mysql\u0026gt; create index idx_test03_c1234 on test03(c1,c2,c3,c4); Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 #用到了 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 31 | const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #索引在逐渐递增 key_len mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39; ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 62 | const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #mysql会自我优化 优化常量的查询顺序 mysql\u0026gt; explain select * from test03 where c2=\u0026#39;a2\u0026#39; and c1=\u0026#39;a1\u0026#39; ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 62 | const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #索引在逐渐递增 key_len mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39;and c3=\u0026#39;a3\u0026#39; ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------+------+----------+-------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 93 | const,const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39;and c3=\u0026#39;a3\u0026#39; and c4=\u0026#39;a4\u0026#39; ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------------+------+----------+-------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 124 | const,const,const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #mysql会自我优化 优化常量的查询顺序 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39;and c4=\u0026#39;a4\u0026#39; and c3=\u0026#39;a3\u0026#39; ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------------+------+----------+-------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 124 | const,const,const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #范围后面全失效 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39;and c3\u0026gt;\u0026#39;a3\u0026#39; and c4=\u0026#39;a4\u0026#39; ; +----+-------------+--------+------------+-------+------------------+------------------+---------+------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+-------+------------------+------------------+---------+------+------+----------+-----------------------+ | 1 | SIMPLE | test03 | NULL | range | idx_test03_c1234 | idx_test03_c1234 | 93 | NULL | 1 | 20.00 | Using index condition | +----+-------------+--------+------------+-------+------------------+------------------+---------+------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec) #我觉得是4个 查询顺序会被mysql优化 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39;and c4\u0026gt;\u0026#39;a4\u0026#39; and c3=\u0026#39;a3\u0026#39; ; +----+-------------+--------+------------+-------+------------------+------------------+---------+------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+-------+------------------+------------------+---------+------+------+----------+-----------------------+ | 1 | SIMPLE | test03 | NULL | range | idx_test03_c1234 | idx_test03_c1234 | 124 | NULL | 1 | 100.00 | Using index condition | +----+-------------+--------+------------+-------+------------------+------------------+---------+------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec) #c3没有统计到里面 用于排序了而不是查找 c4就失效了呗 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39;and c4=\u0026#39;a4\u0026#39; order by c3 ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-----------------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 62 | const,const | 1 | 20.00 | Using index condition | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec) #和上面的没什么区别 c3用去排序了 所以c4就失效了呗 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39; order by c3 ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 62 | const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #用到了索引 a1 和 a2 但是抓到数据之后,由于索引设置的是a1a2a3a4默认的排序是a1a2a3a4但是你这边直接 #开始用a4开始排 你还是人吗 这样抓到数据之后还需要对数据进行文件内部的排序才能展示给大家 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39; order by c4 ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+----------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+----------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 62 | const,const | 1 | 100.00 | Using filesort | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+----------------+ 1 row in set, 1 warning (0.00 sec) #用到了索引 a1 但是排序按照a2 a3排序 不会导致索引失效 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c5=\u0026#39;a5\u0026#39; order by c2,c3 ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 31 | const | 1 | 20.00 | Using where | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-------------+ #用到了索引a1 但是排序按照a3 a2排序 不会导致索引失效 但是检索到数据之后,排序不是索引默认的排序规则a1 a2 a3 而是a3 a2 所以检索到后又按照文件内排序 拍了一遍 Using filesort mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c5=\u0026#39;a5\u0026#39; order by c3,c2 ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 31 | const | 1 | 20.00 | Using where; Using filesort | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------------+ #没有问题哈 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39; order by c2,c3; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 62 | const,const | 1 | 100.00 | NULL | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) #也没有问题哈 索引就给了1234 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39; and c5=\u0026#39;c5\u0026#39; order by c2,c3; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 62 | const,const | 1 | 20.00 | Using where | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) #不是说order by 的顺序是要和索引建立的顺序保持一致吗 为啥不会出现文件内排序呢 那是因为c2=a2出现在where中,相当于你order by的排序已经没有用处了 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c2=\u0026#39;a2\u0026#39; and c5=\u0026#39;c5\u0026#39; order by c3,c2; +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 62 | const,const | 1 | 20.00 | Using where | +----+-------------+--------+------------+------+------------------+------------------+---------+-------------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) #这个没问题哈 c3 c2 会导致文件内排序 mysql\u0026gt; explain select * from test03 where c1 =\u0026#39;a1\u0026#39; and c5=\u0026#39;c5\u0026#39; order by c3,c2; +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 31 | const | 1 | 20.00 | Using where; Using filesort | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------------+ 1 row in set, 1 warning (0.00 sec) #索引没有失效 但是只用到了一个 没有发生文件内排序 mysql\u0026gt; explain select * from test03 where c1=\u0026#39;a1\u0026#39; and c4= \u0026#39;a4\u0026#39; group by c2,c3 ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 31 | const | 1 | 20.00 | Using index condition | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec) #索引没问题 使用了部分索引 但是分组的时候 Using temporary 十死无生啊 分组前必排序 mysql\u0026gt; explain select * from test03 where c1=\u0026#39;a1\u0026#39; and c4= \u0026#39;a4\u0026#39; group by c3,c2 ; +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+----------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+----------------------------------------+ | 1 | SIMPLE | test03 | NULL | ref | idx_test03_c1234 | idx_test03_c1234 | 31 | const | 1 | 20.00 | Using index condition; Using temporary | +----+-------------+--------+------------+------+------------------+------------------+---------+-------+------+----------+----------------------------------------+ 1 row in set, 1 warning (0.00 sec) 总结\n定值 / 范围 还是排序 , 一般order by 是给个范围\ngroup by 基本上都需要进行排序 , 否则会有临时表产生,即temporary\n索引优化 索引分析 索引失效 一般性建议 对于单键索引,尽量选择针对当前query过滤性更好的索引 在选择组合索引的时候,当前query中过滤性最好的字段在索引字段的顺序中 ,位置越靠前越好 在选择组合索引的时候,尽量选择可以能够包含当前query中的where字句中更多字段的索引 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的 image-20211018194551515\rlike后面跟着常量的话就没什么问题能做索引也能跳板\n优化总结口诀 全值匹配我最爱,最左前缀要遵守\n带头大哥不能死,中间兄弟不能断\n索引列上少计算,范围之后全失效\nlike百分写最右, 覆盖索引不写*\n不等空值还有or,索引失效要少用\nvar引号不可丢,sql高级也不难\n查询截取分析 查询优化 慢查询日志 批量数据脚本 show profile 全局查询日志 分析步骤 观察,至少跑一天,看看生产的慢sql情况 开启慢查询日志,设置阙值,比如超过5秒钟的就是慢sql,并将它抓取出来 explain + 慢sql分析 show profile 运维经理或dba,进行sql数据库服务器的参数调优 总结 0\n慢查询的开启并捕获 explain+慢sql分析 show profile查询sql在mysql服务器里面的执行细节和声明周期情况 sql数据库服务器的参数调优 永远小表驱动大表\n类似于嵌套循环nested loop\norderby关键字优化\ngroup by关键字优化\nimage-20211018201006527\r很好分析嘛,如果B数据少于A,那么用B驱动,B在右边那就是先查B,因为B先查,查到的是小表,这样就小表驱动大表了; 如果B数据多余A,那么用A驱动,B在右边,那就是用exists,在B的查询里套上子查询,这样先查的B的同时需要先查A(这样才知道A.id,B才能查),这样就变成小表驱动大表了\nimage-20211018201111638\rmysql\u0026gt; select * from tbl_emp where deptid in (select id from tbl_dept ) ; +----+------+--------+ | id | name | deptid | +----+------+--------+ | 1 | z3 | 1 | | 2 | z4 | 1 | | 3 | z5 | 1 | | 4 | w5 | 2 | | 5 | w6 | 2 | | 6 | s7 | 3 | | 7 | s8 | 4 | +----+------+--------+ 7 rows in set (0.00 sec) #两种最终效果是一样的 但是得考虑哪个是小表哪个是大表 需要小表驱动大表 那就考虑使用哪一种 mysql\u0026gt; select * from tbl_emp where exists (select 1 from tbl_dept where tbl_emp.deptid = tbl_dept.id); +----+------+--------+ | id | name | deptid | +----+------+--------+ | 1 | z3 | 1 | | 2 | z4 | 1 | | 3 | z5 | 1 | | 4 | w5 | 2 | | 5 | w6 | 2 | | 6 | s7 | 3 | | 7 | s8 | 4 | +----+------+--------+ 7 rows in set (0.00 sec) orderby 关键字优化 orderby子句,尽量使用index方式排序,避免使用filesort方式排序 mysql支持两种方式的排序,filesort和index,index效率高,它指ysql扫描索引本身完成排序,filesort方式效率低 order by 满足两种情况,会使用index方式排序 order by 语句使用索引最左前列 使用where子句和order by子句条件列满足索引最左前列 尽可能在索引列上完成排序操作,遵照索引建的最佳左前缀原则 如果不在索引列上,filesort有两种算法:mysql就要启动双路排序和单路排序 双路排序 4.1之前使用双路排序,扫描两次磁盘,最终得到数据,读取行指针和order by 列, 对他们进行排序,然后扫描已经排序好的列表,按照列表中的值重新从列表中读取 从磁盘取排序字段,在buffer进行排序,再从磁盘取其他字段 单路排序 取一批数据,要对磁盘进行两次扫描,众所周知,IO很耗时,在4.1之后,出现了第二种的改进算法,就是单路排序 从磁盘读取查询需要的所有列,按照orderby列在buffer对他们进行排序,然后扫描排序后的列表进行输出,它的效率更快一些,避免了第二次读取数据.并且把随机IO变成了顺序IO,但是它会使用更多的空间,因为它把每一行都保存在内存中了. image-20211018204727314\r优化策略 增大sort_buffer_size参数设置 增大max_length_for_sort_data参数的设置 why image-20211018205003059\rmysql\u0026gt; CREATE TABLE tblA( -\u0026gt; #id int primary key not null autp_increment, -\u0026gt; age int, -\u0026gt; birth timestamp not null -\u0026gt; ); Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; CREATE INDEX idx_A_ageBirth on tblA(age,birth); Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 image-20211018203216016\r默认升序 打乱了就会发生filesort\nimage-20211018203523533\r总结 image-20211018205452929\rgroup by 关键字优化 group by实质是先排序后进行分组,遵照索引建的最佳左前缀 当无法使用索引列,增大max_length_for_sort_data参数的设置+增大sort_buffer_size参数的设置 where高于having , 能写在where限定的条件就不要去having限定了 mysql慢查询日志 image-20211018205757207\rimage-20211018205824359\r如何查看是否开启与如何开启\nmysql\u0026gt; show variables like \u0026#39;%slow_query_log%\u0026#39;; +---------------------+--------------------------+ | Variable_name | Value | +---------------------+--------------------------+ | slow_query_log | ON | | slow_query_log_file | LAPTOP-FKVMDBSI-slow.log | +---------------------+--------------------------+ 2 rows in set, 1 warning (0.01 sec) #只对当前数据库生效 mysql\u0026gt; set global slow_query_log = 1 ; Query OK, 0 rows affected (0.00 sec) image-20211018210231026\r什么样的会记录到慢查询日志里面呢?\nmysql\u0026gt; show variables like \u0026#39;%long_query_time%\u0026#39;; +-----------------+-----------+ | Variable_name | Value | +-----------------+-----------+ | long_query_time | 10.000000 | +-----------------+-----------+ 1 row in set, 1 warning (0.00 sec) image-20211018210404815\r设置慢查询时间阙值\nmysql\u0026gt; set global long_query_time = 3 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show variables like \u0026#39;%long_query_time%\u0026#39;; +-----------------+-----------+ | Variable_name | Value | +-----------------+-----------+ | long_query_time | 10.000000 | +-----------------+-----------+ 1 row in set, 1 warning (0.00 sec) image-20211018210539898\rimage-20211018210653124\r去哪儿找慢sql呀?\n#超过3s了 应该会记录到某个日志里对不对 mysql\u0026gt; select sleep(4); +----------+ | sleep(4) | +----------+ | 0 | +----------+ 1 row in set (4.01 sec)\timage-20211018211230665\r查看有多少条慢查询的sql mysql\u0026gt; show global status like \u0026#39;slow_queries%\u0026#39; ; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | Slow_queries | 2 | +---------------+-------+ 1 row in set (0.00 sec) 配置版 永久生效 image-20211018212354576\r日志分析工具mysqldumpslow 查看帮助信息 s 标识按照何种方式排序 c 访问次数 l 锁定时间 r 返回记录 t 查询时间 al 平均锁定时间 ar 平均返回记录数 at 平均查询时间 t 返回前面多少条的数据 g 后边搭配一个正则匹配模式,大小写不敏感的 image-20211018212608969\rimage-20211018213827239\r批量插入数据 #准备工作 mysql\u0026gt; create database bigdata ; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; use bigdata ; Database changed mysql\u0026gt; CREATE TABLE `dept` ( -\u0026gt; `id` int(10) unsigned NOT NULL AUTO_INCREMENT, -\u0026gt; `deptno` mediumint(8) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, -\u0026gt; `dname` varchar(20) NOT NULL DEFAULT \u0026#39;\u0026#39;, -\u0026gt; `loc` varchar(13) NOT NULL DEFAULT \u0026#39;\u0026#39;, -\u0026gt; PRIMARY KEY (`id`) -\u0026gt; ) ENGINE=InnoDB DEFAULT CHARSET=GBK; Query OK, 0 rows affected, 2 warnings (0.03 sec) mysql\u0026gt; mysql\u0026gt; CREATE TABLE `emp` ( -\u0026gt; `id` int(10) unsigned NOT NULL AUTO_INCREMENT, -\u0026gt; `empno` mediumint(8) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;,/*编号*/ -\u0026gt; `ename` varchar(20) NOT NULL DEFAULT \u0026#39;\u0026#39;,/*名字*/ -\u0026gt; `job` varchar(9) NOT NULL DEFAULT \u0026#39;\u0026#39;,/*工作*/ -\u0026gt; `mgr` mediumint(8) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;,/*上级编号*/ -\u0026gt; `hiredate` date NOT NULL,/*入职时间*/ -\u0026gt; `sal` decimal(7,2) NOT NULL,/*薪水*/ -\u0026gt; `comm` decimal(7,2) NOT NULL,/*红利*/ -\u0026gt; `deptno` mediumint(8) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;,/*部门编号*/ -\u0026gt; PRIMARY KEY (`id`) -\u0026gt; ) ENGINE=InnoDB DEFAULT CHARSET=GBK; Query OK, 0 rows affected, 4 warnings (0.02 sec) mysql\u0026gt; show variables like \u0026#39;log_bin_trust_function_creators\u0026#39; ; +---------------------------------+-------+ | Variable_name | Value | +---------------------------------+-------+ | log_bin_trust_function_creators | OFF | +---------------------------------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; set global log_bin_trust_function_creators = 1 ; Query OK, 0 rows affected (0.00 sec) #重启会失效 如果永久就修改配置文件 mysql\u0026gt; show variables like \u0026#39;log_bin_trust_function_creators\u0026#39; ; +---------------------------------+-------+ | Variable_name | Value | +---------------------------------+-------+ | log_bin_trust_function_creators | ON | +---------------------------------+-------+ 1 row in set, 1 warning (0.00 sec) #创建函数随机产生字符串和部门编号 mysql\u0026gt; delimiter $$ mysql\u0026gt; create function rand_string (n int) returns varchar (255) -\u0026gt; begin -\u0026gt; declare chars_str varchar(100) default \u0026#39;abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ\u0026#39;; -\u0026gt; declare return_str varchar(255) default \u0026#39;\u0026#39;; -\u0026gt; declare i int default 0 ; -\u0026gt; while i\u0026lt;n do -\u0026gt; set return_str = concat (return_str,substring(chars_str,floor(1+rand()*52),1)); -\u0026gt; set i = i + 1; -\u0026gt; end while ; -\u0026gt; return return_str ; -\u0026gt; end $$ Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; create function rand_num() returns int(5) -\u0026gt; begin -\u0026gt; declare i int default 0 ; -\u0026gt; set i = floor(100+rand()*10); -\u0026gt; return i ; -\u0026gt; end $$ Query OK, 0 rows affected, 1 warning (0.01 sec) #创建存储过程 并使用函数 mysql\u0026gt; create procedure insert_emp(in start int(10),in max_num int(10)) -\u0026gt; begin -\u0026gt; declare i int default 0 ; -\u0026gt; set autocommit = 0 ; -\u0026gt; repeat -\u0026gt; set i = i + 1 ; -\u0026gt; insert into emp(empno,ename,job,mgr,hiredate,sal,comm,deptno)values ((start+i),rand_string(6),\u0026#39;SALESMAN\u0026#39;,0001,curdate(),2000,400,rand_num()); -\u0026gt; until i = max_num -\u0026gt; end repeat ; -\u0026gt; commit ; -\u0026gt; end $$ Query OK, 0 rows affected, 2 warnings (0.01 sec) mysql\u0026gt; DELIMITER $$ mysql\u0026gt; CREATE PROCEDURE insert_dept(IN START INT(10),IN max_num INT(10)) -\u0026gt; BEGIN -\u0026gt; DECLARE i INT DEFAULT 0; -\u0026gt; SET autocommit = 0; -\u0026gt; REPEAT -\u0026gt; SET i = i + 1; -\u0026gt; INSERT INTO dept (deptno,dname,loc) VALUES((START+i),rand_string(10), rand_string(8)); -\u0026gt; UNTIL i = max_num -\u0026gt; END REPEAT; -\u0026gt; COMMIT; -\u0026gt; END $$ Query OK, 0 rows affected, 2 warnings (0.01 sec) #调用存储过程 mysql\u0026gt; delimiter ; mysql\u0026gt; call insert_dept(100,10); Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from dept ; +----+--------+------------+----------+ | id | deptno | dname | loc | +----+--------+------------+----------+ | 1 | 101 | sqzyWknJJc | uPRPyWny | | 2 | 102 | JIzyTYkhea | MMwVrWFn | | 3 | 103 | yJHubWCauW | yDuqsQbL | | 4 | 104 | zpcqwlOlOo | amifZKyp | | 5 | 105 | dygjEsdkSJ | PXrTreuK | | 6 | 106 | sImmyFJrNO | JOaNOEFl | | 7 | 107 | sclZmoJqML | uOLngSTP | | 8 | 108 | wKlcBBdKqB | HJlkuqvf | | 9 | 109 | phTUTIJwhu | ELSeUlwz | | 10 | 110 | jvArhMohVh | WoFhVhYw | +----+--------+------------+----------+ 10 rows in set (0.00 sec) mysql\u0026gt; call insert_emp(100001,500000); Query OK, 0 rows affected (31.37 sec) image-20211018214549181\rshow Profile 是什么 是mysql提供可以用来分析当前会话中语句执行的资源消耗情况 可以用于sql的调优测量\n默认情况下,参数处于关闭状态,并保存最近15次的运行结果\n分析步骤\n是否支持 , 看看当前的mysql版本是否支持\nmysql\u0026gt; show variables like \u0026#39;%profiling%\u0026#39;; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | have_profiling | YES | | profiling | OFF | | profiling_history_size | 15 | +------------------------+-------+ 3 rows in set, 1 warning (0.00 sec) 开启功能,默认是关闭,使用前需要开启\nmysql\u0026gt; set profiling = on ; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql\u0026gt; show variables like \u0026#39;%profiling%\u0026#39;; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | have_profiling | YES | | profiling | ON | | profiling_history_size | 15 | +------------------------+-------+ 3 rows in set, 1 warning (0.00 sec) 运行SQL\n查看结果,show profiles\nmysql\u0026gt; show profiles ; +----------+------------+------------------------------------------------------------------+ | Query_ID | Duration | Query | +----------+------------+------------------------------------------------------------------+ | 1 | 0.00142325 | show variables like \u0026#39;%profiling%\u0026#39; | | 2 | 0.00311650 | select * from tbl_emp | | 3 | 0.00040100 | select * from tbl_emp | | 4 | 0.00018025 | SELECT DATABASE() | | 5 | 0.00356750 | select * from tbl_emp | | 6 | 0.00046875 | select * from tbl_emp e inner join tbl_dept on e.deptid = d.id | | 7 | 0.00317325 | select * from tbl_emp e inner join tbl_dept d on e.deptid = d.id | | 8 | 0.00029500 | select * from tbl_emp e inner join tbl_dept d on e.deptid = d.id | | 9 | 0.00031975 | select * from tbl_emp e left join tbl_dept d on e.deptid = d.id | | 10 | 0.00016175 | SELECT DATABASE() | | 11 | 0.48647650 | select * from emp group by id%10 limit 150000 | | 12 | 0.46590675 | select * from emp group by id%20 order by 5 | +----------+------------+------------------------------------------------------------------+ 12 rows in set, 1 warning (0.00 sec) 诊断sql,show profile cpu ,block io for query 上一步前面的问题sql数字号码 ; mysql\u0026gt; show profile cpu , block io for query 7; +--------------------------------+----------+----------+------------+--------------+---------------+ | Status | Duration | CPU_user | CPU_system | Block_ops_in | Block_ops_out | +--------------------------------+----------+----------+------------+--------------+---------------+ | starting | 0.000054 | 0.000000 | 0.000000 | NULL | NULL | | Executing hook on transaction | 0.000003 | 0.000000 | 0.000000 | NULL | NULL | | starting | 0.000005 | 0.000000 | 0.000000 | NULL | NULL | | checking permissions | 0.000002 | 0.000000 | 0.000000 | NULL | NULL | | checking permissions | 0.000003 | 0.000000 | 0.000000 | NULL | NULL | | Opening tables | 0.000041 | 0.000000 | 0.000000 | NULL | NULL | | init | 0.000004 | 0.000000 | 0.000000 | NULL | NULL | | System lock | 0.000007 | 0.000000 | 0.000000 | NULL | NULL | | optimizing | 0.000012 | 0.000000 | 0.000000 | NULL | NULL | | statistics | 0.000027 | 0.000000 | 0.000000 | NULL | NULL | | preparing | 0.000017 | 0.000000 | 0.000000 | NULL | NULL | | executing | 0.002927 | 0.000000 | 0.000000 | NULL | NULL | | end | 0.000005 | 0.000000 | 0.000000 | NULL | NULL | | query end | 0.000002 | 0.000000 | 0.000000 | NULL | NULL | | waiting for handler commit | 0.000007 | 0.000000 | 0.000000 | NULL | NULL | | closing tables | 0.000006 | 0.000000 | 0.000000 | NULL | NULL | | freeing items | 0.000041 | 0.000000 | 0.000000 | NULL | NULL | | cleaning up | 0.000013 | 0.000000 | 0.000000 | NULL | NULL | +--------------------------------+----------+----------+------------+--------------+---------------+ #看看耗时多的 找结论 image-20211019231456204\r日常开发需要注意的结论 converting heap to myisam 查询结果太大 , 内存不够用了往磁盘上搬 creating temp table 创建临时表 拷贝数据到临时表 用完再删除 copying to tmp table on dist 把内存中临时表复制到磁盘,危险!! locked #使用temp临时表很消耗时间 要创建 拷贝 处理 释放 mysql\u0026gt; show profile cpu , block io for query 11; +--------------------------------+----------+----------+------------+--------------+---------------+ | Status | Duration | CPU_user | CPU_system | Block_ops_in | Block_ops_out | +--------------------------------+----------+----------+------------+--------------+---------------+ | starting | 0.000078 | 0.000000 | 0.000000 | NULL | NULL | | Executing hook on transaction | 0.000005 | 0.000000 | 0.000000 | NULL | NULL | | starting | 0.000005 | 0.000000 | 0.000000 | NULL | NULL | | checking permissions | 0.000004 | 0.000000 | 0.000000 | NULL | NULL | | Opening tables | 0.000264 | 0.000000 | 0.000000 | NULL | NULL | | init | 0.000005 | 0.000000 | 0.000000 | NULL | NULL | | System lock | 0.000005 | 0.000000 | 0.000000 | NULL | NULL | | optimizing | 0.000003 | 0.000000 | 0.000000 | NULL | NULL | | statistics | 0.000015 | 0.000000 | 0.000000 | NULL | NULL | | preparing | 0.000011 | 0.000000 | 0.000000 | NULL | NULL | | Creating tmp table | 0.000055 | 0.000000 | 0.000000 | NULL | NULL | | executing | 0.485898 | 0.421875 | 0.046875 | NULL | NULL | | end | 0.000010 | 0.000000 | 0.000000 | NULL | NULL | | query end | 0.000003 | 0.000000 | 0.000000 | NULL | NULL | | waiting for handler commit | 0.000017 | 0.000000 | 0.000000 | NULL | NULL | | closing tables | 0.000007 | 0.000000 | 0.000000 | NULL | NULL | | freeing items | 0.000074 | 0.000000 | 0.000000 | NULL | NULL | | cleaning up | 0.000019 | 0.000000 | 0.000000 | NULL | NULL | +--------------------------------+----------+----------+------------+--------------+---------------+ 18 rows in set, 1 warning (0.00 sec) 全局查询日志 配置启用 image-20211019232353049\r编码启用 image-20211019232435273\rmysql\u0026gt; set global general_log = 1 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; set global log_output = \u0026#39;TABLE\u0026#39; ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from dept ; +----+--------+------------+----------+ | id | deptno | dname | loc | +----+--------+------------+----------+ | 1 | 101 | sqzyWknJJc | uPRPyWny | | 2 | 102 | JIzyTYkhea | MMwVrWFn | | 3 | 103 | yJHubWCauW | yDuqsQbL | | 4 | 104 | zpcqwlOlOo | amifZKyp | | 5 | 105 | dygjEsdkSJ | PXrTreuK | | 6 | 106 | sImmyFJrNO | JOaNOEFl | | 7 | 107 | sclZmoJqML | uOLngSTP | | 8 | 108 | wKlcBBdKqB | HJlkuqvf | | 9 | 109 | phTUTIJwhu | ELSeUlwz | | 10 | 110 | jvArhMohVh | WoFhVhYw | +----+--------+------------+----------+ 10 rows in set (0.01 sec) mysql\u0026gt; select * from mysql.general_log ; +----------------------------+------------------------------+-----------+-----------+--------------+------------------------------------------------------------------+ | event_time | user_host | thread_id | server_id | command_type | argument | +----------------------------+------------------------------+-----------+-----------+--------------+------------------------------------------------------------------+ | 2021-10-19 23:25:31.577792 | root[root] @ localhost [::1] | 12 | 1 | Query | 0x73656C656374202A2066726F6D2064657074 | | 2021-10-19 23:25:44.682913 | root[root] @ localhost [::1] | 12 | 1 | Query | 0x73656C656374202A2066726F6D206D7973716C2E67656E6572616C5F6C6F67 | +----------------------------+------------------------------+-----------+-----------+--------------+------------------------------------------------------------------+ 2 rows in set (0.00 sec) mysql\u0026gt; set global general_log = 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; alter table mysql.general_log modify column argument varchar(100) not null ; Query OK, 3 rows affected (0.04 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; set global general_log = 1 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from mysql.general_log ; +----------------------------+------------------------------+-----------+-----------+--------------+---------------------------------+ | event_time | user_host | thread_id | server_id | command_type | argument | +----------------------------+------------------------------+-----------+-----------+--------------+---------------------------------+ | 2021-10-19 23:25:31.577792 | root[root] @ localhost [::1] | 12 | 1 | Query | select * from dept | | 2021-10-19 23:25:44.682913 | root[root] @ localhost [::1] | 12 | 1 | Query | select * from mysql.general_log | | 2021-10-19 23:28:59.776726 | root[root] @ localhost [::1] | 12 | 1 | Query | set global general_log = 0 | +----------------------------+------------------------------+-----------+-----------+--------------+---------------------------------+ 3 rows in set (0.01 sec) mysql锁机制 锁是计算机协调多个进程或线程并发访问某一资源的机制\n在数据库中,除传统的计算资源如CPU/RAM/IO等的争用以外,数据也是一种供许多用户共享的资源.如何保证数据并发访问的一致性,有效性是所有数据库必须解决的一个问题,锁冲突也是影响数据库并发访问性能的一个重要因素.从这个角度来说,锁对数据库而言显得尤为重要,也更加复杂.\nimage-20211019233809036\r锁的分类\n对数据操作的类型 读/写 读锁(共享锁):针对同一份数据,多个读操作可以同时进行而不会互相影响 写锁(排它锁):当前写操作没有完成前,它会阻断其他写锁和读锁 对数据操作的粒度 表锁/行锁 锁机制中的三锁\n表锁(偏读) 特点 偏向myisam存储引擎,开销小,加锁快,无死锁;锁定粒度大,发生锁冲突的概率最高,并发度最低 #建表 mysql\u0026gt; create table mylock( -\u0026gt; id int not null primary key auto_increment, -\u0026gt; name varchar(20) -\u0026gt; )engine myisam; Query OK, 0 rows affected (0.02 sec) #查看哪些上锁mysql\u0026gt; show open tables ; +--------------------+---------------------------+--------+-------------+ | Database | Table | In_use | Name_locked | +--------------------+---------------------------+--------+-------------+ | mysql | check_constraints | 0 | 0 | | mysql | column_type_elements | 0 | 0 | #加读写锁 mysql\u0026gt; lock table mylock read , emp write ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; show open tables ; +--------------------+---------------------------+--------+-------------+ | Database | Table | In_use | Name_locked | +--------------------+---------------------------+--------+-------------+ | mysql | check_constraints | 0 | 0 | | mysql | column_type_elements | 0 | 0 | | bigdata | emp | 1 | 0 | | mysql | general_log | 0 | 0 | | bigdata | mylock | 1 | 0 | +--------------------+---------------------------+--------+-------------+ #释放锁 mysql\u0026gt; unlock tables ; Query OK, 0 rows affected (0.00 sec) 加读锁\npowershell 中加锁\nmysql\u0026gt; lock table mylock read ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from mylock ; +----+------+ | id | name | +----+------+ | 1 | a | | 2 | b | | 3 | c | | 4 | d | | 5 | e | +----+------+ 5 rows in set (0.00 sec) cmd中也能读\nmysql\u0026gt; use bigdata ; Database changed mysql\u0026gt; select * from mylock ; +----+------+ | id | name | +----+------+ | 1 | a | | 2 | b | | 3 | c | | 4 | d | | 5 | e | +----+------+ 5 rows in set (0.01 sec) 但powershell中加了读锁,不能对该表进行写操作,也就是增删改操作,也不能对其他表进行crud操作\nmysql\u0026gt; update mylock set name = \u0026#39;a2\u0026#39; where id = 1 ; ERROR 1099 (HY000): Table \u0026#39;mylock\u0026#39; was locked with a READ lock and can\u0026#39;t be updated mysql\u0026gt; insert into mylock values(6,\u0026#39;ljs\u0026#39;); ERROR 1099 (HY000): Table \u0026#39;mylock\u0026#39; was locked with a READ lock and can\u0026#39;t be updated mysql\u0026gt; delete from mylock where id = 5 ; ERROR 1099 (HY000): Table \u0026#39;mylock\u0026#39; was locked with a READ lock and can\u0026#39;t be updated mysql\u0026gt; select * from emp ; ERROR 1100 (HY000): Table \u0026#39;emp\u0026#39; was not locked with LOCK TABLES 而cmd不能对该表进行写的操作,可以对该表进行读操作,写操作会阻塞,直到powershell中释放锁,但能对其他表进行crud操作\nmysql\u0026gt; update mylock set name = \u0026#39;a2\u0026#39; where id = 1 ; ^C -- query aborted ERROR 1317 (70100): Query execution was interrupted mysql\u0026gt; insert into mylock values(6,\u0026#39;ljs\u0026#39;); ^C -- query aborted ERROR 1317 (70100): Query execution was interrupted mysql\u0026gt; delete from mylock where id = 5 ; ^C -- query aborted ERROR 1317 (70100): Query execution was interrupted mysql\u0026gt; select * from emp ; +--------+--------+--------+----------+-----+------------+---------+--------+--------+ | id | empno | ename | job | mgr | hiredate | sal | comm | deptno | +--------+--------+--------+----------+-----+------------+---------+--------+--------+ | 1 | 100002 | lPrnpM | SALESMAN | 1 | 2021-10-18 | 2000.00 | 400.00 | 107 | | 2 | 100003 | NuIiSO | SALESMAN | 1 | 2021-10-18 | 2000.00 | 400.00 | 103 | 当powershell解锁后,cmd立刻得到执行\n#powershell端 mysql\u0026gt; unlock tables ; Query OK, 0 rows affected (0.01 sec) #cmd端 等到解锁后立刻执行 mysql\u0026gt; update mylock set name = \u0026#39;a2\u0026#39; where id = 1 ; Query OK, 1 row affected (19.80 sec) Rows matched: 1 Changed: 1 Warnings: 0 image-20211020200516110\rimage-20211020200614618\r加写锁\npowershell加写锁,其他未锁的表都访问不了\nmysql\u0026gt; lock table mylock write ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from mylock ; +----+------+ | id | name | +----+------+ | 1 | a2 | | 2 | b | | 3 | c | | 4 | d | | 5 | e | +----+------+ 5 rows in set (0.01 sec) mysql\u0026gt; update mylock set name = \u0026#39;a4\u0026#39; where id =1 ; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; select * from emp ; ERROR 1100 (HY000): Table \u0026#39;emp\u0026#39; was not locked with LOCK TABLES cmd访问该表,发生阻塞,直至powershell解锁\nmysql\u0026gt; select * from mylock ; +----+------+ | id | name | +----+------+ | 1 | a4 | | 2 | b | | 3 | c | | 4 | d | | 5 | e | +----+------+ 5 rows in set (2.44 sec) image-20211020201254172\rimage-20211020201310837\rimage-20211020201455840\r表锁分析\nshow open tables ; 哪些表被锁了 通过检查table_locks_waited和table_locks_immediate状态变量来分析系统上的表锁定; show status like \u0026rsquo;table%\u0026rsquo; ; mysql\u0026gt; show status like \u0026#39;table%\u0026#39; ; +----------------------------+-------+ | Variable_name | Value | +----------------------------+-------+ | Table_locks_immediate | 104 | | Table_locks_waited | 0 | | Table_open_cache_hits | 89 | | Table_open_cache_misses | 24 | | Table_open_cache_overflows | 0 | +----------------------------+-------+ image-20211020203053434\r行锁 innodb存储引擎,开销大,加锁慢;会出现死锁;锁定粒度最小,发生锁冲突的概率最低,并发度最高 innodb与myisam的最大不同有两点:一是支持事务transactioon;二是采用行级锁 事务\n事务及acid属性\nimage-20211020203617056\r并发事务处理带来的问题\n更新丢失 image-20211020203848386\r脏读 image-20211020204010474\r不可重复读 image-20211020204034952\r幻读 image-20211020204053892\r事务的并发隔离级别\nread uncommitted read committed repeatable read serializable image-20211020204239692\rmysql\u0026gt; show variables like \u0026#39;transaction_isolation\u0026#39; ; +-----------------------+-----------------+ | Variable_name | Value | +-----------------------+-----------------+ | transaction_isolation | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set, 1 warning (0.01 sec) 示例\nmysql\u0026gt; create table test_innodb_lock(a int(11),b varchar(16))engine=innodb; Query OK, 0 rows affected, 1 warning (0.04 sec) mysql\u0026gt; create index test_innodb_a_ind on test_innodb_lock(a); Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; create index test_innodb_lock_b_ind on test_innodb_lock(b); Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 powershell中修改数据\nmysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; update test_innodb_lock set b = \u0026#39;4001\u0026#39; where a = 4 ; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 为保证数据一致性 在cmd中 拿到的肯定还是4000\nmysql\u0026gt; select * from test_innodb_lock ; +------+------+ | a | b | +------+------+ | 1 | b2 | | 3 | 3 | | 4 | 4000 | | 5 | 5000 | | 6 | 6000 | | 7 | 7000 | | 8 | 8000 | | 9 | 9000 | | 1 | b1 | +------+------+ powershell修改数据\nmysql\u0026gt; update test_innodb_lock set b = \u0026#39;4002\u0026#39; where a = 4 ; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 如果不提交 就发生了行锁 cmd中等到powershell中提交了 才会更新 否则会阻塞\nmysql\u0026gt; update test_innodb_lock set b = \u0026#39;4003\u0026#39; where a = 4 ; Query OK, 1 row affected (19.16 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; commit ; Query OK, 0 rows affected (0.01 sec) 动不同的行是没有问题的\nimage-20211020210157165\r无索引行锁升级为表锁\npowershell中由于varchar没有加单引号‘’ 导致类型转换发生了索引失效\nmysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; update test_innodb_lock set a = 41 where b = 4000 ; Query OK, 0 rows affected (0.01 sec) Rows matched: 0 Changed: 0 Warnings: 0 理论上只是行锁，但是索引失效导致行锁升级为了表锁，操作其他行也发现表被锁住了\nmysql\u0026gt; select * from test_innodb_lock ; +------+------+ | a | b | +------+------+ | 1 | b2 | | 3 | 3 | | 4 | 4003 | | 5 | 5000 | | 6 | 6000 | | 7 | 7000 | | 8 | 8000 | | 9 | 9000 | | 1 | b1 | +------+------+ 9 rows in set (0.01 sec) mysql\u0026gt; update test_innodb_lock set b = \u0026#39;9002\u0026#39; where a =9 ; Query OK, 1 row affected (21.24 sec) Rows matched: 1 Changed: 1 Warnings: 0 间隙锁\ncmd中更新一个范围,还没提交\nmysql\u0026gt; update test_innodb_lock set b = \u0026#39;0629\u0026#39; where a\u0026gt;1 and a\u0026lt;6 ; Query OK, 3 rows affected (0.01 sec) Rows matched: 3 Changed: 3 Warnings: 0 mysql\u0026gt; commit ; Query OK, 0 rows affected (0.01 sec) powershell中插入的话要等到cmd中commit的时候才能插入,否则会阻塞\nmysql\u0026gt; insert into test_innodb_lock values (2,\u0026#39;2000\u0026#39;); Query OK, 1 row affected (23.87 sec) 什么是间隙锁\n当我们使用范围条件而不是相等条件检索数据,并请求共享或排他锁时,innodb会给符合条件的已有数据记录的索引项加锁;对于键值再条件范围内但并不存在的记录,叫做间隙GAP\ninnodb也会对这个间隙加锁,这种锁机制就是所谓的间隙锁NETT \u0026ndash;KEY锁\n危害\n因为query执行过程中通过范围查找的话,它会锁定整个范围内所有的索引键值,即使这个键值并不存在\n间隙锁有一个比较致命的弱点,就是当锁定一个范围键值之后,即使某些不存在的键值也会被无辜的锁定,而造成锁定的时候无法插入锁定键值范围内的任何数据,在某些场景下这可能会对性能造成很大的危害\nimage-20211022212523821\r如何锁定一行\nselect xxx \u0026hellip; for update 锁定某一行后,其他的操作会被阻塞,直到锁定行的会话提交commit\ncmd使用begin \u0026hellip; for update 来锁定一行\nmysql\u0026gt; begin ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from test_innodb_lock where a = 8 for update ; +------+------+ | a | b | +------+------+ | 8 | 8000 | +------+------+ 1 row in set (0.01 sec) mysql\u0026gt; commit ; Query OK, 0 rows affected (0.01 sec) powershell不能对该行做改动,除非cmd提交了commit才会释放锁\nmysql\u0026gt; update test_innodb_lock set b = \u0026#39;xxx\u0026#39; where a = 8 ; ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction mysql\u0026gt; update test_innodb_lock set b = \u0026#39;xxx\u0026#39; where a = 8 ; Query OK, 1 row affected (2.17 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; commit ; Query OK, 0 rows affected (0.01 sec) 案例结论 innodb存储引擎由于实现了行级锁定,虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会更高一点,但是在整体并发处理能力方面要远远优于myisam的表级锁定的.当系统并发量较高的时候,innodb的整体性能和myisam相比就会有比较明显的优势了.\n但是,innodb的行级锁定同样也有其脆弱的一面,当我们使用不当的时候,可能会让innodb的整体性能表现不仅不能比myisam高,甚至可能会更差.\n如何分析行锁定\n通过检查innodb_row_lock变量来分析系统上的行锁的争夺情况\nmysql\u0026gt; show status like \u0026#39;innodb_row_lock%\u0026#39; ; +-------------------------------+--------+ | Variable_name | Value | +-------------------------------+--------+ | Innodb_row_lock_current_waits | 0 | | Innodb_row_lock_time | 117831 | | Innodb_row_lock_time_avg | 23566 | | Innodb_row_lock_time_max | 51419 | | Innodb_row_lock_waits | 5 | +-------------------------------+--------+ 5 rows in set (0.01 sec) image-20211022214707680\r优化建议 尽可能让所有数据检索都通过索引来完成,避免无索引行锁升级为表锁\n合理设计索引,尽量缩小锁的范围\n尽可能减少检索条件,避免使用间隙锁\n尽量控制事务大小,减少锁定资源量和时间长度\n尽可能低级别事务隔离\n页锁 开销和加锁时间介于表锁和行锁之间;会出现死锁;锁定粒度介于表锁和行锁之间,并发度一般\n主从复制 复制的基本原理 slave会从master读取binlog来进行数据同步 三步骤+原理图 复制的基本原则 每个slave只有一个master 每个slave只能有一个唯一的服务器ID 每个master可以有多个slave 复制的最大问题 延时 一主一从常见配置 mysql版本一致且后台以服务运行 主从都配置在[mysqld]节点下,都是小写 主机修改my.ini配置文件 [必须]主服务器唯一ID server-id =1 ; [必须]启用二进制日志 log-bin = 自己本地的路径/mysqlbin log-bin =C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Data\\LAPTOP-FKVMDBSI-bin [可选]启用错误日志 log-err = 自己本地的路径/mysqlerr log-err=C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Data\\LAPTOP-FKVMDBSI [可选]根目录 basedir=\u0026ldquo;自己本地路径\u0026rdquo; basedir=\u0026ldquo;C:/Program Files/MySQL/MySQL Server 8.0/\u0026rdquo; [可选]临时目录 好像不行再8.0版本中 tmpdir=\u0026ldquo;自己本地路径\u0026rdquo; tmpdir=\u0026ldquo;C:/Program Files/MySQL/MySQL Server 8.0/\u0026rdquo; [可选]数据目录 data=\u0026ldquo;自己本地路径/Data/\u0026rdquo; datadir=C:/ProgramData/MySQL/MySQL Server 8.0\\Data read-only = 0 主机,读写都可以 [可选]设置不要复制的数据库 binlog-ignore-db=不需要复制的主数据库名字 [可选]设置需要复制的数据库 binlog-do-db=需要复制的主数据库名字 从机修改my.cnf配置文件 [必选]从服务器唯一ID [可选]启用二进制日志 因修改过配置文件,请主机+从机都重启后台mysql服务 主机从机都关闭防火墙 windows手动关闭 关闭虚拟机linux防火墙 service iptables stop 在windows主机上建立账户并授权slave create user \u0026lsquo;zhangsan\u0026rsquo;@\u0026lsquo;192.168.202.64\u0026rsquo; identified by \u0026lsquo;123456\u0026rsquo;; grant replication slave on *.* to \u0026lsquo;zhangsan\u0026rsquo; @ \u0026lsquo;192.168.202.64\u0026rsquo; ; 8.0 不支持grant的时候用identified by flush privileges ; 刷新权限 查询master的状态 show master status ; 记录下file和position的值 在linux从机上配置需要复制的主机 change master to master_host=\u0026lsquo;ip地址\u0026rsquo; , master_user =\u0026lsquo;授权的用户\u0026rsquo; , master_password = \u0026lsquo;密码\u0026rsquo; , master_log_file=\u0026lsquo;mysqlbin.具体数字\u0026rsquo;,master_log_pos = 具体值; change master to master_host=\u0026lsquo;192.168.202.64\u0026rsquo; , master_user =\u0026lsquo;zhangsan\u0026rsquo; , master_password = \u0026lsquo;123456\u0026rsquo; , master_log_file=\u0026lsquo;LAPTOP-FKVMDBSI-bin.000105\u0026rsquo;,master_log_pos = 156; 启动从服务器复制功能 start slave ; show slave status \\G ; 下面两个参数都是yes的话,则说明主从配置成功! slave_io_running :yes slave_sql_running :yes 主机新建库/新建表/insert记录/从机复制 如何停止从服务复制功能 stop slave ; 三步骤+原理图\nimage-20211022215731804\r主从复制配置过程 主机\n设置主服务器\nimage-20211023100459506\r设置二进制日志文件\nimage-20211023095228167\r设置错误文件\nimage-20211023095304402\rimage-20211023100542517\r设置读写都可以 设置忽略和需要复制的数据库 设置数据库目录位置\nimage-20211023101034426\r这里有个坑,使用WSL,linux子系统的话不设置端口会导致端口占用,必须把windows上的mysql服务关掉,linuxmysql才能start 所以再配置文件里改一下端口号试试看\nimage-20211023113130359\r弄完重启主机从机的mysql服务\n在windows主机中授权 从000104的912行开始抄书 复制的数据库是bigdata 忽略的数据库是mysql\nmysql\u0026gt; create user \u0026#39;zhangsan\u0026#39;@\u0026#39;192.168.202.64\u0026#39; identified by \u0026#39;123456\u0026#39;; Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; grant replication slave,replication client on *.* to \u0026#39;zhangsan\u0026#39;@\u0026#39;192.168.202.64\u0026#39; ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; flush privileges ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; show master status ; +----------------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------------+----------+--------------+------------------+-------------------+ | LAPTOP-FKVMDBSI-bin.000104 | 912 | bigdata | mysql | | +----------------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) binlog_do_db为空说明都要复制,我重新设置一下\nimage-20211023115552278\r重启服务,查看状态\nmysql\u0026gt; show master status ; +----------------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +----------------------------+----------+--------------+------------------+-------------------+ | LAPTOP-FKVMDBSI-bin.000105 | 156 | | mysql | | +----------------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 接下来进入linux命令行进行操作 通过 Last_IO_Errno 和 Last_SQL_Errno 来排查问题 简单的\nmysql\u0026gt; change master to master_host=\u0026#39;192.168.202.64\u0026#39; , master_user =\u0026#39;zhangsan\u0026#39; , master_password = \u0026#39;123456\u0026#39; , master_log_file=\u0026#39;LAPTOP-FKVMDBSI-bin.000105\u0026#39;,master_log_pos = 156; Query OK, 0 rows affected, 8 warnings (0.00 sec) mysql\u0026gt; start slave ; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql\u0026gt; show slave status \\G ; *************************** 1. row *************************** Slave_IO_State: Waiting for source to send event Master_Host: 192.168.202.64 Master_User: zhangsan Master_Port: 3306 Connect_Retry: 60 Master_Log_File: LAPTOP-FKVMDBSI-bin.000105 Read_Master_Log_Pos: 156 Relay_Log_File: yourtreedad-relay-bin.000003 Relay_Log_Pos: 334 Relay_Master_Log_File: LAPTOP-FKVMDBSI-bin.000105 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 156 Relay_Log_Space: 549 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: 3a5f9439-a33e-11eb-85f6-002b67a4fefa Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Replica has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: Master_public_key_path: Get_master_public_key: 0 Network_Namespace: 1 row in set, 1 warning (0.00 sec) ERROR: No query specified image-20211023150356197\r起飞!!!\n完结撒花~~~\n😜😋🤣😊\n","date":"2021-10-12T19:35:55+08:00","image":"https://linjianshu.github.io/hutomo-abrianto-l2jk-uxb1BY-unsplash.jpg","permalink":"https://linjianshu.github.io/p/test-chinese/","title":"Mysql高级"},{"content":"Go趣学指南 备注:\n内置函数\nlen() cap() append() delete() new() copy() 本书未涉及:\niota表示声明连续的常量 移位操作符\u0026laquo; \u0026raquo; 位运算符 \u0026amp; | 关键字continue和关键字goto和标签 遮蔽变量的具体规则 复数和虚数 裸返回(bare return) 空借口 interface{} 浅尝即止 介绍了类型断言但没有介绍类型判断 双向通道 初始化操作的init特殊函数 每个内置函数没有详细介绍,例如分配内存并返回指针的new函数和复制切片的copy函数 没有说明如何将自己的包分享给别人 git版本控制 丰富的工具和库组成的生态系统 入门 并非所有编程语言都需要编译才能运行,如python ruby和其他一些流行语言就选择了在程序运行的时候,通过解释器一条接一条地转换代码中的声明,但这也意味着bug可能会隐藏在测试尚未触及的代码当中.\n解释器不仅能够让开发过程变得迅速且具有交互性,还能够让语言本身变得灵活,相反编译语言因为缓慢的编译速度常常为人诟病,但实际上并非所有的编译语言都是如此.\ngo想要构造地像c++和java这类静态编译语言一样安全高效,还可以像python这类动态型解释性语言一样轻巧且充满乐趣.\ngo编译器的优点 go的编译可以在极短的时间内完成,只需要一条命令,排除了可能会导致歧义的特性,为传统语言死板的数据结构提供了轻量级别的代替品.它可以在程序运行之前找出代码中一些人为失误,如拼写错误等.\ngo能够利用多核机器商的每个核心获得额外的性能优势.\n包和函数 package关键字声明了代码所属的包,编写代码都会被组织称各式各样的包.go语言本身就提供了这些包,标准库.\nimport关键字导入自己将要用到的包,math包提供了sin cos tan sqrt 等等函数,fmt包则提供了用于格式化输入和输出的函数.\nfunc关键字用于声明函数,每个函数的函数体body都要用大括号{}包围起来\nmain标识符具有特殊意义,从main包的main函数开始执行,如果main不存在,将报告一个错误\n每次用到被导入包中的某个函数时,我们都需要在函数的名字前面加上包的名字以及一个点号座位前缀.\ngo语言的这一特性可以让用户在阅读代码的时候立即弄清楚各个函数分别来自哪些包.\n速查 fmt包提供了格式化输入输出的功能 go程序从main包的main函数开始执行 唯一允许的大括号放置风格 go对于大括号{}的摆放位置非常挑剔.左大括号与func关键字位于同一行,而右大括号单独占一行,除此之外,其他的放置风格都是不允许的.\n不需要加封号,go编译器将自动代劳,代价是遵守大括号放置风格\n小结 每个go程序都有包中包含的函数组成 编程语言中的标点符号也是至关重要的 go关键字 package import func 命令式编程 被美化的计算器 执行计算 算术操作符 + - * / %\n注释 \\\\\n格式化输出 与print和println不一样,printf接受第一个参数总是string,第二个参数是表达式,格式化变量%v会在之后被替换成表达式的值\n换行符 \\n\n可以指定多个格式化变量,按顺序把他们替换成相应的值\nprintf还能够调整文本的对齐位置 用户通过指定带有宽度的格式化变量%4v 当宽度为正数时,空格将被填充至文本左边,而当宽度为负数时,空格将被填充至文本右边.\nfunc main() { fmt.Printf(\u0026#34;%-15v\\n\u0026#34;, \u0026#34;SpaceX\u0026#34;) fmt.Printf(\u0026#34;%15v\\n\u0026#34;, \u0026#34;Vigin Galactic\u0026#34;) } SpaceX Vigin Galactic 进程 已完成，退出代码为 0 常量和变量 两个新的关键字var 和const\n常量是不能被修改的,变量必须先声明后使用\n可以一次声明多个变量,或者在同一行里声明多个变量\nfunc main() { fmt.Printf(\u0026#34;%-15v\\n\u0026#34;, \u0026#34;SpaceX\u0026#34;) fmt.Printf(\u0026#34;%15v\\n\u0026#34;, \u0026#34;Vigin Galactic\u0026#34;) var ( name = \u0026#34;ljs\u0026#34; age = 15 ) var name1 ,age1 = \u0026#34;ljs\u0026#34;,10 fmt.Println(name , age) fmt.Println(name1,age1) } SpaceX Vigin Galactic ljs 15 ljs 10 进程 已完成，退出代码为 0 增量和赋值操作符 赋值的同时执行一些操作 i++ i\u0026ndash;\ngo并不支持++i这种前置增量操作\n数字游戏 如果我们在写代码的时候忘记对伪随机数执行加一操作,那么程序将返回一个0-n-1数字,而不是我们想要的0-n的数字,这是典型的\u0026quot;差一错误 off-by-one error\u0026quot;的例子\nfunc main() { rand.Seed(time.Now().UnixNano()) intn := rand.Intn(10)+1 fmt.Println(intn) fmt.Println(\u0026#34;apppppple\u0026#34;\u0026gt;\u0026#34;banana\u0026#34;) } 10 false 进程 已完成，退出代码为 0 故此,生成56000000至401000000的随机距离,应该是\nvar distance = rand.Intn(345000001)+56000000 小结 print println printf都可以将文本和数值显示到屏幕上\nconst关键字 声明常量 var关键字 声明变量\nrand包的导入路径为math/rand 包中的Intn可以生成伪随机数\n认识关键字 import package func const var\n循环与分支 if 和 switch for循环 基于条件实现循环和分支处理 真或假 python和js中就把空文本\u0026quot;\u0026ldquo;和数字零看作是\u0026quot;假\u0026rdquo;,但是ruby和elixir却把这两个值看作\u0026quot;真\u0026quot;.对go来说,true是唯一的真值,而false是唯一的假值.\nstrings.Contains函数返回真假\n运算符既可以比较数值,也可以比较文本\njs和PHP都提供了特殊的三等号===运算符来实现严格的相等性检查,go只提供了一个相等运算符,而且她不允许直接将文本和数值进行比较.\napple和banana两个单词哪个更大,显然是比较字母 banana更大\n逻辑运算符 go也采用了短路逻辑\n使用switch实现分支 switch a {\ncase \u0026ldquo;helloworld\u0026rdquo;: \u0026hellip;\ncase \u0026ldquo;hello ljs\u0026rdquo;: \u0026hellip;\ndefault: \u0026hellip;\n}\nswitch {\ncase a==\u0026ldquo;helloworld\u0026rdquo;: \u0026hellip;\ncase a==\u0026ldquo;hello ljs\u0026rdquo;: \u0026hellip;\ndefault: \u0026hellip;\n}\nfunc main() { //说明fallthrough只能将下降延续到下一个case语句中 下下个就不行了 并且啊 fallthrough的时候还不需要判断条件就可以执行 score := 79 switch { case score \u0026lt; 100: fmt.Println(\u0026#34;fuck\u0026#34;) fallthrough case score == 90: fmt.Println(\u0026#34;okok\u0026#34;) fallthrough case score \u0026lt; 80: fmt.Println(\u0026#34;just so so\u0026#34;) case score \u0026lt; 60: fmt.Println(\u0026#34;shit shit shit\u0026#34;) } } fuck okok just so so 进程 已完成，退出代码为 0 **注意:\t**在C Java Js等语言中,下降是switch语句各个分支的默认行为,而go对此此案用了更为谨慎的做法,即用户需要显式地使用fallthrough关键字才会引发下降\n使用循环实现重复执行 func main() { count := 10 for count \u0026gt; 0 { intn := rand.Intn(100) if intn == 0 { fmt.Println(\u0026#34;发射失败\u0026#34;) break } else { fmt.Println(count) count-- time.Sleep(1 * time.Second) } } } 通过不为for语句设置任何条件来产生无限循环,然后在有需要的时候通过在循环体内部使用break来跳出循环\nfunc main() { var i int fmt.Println(\u0026#34;请输入100以内要猜的数字\u0026#34;) fmt.Scanf(\u0026#34;%d\u0026#34;,\u0026amp;i) now := time.Now() rand.Seed(time.Now().UnixNano()) for { intn:= rand.Intn(100) if intn==i { fmt.Println(i) break } fmt.Println(intn) time.Sleep(10*time.Millisecond) } fmt.Println(\u0026#34;用时: \u0026#34;,time.Now().Sub(now).String()) } 小结 go通过if switch for 来实现分支判断和重复执行代码 变量作用域 变量在短暂使用之后会被丢弃\n请考虑这一点 虽然计算机的随机访问存储器RAM可以记住大量值,但是程序代码除了被计算机读取之外,还需要被人类阅读,所以应该尽可能保持简洁\n如果可以随时修改或者在任何位置随意访问程序中的变量,那么光是跟踪大型程序中的变量就足以让人手忙脚乱.\n变量作用域的好处就是让程序员聚焦于给定函数或者部分代码的相关变量,而不需要考虑除此之外的其他变量.\n审视作用域 变量一旦脱离作用域,那么尝试继续访问它将引发错误.\n变量作用域的另一个好处就是我们可以为不同的变量复用相同的名字\n除此之外,变量作用域可以帮助我们更好的阅读代码,我们无需在脑海里记住所有变量\n简短声明 简短声明为var关键字提供了另一种备选语法,该语法可以在一些无法使用var关键字的地方使用.\nfunc main() { //短声明就是在var不能使用的时候,替代var来声明变量,同时提高可读性,另外缩小变量的作用域范围,提高变量名的复用性 //可以在case里放置if语句诶 for i := 0; i \u0026lt; 1; i++ { fmt.Println(i) } if i := 1; i \u0026gt; 0 { fmt.Println(\u0026#34;大于0\u0026#34;) } switch i := 1; i { case 1 :fmt.Println(\u0026#34;这是1诶!\u0026#34;) } switch i := 1; i \u0026gt; 0 { case true:fmt.Println(\u0026#34;真的诶!\u0026#34;) } switch i := 1; { case i ==1 :fmt.Println(\u0026#34;真的是1诶!!!\u0026#34;) } } 在使用简短声明的情况下,对i变量的声明和初始化将成为for循环的一部分,该变量在循环结束之后脱离作用域,外部无法访问\n**提示:\t**从代码可读性考虑,声明变量的位置和使用变量的位置应该尽可能邻近\n除了for循环之外,简短声明还可以在if语句 switch语句中使用\n作用域的范围 **注意:\t**包作用域在声明变量时不允许使用简短声明,函数作用域比包作用域的范围狭窄.\nswitch分支的作用域是唯一一种无需使用大括号标识的作用域.\n如果作用域约束太死,就会导致代码重复,我们应该根据这种现象判断是否变量太过约束,并实施重构.\n小结 简短声明不仅仅是var声明的快捷方式,他还可以用在var声明无法使用的地方 类型 字符 文本 数字 基本类型\n实数 浮点数的二进制比位被一分为二,其中一部分用于表示杯子或者说桶bucket,另一部分则用于表示桶中的硬币或者说偏移量\n尽管每个被子能够容纳的最大硬币数量是一致的,但是每个杯子能够表示的数字却是各不相同的.通过控制杯子中的数量可以让一些杯子以较高精度表示小范围数字,或者以较低精度表示大范围数字.\n声明浮点型类型变量 go编译器支持自动推断,所有带小数点的数字在默认情况下都会被设置为float64类型\ngo语言拥有两种浮点类型,默认为float64,很多语言中使用术语双精度浮点数double来描述这种浮点数;另一种浮点类型是float32,又称单精度浮点数,4字节,提供的精度不如float64,使用时需要指定变量类型\n**注意:\t**诸如三位游戏中数量庞大的数据时,使用float32牺牲精度的代价来降低内存占用,是有意义的.而math包的函数处理都是float64类型的值,除非有特殊理由,否则应该优先使用float64类型.\n零值 每种类型都有对应的默认值,我们称为零值.当声明一个变量但是却没有为它设置初始值的时候,它的值就是零值.float32零值就是0.0\n打印浮点类型 使用格式化变量%f来指定被打印小数的位数,甚至可以根据给定的宽度和精度格式化变量值\n精度用于指定小数点之后应该出现的数字数量\n宽度指定了打印整个实数(包括整数部分/小数部分/小数点在内)需要显示的最小字符数量\n长了就被截断了truncate\n如果用户给定的宽度比打印实数所需的字符数量要大,那么将使用空格填出输出的左侧\n如果想使用0而不是空格来填充输出的左侧,在宽度前面加上一个0即可\nfunc main() { third:=1.0/3 fmt.Println(third) fmt.Printf(\u0026#34;%v\\n\u0026#34;,third) fmt.Printf(\u0026#34;%f\\n\u0026#34;,third) fmt.Printf(\u0026#34;%.3f\\n\u0026#34;,third) fmt.Printf(\u0026#34;%4.2f\\n\u0026#34;,third) fmt.Printf(\u0026#34;%5.2f\\n\u0026#34;,third) fmt.Printf(\u0026#34;%05.2f\\n\u0026#34;,third) } 0.3333333333333333 0.3333333333333333 0.333333 0.333 0.33 0.33 00.33 浮点数的精确性 浮点数计算经常会受到舍入错误的影响.为了尽可能减少舍入错误,我们可以将乘法放到出除法的前面执行,类似数值分析防止误差放大.\n比较浮点数 为了避免舍入错误,我们不直接比较两个浮点数,而是计算他们之间的差,是否足够小来判断两个浮点数是否相等.因为我们可以使用math包提供的Abs函数来计算绝对值\nfmt.Println(math.Abs(0.1+0.2 -0.3)\u0026lt;0.0001) **提示:\t**引发浮点数错误的上限值被称为机械最小值,float64是2^-52,float32是2^-23.不幸的是,浮点数错误累积的相当快,因为为了对浮点数进行比较,必须想上列中设定的0.0001那样,根据自己的应用选择一个合适的容差.\n小结 浮点类型的应用范围非常广,但是她的精确性在某些情况下是值得商榷的. 整数 不能存储分数,不会出现浮点类型的精度问题,但每种类型的取值范围各不相同\n声明整数类型变量 众多整数类型中,有5种整数类型是有符号的signed,这意味着他们可以表示正整数也可以表示负整数\n除了有符号整数之外,go还提供了5种只能表示非负整数的无符号unsigned整数类型.例如uint.\ngo进行类型推断的时候总是会选择int类型座位整数值的类型\n为不同场合而设的整数类型 类型 取值范围 内存占用情况 int8 -128-127 8位 uint8 0-255 8位 int16 -32768-32767 16位 uint16 0-65535 16位 int32 -2147483648-2147483647 32位 uint32 0-4294967295 32位 int64 64位 uint64 64位 int类型和uint类型会根据目标硬件选择最合适的位长\n**注意:\t**int不是任何类型的别名,int int32和int64实际上是三种不同的类型\n了解类型 可以使用printf函数提供的格式化变量%T去查看指定变量的类型\n//复用格式化变量 day := 365 fmt.Printf(\u0026#34;one year has %05d days , day is %[1]T type \\n\u0026#34;, day) fmt.Printf(\u0026#34;day is %T type , one year has %05[1]d days\\n\u0026#34;, day) 我们可以将[1]添加到第二个格式化变量%v中,以此来复用第一个格式化变量的值,从而避免代码重复.\none year has 00365 days , day is int type day is int type , one year has 00365 days 十六进制数 十进制对于拥有十根手指的人类来说是一种非常棒的数字系统,但与之相比,十六进制更适合计算机.因为一个十六进制需要消耗4个二进制位,也就是半字节byte,而2个十六进制数则正好需要消耗8个二进制位,也就是1字节.\ngo语言要求十六进制数字必须带有0x前缀.\nvar red , green , blue unit8 = 0,141,213 var red , green , bule unit8 = 0x00 , 0x8d , 0xd5 //这两都一样的 在使用printf函数打印十六进制数字的时候,你可以使用%x或者%X作为格式化变量:\n//十六进制打印成二进制 fmt.Printf(\u0026#34;%05b \\n\u0026#34;, 0xa) 为了能够完美适配层叠样式表文件的颜色和数字,我们需要用到格式化变量%2x.和之前一样0表示用0填充,2表示宽度为2.\nfmt.Printf(\u0026#34;color: #%02x%02x%02x;\u0026#34;,red,green,blue) //打印出\u0026#34;color: #008dd5\u0026#34; 整数回绕 整数类型虽然不会像浮点类型那样因为舍入错误而导致不精确,但它也有自己的局限.那就是有限的取值范围.\n在go中,当超过整数类型的取值范围时,会出现整数回绕wrap around现象.\n例如uint8=255 255+1=\u0026gt;0 int8=127 127+1=\u0026gt;-128\n聚焦二进制位 同样的,使用格式化变量%b,且可以选择启用零填充并指定格式化输出的最小长度。\nfmt.Printf(\u0026#34;%08b\\n\u0026#34;, green) //00000011 由于int类型和uint类型的位长在不同硬件上可能会有所不同,因此math包没有定义这两种类型的最大值常量和最小值常量.\n避免时间回绕 基于unix的操作系统都使用协调世界时UTC 1970.1.1以来的秒数来表示时间,但这个秒数在2038年将超过20亿,大致相当于int32类型的最大值.幸运的是,这个问题可以通过使用64位整数来解决,使用int64或uint64都可以存储\u0026gt;20亿的数字.\n//使用int64解决int32只能表示到2038年的问题 unix := time.Unix(12622780800, 0) fmt.Println(unix) 小结 除非回绕正是你所需要的,否则就应该谨慎的选择合适的整数类型以避免回绕. 大数 学会使用指数来减少键入0的次数 学会使用big包处理非常大的数 学会使用大常量和字面值 计算机编程经常需要权衡利弊,取舍折中.例如浮点数虽然可以存储任意大小的数字,但是有时候会不精确和不准确,相反,整数虽然准确,但是会收到取值范围的限制.本章将介绍两种方案,可以代替float和int,提供数值巨大并且计算精确的数字.\n请考虑这一点 CPU都会为整数运算和浮点数运算提供优化,并且这种优化有时候也适用于其他数值表示.\n指数形式写法 //利用指数来减少0的键入次数 fmt.Println(10e2) //1000 如果:如果用户没有显式的为包含指数的数值变量指定类型,那么go将推断其类型为float64\nbig包 big.Int big.Float big.Rat 存储1/3 一旦决定使用big.Int,就需要在等式的每个部分都是用这种类型,即使对于已经存在的常量来说也是如此.big.Int类型的最基本的方法就是使用NewInt函数,函数接受一个int64类型的值作为输入,返回一个big.Int类型的值作为输出.\nnewInt := big.NewInt(240000000) fmt.Println(newInt) 此外,对于\u0026gt;int64取值范围的数字,我们可以通过给定一个string来创建响应的big.Int类型的值\n//大数 b := new(big.Int) b.SetString(\u0026#34;2400000000\u0026#34;, 10) fmt.Println(b) 因为数值是基于十进制的,所以第二个参数是10\n**注意:\t**方法跟函数非常相似,至于内置函数new则是为指针而设的.\n可以使用Div方法去执行相应的除法操作\n//大数 b := new(big.Int) b.SetString(\u0026#34;2400000000\u0026#34;, 10) fmt.Println(b) newInt := big.NewInt(240000000) fmt.Println(newInt) b.Div(b, newInt) fmt.Println(b) //10 正如所示,big.Int这样的大类型虽然能够精确地表示任意大小的数值,但代价是用起来比int/float等原生类型要麻烦,而且运行速度也会相对较慢.\n大小非同寻常的常量 常量声明可以跟变量声明一样带有类型,但常量也无法用uint64来表示巨大的数值\n所以go语言在处理常量时的做法与处理变量时的做法并不相同.go语言不会为常量推断类型,而是直接将其标识为无类型untyped,这样就不会引发溢出错误.\nconst name = 1 //不会自动推断类型 类型是untyped //字面量和常量底层将由big包提供支持 不会为常量和字面量推断类型 //常量和bigint无法转换 const distance = 236000000000000000 const guangnian = 100000000 //b2 := new(big.Int) //setString, _ := b2.SetString(\u0026#34;236000000000000000\u0026#34;, 10) //setString.Div(setString,guangnian) fmt.Println(distance / guangnian) 常量通过关键字const来进行声明,除此之外,程序里的每个字面量值literal value也都是常量.\n因为go的编译器就是用go语言编写的,并且在底层实现中,无类型的数值常量将由big包提供支持.\n变量也可以使用常量作为值,只要变量的大小能够容纳常量即可.\n尽管go编译器使用big包处理无类型的数值常量,但常量和big.Int值是无法互换的\n小结 无类型常量可以存储非常大的数值,并且所有数值型字面量都是无类型常量. 无类型常量在被用作函数参数的时候,必须转换为有类型变量. 多语言文本 计算机在表示文本的时候使用了一些特殊技巧,从而使这种表示既节省存储空间又足够灵活.\n如果你声明了一个变量,但是没有为它赋值,那么go语言将使用变量类型的零值对其进行初始化,而string类型的零值就是空字符串\u0026quot;\u0026quot;\n原始字符串字面量 字符串字面量可以包含转义字符,可以使用反引号`而不是双引号来包围文本\n原始字符串字面量可以在代码里跨越多个文本行\n//使用反引号包围的叫做原始字符字面量 fmt.Printf(\u0026#34;hello world \\t\\t\u0026#34;) fmt.Printf(`hello world \\t\\t`) 字符/代码点/符文和字节 go语言提供了rune(符文)类型,该类型是int32的别名,此外go语言还提供了uint8类型的别名byte,这种类型可以很好地表示二进制数据,也可以表示ASCII的英文字符,刚好128个\n**类型别名:\t**因为类型别名实际上就是同一类型的不同名字,所以rune和int32是可以互换的,当然,用户也可以自行声明类型别名\ntype byte = uint8 使用格式化变量%c来打印字符而不是数字本身\nfmt.Printf(\u0026#34;\\n%c\u0026#34;, 65) fmt.Printf(\u0026#34;\\n%c\u0026#34;, 128515) var rune = 65 fmt.Printf(\u0026#34;\\n%c\u0026#34;, rune) fmt.Println(strconv.Atoi(string(\u0026#39;😃\u0026#39;))) //这样不行 只能给string进行转换成int 比如\u0026#34;110\u0026#34;-\u0026gt;110 fmt.Printf(\u0026#34;%d\\n\u0026#34;, \u0026#39;😃\u0026#39;) A 😃 A0 strconv.Atoi: parsing \u0026#34;😃\u0026#34;: invalid syntax 128515 **提示:\t**虽然任意一种整数类型都可以使用格式化变量%c,但是通过使用别名rune可以表明数字960的用途是用来表示字符的,而不是用来表示数字.\ngo提供了相应的字符字面量句法,用户只需要向\u0026rsquo;A\u0026rsquo;这样使用单引号将字符包围起来,就可以取得该字符的代码点.如果用户声明了一个字符字面量却没有为其指定类型,那么go将推断该变量的类型为rune\n虽然rune类型代表的是一个字符,但它实际上存储的仍然是数字值.\n字符串操作 go的字符串并不容易被操纵.我们可以将不同字符串赋值给同一个变量,但是无法对字符串本身进行修改\n可以通过方括号[]指定指向字符串的索引,但是不能修改这些字符\nRuby中的字符串和C的字符数组允许被修改,而go中的字符串与python/java/js中的字符串一样,都是不可变的,你不能修改go中的字符串.\ns := \u0026#34;shalom\u0026#34; for _, c := range s { fmt.Printf(\u0026#34;%d\\n\u0026#34;, c) } fmt.Println(\u0026#39;A\u0026#39; - \u0026#39;a\u0026#39;) fmt.Printf(\u0026#34;%c\\n\u0026#34;, \u0026#39;x\u0026#39;+3-26) 115 104 97 108 111 109 -32 a 将字符串解码为符文 以往我们访问字符串通常都是访问字符串的每个字节(8位),但是没有考虑到各个字符可能会由多个字节组成(如16位或32位),例如中文/韩文/日语等.所以处理字符串前,先将他们解码为rune类型,也就是4字节32位.\n**注意:\t**go语言和很多编程语言不同的一点在于,go允许函数返回多个值\nforrange关键字可以迭代各种不同的收集器,还可以解码UTF-8编码的字符串,而fori就不行.\n不需要某个返回值的时候,使用_来省略即可.\n//forrange可以解析UTF-8的编码 所以这里遍历是没有问题的 for _, v := range \u0026#34;镜中花,水中月\u0026#34; { fmt.Printf(\u0026#34;%c %[1]T \\n\u0026#34;, v) } //fori不能解析UTF-8编码 求len的时候就已经出问题了 shi := \u0026#34;镜中花,水中月\u0026#34; for i := 0; i \u0026lt; len(shi); i++ { fmt.Printf(\u0026#34;%c %[1]T \\n\u0026#34;, shi[i]) } fmt.Println(len(\u0026#34;镜中花,水中月\u0026#34;)) //len返回的是字符串占位的字节长度 这里返回19 镜 int32 中 int32 花 int32 , int32 水 int32 中 int32 月 int32 é uint8 ä uint8 ¸ uint8 ­ uint8 è uint8 ± uint8 , uint8 æ uint8 ° uint8 ´ uint8 ä uint8 ¸ uint8 ­ uint8 æ uint8 19 此外,可以使用utf8包的函数来处理字符串\n//使用utf8包和函数 //解析第一个字占几字节 具体值是多少 decodeRune, size := utf8.DecodeRune([]byte(shi)) fmt.Println(size) fmt.Printf(\u0026#34;%c \\n\u0026#34;, decodeRune) //查看一共解析了几个字 inString := utf8.RuneCountInString(shi) fmt.Println(inString) //解析第一个字占几字节 具体值是多少 runeInString, size1 := utf8.DecodeRuneInString(shi) fmt.Printf(\u0026#34;%c %d bytes\\n\u0026#34;, runeInString, size1) s3 := \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34; decodeRuneInString, i := utf8.DecodeRuneInString(s3) fmt.Println(decodeRuneInString, \u0026#34; \u0026#34;, i) //判断它占了几个字节 r, size2 := utf8.DecodeRuneInString(\u0026#34;¿\u0026#34;) fmt.Println(r, \u0026#34; \u0026#34;, size2) //go使用UTF-8可变长度编码,每个字符根据需要占用1-4个字节的内存空间 //可能会问fori和forr的区别吧 3 镜 7 镜 3 bytes 97 1 191 2 小结 使用反引号` 可以包围原始字符串字面量,像\\n这样的转义字符将原样保留 字符串是不可变的,可以独立访问字符串中的每个字符,但是不能修改他们 字符串使用UTF-8可变长度编码,每个字符需要占用1-4个字节内存空间 byte是uint8类型的别名,而rune是int32类型的别名 关键字range可以将UTF-8编码的字符串解码为符文 类型转换 学会在数值、字符串和布尔值之间实施类型转换 类型不能混合使用 如果尝试拼接数值和字符串,那么go编译器将报告一个错误(无效操作:不匹配的类型)\n在其他语言中混合使用多种类型 有些编程语言在程序员同时给定两种或多种不同类型的值时,会尽可能猜测程序员的意图.对于实施隐式类型转换的语言来说,不能熟记各种隐式转换规则的人将难以预测代码行为.对go编译器而言,它不会这样,只会引发一个类型不匹配的错误.\n混合使用整数类型和浮点类型同样会引发类型不匹配的错误.\ngo不会对你的意图做任何的假设,你必须通过显式的类型转换来解决这个问题.\n数字类型转换 虽然go语言不允许混合使用不同类型的变量,但是通过类型转换,可以顺利运行.\n将浮点转为整数,将直接被截断而不会做任何舍入操作.\n此外,各种长度不同的类型之间的转换.从取值范围小的类型转换为取值范围较大的类型总是安全的,但其他方式的类型转换则存在风险.\n类型转换的危险之处 之所以go希望我们进行显式的类型转换,就是让我们三思而后行,思考类型转换可能引发的后果.\n例如整数类型变量转化的时候会不会出现数值过大产生回绕行为.\n我们可以通过math包提供的最小常量和最大常量,来检测值的转换是否得到了无效值.\nvar bh float64 = 32768 if bh \u0026gt; math.MaxInt16 || bh \u0026lt; math.MinInt16 { fmt.Println(bh \u0026gt; math.MaxInt16 || bh \u0026lt; math.MinInt16) } **注意:\t**因为math包提供的最小常量和最大常量都是无类型的,所以程序可以直接使用浮点数bh去跟整数maxint16做比较.\n字符串转换 将rune或者byte转换为string,和使用格式化变量%c将符文和字节显示成字符得到的结果是一样的\nvar pi rune = 960 var alpha rune = 940 var omega rune = 969 var bang byte = 33 //直接对数字执行string 不会把33=\u0026gt;\u0026#34;33\u0026#34; 而是会把33代表的字符char找出来 fmt.Println(string(pi), string(alpha), string(omega), string(bang)) fmt.Printf(\u0026#34;%c %c %c %c \\n\u0026#34;, pi, alpha, omega, bang) π ά ω ! π ά ω ! 如前所述,数字代码点转换为字符串的方法实际山适用于所有整数类型\ncountdown := 10 //将数字直接变成字符串 而不是char 使用itoa或者sprint fmt.Println(\u0026#34;launch in T minus \u0026#34; + strconv.Itoa(countdown) + \u0026#34; seconds.\u0026#34;) fmt.Println(\u0026#34;launch in T minus \u0026#34; + fmt.Sprintf(\u0026#34;%v\u0026#34;, countdown) + \u0026#34; seconds.\u0026#34;) 另外,如果我们需要把字符串转换为数值,那么可以使用strconv包提供的atoi函数.需要注意的是,因为字符串里面可能含有无法转换为数字的奇怪文字,或者非常大以至于无法用整数类型表示的数字,那么atoi会返回一个错误,我们需要对错误进行处理.\n静态类型 在go中,变量一旦被声明,就有了类型并且无法改变它的类型,这种机制成为静态类型.尝试在go中使用同一个变量操纵多个不同类型的值,将引发go编译器报告错误.\n与静态类型相反,js/python/ruby等语言都采用了名为动态类型的机制.\ngo也提供了一些特殊的机制来应对类型不确定的情况.我猜的,例如反射,断言,空接口类型.\n转换布尔值 在go语言中,布尔值并没有与之相等的数字值或字符串值,因此尝试使用string(false) int(false)huozhe bool(1) bool(\u0026ldquo;yes\u0026rdquo;) 都会导致编译器报错.\n小结 显式的类型转换能够避免编程中的歧义 ","date":"2021-10-11T09:17:59+08:00","permalink":"https://linjianshu.github.io/p/go%E8%B6%A3%E5%AD%A6%E6%8C%87%E5%8D%97/","title":"Go趣学指南"},{"content":"mysql学习文档 一 为什么要学习数据库 二 数据库的相关概念 DBMS DB SQL\n三 数据库存储数据的特点 四 初始mysql mysql产品的介绍\nmysql产品的安装\nmysql服务的启动和停止\nmysql服务的登陆和退出\nmysql的常见命令和语法规范\n五DQL语言的学习 基础查询\n条件查询\n排序查询\n常见函数\n分组查询\n连接查询\n子查询\n分页查询\nunion联合查询\n六 DML语言的学习 插入语句\n修改语句\n删除语句\n七 DDL语言的学习 库和表的管理\n常见数据类型介绍\n常见约束\n保存数据的容器:\n数组 集合 内存数据 断电就没了\n文件 但是文件不好查找\n因此把文件做成方便增删改查的软件 对文件进行操作 这样的软件就叫做数据库\n数据库的好处 实现数据持久化 使用完整的管理系统统一管理,易于查询 数据库的概念 DB 数据库 database:存储数据的仓库,保存了一系列有组织的数据.\nDBMS 数据库管理系统 database management system 数据库是通过dbms创建和操作的容器\n常见的数据库管理系统 mysql oracle db2 sqlserver\nSQL 结构化查询语言 structure query language :专门用来与数据库通信的语言\nsql的优点:\n不是某个特定数据库供应商专有的语言,几乎所有DBMS都支持sql 简单易学 虽然简单,但实际上是一种强有力的语言,灵活使用其语言元素,可以进行非常复杂和高级的数据库操作 类似于管家 管理 文件柜 DBMS 管理 DB\n数据库的特点 将数据放到表中,表再放到库中 一个数据库中够可以有多个表,每个表都有一个自己的名字,用来标识自己,表名具有唯一性 表具有一些特性,这些特性定义了数据在表中如何存储,类似java中类的设计 表由列组成,我们也称为字段.所有表都是由一个或多个列组成的,每个列类似java中的属性 表中的数据是按行存储的,每一行类似于java中的对象 Mysql产品的特点 mysql数据库隶属于mysqlab公司,总部位于瑞典,后被oracle收购 优点 成本低:开放源代码,一般可以免费使用 性能高:执行很快 简单:很容易安装和使用 DBMS分为两类 基于共享文件系统的DBMS 例如 access 基于客户机\u0026mdash;服务器的DBMS 例如 mysql oracle sqlserver mysql版本 社区版 免费 企业版 收费 mysql卸载 先控制面板卸载\n然后在安装目录下删除文件夹\n然后在programdata中删除残余文件\n清理注册表\nimage-20210919154523464\rmy.ini 配置文件 image-20210919160841225\r端口号 安装位置 数据存放位置 字符集 默认存储引擎 语法模式 最大连接数\n改完服务需要重启\nmysql服务的启动和停止 image-20210919161439996\rmysql服务端的登陆和退出 使用mysql command line client 不建议 只适用于root用户 image-20210919161620401\rimage-20210919161637466\r2.命令行 p输入密码不能有空格 -h 主机名 -P 端口号 -u 用户名 -p密码\nimage-20210919161848290\r简化命令 退出exit 或者 ctrl+C\nimage-20210919161938321\r基本命令\nshow databases ; use tset ; //进入数据库 image-20210919163057930\rshow tables ; //查看数据库里的表 在当前用户进入的数据库中查看 show tables from sys ; //查看数据库里的表 可以在当前数据库中查看别的数据库中的表 select database() ; //查看当前处于什么位置 类似于linux中的 pwd create table ... //创建表 image-20210919163334648\rdesc stuInfo ; //查看表stuInfo中的字段 insert into stuInfo(id,name) value (1,\u0026#39;ljs\u0026#39;) ; delete from stuInfo where id = 1; update stuInfo set name =\u0026#39;jwt\u0026#39; where id =1; select * from stuInfo ; #增删改查 image-20210919163430191\r练习\nimage-20210919164509494\rsql select version() ; //查看版本号 sql中 cmd mysql --version mysql -V mysql的语法规范 不区分大小写,但建议关键字大写,表名 列名小写 每条命令用分号结尾 每条命令根据需要,可以进行缩进或者换行 注释 单行注释 #注释文字 \u0026ndash; 注释文字 (必须要有空格) 多行注释 /* lkdfjasldfj */ 基础查询 select 查询列表 from 表名\n查询列表可以是:表中的字段 / 常量值 / 表达式 / 函数 查询的结果可以是一个虚拟的表格 查询单个字段\n查询多个字段\n查询所有字段\nselect * 不能控制字段的显示顺序\n之所以用`` 着重号 第一为了直白,第二为了区分关键字 防止与关键字重名\n查询常量\n查询表达式\n查询函数\nimage-20210919202609756\rselect 100 ; select \u0026#39;join\u0026#39; ; select 100*98 ; select database () ; select version () ; show tables ; 起别名 方便理解 如果要查询的字段有重名的情况,使用别名可以区分开来\n方式一: 使用as\n方式二: 直接不用as\nselect last_name as 姓 ,first_name as 名 from employees ; select last_name 姓 ,first_name 名 from employees ; # 防止歧义 双引号也行 单引号也可以 select salary as `out put` from employees ; 去重\nselect database() ; show tables ; desc employees ; select distinct department_id from employees ; image-20210919203515527\r+号的作用\n姓名连接成一个字段 , 显示为姓名\n以下错误\nimage-20210919203805417\rjava中的+号:\n运算符 , 操作数为数值型 连接符, 只要有一个操作数为字符串 mysql中的+号:\n仅仅只有一个功能:运算符 select 100+90 ;\nselect \u0026lsquo;123\u0026rsquo; +90 ; 其中一方为字符型,视图将字符型数值转换为数值型, 如果转换成功,则继续做加法运算\nselect \u0026lsquo;james\u0026rsquo; + 90 ; 如果转换失败,则将字符型数值转换成0\nselect null +10 ; 只要其中一方为null , 则结果肯定为null image-20210919204251938\r所以需要使用函数 concat() ;\n#这是错误的用法 , 加上了单引号 , 无法解析 select concat (\u0026#39;last_name\u0026#39; , \u0026#39;first_name\u0026#39;) 姓名 from employees ; #这是正确的 select concat (last_name , first_name) 姓名 from employees ; 显示出表employees中的全部列,各个列之间用逗号连接,列头显示成out_put #查看某表列名 select column_name fuck_name from information_schema.columns where table_schema = \u0026#39;myemployees\u0026#39; and table_name = \u0026#39;employees\u0026#39; ; #没问题 因为不存在null select concat (employee_id ,\u0026#39;,\u0026#39;,first_name ) from employees ; #有问题 因为存在null , 导致那行都变成null 了 select concat (employee_id ,\u0026#39;,\u0026#39;,first_name,\u0026#39;,\u0026#39;,commission_pct ) from employees ; +----------------------------------------------------------+ | concat (employee_id ,\u0026#39;,\u0026#39;,first_name,\u0026#39;,\u0026#39;,commission_pct ) | +----------------------------------------------------------+ | NULL | | NULL | | NULL | | NULL | | NULL | 引入函数 IFNULL select IFNULL(a,b) select ifnull(commission_pct,0) as 奖金率, commission_pct from employees ; mysql\u0026gt; select ifnull(commission_pct,0) as 奖金率, commission_pct from employees ; +--------+----------------+ | 奖金率 | commission_pct | +--------+----------------+ | 0.00 | NULL | | 0.00 | NULL | | 0.00 | NULL | | 0.00 | NULL | | 0.00 | NULL | | 0.00 | NULL | | 0.40 | 0.40 | | 0.30 | 0.30 | | 0.30 | 0.30 | #这是正确的 select concat (employee_id ,\u0026#39;,\u0026#39;,first_name,\u0026#39;,\u0026#39;,ifnull(commission_pct,0) ) from employees ; +--------------------------------------------------------------------+ | concat (employee_id ,\u0026#39;,\u0026#39;,first_name,\u0026#39;,\u0026#39;,ifnull(commission_pct,0) ) | +--------------------------------------------------------------------+ | 142,Curtis,0.00 | | 143,Randall,0.00 | | 144,Peter,0.00 | | 161,Sarath,0.25 | | 169,Harrison,0.20 | | 170,Tayler,0.20 | | 171,William,0.15 | 条件查询 select 查询列表 from 表名 where 筛选条件 ; 先查表名有没有在,再筛选,再查询\n分类\n按条件表达式筛选 条件运算符 \u0026gt; \u0026lt; = \u0026lt;\u0026gt;(不等于) 按逻辑表达式筛选 作用用于连接条件表达式 \u0026amp;\u0026amp; || ! and or not 模糊查询 like between and in is null #条件运算符 select * from employees where salary \u0026gt;12000 ; #逻辑运算符 select first_name , department_id from employees where department_id \u0026lt;\u0026gt; 90 ; #逻辑表达式筛选 select first_name , salary , commission_pct from employees where salary \u0026gt;10000 and salary \u0026lt;20000 ; #好像三个不太一样 select * from employees where not(department_id between 90 and 120) or salary \u0026gt;15000 ; select * from employees where department_id not in(90, 120) or salary \u0026gt;15000 ; select * from employees where department_id not in(department_id between 90 and 120) or salary \u0026gt;15000 ; 模糊查询\nlike 一般和通配符使用 % 0到任意个字符 _ 任意一个字符 between and in is null | is not null #模糊查询 select * from employees where first_name like \u0026#39;%a%\u0026#39; ; select first_name , salary from employees where first_name like \u0026#39;__e_a%\u0026#39; ; #如果不想使用转义字符 , 第二个字符就是_ 而不是任意单个字符的话 mysql\u0026gt; select last_name from employees where last_name like \u0026#39;_\\_%\u0026#39; ; +-----------+ | last_name | +-----------+ | K_ing | | K_ing | +-----------+ 2 rows in set (0.00 sec) #或者使用以下这种 使用ESCAPE 来取消转义 mysql\u0026gt; select last_name from employees where last_name like \u0026#39;_$_%\u0026#39; escape \u0026#39;$\u0026#39; ; +-----------+ | last_name | +-----------+ | K_ing | | K_ing | +-----------+ 2 rows in set (0.00 sec) mysql\u0026gt; select last_name from employees where last_name like \u0026#39;_h_%\u0026#39; escape \u0026#39;h\u0026#39; ; +-----------+ | last_name | +-----------+ | K_ing | | K_ing | +-----------+ 2 rows in set (0.00 sec) between and 提高语句简洁度 左右都包含临界值 不能颠倒顺序 #左闭右闭 select * from employees where employee_id between 100 and 120 ; in 判断某字段的值是否属于in列表中的某一项 使用 in 提高语句的简洁度\nin 列表的值类型必须一致或兼容\nin 不支持通配符 毕竟不是like关键字\nselect employee_id , job_id from employees where job_id in(\u0026#39;IT_PROG\u0026#39;,\u0026#39;AD_VP\u0026#39;,\u0026#39;AD_PRES\u0026#39;) ; is null = 或 \u0026lt;\u0026gt; 不能用于判断null值 select first_name , commission_pct from employees where commission_pct is null ; is not null 安全等于 \u0026lt;=\u0026gt; #安全等于可以用来判断是不是为空 select first_name , commission_pct from employees where commission_pct \u0026lt;=\u0026gt; null ; #安全等于也可以用来判断是不是某个数值 mysql\u0026gt; select last_name , salary from employees where salary \u0026lt;=\u0026gt; 12000 ; +-----------+----------+ | last_name | salary | +-----------+----------+ | Greenberg | 12000.00 | | Errazuriz | 12000.00 | | Higgins | 12000.00 | +-----------+----------+ 3 rows in set (0.00 sec) 安全等于和is null 的区别 is null 仅仅可以判断null值 , 可读性较高 , 建议使用\n\u0026lt;=\u0026gt; 既可以判断null值,又可以判断普通的数值\n复习一下 mysql 与mysql的第一次亲密接触 数据库的好处 持久化数据到本地 结构化查询 数据库的常见概念 DB 数据库,存储数据的容器 DBMS 数据库管理系统, 又称为数据库软件或数据库产品,用于创建或管理DB SQL 结构化查询语言 ,用于和数据库通信的语言,不是某个数据库软件特有的,而是几乎所有的主流数据库软件通用的语言 数据库存储的特点 数据存放到表中,然后表再存放到库中 一个库中可以有多张表,每张表具有唯一的表名用以标识自己 表有一个或多个列,列又称为字段,相当于java中的属性 表中的每一行数据,相当于java中的对象 常见的数据库管理系统 mysq oracle db2 sqlserver\nmysql的介绍 mysql的背景 前身属于瑞典的一家公司 mysql ab , 08被sun收购 , 09年被oracle收购\nmysql的优点 开源免费成本低 性能高 , 移植性好 体积小,便于安装 mysql的安装 属于c/s架构的软件,一般来讲是安装服务端\n企业版/社区版\n环境变量配置\nmysql服务的启动和停止 net start mysql\n图形化界面里开服务\nmysql服务的登陆和退出 mysql -h localhost -P 3306 -u root -p123456\nexit或者ctrl+C\nDQL语言 基础查询 select 查询列表 from 表名\n特点\n查询列表可以是字段/常量 / 表达式/ 函数/ 也可以是多个 查询结果是一个虚拟表 示例\n查询单个字段 select 字段名 from 表名 ;\n查询多个字段 select 字段名 , 字段名 from 表名 ;\n查询所有字段 select * from 表名 ;\n查询常量 select 常量 as \u0026hellip; ;\n注意:字符型和日期型的常量值必须用单引号引起来,数值型不需要\n查询函数 select 函数名(实参列表) ;\n查询表达式 select 100%98 ;\n起别名 as 空格 去重 distinct 只能给一个参数用\n+号的作用 只能做加法运算\nselect 数值+数值 ; 直接运算\nselect 字符 +数值 ; 尝试隐式转换然后运算 , 成功就成功,不成功就是0+数值\nselect null + 数值; 返回null\nconcat函数 拼接字符\nselect concat (字符1 , 字符2 , 字符3 \u0026hellip;) ;\nifnull函数 判断某自字段或表达式是否为null , 如果为null 返回指定的值, 否则返回原本的值\nselect ifnull(commission_pct,0) from employees ; 如果是null则返回0 , 如果不是null , 则返回原值\nisnull函数 判断是不是null , 是的话返回1 , 否的话就返回0\n条件查询 select 查询列表 from 表名 where 筛选条件\n筛选条件的分类\n简单条件运算符 \u0026gt; \u0026lt; = \u0026lt;\u0026gt; \u0026lt;=\u0026gt; \u0026gt;= \u0026lt;= 逻辑运算符 || \u0026amp;\u0026amp; ! and or not 模糊查询 like in is null is not null between and\nlike :一般搭配通配符使用, 用于判断字符型数值, 在5.5版本之后 , 也可以判断int类型的 , % 和 _ 区别\nmysql\u0026gt; select * from employees where department_id like \u0026#39;1__\u0026#39; ; +-------------+-------------+-----------+----------+--------------+------------+----------+----------------+------------+---------------+---------------------+ | employee_id | first_name | last_name | email | phone_number | job_id | salary | commission_pct | manager_id | department_id | hiredate | +-------------+-------------+-----------+----------+--------------+------------+----------+----------------+------------+---------------+---------------------+ | 108 | Nancy | Greenberg | NGREENBE | 515.124.4569 | FI_MGR | 12000.00 | NULL | 101 | 100 | 1998-03-03 00:00:00 | | 109 | Daniel | Faviet | DFAVIET | 515.124.4169 | FI_ACCOUNT | 9000.00 | NULL | 108 | 100 | 1998-03-03 00:00:00 | | 110 | John | Chen | JCHEN | 515.124.4269 | FI_ACCOUNT | 8200.00 | NULL | 108 | 100 | 2000-09-09 00:00:00 | | 111 | Ismael | Sciarra | ISCIARRA | 515.124.4369 | FI_ACCOUNT | 7700.00 | NULL | 108 | 100 | 2000-09-09 00:00:00 | | 112 | Jose Manuel | Urman | JMURMAN | 515.124.4469 | FI_ACCOUNT | 7800.00 | NULL | 108 | 100 | 2000-09-09 00:00:00 | | 113 | Luis | Popp | LPOPP | 515.124.4567 | FI_ACCOUNT | 6900.00 | NULL | 108 | 100 | 2000-09-09 00:00:00 | | 205 | Shelley | Higgins | SHIGGINS | 515.123.8080 | AC_MGR | 12000.00 | NULL | 101 | 110 | 2016-03-03 00:00:00 | | 206 | William | Gietz | WGIETZ | 515.123.8181 | AC_ACCOUNT | 8300.00 | NULL | 205 | 110 | 2016-03-03 00:00:00 | +-------------+-------------+-----------+----------+--------------+------------+----------+----------------+------------+---------------+---------------------+ 8 rows in set (0.00 sec) is null 和\u0026lt;=\u0026gt; 的区别 is null 只会判断null\n\u0026lt;=\u0026gt; 不仅判断null 还可以普通类型的数值\n排序查询 select 查询列表 from 表 where 筛选条件 order by 排序列表 asc|desc\n默认是asc 升序\n支持单个字段/多个字段/表达式/函数/别名\norder by 一般是放在查询语句的最后面 limit子句除外\n按表达式排序 按字段排序 按别名排序 按函数排序 按多字段排序 select * from employees order by salary desc ; select * from employees order by salary asc ; #默认升序 asc select * from employees where department_id \u0026gt;=90 order by hiredate desc ; # *必须放在前面 可以按照表达式排序 也可以按照别名排序 select * , salary*12*(1+ifnull(commission_pct,0))as 年薪 from employees order by 年薪 desc; # 按照函数排序 select last_name , salary from employees order by length(last_name) desc ; #双重排序 先按照工资升序排 , 再按照员工编号降序排 select * from employees order by salary asc , employee_id desc ; 练习\nselect last_name , department_id , salary * 12 * (1+ifnull(commission_pct,0)) as 年薪 from employees order by 年薪 desc , length(last_name) asc ; #以下用法 错误 between and 不能 按照 别名来 select last_name , salary as 工资 from employees where not(工资 between 8000 and 17000) order by 工资 ; #以下用法 正确 select last_name , salary as 工资 from employees where not(salary between 8000 and 17000) order by 工资 ; #可以这样 直接 not between and select last_name , salary as 工资 from employees where salary not between 8000 and 17000 order by 工资 select * from employees where email like \u0026#39;%e%\u0026#39; order by length(email) desc , department_id ; 常见函数 功能:类似于java中的方法,将一组逻辑语句封装在方法体中,对外暴露方法名\n好处:1.隐藏了实现细节 2.提高代码的重用性\n调用: select 函数名(实参列表) [from 表] ;\n特点:\n叫什么 函数名 干什么 函数功能 分类：\n单行函数 字符函数 length concat substr substring replace lpad rpad upper lower instr trim 数学函数 mod floor round ceil truncate 日期函数 now curdate curtime year month monthname day hour minute second date_format str_to_date 其他函数 流程控制函数 concat / length / ifnull 等 分组函数 做统计使用 又称为统计函数、聚合函数、组函数 #查看字节长度 mysql\u0026gt; select length(\u0026#39;lalala\u0026#39;) ; +------------------+ | length(\u0026#39;lalala\u0026#39;) | +------------------+ | 6 | +------------------+ 1 row in set (0.00 sec) #查看字节长度 mysql\u0026gt; select length (\u0026#39;林健树\u0026#39;) ; +-------------------+ | length (\u0026#39;林健树\u0026#39;) | +-------------------+ | 6 | +-------------------+ 1 row in set (0.00 sec) #展示字符集 mysql\u0026gt; show variables like \u0026#39;%char%\u0026#39; ; +--------------------------+---------------------------------------------------------+ | Variable_name | Value | +--------------------------+---------------------------------------------------------+ | character_set_client | gbk | | character_set_connection | gbk | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | gbk | | character_set_server | utf8mb4 | | character_set_system | utf8mb3 | | character_sets_dir | C:\\Program Files\\MySQL\\MySQL Server 8.0\\share\\charsets\\ | +--------------------------+---------------------------------------------------------+ #拼接字符 select concat(last_name , \u0026#39;_\u0026#39; , first_name ) from employees ; # upper / lower select upper(\u0026#39;aaabbbccc\u0026#39;) ; select lower(\u0026#39;aBc\u0026#39;) ; #函数嵌套 select concat(lower(last_name),\u0026#39;_\u0026#39;,upper(first_name)) from employees ; #substr / substring #sql中索引从1开始 mysql\u0026gt; select substring(\u0026#39;李莫愁爱上了陆展元\u0026#39;,7) out_put ; +---------+ | out_put | +---------+ | 陆展元 | +---------+ 1 row in set (0.00 sec) #函数的重载 从指定索引出指定字符长度的字符 mysql\u0026gt; select SUBSTRING(\u0026#39;李莫愁爱上了陆展元\u0026#39;,1,3) ; +-------------------------------------+ | SUBSTRING(\u0026#39;李莫愁爱上了陆展元\u0026#39;,1,3) | +-------------------------------------+ | 李莫愁 | +-------------------------------------+ 1 row in set (0.00 sec) select concat(concat(upper(substring(first_name,1,1)),substr(first_name,2)),\u0026#39;_\u0026#39;,last_name) from employees ; #instr 判断是否在字符串中 #返回的是第一次出现的索引 索引仍然从1开始 , 如果找不到返回0 mysql\u0026gt; select instr(\u0026#39;杨不悔爱上了尹柳霞\u0026#39;,\u0026#39;尹柳霞\u0026#39;) ; +--------------------------------------+ | instr(\u0026#39;杨不悔爱上了尹柳霞\u0026#39;,\u0026#39;尹柳霞\u0026#39;) | +--------------------------------------+ | 7 | +--------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select instr(\u0026#39;杨不悔尹柳霞爱上了尹柳霞\u0026#39;,\u0026#39;尹柳霞\u0026#39;) out_put ; +---------+ | out_put | +---------+ | 4 | +---------+ 1 row in set (0.00 sec) #trim 去空格 mysql\u0026gt; select length(\u0026#39; 张翠山 \u0026#39;) , length (trim(\u0026#39; 张翠山 \u0026#39;)) ; +------------------------+--------------------------------+ | length(\u0026#39; 张翠山 \u0026#39;) | length (trim(\u0026#39; 张翠山 \u0026#39;)) | +------------------------+--------------------------------+ | 12 | 6 | +------------------------+--------------------------------+ 1 row in set (0.00 sec) #trim 可以去掉指定的字符或者字符串 中间不会去掉的 mysql\u0026gt; select trim(\u0026#39;a\u0026#39; from \u0026#39;aabbaaccaa\u0026#39;) as out_put ; +---------+ | out_put | +---------+ | bbaacc | +---------+ 1 row in set (0.00 sec) #trim 只是按照单位去去的 mysql\u0026gt; select trim(\u0026#39;aa\u0026#39; from \u0026#39;aaabbaaccaaa\u0026#39;) as out_put ; +----------+ | out_put | +----------+ | abbaacca | +----------+ 1 row in set (0.00 sec) #lpad 用指定的字符来实现左填充指定长度 mysql\u0026gt; select lpad(\u0026#39;殷素素\u0026#39;,10,\u0026#39;*\u0026#39;) ; +-----------------------+ | lpad(\u0026#39;殷素素\u0026#39;,10,\u0026#39;*\u0026#39;) | +-----------------------+ | *******殷素素 | +-----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select lpad(\u0026#39;97\u0026#39;,3,\u0026#39;0\u0026#39;) ; +------------------+ | lpad(\u0026#39;97\u0026#39;,3,\u0026#39;0\u0026#39;) | +------------------+ | 097 | +------------------+ 1 row in set (0.00 sec) #lpad 如果长度超过了 反而会发生截断 从左边开始向右边截断 mysql\u0026gt; select lpad(\u0026#39;101\u0026#39;,2,\u0026#39;0\u0026#39;) ; +-------------------+ | lpad(\u0026#39;101\u0026#39;,2,\u0026#39;0\u0026#39;) | +-------------------+ | 10 | +-------------------+ 1 row in set (0.00 sec) #Rpad同理 #replace替换 mysql\u0026gt; select replace(\u0026#39;张无忌爱上了周芷若\u0026#39;,\u0026#39;周芷若\u0026#39;,\u0026#39;赵敏\u0026#39;) as out_put ; +------------------+ | out_put | +------------------+ | 张无忌爱上了赵敏 | +------------------+ 1 row in set (0.00 sec) #replace 凡是有的全部替换喔 mysql\u0026gt; select replace(\u0026#39;周芷若张无忌爱上了周芷若\u0026#39;,\u0026#39;周芷若\u0026#39;,\u0026#39;赵敏\u0026#39;) as out_put ; +----------------------+ | out_put | +----------------------+ | 赵敏张无忌爱上了赵敏 | +----------------------+ 1 row in set (0.00 sec) 数学函数 round 四舍五入\n#round 四舍五入 mysql\u0026gt; select round(4.65) ; +-------------+ | round(4.65) | +-------------+ | 5 | +-------------+ 1 row in set (0.00 sec) #round 两个参数时,后面的参数是值按小数点后几位来四舍五入 mysql\u0026gt; select round(4.65,1) ; +---------------+ | round(4.65,1) | +---------------+ | 4.7 | +---------------+ mysql\u0026gt; select round(4.65,0) ; +---------------+ | round(4.65,0) | +---------------+ | 5 | +---------------+ 1 row in set (0.00 sec) #ceil 向上取整 mysql\u0026gt; select ceil(1.001) ; +-------------+ | ceil(1.001) | +-------------+ | 2 | +-------------+ 1 row in set (0.00 sec) #floor 向下取整 mysql\u0026gt; select floor(-1.01) ; +--------------+ | floor(-1.01) | +--------------+ | -2 | +--------------+ 1 row in set (0.00 sec) #truncate 截断 保留小数点后几位 mysql\u0026gt; select truncate(1.6999,2) ; +--------------------+ | truncate(1.6999,2) | +--------------------+ | 1.69 | +--------------------+ 1 row in set (0.00 sec) #mod 取余运算 a-a/b*b a/b会发生截断的可能 所以这个等式没毛病 # -10 mod -3 = -1 -10 mod 3 = -1 10 mod -3 = 1 只要被除数是- 就是- mysql\u0026gt; select mod(10,-3) ; +------------+ | mod(10,-3) | +------------+ | 1 | +------------+ 1 row in set (0.00 sec) 日期函数 # now 返回当前系统日期 包含时间 mysql\u0026gt; select now() ; +---------------------+ | now() | +---------------------+ | 2021-09-20 16:00:28 | +---------------------+ 1 row in set (0.00 sec) # curdate 返回当前日期 不包含时间 mysql\u0026gt; select curdate() ; +------------+ | curdate() | +------------+ | 2021-09-20 | +------------+ 1 row in set (0.00 sec) # curtime 返回当前时间 不包含日期 mysql\u0026gt; select curtime() ; +-----------+ | curtime() | +-----------+ | 16:01:21 | +-----------+ 1 row in set (0.00 sec) #获取指定的部分 , 年 月 日 时 分 秒 mysql\u0026gt; select year(now()) 年 , month (\u0026#39;1998-1-1\u0026#39;) 月, day(curdate())日 ; +------+------+------+ | 年 | 月 | 日 | +------+------+------+ | 2021 | 1 | 20 | +------+------+------+ 1 row in set (0.00 sec) # 获取月份的英文 mysql\u0026gt; select monthname(hiredate) 月份英文, year(hiredate) from employees ; +-----------+----------------+ | 月份英文 | year(hiredate) | +-----------+----------------+ | April | 1992 | | April | 1992 | # 日期转换函数 str_to_date() date_format() mysql\u0026gt; select str_to_date (\u0026#39;9--10--2021\u0026#39;,\u0026#39;%m--%d--%Y\u0026#39;) as out_put ; +------------+ | out_put | +------------+ | 2021-09-10 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select date_format(\u0026#39;2021-09-20\u0026#39;,\u0026#39;%y年%m月%d日\u0026#39;) as out_put ; +--------------+ | out_put | +--------------+ | 21年09月20日 | +--------------+ 1 row in set (0.00 sec) # 前端传进来的是字符串 而且格式不一 我们要使用函数来将字符串做处理 解析成想要的格式 然后再到数据库中查找 mysql\u0026gt; select hiredate from employees where hiredate = str_to_date(\u0026#39;4-3 1992\u0026#39;,\u0026#39;%c-%d %Y\u0026#39;) ; +---------------------+ | hiredate | +---------------------+ | 1992-04-03 00:00:00 | | 1992-04-03 00:00:00 | | 1992-04-03 00:00:00 | | 1992-04-03 00:00:00 | | 1992-04-03 00:00:00 | +---------------------+ 5 rows in set (0.00 sec) #数据库这边也需要做好相应的处理 将日期处理成对应格式字符串然后返回回去 mysql\u0026gt; select last_name ,date_format(hiredate,\u0026#39;%m月/%d日 %y年\u0026#39;) as 入职日期 from employees where commission_pct \u0026lt;=\u0026gt; null ; +-------------+----------------+ | last_name | 入职日期 | +-------------+----------------+ | K_ing | 04月/03日 92年 | | Kochhar | 04月/03日 92年 | image-20210920161042293\rimage-20210920161613677\r其他函数 mysql\u0026gt; select version() ; +-----------+ | version() | +-----------+ | 8.0.24 | +-----------+ 1 row in set (0.00 sec) mysql\u0026gt; select database() ; +-------------+ | database() | +-------------+ | myemployees | +-------------+ 1 row in set (0.00 sec) mysql\u0026gt; select user() ; +----------------+ | user() | +----------------+ | root@localhost | +----------------+ 1 row in set (0.00 sec) 流程控制函数 # IF函数 true就是第二个参数 false就是第三个参数 mysql\u0026gt; select commission_pct , if(isnull(commission_pct)=0,\u0026#39;没奖金 呵呵\u0026#39;,\u0026#39;有奖金 嘻嘻\u0026#39;) 备注 from employees ; +----------------+-------------+ | commission_pct | 备注 | +----------------+-------------+ | NULL | 有奖金 嘻嘻 | | NULL | 有奖金 嘻嘻 | # mysql中默认 0就是第三个参数 1就是第二个参数 mysql\u0026gt; select commission_pct , if(isnull(commission_pct),\u0026#39;没奖金 呵呵\u0026#39;,\u0026#39;有奖金 嘻嘻\u0026#39;) 备注 from employees ; +----------------+-------------+ | commission_pct | 备注 | +----------------+-------------+ | NULL | 没奖金 呵呵 | | NULL | 没奖金 呵呵 | mysql\u0026gt; select commission_pct , if(isnull(commission_pct),concat(\u0026#39;没奖金 呵呵 \u0026#39;,0),concat(\u0026#39;有奖金 嘻嘻 \u0026#39;,commission_pct)) 备注 from employees ; +----------------+------------------+ | commission_pct | 备注 | +----------------+------------------+ | NULL | 没奖金 呵呵 0 | | NULL | 没奖金 呵呵 0 | #case 函数 相当于 switch case的效果 /* case 要判断的字段或者表达式 when 常量1 then 要显示的值1或语句1 when 常量2 then 要显示的值2或语句2 ... else 要显示的值n或语句n end */ mysql\u0026gt; select salary 原始工资 , department_id 部门, case department_id when 30 then salary*1.1 when 40 then salary*1.2 when 50 then salary*1.3 else salary end as 新工资 from employees ; +----------+------+----------+ | 原始工资 | 部门 | 新工资 | +----------+------+----------+ | 24000.00 | 90 | 24000.00 | | 17000.00 | 90 | 17000.00 | #case 多重if类似于 /* case when 条件1 then 要显示的值1或语句1 when 条件2 then 要显示的值2或语句2 ... else 要显示的值n或语句n end */ mysql\u0026gt; select salary , case when salary \u0026gt;20000 then \u0026#39;A\u0026#39; when salary \u0026gt;15000 then \u0026#39;B\u0026#39; when salary \u0026gt;10000 then \u0026#39;C\u0026#39; else \u0026#39;D\u0026#39; end as 工资级别 from employees ; +----------+----------+ | salary | 工资级别 | +----------+----------+ | 24000.00 | A | | 17000.00 | B | | 17000.00 | B | 练习\nselect employee_id , last_name , salary , salary * 1.2 as `new salary` from employees ; mysql\u0026gt; select last_name , substr(last_name , 1,1) as szm ,length(last_name) `length` from employees order by szm ; +-------------+------+--------+ | last_name | szm | length | +-------------+------+--------+ | Austin | A | 6 | | Atkinson | A | 8 | mysql\u0026gt; select concat(last_name,\u0026#39; earns \u0026#39; ,salary ,\u0026#39; monthly but wants \u0026#39;, salary*3 ) `Dream Salary` from employees ; +-----------------------------------------------------+ | Dream Salary | +-----------------------------------------------------+ | K_ing earns 24000.00 monthly but wants 72000.00 | | Kochhar earns 17000.00 monthly but wants 51000.00 | mysql\u0026gt; select job_id as job , case job_id when \u0026#39;AD_PRES\u0026#39; then \u0026#39;A\u0026#39; when \u0026#39;ST_MAN\u0026#39; then \u0026#39;B\u0026#39; when \u0026#39;IT_PROG\u0026#39; then \u0026#39;C\u0026#39;end grade from employees ; +------------+-------+ | job | grade | +------------+-------+ | AC_ACCOUNT | NULL | | AC_MGR | NULL | 分组函数 功能:用作统计使用,又称为聚合函数或统计函数或组函数\n分类:\nsum 求和 avg平均值 max最大值 min最小值 count计算个数\nmysql\u0026gt; select sum(salary) from employees ; +-------------+ | sum(salary) | +-------------+ | 691400.00 | +-------------+ 1 row in set (0.00 sec) mysql\u0026gt; select avg(salary) from employees ; +-------------+ | avg(salary) | +-------------+ | 6461.682243 | +-------------+ 1 row in set (0.00 sec) mysql\u0026gt; select min(salary) from employees ; +-------------+ | min(salary) | +-------------+ | 2100.00 | +-------------+ 1 row in set (0.00 sec) mysql\u0026gt; select max(salary) from employees ; +-------------+ | max(salary) | +-------------+ | 24000.00 | +-------------+ 1 row in set (0.00 sec) mysql\u0026gt; select count(salary) from employees ; +---------------+ | count(salary) | +---------------+ | 107 | +---------------+ 1 row in set (0.00 sec) mysql\u0026gt; select sum(salary) 和 , round(avg(salary),2) 平均 , min(salary) 最低 , max(salary) 最高,count(salary) 个数 from employees ; +-----------+---------+---------+----------+------+ | 和 | 平均 | 最低 | 最高 | 个数 | +-----------+---------+---------+----------+------+ | 691400.00 | 6461.68 | 2100.00 | 24000.00 | 107 | +-----------+---------+---------+----------+------+ #参数支持哪些类型 #sum avg 不支持字符型 mysql\u0026gt; select sum(last_name) , avg(last_name) from employees ; +----------------+----------------+ | sum(last_name) | avg(last_name) | +----------------+----------------+ | 0 | 0 | +----------------+----------------+ # max min 支持字符型/日期型 只要能够排序 max 和 min就能支持 mysql\u0026gt; select max(last_name) , min(last_name) from employees ; +----------------+----------------+ | max(last_name) | min(last_name) | +----------------+----------------+ | Zlotkey | Abel | +----------------+----------------+ mysql\u0026gt; select max(hiredate) , min(hiredate) from employees ; +---------------------+---------------------+ | max(hiredate) | min(hiredate) | +---------------------+---------------------+ | 2016-03-03 00:00:00 | 1992-04-03 00:00:00 | +---------------------+---------------------+ 1 row in set (0.00 sec) #count支持计数 计的是非null的数 mysql\u0026gt; select count(last_name) from employees ; +------------------+ | count(last_name) | +------------------+ | 107 | +------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select count(commission_pct)from employees ; +-----------------------+ | count(commission_pct) | +-----------------------+ | 35 | +-----------------------+ #判断是否忽略null来计算 这里说明sum肯定是没参与 因为如果有null null+任何都是null 不可能有值 #avg也没有参与 所以avg不将null的项加入运算 mysql\u0026gt; select sum(commission_pct)总计 , avg(commission_pct) 平均值, sum(commission_pct)/35 没参与 , sum(commission_pct)/107 参与了 from employees ; +------+----------+----------+----------+ | 总计 | 平均值 | 没参与 | 参与了 | +------+----------+----------+----------+ | 7.80 | 0.222857 | 0.222857 | 0.072897 | +------+----------+----------+----------+ 1 row in set (0.00 sec) #min 和 max 也忽略了null 否则肯定会在一头出现的 mysql\u0026gt; select max(commission_pct) max , min(commission_pct) min from employees ; +------+------+ | max | min | +------+------+ | 0.40 | 0.10 | +------+------+ 1 row in set (0.00 sec) #可以和distinct 匹配使用 mysql\u0026gt; select sum(distinct salary) 去重, sum(salary) 不去重 from employees ; +-----------+-----------+ | 去重 | 不去重 | +-----------+-----------+ | 397900.00 | 691400.00 | +-----------+-----------+ 1 row in set (0.00 sec) mysql\u0026gt; select count(distinct(salary)) 几种工资 from employees ; +----------+ | 几种工资 | +----------+ | 57 | +----------+ 1 row in set (0.00 sec) # count 1 和 2 意思是加了一列 那么当然就等同于统计行数辣 mysql\u0026gt; select count(*) from employees ; +----------+ | count(*) | +----------+ | 107 | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; select count(1) from employees ; +----------+ | count(1) | +----------+ | 107 | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; select count(2) from employees ; +----------+ | count(2) | +----------+ | 107 | +----------+ 1 row in set (0.00 sec) 所有的分组函数 都忽略null值\n可以和distinct搭配\ncount函数的详细介绍\n效率:\nMYISAM 存储引擎下, count(*) 的效率高\nINNODB存储引擎下, count(*) 和 count(1) 的效率差不多,比count(字段) 要高一点儿\n和分组函数一同查询的字段有限制\n#已经不存在逻辑意义了 mysql\u0026gt; select avg(salary) , employee_id from employees ; +-------------+-------------+ | avg(salary) | employee_id | +-------------+-------------+ | 6461.682243 | 100 | +-------------+-------------+ 1 row in set (0.00 sec) 和分组函数一同查询的字段要求是group by 后的字段\n练习一下\nmysql\u0026gt; select datediff(max(hiredate),min(hiredate)) from employees ; +---------------------------------------+ | datediff(max(hiredate),min(hiredate)) | +---------------------------------------+ | 8735 | +---------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select datediff(now(),\u0026#39;1997-11-21\u0026#39;) 活了多久了 ; +------------+ | 活了多久了 | +------------+ | 8705 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select count(*) from employees where department_id = 90 ; +----------+ | count(*) | +----------+ | 3 | +----------+ 1 row in set (0.00 sec) 分组查询 select 分组函数, 列(要求出现在group by的后面) from 表 where 筛选条件 group by 分组的列表 order by 子句\n**注意:\t**查询列表必须特殊,要求是分组函数和group by 后出现的字段\ngroup by可以使用别名 oracle是不支持的 mysql支持\nhaving 可以使用别名 oracle是不支持的 mysql支持\norder by 可以使用别名 oracle是不支持的 mysql支持\nwhere 不可以使用别名\nmysql\u0026gt; select max(salary) 最高工资 , job_id 工种 from employees group by 工种 ; +----------+------------+ | 最高工资 | 工种 | +----------+------------+ | 8300.00 | AC_ACCOUNT | | 12000.00 | AC_MGR | | 4400.00 | AD_ASST | mysql\u0026gt; select count(*) 部门个数 , location_id 位置 from departments group by 位置; +----------+------+ | 部门个数 | 位置 | +----------+------+ | 1 | 1400 | | 1 | 1500 | mysql\u0026gt; select avg(salary) 平均工资,department_id 部门编号 from employees where email like \u0026#39;%a%\u0026#39; group by 部门编号 ; +--------------+----------+ | 平均工资 | 部门编号 | +--------------+----------+ | 7000.000000 | NULL | | 4400.000000 | 10 | +--------------+----------+ 11 rows in set (0.00 sec) #查询有奖金的每个领导手下员工的最高工资 很奇怪 mysql\u0026gt; select max(salary)最高工资,manager_id 领导 from employees where commission_pct \u0026lt;=\u0026gt; null group by manager_id ; +----------+------+ | 最高工资 | 领导 | +----------+------+ | 24000.00 | NULL | | 17000.00 | 100 | | 9000.00 | 102 | | 6000.00 | 103 | | 12000.00 | 101 | | 9000.00 | 108 | | 3100.00 | 114 | | 3200.00 | 120 | | 4200.00 | 121 | | 3800.00 | 122 | | 4000.00 | 123 | | 3500.00 | 124 | | 6000.00 | 201 | | 8300.00 | 205 | +----------+------+ 14 rows in set (0.00 sec) mysql\u0026gt; select max(salary)最高工资,manager_id 领导 from employees where commission_pct is not null group by manager_id ; +----------+------+ | 最高工资 | 领导 | +----------+------+ | 14000.00 | 100 | | 10000.00 | 145 | | 10000.00 | 146 | | 10500.00 | 147 | | 11500.00 | 148 | | 11000.00 | 149 | +----------+------+ 6 rows in set (0.00 sec) #查询每个部门的员工个数 其实就是having 在每个group之下的筛选 mysql\u0026gt; select department_id 部门 , count(*)员工个数 from employees group by 部门 having 员工个数\u0026gt;2 ; +------+----------+ | 部门 | 员工个数 | +------+----------+ | 30 | 6 | | 50 | 45 | | 60 | 5 | | 80 | 34 | | 90 | 3 | | 100 | 6 | +------+----------+ 6 rows in set (0.00 sec) #查询每个工种有奖金的员工的最高工资\u0026gt;12000的工种编号和最高工资 mysql\u0026gt; select max(salary) 最高工资 , job_id 工种编号 from employees where commission_pct is not null group by 工种编号 having 最高工资\u0026gt;12000 ; +----------+----------+ | 最高工资 | 工种编号 | +----------+----------+ | 14000.00 | SA_MAN | +----------+----------+ 1 row in set (0.00 sec) #查询领导编号\u0026gt;102的每个领导手下的最低工资\u0026gt;5000的领导编号是那个,以及其最低工资 mysql\u0026gt; select min(salary) 最低工资 , manager_id 领导编号 from employees where manager_id\u0026gt;102 group by 领导编号 having 最低工资\u0026gt;5000 ; +----------+----------+ | 最低工资 | 领导编号 | +----------+----------+ | 6900.00 | 108 | | 7000.00 | 145 | 特点 分组查询中的筛选条件分为两类 分组前筛选 来源于原始表 放在group by 子句的前面 使用where关键字 分组后筛选 来源于分组后的结果集 放在group by子句的后面 使用having关键字 分组函数 min max count avg 作为条件肯定是放在having子句中 能用分组前筛选的,就优先考虑放在分组前面,考虑到性能 group by 子句支持单个字段分组,多个字段分组(多个字段之间用逗号隔开,没有顺序之分),也支持表达式或函数(较少) 也可以添加排序(排序放在整个分组查询的最后) 按表达式或函数分组 #按员工姓名的长度分组,查询每一组的员工个数,筛选同学个数\u0026gt;5的有哪些 mysql\u0026gt; select length(last_name) 姓名长度 , count(*) 员工个数 from employees group by length(last_name) having 员工个数\u0026gt;5 ; +----------+----------+ | 姓名长度 | 员工个数 | +----------+----------+ | 5 | 29 | | 7 | 15 | 按多个字段分组 #查询每个部门每个工种的员工的平均工资 交换group by 的顺序不影响 mysql\u0026gt; select avg(salary) 平均工资, department_id 部门编号 , job_id 工种编号 from employees group by 部门编号 , 工种编号 ; +--------------+----------+------------+ | 平均工资 | 部门编号 | 工种编号 | +--------------+----------+------------+ | 24000.000000 | 90 | AD_PRES | | 17000.000000 | 90 | AD_VP | | 5760.000000 | 60 | IT_PROG | 分组后添加排序 mysql\u0026gt; select avg(salary) 平均工资, department_id 部门编号 , job_id 工种编号 from employees group by 部门编号 , 工种编号 order by 平均工资 asc ; +--------------+----------+------------+ | 平均工资 | 部门编号 | 工种编号 | +--------------+----------+------------+ | 2780.000000 | 30 | PU_CLERK | | 2785.000000 | 50 | ST_CLERK | 练习一下\nmysql\u0026gt; select job_id 工种, max(salary) 最大 ,min(salary) 最小 ,avg(salary) 平均 ,sum(salary) 总和 from employees group by 工种 order by 工种 asc ; +------------+----------+----------+--------------+-----------+ | 工种 | 最大 | 最小 | 平均 | 总和 | +------------+----------+----------+--------------+-----------+ | AC_ACCOUNT | 8300.00 | 8300.00 | 8300.000000 | 8300.00 | | AC_MGR | 12000.00 | 12000.00 | 12000.000000 | 12000.00 | mysql\u0026gt; select max(salary)-min(salary) DIFFERENCE from employees ; +------------+ | DIFFERENCE | +------------+ | 21900.00 | +------------+ mysql\u0026gt; select manager_id 领导编号, employee_id 员工编号, min(salary) 最低工资 from employees where salary \u0026gt;=6000 and manager_id is not null group by 领导编号 ; +----------+----------+----------+ | 领导编号 | 员工编号 | 最低工资 | +----------+----------+----------+ | 100 | 101 | 6500.00 | | 102 | 103 | 9000.00 | mysql\u0026gt; select department_id 部门编号 , count(*) 员工数量 , avg(salary) 平均工资 from employees group by 部门编号 order by 平均工资 desc ; +----------+----------+--------------+ | 部门编号 | 员工数量 | 平均工资 | +----------+----------+--------------+ | 90 | 3 | 19333.333333 | | 110 | 2 | 10150.000000 | mysql\u0026gt; select job_id 工种 , count(*)人数 from employees group by 工种 ; +------------+------+ | 工种 | 人数 | +------------+------+ | AC_ACCOUNT | 1 | | AC_MGR | 1 | 连接查询 含义:又称为多表查询,当查询的字段来自于多个表时,就会用到连接查询\n笛卡尔积现象: 表1 有m行 表2 有n行 结果有m*n行\n发生原因:没有有效的连接条件\n如何避免:添加有效的连接条件\nimage-20210921141653473\r每个都匹配了一遍 , 这不好 ,都是我的\nmysql\u0026gt; select name , boyName from beauty , boys where beauty.boyfriend_id =boys.id ; +------------+---------+ | name | boyName | +------------+---------+ | Angelababy | 黄晓明 | | 热巴 | 鹿晗 | | 周芷若 | 张无忌 | | 小昭 | 张无忌 | | 王语嫣 | 段誉 | | 赵敏 | 张无忌 | +------------+---------+ 分类:\n按照年代分类 sql92标准 仅仅支持内连接 sql99标准 [推荐] 支持内连接+外连接(左外+右外)+交叉连接 按功能分类 内连接 等值连接 非等值连接 自连接 外连接 左外连接 右外连接 全外连接 交叉连接 #以下是sql92标准的等值连接用法 mysql\u0026gt; select last_name , department_name from employees , departments where employees.department_id =departments.department_id ; +-------------+-----------------+ | last_name | department_name | +-------------+-----------------+ | K_ing | Exe | | Kochhar | Exe | #为表起别名 提高语句的简洁度 区分多个重名的字段 mysql\u0026gt; select last_name , e.job_id , job_title from employees e , jobs where e.job_id = jobs.job_id ; +-------------+------------+---------------------------------+ | last_name | job_id | job_title | +-------------+------------+---------------------------------+ | Gietz | AC_ACCOUNT | Public Accountant | | Higgins | AC_MGR | Accounting Manager | #交换表的出现顺序是可以的 #加上筛选条件 mysql\u0026gt; select last_name , commission_pct , department_name from employees e ,departments d where commission_pct is not null and e.department_id = d.department_id ; +------------+----------------+-----------------+ | last_name | commission_pct | department_name | +------------+----------------+-----------------+ | Russell | 0.40 | Sal | | Partners | 0.30 | Sal | mysql\u0026gt; select department_name , city from departments d ,locations l where d.location_id = l.location_id and city like \u0026#39;_o%\u0026#39; ; +-----------------+---------------------+ | department_name | city | +-----------------+---------------------+ | IT | Southlake | | Shi | South San Francisco | #查询每个城市的部门个数 mysql\u0026gt; select city , count(*) 部门个数 from departments d , locations l where d.location_id = l.location_id group by city ; +---------------------+----------+ | city | 部门个数 | +---------------------+----------+ | Southlake | 1 | | South San Francisco | 1 | | Seattle | 21 | mysql\u0026gt; select d.department_id , department_name , d.manager_id , min(salary) 最低工资 from employees e , departments d where e.department_id = d.department_id and commission_pct is not null group by department_id ; +---------------+-----------------+------------+----------+ | department_id | department_name | manager_id | 最低工资 | +---------------+-----------------+------------+----------+ | 80 | Sal | 145 | 6100.00 | +---------------+-----------------+------------+----------+ mysql\u0026gt; select job_title , count(*) 员工个数 from employees e , jobs j where e.job_id = j.job_id group by j.job_id order by 员工个数 desc ; +---------------------------------+----------+ | job_title | 员工个数 | +---------------------------------+----------+ | Sales Representative | 30 | | Shipping Clerk | 20 | #三表连接 mysql\u0026gt; select last_name , department_name , city from employees e , departments d , locations l where e.department_id = d.department_id and d.location_id = l.location_id ; +-------------+-----------------+---------------------+ | last_name | department_name | city | +-------------+-----------------+---------------------+ | Whalen | Adm | Seattle | | Hartstein | Mar | Toronto | 注意:如果为表起了别名,则查询的字段就不能使用原来的表名去限定了\nsql92标准 等值连接 多表等值连接的结果为多表的交集部分 n表连接,至少需要n-1个连接条件 多表的顺序没有要求 一般需要为表其别名 可以搭配前面介绍的所有子句使用,比如排序/筛选/分组 非等值连接 #非等值连接 也可以加上排序/筛选/分组 mysql\u0026gt; select salary , grade_level from employees e , job_grades g where salary between lower_sal and highest_sal ; +----------+-------------+ | salary | grade_level | +----------+-------------+ | 24000.00 | E | | 17000.00 | E | ​\t3.自连接\n# mysql\u0026gt; select a.last_name 员工名 ,b.last_name 领导名称 from employees a , employees b where a.manager_id =b.employee_id ; +-------------+-----------+ | 员工名 | 领导名称 | +-------------+-----------+ | Kochhar | K_ing | | De Haan | K_ing | 练习一下 mysql\u0026gt; select max(salary) , min(salary) from employees ; +-------------+-------------+ | max(salary) | min(salary) | +-------------+-------------+ | 24000.00 | 2100.00 | +-------------+-------------+ mysql\u0026gt; select employee_id , job_id , last_name from employees order by department_id desc , salary asc ; +-------------+------------+-------------+ | employee_id | job_id | last_name | +-------------+------------+-------------+ | 206 | AC_ACCOUNT | Gietz | | 205 | AC_MGR | Higgins | mysql\u0026gt; select job_id from employees where job_id like \u0026#39;%a%e%\u0026#39; order by job_id ; +---------+ | job_id | +---------+ | AD_PRES | | SA_REP | mysql\u0026gt; select substr(\u0026#39;aabbcc\u0026#39;,3) ; +--------------------+ | substr(\u0026#39;aabbcc\u0026#39;,3) | +--------------------+ | bbcc | +--------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select trim( \u0026#39;aa\u0026#39; from \u0026#39;aaabbbcccaaa\u0026#39;) ; +---------------------------------+ | trim( \u0026#39;aa\u0026#39; from \u0026#39;aaabbbcccaaa\u0026#39;) | +---------------------------------+ | abbbccca | +---------------------------------+ 1 row in set (0.00 sec) 复习一下 语法\nselect 查询列表 from 表 where 筛选条件 order by 排序列表 asc|desc\n特点\nasc 升序 默认 desc 降序\n排序列表 支持 单个字段 多个字段 函数 表达式 别名\norder by 位置一般放在查询语句的最后(除了limit语句之外)\n常见函数\n功能:类似于java中的方法\n好处:提高重用性和隐藏实现细节\n调用:select 函数名(实参列表) ;\n单行函数\n字符函数 length concat substr substring upper lower instr replace trim lpad rpad 数学函数 truncate round ceil mod floor rand(获取随机数 0-1) 日期函数 curdate curtime now year month monthname day hour minute second date_format str_to_date timediff datediff 其他函数 version user database ifnull isnull md5(自动将字符加密成md格式密文) 流程控制函数 if case when then else end mysql\u0026gt; select MD5(\u0026#39;lalala123\u0026#39;) ; +----------------------------------+ | MD5(\u0026#39;lalala123\u0026#39;) | +----------------------------------+ | 24500fa6ecaeb8300905727802af3081 | +----------------------------------+ 1 row in set (0.00 sec) 流程控制函数\nif(条件表达式, 表达式1 , 表达式2) 如果条件表达式成立, 返回表达式1 , 否则返回表达式2 #case 情况1 case 变量或表达式或字段 when 常量1 then 值1 when 常量2 then 值2 else 值n end #case 情况2 case when 条件1 then 值1 when 条件2 then 值2 else 值n end 分组函数 分类\nmax min avg sum count\n特点\nselect max(字段) from 表名\n支持的类型\nsum 和 avg 一般用于处理数值型\nmax min count 可以处理任何数据类型\n以上分组函数都忽略null\n都可以搭配distinct使用,实现去重的统计\nselect sum(distinct 字段) from 表 ;\ncount函数\ncount(字段) 统计该字段非空值的个数\ncount(*) 统计结果集的行数\ncount(1) 统计结果集的行数\n效率上:\nmyisam 存储引擎 count(*) 最高\ninnodb 存储引擎 count(*)和count(1) 效率\u0026gt;count(字段)\n和分组函数一同查询的字段,要求是group by后面出现的字段\n分组查询 select 分组函数, 分组后的字段 from 表 where 筛选条件 group by 分组的字段 having 分组后的筛选 order by 排序列表\n分组前筛选 where 原始表 group by的前面\n分组后筛选 having 分组后的结果 group by的后面\n连接查询 含义 当查询中涉及到了多个表的字段,需要使用多表连接\nselect 字段1 , 字段2 from 表1 , 表2\n笛卡儿乘积:当查询多个表时,没有添加有效的连接条件,导致多个表所有行实现完全连接\n如何解决:添加有效的连接条件\n分类 按年代分类 sql92 等值 非等值 自连接 也支持一部分外连接 用于oracle sqlserver , mysql不支持 sql99 [推荐使用] 内连接 等值 非等值 自连接 外连接 左外 右外 全外(mysql 不支持) 交叉连接 等值连接: select 查询列表 from 表1 别名, 表2 别名 where 表1.key = 表2.key and 筛选条件 group by 分组字段 having 分组后的筛选 order by 排序字段\n特点:\n一般为表起别名 多表顺序可以调换 n表连接至少需要n-1个连接条件 等值连接的结果是多表的交集部分 非等值连接 select 查询列表 from 表1 别名, 表2 别名 where 非等值连接条件 and 筛选条件 group by 分组字段 having 分组后的筛选 order by 排序字段\n自连接 select 查询列表 from 表 别名1, 表 别名2 where 等值连接条件 and 筛选条件 group by 分组字段 having 分组后的筛选 order by 排序字段\n练习一下\nmysql\u0026gt; select last_name , e.department_id , department_name from employees e , departments d where e.department_id = d.department_id ; +-------------+---------------+-----------------+ | last_name | department_id | department_name | +-------------+---------------+-----------------+ | Whalen | 10 | Adm | | Hartstein | 20 | Mar | mysql\u0026gt; select job_id , d.location_id from employees e , departments d where d.department_id = 90 and e.department_id = d.department_id ; +---------+-------------+ | job_id | location_id | +---------+-------------+ | AD_PRES | 1700 | | AD_VP | 1700 | mysql\u0026gt; select last_name , department_name , d.location_id , city from employees e , departments d ,locations l where e.department_id = d.department_id and d.location_id = l.location_id and commission_pct is not null ; +------------+-----------------+-------------+--------+ | last_name | department_name | location_id | city | +------------+-----------------+-------------+--------+ | Russell | Sal | 2500 | Oxford | | Partners | Sal | 2500 | Oxford | mysql\u0026gt; select last_name , job_id , d.department_id , department_name from employees e ,departments d , locations l where e.department_id = d.department_id and d.location_id = l.location_id and city =\u0026#39;Toronto\u0026#39; ; +-----------+--------+---------------+-----------------+ | last_name | job_id | department_id | department_name | +-----------+--------+---------------+-----------------+ | Hartstein | MK_MAN | 20 | Mar | | Fay | MK_REP | 20 | Mar | +-----------+--------+---------------+-----------------+\\ #查询每个工种 每个部门的部门名 工种名 和最低工资 mysql\u0026gt; select department_name , job_title ,min(salary) from employees e , departments d,jobs j where e.department_id = d.department_id and j.job_id = e.job_id group by j.job_title , d.department_name ; +-----------------+---------------------------------+-------------+ | department_name | job_title | min(salary) | +-----------------+---------------------------------+-------------+ | Acc | Public Accountant | 8300.00 | | Acc | Accounting Manager | 12000.00 | #查询每个国家下的部门个数大于2的国家编号 mysql\u0026gt; select country_id,count(*) 部门个数 from locations l , departments d where l.location_id = d.location_id group by country_id having 部门个数\u0026gt;2 ; +------------+----------+ | country_id | 部门个数 | +------------+----------+ | US | 23 | +------------+----------+ #选择指定员工的姓名 员工号 以及他的管理者的姓名和员工号 结果类似于下面的格式 mysql\u0026gt; select a.last_name employees , a.employee_id Emp , b.last_name manager , b.employee_id Mgr from employees a , employees b where a.manager_id = b.employee_id ; +-------------+-----+-----------+-----+ | employees | Emp | manager | Mgr | +-------------+-----+-----------+-----+ | Kochhar | 101 | K_ing | 100 | | De Haan | 102 | K_ing | 100 | sql99语法 语法:\nselect 查询列表 from 表1 别名 连接类型 join 表2 别名 on 连接条件 where 筛选条件 group by 分组条件 having 筛选条件 order by 排序列表\n分类:\n内连接: inner\n外连接:\n​\t左外:left outer\n​\t右外:right outer\n​\t全外:full outer\n交叉连接 :cross\n内连接 select 查询列表 from 表1 别名 inner join 表2 别名 on 连接条件 where 筛选条件 \u0026hellip;\n分类:\n等值连接 非等值连接 自连接 #调换顺序是可以的 mysql\u0026gt; select last_name , department_name from employees e inner join departments d on e.department_id = d.department_id ; +-------------+-----------------+ | last_name | department_name | +-------------+-----------------+ | Whalen | Adm | mysql\u0026gt; select last_name , job_title from employees e inner join jobs j on e.job_id = j.job_id where last_name like \u0026#39;%e%\u0026#39; ; +-------------+---------------------------------+ | last_name | job_title | +-------------+---------------------------------+ | De Haan | Administration Vice President | | Ernst | Programmer | mysql\u0026gt; select last_name , job_title from employees e inner join jobs j on e.job_id = j.job_id where e.last_name like \u0026#39;%e%\u0026#39; ; +-------------+---------------------------------+ | last_name | job_title | +-------------+---------------------------------+ | De Haan | Administration Vice President | | Ernst | Programmer | #查询部门个数\u0026gt;3的城市名和部门个数 mysql\u0026gt; select city , count(*) 部门个数 from departments d join locations l on d.location_id = l.location_id group by l.location_id having 部门个数\u0026gt;3 ; +---------+----------+ | city | 部门个数 | +---------+----------+ | Seattle | 21 | +---------+----------+ #查询哪个部门的员工个数\u0026gt;3的部门名和员工个数,并按个数降序 mysql\u0026gt; select department_name , count(*) 员工个数 from departments d inner join employees e on e.department_id = d.department_id group by e.department_id having count(*)\u0026gt;3 order by count(*) desc; +-----------------+----------+ | department_name | 员工个数 | +-----------------+----------+ | Shi | 45 | | Sal | 34 | | Pur | 6 | #多表连接 是有顺序的 第一个表和第二个表在连接的时候形成了新的表 然后新的表里的字段和第三个表里的字段再连接 所以是有顺序之分的 这个和两表连接有差别 mysql\u0026gt; select last_name , department_name , job_title from employees e join departments d on e.department_id = d.department_id join jobs j on j.job_id = e.job_id order by department_name desc ; +-------------+-----------------+---------------------------------+ | last_name | department_name | job_title | +-------------+-----------------+---------------------------------+ | Taylor | Shi | Shipping Clerk | | Fleaur | Shi | Shipping Clerk | 特点:\n添加排序/分组/筛选 inner可以省略 筛选条件放在where后面 , 连接条件放在on后面, 提高分离性, 便于阅读 inner join等值连接和sql92中的等值连接效果是一样的,都是查询多表的交集 非等值连接 #非等值连接 mysql\u0026gt; select salary , grade_level from employees e join job_grades g on e.salary between g.lower_sal and g.highest_sal ; +----------+-------------+ | salary | grade_level | +----------+-------------+ | 24000.00 | E | | 17000.00 | E | #查询工资级别的个数\u0026gt;2并且按工资级别降序 mysql\u0026gt; select count(*) 级别个数 , grade_level from employees e join job_grades g on e.salary between g.lower_sal and g.highest_sal group by g.grade_level having 级别个数\u0026gt;2 order by g.grade_level ; +----------+-------------+ | 级别个数 | grade_level | +----------+-------------+ | 24 | A | | 26 | B | | 38 | C | 自连接 #自连接 #查询员工姓名和他的领导的姓名 mysql\u0026gt; select a.last_name , b.last_name from employees a join employees b on a.manager_id = b.employee_id ; +-------------+-----------+ | last_name | last_name | +-------------+-----------+ | Kochhar | K_ing | | De Haan | K_ing | 外连接 应用场景 用于查询一个表中有,另一个表中没有的记录\n特点\n外连接的查询结果为主表中的所有记录 如果从表中有和他匹配的,则显示匹配的值 如果从表中没有和他匹配的,则显示null 外连接查询结果=内连接结果+主表中有而从表中没有的记录 左外连接,left join左边的是主表 右外连接,right join右边的是主表 交换两表的顺序和关键字,可以实现同样的结果 #查询没有男朋友的女神名 #这样的话就是内连接 内连接是取的交集 没有用查不到 mysql\u0026gt; select name,b.id from beauty g join boys b on g.boyfriend_id = b.id ; +------------+----+ | name | id | +------------+----+ | Angelababy | 3 | | 热巴 | 2 | #这样的话就是外连接 外连接全取了 要加筛选条件 mysql\u0026gt; select name,b.id from beauty g left join boys b on g.boyfriend_id = b.id ; +------------+------+ | name | id | +------------+------+ | 柳岩 | NULL | | 苍老师 | NULL | | Angelababy | 3 | #这样没错 mysql\u0026gt; select name,b.id from beauty g left join boys b on g.boyfriend_id = b.id where b.id is null ; +--------+------+ | name | id | +--------+------+ | 柳岩 | NULL | | 苍老师 | NULL | #查询那个部门没有员工 mysql\u0026gt; select d.department_id ,department_name from departments d left join employees e on d.department_id = e.department_id where e.department_id is null ; +---------------+-----------------+ | department_id | department_name | +---------------+-----------------+ | 120 | Tre | | 130 | Cor | 全外连接 好像不支持 全外连接=内连接的结果+表1中有但表2没有的+表2中有但表1没有的 交叉连接 #交叉做 笛卡尔乘积 mysql\u0026gt; select beauty.* , boys.* from beauty cross join boys ; +----+------------+------+---------------------+-------------+--------------+--------------+----+---------+--------+ | id | name | sex | borndate | phone | photo | boyfriend_id | id | boyName | userCP | +----+------------+------+---------------------+-------------+--------------+--------------+----+---------+--------+ | 1 | 柳岩 | 女 | 1988-02-03 00:00:00 | 18209876577 | NULL | 8 | 4 | 段誉 | 300 | | 1 | 柳岩 | 女 | 1988-02-03 00:00:00 | sql92和sql99的区别 功能:sql99 支持的较多\n可读性:sql99实现连接条件和筛选条件的分离,可读性较高\nimage-20210923202009215\rimage-20210923202111351\r#查询编号\u0026gt;3的女生的男朋友信息,如果有则列出,如果没有就null填充 mysql\u0026gt; select g.id 女生id,g.name ,b.* from beauty g left join boys b on g.boyfriend_id = b.id where g.id\u0026gt;3 ; +--------+--------+------+---------+--------+ | 女生id | name | id | boyName | userCP | +--------+--------+------+---------+--------+ | 4 | 热巴 | 2 | 鹿晗 | 800 | | 5 | 周冬雨 | NULL | NULL | NULL | | 6 | 周芷若 | 1 | 张无忌 | 100 | #查询哪个城市没有部门 mysql\u0026gt; select city 这个城市没有部门 from locations l left join departments d on l.location_id = d.location_id where department_id is null ; +------------------+ | 这个城市没有部门 | +------------------+ | Roma | | Venice | 子查询 含义:出现在其他语句中的eslect语句,称为子查询或内查询\n外部的查询语句,称为主查询或外查询\n分类:\n按子查询出现的位置 select后面 一般只支持标量子查询 from后面 支持表子查询 where 或者 having 后面**(重要)** 支持标量子查询/列子查询/行子查询 exists 后面 (相关子查询) 表子查询 按功能(结果集的行列书不同) 标量子查询(结果集只有一行一列) 列子查询(结果集中只有一列多行) 行子查询(结果集有一行多列) 表子查询(结果结一般为多行多列) where或having后面的子查询 支持标量子查询 / 列子查询 / 行子查询(多列多行)\n特点:\n子查询放在小括号内 一般放在条件的右侧 标量子查询,一般搭配着单行操作符使用 \u0026gt; \u0026lt; \u0026gt;= \u0026lt;= \u0026lt;\u0026gt; 列子查询,一般搭配着多行操作符使用 in any/some all 子查询的执行顺序优先于主查询执行,主查询的条件用到了子查询的结果 标量子查询 #谁的工资比Abel高 mysql\u0026gt; select last_name , salary from employees where salary\u0026gt;(select salary from employees where last_name = \u0026#39;Abel\u0026#39;) ; +-----------+----------+ | last_name | salary | +-----------+----------+ | K_ing | 24000.00 | | Kochhar | 17000.00 | mysql\u0026gt; select last_name , job_id ,salary from employees where employee_id=141 and salary \u0026gt;(select salary from employees where employee_id =143) ; +-----------+----------+---------+ | last_name | job_id | salary | +-----------+----------+---------+ | Rajs | ST_CLERK | 3500.00 | +-----------+----------+---------+ #查询 job_id 和 141号员工的job_id相同的,salary比143号员工多的员工 mysql\u0026gt; select last_name , job_id ,salary from employees where job_id=(select job_id from employees where employee_id =141) and salary \u0026gt;(select salary from employees where employee_id =143) ; +-------------+----------+---------+ | last_name | job_id | salary | +-------------+----------+---------+ | Nayer | ST_CLERK | 3200.00 | | Mikkilineni | ST_CLERK | 2700.00 | | Bissot | ST_CLERK | 3300.00 | #查询公司工资最少的员工的last_name , job_id, 和salary mysql\u0026gt; select last_name , job_id , salary from employees where salary = (select min(salary) from employees ) ; +-----------+----------+---------+ | last_name | job_id | salary | +-----------+----------+---------+ | Olson | ST_CLERK | 2100.00 | +-----------+----------+---------+ 1 row in set (0.00 sec) #查询最低工资大于50号部门的最低工资的部门id和其最低工资 mysql\u0026gt; select department_id , min(salary) 最低工资 from employees group by department_id having min(salary) \u0026gt;(select min(salary) from employees where department_id = 50) ; +---------------+----------+ | department_id | 最低工资 | +---------------+----------+ | NULL | 7000.00 | | 10 | 4400.00 | 标量子查询可能出现的问题 子查询里查到的元素个数不止一个 子查询里压根没查到任何元素 列子查询 image-20210923211703043\rany就是大于最小值小于最大值 all就是大于最大值小于最小值\n#查询location_id是1400或1700的部门中的所有员工姓名 mysql\u0026gt; select last_name from employees e where department_id in (select distinct department_id from departments where location_id in (1400,1700)); +------------+ | last_name | +------------+ | Hunold | | Ernst | | Austin | #返回比job_id为IT_PROG部门任意工资低的员工的员工号/姓名/job_id以及salary mysql\u0026gt; select employee_id , last_name , job_id , salary from employees where salary \u0026lt; any(select salary from employees where job_id=\u0026#39;IT_PROG\u0026#39;) ; +-------------+-------------+------------+---------+ | employee_id | last_name | job_id | salary | +-------------+-------------+------------+---------+ | 104 | Ernst | IT_PROG | 6000.00 | | 105 | Austin | IT_PROG | 4800.00 | #也可以使用max或者min来代替any mysql\u0026gt; select employee_id , last_name , job_id , salary from employees where salary \u0026lt; any(select salary from employees where job_id=\u0026#39;IT_PROG\u0026#39;) order by employee_id; +-------------+-------------+------------+---------+ | employee_id | last_name | job_id | salary | +-------------+-------------+------------+---------+ | 104 | Ernst | IT_PROG | 6000.00 | | 105 | Austin | IT_PROG | 4800.00 | #all也是同样的 #in 和 =Any也是一样的 #not in 和 \u0026lt;\u0026gt;All也是一样的 行子查询 #查询员工编号最小并且工资最高的员工信息 (不一定存在) #简单粗暴的做法 mysql\u0026gt; select * from employees where employee_id = (select min(employee_id) from employees ) and salary = (select max(salary) from employees ) ; +-------------+------------+-----------+-------+--------------+---------+----------+----------------+------------+---------------+---------------------+ | employee_id | first_name | last_name | email | phone_number | job_id | salary | commission_pct | manager_id | department_id | hiredate | +-------------+------------+-----------+-------+--------------+---------+----------+----------------+------------+---------------+---------------------+ | 100 | Steven | K_ing | SKING | 515.123.4567 | AD_PRES | 24000.00 | NULL | NULL | 90 | 1992-04-03 00:00:00 | +-------------+------------+-----------+-------+--------------+---------+----------+----------------+------------+---------------+---------------------+ 1 row in set (0.00 sec) #行子查询 有局限性 mysql\u0026gt; select * from employees where (employee_id,salary)=(select min(employee_id),max(salary) from employees) ; +-------------+------------+-----------+-------+--------------+---------+----------+----------------+------------+---------------+---------------------+ | employee_id | first_name | last_name | email | phone_number | job_id | salary | commission_pct | manager_id | department_id | hiredate | +-------------+------------+-----------+-------+--------------+---------+----------+----------------+------------+---------------+---------------------+ | 100 | Steven | K_ing | SKING | 515.123.4567 | AD_PRES | 24000.00 | NULL | NULL | 90 | 1992-04-03 00:00:00 | +-------------+------------+-----------+-------+--------------+---------+----------+----------------+------------+---------------+---------------------+ 1 row in set (0.00 sec) 放在select后面的子查询 仅仅支持标量子查询\n#查询每个部门的员工个数 #通过子查询来做 mysql\u0026gt; select d.* ,(select count(*) from employees where department_id=d.department_id) from departments d ; +---------------+-----------------+------------+-------------+----------------------------------------------------------------------+ | department_id | department_name | manager_id | location_id | (select count(*) from employees where department_id=d.department_id) | +---------------+-----------------+------------+-------------+----------------------------------------------------------------------+ | 10 | Adm | 200 | 1700 | 1 | | 20 | Mar | 201 | 1800 | 2 | #也可以通过左右连接来做 mysql\u0026gt; select d.* , count(*) from employees e right join departments d on e.department_id = d.department_id group by d.department_id ; +---------------+-----------------+------------+-------------+----------+ | department_id | department_name | manager_id | location_id | count(*) | +---------------+-----------------+------------+-------------+----------+ | 10 | Adm | 200 | 1700 | 1 | | 20 | Mar | 201 | 1800 | 2 | | 30 | Pur | 114 | 1700 | 6 | #查询员工号=102的部门名 mysql\u0026gt; select employee_id ,(select department_name from departments where department_id =e.department_id) from employees e where e.employee_id =102; +-------------+--------------------------------------------------------------------------------+ | employee_id | (select department_name from departments where department_id =e.department_id) | +-------------+--------------------------------------------------------------------------------+ | 102 | Exe | +-------------+--------------------------------------------------------------------------------+ 1 row in set (0.00 sec) from后面 特点：将子查询充当一张表 要求必须起别名\n#查询每个部门的平均工资的工资等级 #sql92语法 mysql\u0026gt; select department_id ,grade_level,av from (select department_id , avg(salary) av from employees group by department_id) a,job_grades where av between lower_sal and highest_sal ; +---------------+-------------+--------------+ | department_id | grade_level | av | +---------------+-------------+--------------+ | NULL | C | 7000.000000 | | 10 | B | 4400.000000 | #sql99语法 mysql\u0026gt; select av.department_id , grade_level from (select e.department_id , avg(salary) avs from employees e group by e.department_id) av join job_grades j on av.avs between j.lower_sal and j.highest_sal ; +---------------+-------------+ | department_id | grade_level | +---------------+-------------+ | NULL | C | | 10 | B | | 20 | C | exists后面（子查询） select exists(select employee_id from employees)\n语法:\nexists(完整的查询语句) 结果是1/0\n#回顾 mysql\u0026gt; select last_name , (select department_name from departments where department_id = e.department_id )部门 from employees e; +-------------+------+ | last_name | 部门 | +-------------+------+ | K_ing | Exe | | Kochhar | Exe | #查询有员工的部门名 mysql\u0026gt; select d.department_id , d.department_name from departments d where exists(select d.department_id from employees e where d.department_id = e.department_id); +---------------+-----------------+ | department_id | department_name | +---------------+-----------------+ | 10 | Adm | | 20 | Mar | #可以用in来代替 mysql\u0026gt; select d.department_id , d.department_name from departments d where d.department_id in (select distinct e.department_id from employees e ) ; +---------------+-----------------+ | department_id | department_name | +---------------+-----------------+ | 10 | Adm | | 20 | Mar | #查询没有女朋友的男生信息 mysql\u0026gt; select b.* from boys b where not exists(select boyfriend_id from beauty where boyfriend_id =b.id) ; +----+---------+--------+ | id | boyName | userCP | +----+---------+--------+ | 4 | 段誉 | 300 | +----+---------+--------+ 1 row in set (0.00 sec) 练习一下\nmysql\u0026gt; select last_name , salary from employees where department_id = (select department_id from employees where last_name = \u0026#39;Zlotkey\u0026#39;) ; +------------+----------+ | last_name | salary | +------------+----------+ | Russell | 14000.00 | | Partners | 13500.00 | mysql\u0026gt; select last_name , salary from employees where salary \u0026gt; (select avg(salary) from employees ) ; +------------+----------+ | last_name | salary | +------------+----------+ | K_ing | 24000.00 | | Kochhar | 17000.00 | #查询各部门中工资比本部门平均工资中搞的员工和员工号,姓名和工资 mysql\u0026gt; select e.department_id , e.employee_id , e.last_name , e.salary from employees e where salary \u0026gt;(select avg(salary) from employees where department_id = e.department_id ) ; +---------------+-------------+-----------+----------+ | department_id | employee_id | last_name | salary | +---------------+-------------+-----------+----------+ | 90 | 100 | K_ing | 24000.00 | | 60 | 103 | Hunold | 9000.00 | mysql\u0026gt; select department_id , employee_id , last_name from employees where department_id in (select department_id from employees where last_name like \u0026#39;%u%\u0026#39;) ; +---------------+-------------+-------------+ | department_id | employee_id | last_name | +---------------+-------------+-------------+ | 60 | 103 | Hunold | | 60 | 104 | Ernst | #查询部门的location_id是1700的部门工作的员工的员工号 mysql\u0026gt; select e.employee_id , e.department_id from employees e where e.department_id in (select department_id from departments where location_id =1700) ; +-------------+---------------+ | employee_id | department_id | +-------------+---------------+ | 200 | 10 | | 114 | 30 | mysql\u0026gt; select last_name , salary from employees where manager_id in (select employee_id from employees where last_name = \u0026#39;K_ing\u0026#39;) ; +-----------+----------+ | last_name | salary | +-----------+----------+ | Kochhar | 17000.00 | | De Haan | 17000.00 | #查询最高工资的员工的姓名,要求first_name和last_name显示为一列,列名为姓名 mysql\u0026gt; select concat(a.姓 , a.名)姓名 from (select first_name 姓,last_name 名 from employees where salary = (select max(salary) from employees)) a ; +-------------+ | 姓名 | +-------------+ | StevenK_ing | +-------------+ 1 row in set (0.00 sec) 分页查询 应用场景:当要显示的数据,一页显示不全,需要分页提交sql请求的时候\n语法:select 查询列表 from 表 inner join 表2 on 连接条件 group by 分组字段 having 分组后的筛选 order by 排序后的字段 limit offset,size ;\noffset要显示条目的起始索引(起始索引从0开始)\nsize要显示的条目个数\n特点:\nlimit语句放在查询语句的最后 公式 要显示的页数 page 每页的条目数size , 那么就是limit (page-1)*size,size mysql\u0026gt; select * from employees limit 0,5 ; +-------------+------------+-----------+----------+--------------+---------+----------+----------------+------------+---------------+---------------------+ | employee_id | first_name | last_name | email | phone_number | job_id | salary | commission_pct | manager_id | department_id | hiredate | +-------------+------------+-----------+----------+--------------+---------+----------+----------------+------------+---------------+---------------------+ | 100 | Steven | K_ing | SKING | 515.123.4567 | AD_PRES | 24000.00 | NULL | NULL | 90 | 1992-04-03 00:00:00 | | 101 | Neena | Kochhar | NKOCHHAR | 515.123.4568 | AD_VP | 17000.00 | NULL | 100 | 90 | 1992-04-03 00:00:00 | | 102 | Lex | De Haan | LDEHAAN | 515.123.4569 | AD_VP | 17000.00 | NULL | 100 | 90 | 1992-04-03 00:00:00 | | 103 | Alexander | Hunold | AHUNOLD | 590.423.4567 | IT_PROG | 9000.00 | NULL | 102 | 60 | 1992-04-03 00:00:00 | | 104 | Bruce | Ernst | BERNST | 590.423.4568 | IT_PROG | 6000.00 | NULL | 103 | 60 | 1992-04-03 00:00:00 | +-------------+------------+-----------+----------+--------------+---------+----------+----------------+------------+---------------+---------------------+ 5 rows in set (0.00 sec) #如果从第一条开始的话,那么这样可以省略前一个数字 mysql\u0026gt; select * from employees limit 5 ; +-------------+------------+-----------+----------+--------------+---------+----------+----------------+------------+---------------+---------------------+ | employee_id | first_name | last_name | email | phone_number | job_id | salary | commission_pct | manager_id | department_id | hiredate | +-------------+------------+-----------+----------+--------------+---------+----------+----------------+------------+---------------+---------------------+ | 100 | Steven | K_ing | SKING | 515.123.4567 | AD_PRES | 24000.00 | NULL | NULL | 90 | 1992-04-03 00:00:00 | | 101 | Neena | Kochhar | NKOCHHAR | 515.123.4568 | AD_VP | 17000.00 | NULL | 100 | 90 | 1992-04-03 00:00:00 | | 102 | Lex | De Haan | LDEHAAN | 515.123.4569 | AD_VP | 17000.00 | NULL | 100 | 90 | 1992-04-03 00:00:00 | | 103 | Alexander | Hunold | AHUNOLD | 590.423.4567 | IT_PROG | 9000.00 | NULL | 102 | 60 | 1992-04-03 00:00:00 | | 104 | Bruce | Ernst | BERNST | 590.423.4568 | IT_PROG | 6000.00 | NULL | 103 | 60 | 1992-04-03 00:00:00 | +-------------+------------+-----------+----------+--------------+---------+----------+----------------+------------+---------------+---------------------+ 5 rows in set (0.00 sec) #第11到第25条 mysql\u0026gt; select * from employees limit 10,15 ; mysql\u0026gt; select * from employees where commission_pct is not null order by salary*(1+commission_pct) desc limit 0,10 ; 练习一下 mysql\u0026gt; select substr(email,1,instr(email,\u0026#39;@\u0026#39;)-1) from stuinfo ; mysql\u0026gt; select count(*) 个数 , sex from stuinfo group by sex ; mysql\u0026gt; select min(age) , (select gradeName , id from grade where id = stuinfo.gradeid) from stuinfo group by gradeId ; mysql\u0026gt; select min(age) , (select gradeName , id from grade where id = stuinfo.id) from stuinfo group by gradeId having min(age)\u0026gt;20; 查询语句中涉及到的所有关键字,以及执行先后顺序. select 查询列表 ⑦\nfrom 表 ① 锁定数据源\n连接类型 join 表2 ②拼接数据源 笛卡尔儿乘积\non 连接条件 ③缩小数据源 非笛卡尔乘积\nwhere 筛选条件 ④缩小数据范围\ngroup by 分组列表 ⑤\nhaving 分组后的筛选 ⑥分组后筛选\norder by 排序列表 ⑧\nlimit 偏移,条目数; ⑨\nsql99语法 内连接 select 查询列表 from 表1 别名 inner join 表2 别名 on 连接条件 where 筛选条件 group by 分组列表 having 分组后的筛选 order by 排序列表 limit子句\n特点:\n表的顺序可以调换\n内连接的结果=多表的交集\nn表连接至少需要n-1个连接条件\n分类: 等值连接 非等值连接 自连接\n外连接 select 查询列表 from 表1 别名 left|right|full outer join 表2 别名 on 连接条件\nwhere 筛选条件 group by 分组列表 having 分组后的筛选 order by 排序列表 limit 子句;\n特点:\n查询的结果=主表中所有的行,其中从表和他匹配的将显示匹配行,如果从表没有匹配的则显示null\nleft join 左边的就是主表,right join右边的就是主表\nfull join 两边都是主表\n一般用于查询除了交集部分的剩余的不匹配的行\n交叉连接 select 查询列表 from 表1 别名 cross join 表2 别名 ;\n**特点:\t**\n类似于笛卡尔乘积\n子查询 嵌套在其他语句内部的select语句称为子查询或内查询\n外面的语句可以是insert update select delete 等等,一般select 作为外面语句较多\n外面如果为select语句,则此语句成为外查询或主查询\n**分类:\t**\n按出现的位置\nselect 后面 仅仅支持标量子查询 from 后面 表子查询 where或having后面 标量子查询 / 列子查询 / 行子查询 exists后面 标量子查询 列子查询 行子查询 表子查询 按结果集的行列\n标量子查询(单行子查询):结果集为一行一列 列子查询(多行子查询):结果集为多行一列 行子查询(结果集为多行多列) 表子查询(结果集为多行多列) 示例\n标量子查询\n查询最低工资的员工姓名和工资\nmysql\u0026gt; select last_name , salary from employees where salary=(select min(salary) from employees) ; +-----------+---------+ | last_name | salary | +-----------+---------+ | Olson | 2100.00 | +-----------+---------+ 1 row in set (0.00 sec) 列子查询\n查询所有是领导的员工姓名\nmysql\u0026gt; select last_name from employees where employee_id in (select manager_id from employees) ; +-----------+ | last_name | +-----------+ | K_ing | | De Haan | 分页查询 当要查询的条目数太多,一页显示不全\n语法\nselect 查询列表 from 表 limit offset,size\n**注意\t** offset代表的是起始的条目索引,默认是从0开始 size代表的是要显示的条目数\n公式 limit (page-1)*size , size\n练习一下 mysql\u0026gt; select last_name from employees where employee_id in (select manager_id from employees) ; +-----------+ | last_name | +-----------+ | K_ing | | De Haan | #查询平均工资最低的部门信息 直接使用order by 平均工资 asc 再limit 1 mysql\u0026gt; select d.* from departments d where d.department_id = (select department_id from employees group by department_id order by avg(salary) asc limit 1); +---------------+-----------------+------------+-------------+ | department_id | department_name | manager_id | location_id | +---------------+-----------------+------------+-------------+ | 50 | Shi | 121 | 1500 | +---------------+-----------------+------------+-------------+ #查询平均工资最低的部门信息和它的平均工资 mysql\u0026gt; select d.*,a.avgsalary from departments d join (select department_id,avg(salary) avgsalary from employees group by department_id order by avg(salary) asc limit 1) a on d.department_id = a.department_id; +---------------+-----------------+------------+-------------+-------------+ | department_id | department_name | manager_id | location_id | avgsalary | +---------------+-----------------+------------+-------------+-------------+ | 50 | Shi | 121 | 1500 | 3475.555556 | +---------------+-----------------+------------+-------------+-------------+ 1 row in set (0.00 sec) #查询平均工资最高的job信息 mysql\u0026gt; select j.* from jobs j where j.job_id =(select job_id from employees group by job_id order by avg(salary) desc limit 1); +---------+-----------+------------+------------+ | job_id | job_title | min_salary | max_salary | +---------+-----------+------------+------------+ | AD_PRES | President | 20000 | 40000 | +---------+-----------+------------+------------+ mysql\u0026gt; select avg(salary),department_id from employees group by department_id having avg(salary) \u0026gt; (select avg(salary) from employees ) ; +--------------+---------------+ | avg(salary) | department_id | +--------------+---------------+ | 7000.000000 | NULL | | 9500.000000 | 20 | | 6500.000000 | 40 | | 10000.000000 | 70 | | 8955.882353 | 80 | | 19333.333333 | 90 | | 8600.000000 | 100 | | 10150.000000 | 110 | +--------------+---------------+ mysql\u0026gt; select * from employees where employee_id in (select manager_id from employees ) ; +-------------+------------+-----------+----------+--------------------+---------+----------+----------------+------------+---------------+---------------------+ | employee_id | first_name | last_name | email | phone_number | job_id | salary | commission_pct | manager_id | department_id | hiredate | +-------------+------------+-----------+----------+--------------------+---------+----------+----------------+------------+---------------+---------------------+ | 100 | Steven | K_ing | SKING | 515.123.4567 | AD_PRES | 24000.00 | NULL | NULL | 90 | 1992-04-03 00:00:00 | | 102 | Lex | De Haan | LDEH #查询各个部门中最高工资中最低的那个部门的最低工资是多少 mysql\u0026gt; select min(salary) from employees where department_id =(select department_id from (select max(salary),department_id from employees group by department_id order by max(salary) asc limit 1) a ); +-------------+ | min(salary) | +-------------+ | 4400.00 | +-------------+ 1 row in set (0.00 sec) #查询平均工资最高的部门的manager的详细信息:last_name , department_id , email , salary mysql\u0026gt; select last_name , department_id , email , salary from employees where employee_id =(select manager_id from departments where department_id = (select department_id from employees group by department_id order by avg(salary) desc limit 1)) ; +-----------+---------------+-------+----------+ | last_name | department_id | email | salary | +-----------+---------------+-------+----------+ | K_ing | 90 | SKING | 24000.00 | +-----------+---------------+-------+----------+ 练习一下\nmysql\u0026gt; select count(*)个数 , (select majorid from major where majorid = s.majorid)专业号 from student s group by majorid ; +------+--------+ | 个数 | 专业号 | +------+--------+ | 8 | 1 | | 3 | 2 | mysql\u0026gt; select avg(score),max(score) from result group by studentno ; +--------------------+------------+ | avg(score) | max(score) | +--------------------+------------+ | 100 | 100 | | 90 | 90 | #查询姓张的每个学生的最低分大于60的学号姓名 其实可以用join 就不用那么麻烦了 mysql\u0026gt; select min(score) 最低分,r.studentno,(select s.studentname from student s where s.studentno=r.studentno and s.studentname like\u0026#39;张%\u0026#39;) a from result r group by r.studentno having 最低分\u0026gt;60 and a is not null ; +--------+-----------+--------+ | 最低分 | studentno | a | +--------+-----------+--------+ | 100 | s001 | 张三封 | | 70 | s004 | 张翠山 | +--------+-----------+--------+ #可以使用diff函数 和 join mysql\u0026gt; select s.studentname,(select majorname from major where majorid = s.majorid) 专业名称 from student s where s.borndate \u0026gt; \u0026#39;1998-1-1\u0026#39; ; +-------------+----------+ | studentname | 专业名称 | +-------------+----------+ | 张无忌 | html5 | | 赵敏 | javaee | +-------------+----------+ 2 rows in set (0.00 sec) mysql\u0026gt; select s.studentname from student s join major m on s.majorid = m.majorid where datediff(s.borndate,\u0026#39;1998-1-1\u0026#39;)\u0026gt;0 ; +-------------+ | studentname | +-------------+ | 张无忌 | | 赵敏 | +-------------+ 2 rows in set (0.00 sec) #查询每个专业的男生人数和女生人数分别是多少 在这里s.majorid=s1.majorid s1一定不能省略 mysql\u0026gt; select s1.majorid,(select count(*) from student s where s.majorid=s1.majorid and s.sex =\u0026#39;男\u0026#39;)男生,(select count(*) from student s where s.majorid=s1.majorid and s.sex=\u0026#39;女\u0026#39;) 女生 from student s1 group by s1.majorid ; +---------+------+------+ | majorid | 男生 | 女生 | +---------+------+------+ | 1 | 5 | 3 | | 2 | 2 | 1 | | 3 | 2 | 2 | +---------+------+------+ 3 rows in set (0.00 sec) #查询专业和张翠山一样的学生的最低分 mysql\u0026gt; select min(score) from result where studentno in (select s.studentno from student s where majorid =(select majorid from student where studentname =\u0026#39;张翠山\u0026#39;) and studentname \u0026lt;\u0026gt;\u0026#39;张翠山\u0026#39;) group by studentno; +------------+ | min(score) | +------------+ | 100 | | 90 | +------------+ 2 rows in set (0.00 sec) #查询大于60分的学生的姓名 密码 专业名 mysql\u0026gt; select s.studentname , s.loginpwd , (select majorname from major where majorid = s.majorid) from student s where s.studentno in (select distinct studentno from result where score \u0026gt;60) ; +-------------+----------+---------------------------------------------------------+ | studentname | loginpwd | (select majorname from major where majorid = s.majorid) | +-------------+----------+---------------------------------------------------------+ | 张三封 | 8888 | javaee | | 殷天正 | 8888 | javaee | | 周伯通 | 8888 | html5 | | 张翠山 | 8888 | javaee | | 小小张 | 8888 | android | | 张无忌 | 8888 | html5 | +-------------+----------+---------------------------------------------------------+ #按邮箱的位数分组,并查询个数 mysql\u0026gt; select count(*)个数, length(s.email) from student s group by length(s.email) ; +------+-----------------+ | 个数 | length(s.email) | +------+-----------------+ | 1 | 20 | | 2 | 19 | | 2 | 18 | | 6 | NULL | | 2 | 17 | | 2 | 15 | +------+-----------------+ #查询学生名 专业名 分数 这是错误的 如果使用join是取完全交集 mysql\u0026gt; select s.studentname ,m.majorname , r.score from student s join major m on s.majorid = m.majorid join result r on s.studentno = r.studentno ; +-------------+-----------+-------+ | studentname | majorname | score | +-------------+-----------+-------+ | 张翠山 | javaee | 70 | | 殷天正 | javaee | 90 | #查询学生名 专业名 分数 这是错误的 应该使用left join防止出现score为null的情况 mysql\u0026gt; select s.studentname ,m.majorname , r.score from student s join major m on s.majorid = m.majorid left join result r on s.studentno = r.studentno ; +-------------+-----------+-------+ | studentname | majorname | score | +-------------+-----------+-------+ | 张三封 | javaee | 100 | | 殷天正 | javaee | 90 | | 周伯通 | html5 | 80 | mysql\u0026gt; select s.studentname ,m.majorname , r.score from student s join major m on s.majorid = m.majorid left join result r on s.studentno = r.studentno ; #查询没有成绩的学生人数 mysql\u0026gt; select * from (select distinct s.studentno 学号,(select score from result where studentno =s.studentno limit 1 )a from student s) b where b.a is null ; +------+------+ | 学号 | a | +------+------+ | S007 | NULL | | S008 | NULL | | S009 | NULL | mysql\u0026gt; select count(*) from (select distinct s.studentno 学号,(select score from result where studentno =s.studentno limit 1 )a from student s) b where b.a is null ; +----------+ | count(*) | +----------+ | 9 | +----------+ 联合查询 union 联合 合并:将多条查询语句的结果合并成一个结果\n查询语句1 union 查询语句2 union 查询语句3 \u0026hellip;\n查询部门编号\u0026gt;90 或 邮箱包含a的员工信息\n应用场景\n保证两个表的列数一致 , 并不要求两个表的列名一致 ,就可以使用联合查询\n要查询的结果来源于多个表,且多个表没有直接的连接关系,但查询的信息一致时\n例如全站搜索 ,肯定不可能所有的数据都放在一个表里 , 所以这时候就需要union\n注意\nunion 会默认去重\nunion all 可以包含重复项\nmysql\u0026gt; select * from employees where department_id \u0026gt;90 or email like\u0026#39;%a%\u0026#39; ; mysql\u0026gt; select * from employees where department_id \u0026gt;90 union select * from employees where email like\u0026#39;%a%\u0026#39; ; DML语言 数据操作语言 插入 insert\n更新 update\n删除 delete\n插入语句 方式一\n语法:\ninsert into 表名(列名, \u0026hellip;) values(值, \u0026hellip;) ;\n注意\n插入的值的类型要与列的类型一直或兼容 不可以为null的列必须插入值,可以为null的列如何插入值 插入null 或者在 into beauty(少一点字段) 列的顺序可以调换 列和值的个数必须一致 可以省略列名,默认所有列名,而且列的顺序和表中列的顺序一直 #经典型 insert mysql\u0026gt; insert into beauty(id,name,sex,borndate,phone,photo,boyfriend_id) values(13,\u0026#39;唐艺昕\u0026#39;,\u0026#39;女\u0026#39;,\u0026#39;1990-4-23\u0026#39;,\u0026#39;18988888\u0026#39;,null,2); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into beauty(id,name,sex,phone) values(14,\u0026#39;金星\u0026#39;,\u0026#39;女\u0026#39;,\u0026#39;13888888\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into beauty values(18,\u0026#39;张飞\u0026#39;,\u0026#39;女\u0026#39;,\u0026#39;1990-4-23\u0026#39;,\u0026#39;119\u0026#39;,null,null); Query OK, 1 row affected (0.00 sec) **方式二\t**\n语法\ninsert into 表名 set 列名 = 值 , 列名 = 值 \u0026hellip;\nmysql\u0026gt; insert into beauty set id = 19 , name = \u0026#39;文涛\u0026#39; , phone = \u0026#39;999\u0026#39; ; Query OK, 1 row affected (0.00 sec) **两种方式的区别\t**\n方式一支持多行插入,方式二不支持 方式一支持子查询,方式二不支持 #方式一 支持子查询 mysql\u0026gt; insert into beauty(id,name,phone) select 26,\u0026#39;宋西\u0026#39;,\u0026#39;11809866\u0026#39;; Query OK, 1 row affected (0.01 sec) Records: 1 Duplicates: 0 Warnings: 0 #方式一 支持多行插入 mysql\u0026gt; insert into beauty(id,name,phone) select id , boyname,\u0026#39;120\u0026#39; from boys where id\u0026lt;3; ERROR 1062 (23000): Duplicate entry \u0026#39;1\u0026#39; for key \u0026#39;beauty.PRIMARY\u0026#39; 修改语句 修改单表的记录(重要)\nupdate 表名 set 列=新值 , 列=新值 where 筛选条件 ;\nupdate beauty set phone = \u0026#39;11010011\u0026#39; where name like \u0026#39;唐%\u0026#39; ; update boys set boyname = \u0026#39;张飞\u0026#39; ,userCp = 10 where id = 2 ; 修改多表的记录(补充)\nsql92语法\nupdate 表1 别名 , 表2 别名\nset 列=值 , \u0026hellip; where 连接条件 and 筛选条件 ;\nsql99语法\nupdate 表1 别名 inner join 表2 别名 on 连接条件 set 列=值, \u0026hellip; where 筛选条件\n#修改张无忌的女朋友的手机号为114 mysql\u0026gt; update beauty b join boys on b.boyfriend_id = boys.id set phone = \u0026#39;114\u0026#39; where boys.boyname =\u0026#39;张无忌\u0026#39; ; Query OK, 3 rows affected (0.00 sec) Rows matched: 3 Changed: 3 Warnings: 0 #也可以使用修改单表 使用子查询 mysql\u0026gt; update beauty b set phone = \u0026#39;115\u0026#39; where b.boyfriend_id = (select id from boys where boyname =\u0026#39;张无忌\u0026#39;) ; Query OK, 3 rows affected (0.00 sec) Rows matched: 3 Changed: 3 Warnings: 0 #修改没有男朋友的女神的男朋友编号都为2号 #先select mysql\u0026gt; select b.name ,b.boyfriend_id,boyname from beauty b left join boys on b.boyfriend_id = boys.id where boyfriend_id is not null and boyname is null; +--------+--------------+---------+ | name | boyfriend_id | boyname | +--------+--------------+---------+ | 柳岩 | 8 | NULL | | 苍老师 | 9 | NULL | | 周冬雨 | 9 | NULL | | 岳灵珊 | 9 | NULL | | 双儿 | 9 | NULL | | 夏雪 | 9 | NULL | +--------+--------------+---------+ 6 rows in set (0.00 sec) #再update mysql\u0026gt; update beauty b left join boys on b.boyfriend_id = boys.id set b.boyfriend_id =2 where boyfriend_id is not null and boyname is null; Query OK, 6 rows affected (0.00 sec) Rows matched: 6 Changed: 6 Warnings: 0 #再查一下 mysql\u0026gt; select b.name ,b.boyfriend_id,boyname from beauty b left join boys on b.boyfriend_id = boys.id where boyfriend_id is not null and boyname is null; Empty set (0.00 sec) 删除语句 方式一 delete\n方式二 truncate\n语法:truncate table 表名 (删除的是所有的 不能加筛选条件)\n单表的删除\n语法:delete from 表名 where 筛选条件\n多表的删除\n语法:\nsql92语法\ndelete 表1的别名 from 表1 别名 , 表2 别名 where 连接条件 and 筛选条件 ; //删除的是表1的数据内容\ndelete 表2的别名 from 表1 别名 , 表2 别名 where 连接条件 and 筛选条件 ; //删除的是表2的数据内容\ndelete 表1的别名, 表2的别名 from 表1 别名 , 表2 别名 where 连接条件 and 筛选条件 ; //删除的是表1和表2的数据内容\nsql99语法\ndelete 表1的别名,表2的别名 from 表1 别名 join 表2 别名 on 连接条件 where 筛选条件\n#单表的删除 delete from beauty where phone like \u0026#39;%9\u0026#39; ; #删除张无忌的女朋友的信息 #多表删除 mysql\u0026gt; delete b from beauty b join boys boy on b.boyfriend_id = boy.id where boy.boyname = \u0026#39;张无忌\u0026#39; ; Query OK, 3 rows affected (0.01 sec) #删除黄晓明和他女朋友的信息 mysql\u0026gt; delete g , b from beauty g join boys b on g.boyfriend_id = b.id where b.boyname = \u0026#39;黄晓明\u0026#39; ; Query OK, 2 rows affected (0.00 sec) 方式二 truncate语句\n直接清空 truncate table boys ;\ndelete和truncate的区别 delete可以加where条件 , truncate不能加 truncate 删除, 效率高一丢丢 假如要删除的表中有自增长列,如果用delete删除后,再插入数据,自增长列的值依旧是从断点开始,而如果truncate删除后,再插入数据,自增长列的值从1开始 truncate删除没有返回值,delete删除有返回值 truncate删除回滚,delete删除可以回滚 练习一下 mysql\u0026gt; desc users ; +---------------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------------+-------------+------+-----+---------+-------+ | id | int | YES | | NULL | | | userid | varchar(10) | YES | | NULL | | | department_id | int | YES | | NULL | | +---------------+-------------+------+-----+---------+-------+ mysql\u0026gt; insert into my_employees(First_name,Last_name,Userid,salary) values (\u0026#39;patel\u0026#39;,\u0026#39;Ralph\u0026#39;,\u0026#39;Rpatel\u0026#39;, 895),(\u0026#39;Dance\u0026#39; , \u0026#39;Betty\u0026#39; , \u0026#39;Bdancs\u0026#39; , 860),(\u0026#39;Biri\u0026#39;,\u0026#39;Ben\u0026#39;,\u0026#39;Bbiri\u0026#39;, 1100),(\u0026#39;Newman\u0026#39;,\u0026#39;Chad\u0026#39;,\u0026#39;Cnewman\u0026#39;,750),(\u0026#39;Ropeburn\u0026#39;,\u0026#39;Audrey\u0026#39; ,\u0026#39;Aropebur\u0026#39;,1150); Query OK, 5 rows affected (0.01 sec) Records: 5 Duplicates: 0 Warnings: 0 #也可以这样 mysql\u0026gt; insert into my_employees(First_name,Last_name,Userid,salary) select \u0026#39;patel\u0026#39;,\u0026#39;Ralph\u0026#39;,\u0026#39;Rpatel\u0026#39;, 895 union select \u0026#39;Dance\u0026#39; , \u0026#39;Betty\u0026#39; , \u0026#39;Bdancs\u0026#39; , 860 union select \u0026#39;Biri\u0026#39;,\u0026#39;Ben\u0026#39;,\u0026#39;Bbiri\u0026#39;, 1100 union select \u0026#39;Newman\u0026#39;,\u0026#39;Chad\u0026#39;,\u0026#39;Cnewman\u0026#39;,750 union select \u0026#39;Ropeburn\u0026#39;,\u0026#39;Audrey\u0026#39; ,\u0026#39;Aropebur\u0026#39;,1150; mysql\u0026gt; insert into users(userid,id) values(\u0026#39;Rpatel\u0026#39;,10),(\u0026#39;Bdancs\u0026#39;,10),(\u0026#39;Bbiri\u0026#39;,20),(\u0026#39;Chewman\u0026#39;,30),(\u0026#39;Aropebur\u0026#39;,40); Query OK, 5 rows affected (0.01 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql\u0026gt; update my_employees set last_name = \u0026#39;drelxer\u0026#39; where id =3 ; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; update my_employees set salary = 1000 where salary \u0026lt;900 ; Query OK, 3 rows affected (0.00 sec) Rows matched: 3 Changed: 3 Warnings: 0 mysql\u0026gt; delete me , u from my_employees me join users u on me.userid = u.userid where u.userid = \u0026#39;Bbiri\u0026#39;; Query OK, 2 rows affected (0.00 sec) mysql\u0026gt; truncate table users ; DDL 数据定义语言\n库和表的管理\n库的管理 创建/修改/删除\n表的管理 创建/修改/删除\n创建:create\n修改:alter\n删除:drop\n库的管理 库的创建 语法 create database [if not exists] 库名 ;\n#如果已存在 这样执行会报错 mysql\u0026gt; create database books ; Query OK, 1 row affected (0.01 sec) #会先判断一下 mysql\u0026gt; create database if not exists books ; Query OK, 1 row affected, 1 warning (0.00 sec) 库的修改 更改库的字符集\nalter database books character set gbk ; 库的删除 drop database books ; drop database if exists books ; 表的管理 表的创建 create table 表名 ( 列名 列的类型[(长度) 约束], 列名 列的类型[(长度) 约束], 列名 列的类型[(长度) 约束], 列名 列的类型[(长度) 约束], 列名 列的类型[(长度) 约束], ... ) mysql\u0026gt; select database() ; +-------------+ | database() | +-------------+ | myemployees | +-------------+ 1 row in set (0.00 sec) mysql\u0026gt; use books ; Database changed mysql\u0026gt; create table book( id int , bName varchar(20) , price double , authorId int ,publishDate datetime) ; Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; desc book ; +-------------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------------+-------------+------+-----+---------+-------+ | id | int | YES | | NULL | | | bName | varchar(20) | YES | | NULL | | | price | double | YES | | NULL | | | authorId | int | YES | | NULL | | | publishDate | datetime | YES | | NULL | | +-------------+-------------+------+-----+---------+-------+ 5 rows in set (0.00 sec) mysql\u0026gt; create table author (id int, au_name varchar(20) , nation varchar(10)) ; Query OK, 0 rows affected (0.02 sec) 表的修改 alter table 表名 add column / drop column / change column /modify column /raname to 列名/列类型/表名\n修改列名 修改列的类型或约束 添加新列 删除列 修改表名 #修改列名 mysql\u0026gt; alter table book change column publishDate pbDate datetime; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 #修改列的类型或约束 mysql\u0026gt; alter table book modify column pbdate timestamp; Query OK, 0 rows affected (0.05 sec) Records: 0 Duplicates: 0 Warnings: 0 #添加新列 mysql\u0026gt; alter table author add column annual double ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 #删除列 mysql\u0026gt; alter table book drop column annual ; Query OK, 0 rows affected (0.04 sec) Records: 0 Duplicates: 0 Warnings: 0 #修改表名 mysql\u0026gt; alter table author rename to book_author ; Query OK, 0 rows affected (0.01 sec) 表的删除 drop table 表\ndrop table if exist 表\n通用的写法:\ndrop database if exists 旧库名 ;\ncreate database 库名 ;\ndrop table if exists 旧表名;\ncreate table 表名 (\u0026hellip;) ;\n表的复制 仅仅复制表的结构 mysql\u0026gt; create table copy like author ; Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; select * from copy ; Empty set (0.00 sec) 复制表的结构和数据 #子查询 mysql\u0026gt; create table copy2 select * from author ; Query OK, 4 rows affected (0.02 sec) Records: 4 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from copy2 ; +------+----------+--------+ | id | au_name | nation | +------+----------+--------+ | 1 | 村上春树 | 日本 | | 2 | 莫言 | 中国 | | 3 | 冯唐 | 中国 | | 4 | 金庸 | 中国 | +------+----------+--------+ 4 rows in set (0.00 sec) 只复制部分数据 #根据一张表的部分数据 建立另一张表 mysql\u0026gt; create table copy3 select id,au_name from author where nation =\u0026#39;中国\u0026#39; ; Query OK, 3 rows affected (0.02 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from copy3 ; +------+---------+ | id | au_name | +------+---------+ | 2 | 莫言 | | 3 | 冯唐 | | 4 | 金庸 | +------+---------+ 3 rows in set (0.00 sec) 仅仅复制某些字段 #这样就只会复制字段,并且不满足条件不携带任何一条数据过来 mysql\u0026gt; create table copy4 select id from author where 0 ; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from copy4 ; Empty set (0.00 sec) 练习一下 mysql\u0026gt; create database test ; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; create table dept1(id int(7),name varchar(25)); Query OK, 0 rows affected, 1 warning (0.03 sec) #将departments中的数据插入新表 mysql\u0026gt; create table dept2 select * from myemployees.departments ; Query OK, 27 rows affected (0.02 sec) Records: 27 Duplicates: 0 Warnings: 0 mysql\u0026gt; create table emp5 (id int(7),first_name varchar(25),last_name varchar(25),dept_id int(7)) ; Query OK, 0 rows affected, 2 warnings (0.02 sec) #这样是修改列名和类型的 mysql\u0026gt; alter table emp5 change column last_name last_name varchar(50); Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 #这样只是修改类型的 mysql\u0026gt; alter table emp5 modify column last_name varchar(50) ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 #复制结构 mysql\u0026gt; create table employees2 like myemployees.employees ; Query OK, 0 rows affected, 2 warnings (0.03 sec) mysql\u0026gt; drop table emp5 ; Query OK, 0 rows affected (0.02 sec) #修改表的名字 mysql\u0026gt; alter table employees2 rename to emp5 ; Query OK, 0 rows affected (0.02 sec) #增加列 mysql\u0026gt; alter table dept1 add column test_column int ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; alter table emp5 add column test_column int ; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 #删除列 mysql\u0026gt; alter table emp5 drop column department_id ; Query OK, 0 rows affected (0.04 sec) Records: 0 Duplicates: 0 Warnings: 0 常见的数据类型 数值型\n整形 小数 定点数 浮点数 字符型\n较短的文本 char varchar 较长的文本 text blob(较长的二进制数据) 日期型:\n整形\nimage-20210926214209015\r分类\ntinyint smallint mediumin int/interger bigint\n1 2 3 4 8\n特点\n如果不设置无符号还是有符号，默认是有符号，如果想设置无符号，需要添加unsigned关键字 如果插入的数值超出了类型的范围,会报out of range异常 ,但是与mysql5.0不同的是,现在不会插入数据了,mysql5.0会插入临界值 如果不设置长度,会有默认的长度 如何设置无符号和有符号\nmysql\u0026gt; desc tab_int ; +-------+------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+------+------+-----+---------+-------+ | t1 | int | YES | | NULL | | +-------+------+------+-----+---------+-------+ 1 row in set (0.01 sec) #说明能够插入负数 说明默认的int是有符号的int mysql\u0026gt; insert into tab_int values(-123456) ; Query OK, 1 row affected (0.01 sec) # mysql\u0026gt; drop table if exists tab_int ; Query OK, 0 rows affected (0.02 sec) #插入无符号int类型 mysql\u0026gt; create table tab_int ( t1 int , t2 int unsigned) ; Query OK, 0 rows affected (0.02 sec) #想给无符号整数插入负数的话会报错 0行一共 但是在mysql5.5会插入 然后默认填充0 mysql\u0026gt; insert into tab_int values(-123456,-123456) ; ERROR 1264 (22003): Out of range value for column \u0026#39;t2\u0026#39; at row 1 mysql\u0026gt; select * from tab_int ; Empty set (0.00 sec) #zerofill 默认长度不够以0填充 默认是无符号数 int(7)不是2的7位,代表的是显示的最大宽度 mysql\u0026gt; create table int_zeroFill (t1 int(7) zerofill , t2 int(7) zerofill); Query OK, 0 rows affected, 4 warnings (0.02 sec) mysql\u0026gt; desc int_zeroFill ; +-------+--------------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------------------+------+-----+---------+-------+ | t1 | int(7) unsigned zerofill | YES | | NULL | | | t2 | int(7) unsigned zerofill | YES | | NULL | | +-------+--------------------------+------+-----+---------+-------+ 2 rows in set (0.01 sec) mysql\u0026gt; insert into int_zerofill values (123,123); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from int_zerofill ; +---------+---------+ | t1 | t2 | +---------+---------+ | 0000123 | 0000123 | +---------+---------+ 1 row in set (0.00 sec) 小数 image-20210929224058024\r浮点型\nfloat(M,D)\ndouble(M,D)\n定点型\ndec(M,D)\ndecimal(M,D)\n特点:\nM和D什么意思 m是小数部位+整数部位 d是小数部位 如果超过范围, 则插入临界值 m和d都可以省略 如果是decimal , 则m默认为10,d默认为0 如果是float和double,则会根据插入的数值的精度来决定精度 定点型和浮点型的区别 定点型的精确度较高,如果要求插入数值的精度较高如货币运算等则考虑使用 #小数 mysql\u0026gt; create table tab_float (f1 float(5,2) ,f2 double(5,2) ,f3 decimal(5,2)) ; Query OK, 0 rows affected, 2 warnings (0.02 sec) mysql\u0026gt; insert into tab_float values (123.45,123.45,123.45) ; Query OK, 1 row affected (0.01 sec) #会被截取 位数太长的话 mysql\u0026gt; insert into tab_float values (123.456,123.456,123.456) ; Query OK, 1 row affected, 1 warning (0.00 sec) #短了就自动填充 mysql\u0026gt; insert into tab_float values (123.4 , 123.4 , 123.4) ; Query OK, 1 row affected (0.00 sec) #(5,2) 2代表小数后几位 mysql\u0026gt; select * from tab_float ; +--------+--------+--------+ | f1 | f2 | f3 | +--------+--------+--------+ | 123.45 | 123.45 | 123.45 | | 123.46 | 123.46 | 123.46 | | 123.40 | 123.40 | 123.40 | +--------+--------+--------+ 3 rows in set (0.00 sec) #超出位数了 超出的话mysql8.0将不会插入 (5,2) 5代表一共多少位数 , 如果小数位2位,那整数位最多3位,所以整数最多999 mysql5.0会插入最大值 mysql\u0026gt; insert into tab_float values(1523.4,1523.4,1523.4); ERROR 1264 (22003): Out of range value for column \u0026#39;f1\u0026#39; at row 1 mysql\u0026gt; select * from tab_float ; +--------+--------+--------+ | f1 | f2 | f3 | +--------+--------+--------+ | 123.45 | 123.45 | 123.45 | | 123.46 | 123.46 | 123.46 | | 123.40 | 123.40 | 123.40 | +--------+--------+--------+ 3 rows in set (0.00 sec) #如果不填写 m和d decimal默认是(10,0) 小数后面是0位 mysql\u0026gt; create table tab_float_default (f1 float , f2 double , f3 decimal) ; Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; desc tab_float_default ; +-------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+---------------+------+-----+---------+-------+ | f1 | float | YES | | NULL | | | f2 | double | YES | | NULL | | | f3 | decimal(10,0) | YES | | NULL | | +-------+---------------+------+-----+---------+-------+ 3 rows in set (0.01 sec) #如果插入了多了,会自动截断 mysql\u0026gt; insert into tab_float_default values (123.456,123.456,123.456) ; Query OK, 1 row affected, 1 warning (0.01 sec) mysql\u0026gt; select * from tab_float_default ; +---------+---------+------+ | f1 | f2 | f3 | +---------+---------+------+ | 123.456 | 123.456 | 123 | +---------+---------+------+ 1 row in set (0.00 sec) 选择类型的原则 所选择的类型越简单越好,能保存数值的类型越小越好\n字符型 较短的文本:\nchar\nvarchar\n较长的文本:\ntext\nblob(较大的二进制)\n其他:\nbinary和varbinary用于保存较短的二进制数据\nenum用于保存枚举\nset用于保存集合\nimage-20210929230011199\r特点:\nchar char(m) m代表最大的字符数,可以省略,默认为1 代表固定长度的字符 效率高一点 varchar varchar(m) m代表最大的字符数,不可以省略 可变长度的字符 比较节省 效率低一点 image-20210929230312590\r#类型为enum的字段 mysql\u0026gt; create table tab_char(c1 enum(\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;)); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; desc tab_char ; +-------+-------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------------+------+-----+---------+-------+ | c1 | enum(\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;) | YES | | NULL | | +-------+-------------------+------+-----+---------+-------+ 1 row in set (0.01 sec) mysql\u0026gt; insert into tab_char values(\u0026#39;a\u0026#39;) ; Query OK, 1 row affected (0.01 sec) #不区分大小写 mysql\u0026gt; insert into tab_char values(\u0026#39;A\u0026#39;); Query OK, 1 row affected (0.00 sec) #没有定义的插入不进去 mysql\u0026gt; insert into tab_char values (\u0026#39;m\u0026#39;); ERROR 1265 (01000): Data truncated for column \u0026#39;c1\u0026#39; at row 1 mysql\u0026gt; select * from tab_char ; +------+ | c1 | +------+ | a | | a | +------+ 2 rows in set (0.00 sec) image-20210929230732259\r可以从在一个字段里插入多个元素辣\n#创建类型为set的字段 mysql\u0026gt; create table tab_set(s1 set(\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;)); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into tab_set values(\u0026#39;a\u0026#39;); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; insert into tab_set values(\u0026#39;a,B\u0026#39;); Query OK, 1 row affected (0.00 sec) #不符合的不会插入 mysql\u0026gt; insert into tab_set values (\u0026#39;a,m\u0026#39;); ERROR 1265 (01000): Data truncated for column \u0026#39;s1\u0026#39; at row 1 mysql\u0026gt; select * from tab_set ; +------+ | s1 | +------+ | a | | a,b | +------+ 2 rows in set (0.00 sec) 日期型 分类:\ndate只保存日期\ntime只保存时间\nyear只保存年\ndatetime 保存日期+时间\ntimestamp 保存日期+时间\n特点:\ndatetime 字节 8 范围 1000-9999 不受时区影响\ntimastamp 字节 4 范围 1970-2038 受时区影响\nimage-20210929233916597\rimage-20210929234007359\rmysql\u0026gt; select * from tab_date ; +---------------------+---------------------+ | t1 | t2 | +---------------------+---------------------+ | 2021-09-29 23:40:53 | 2021-09-29 23:40:53 | +---------------------+---------------------+ 1 row in set (0.00 sec) #时区 如果将时区改成其他时区 , timestamp可以更加真实地反映当前时区的真实时间 而不是不变 mysql\u0026gt; show variables like \u0026#39;time_zone\u0026#39; ; +---------------+--------+ | Variable_name | Value | +---------------+--------+ | time_zone | SYSTEM | +---------------+--------+ 1 row in set, 1 warning (0.00 sec) 复习一下 联合查询\nunion 联合 , 将多次查询结果合并为一个结果\n查询语句1 union [all] 查询语句2 \u0026hellip;\n**意义\t**\n将一条比较复杂的查询语句拆分为多条语句 适用于查询多个表的时候,查询的列基本是一致的 特点\n要求多条查询语句的查询列数必须一致 要求多条查询语句的查询的各列类型/顺序最好一致 不一致会视图隐式转换 union会默认去重 和 union all 可以包含重复项 查询的语法:\nselect * ⑦\nfrom 表1 别名 ①\njoin 表2 别名 ②\non 连接条件 ③\nwhere 筛选条件 ④\ngroup by 分组条件 ⑤\nhaving 分组后筛选条件 ⑥\norder by 排序条件 ⑧\nlimit(起始索引,条目数)选多少个 ⑨\nunion \u0026hellip;\nDML语言 插入\ninsert into 表名 (字段名 , \u0026hellip;) values (\u0026hellip;) //一一对应\n特点\n要求值的类型和字段的类型要一致或兼容 字段的个数和顺序不一定与原始表中的字段的个数和顺序一致,但必须保证值和字段一一对应 假如可以为null的字段,注意可以通过以下两种方式插入null值 字段和值都省略 字段写上,然后值也使用null插入 字段和值的个数必须一致 字段名可以省略,但是默认为所有列 插入2\ninsert into 表名 set 字段名 = 值 , 字段名 = 值 \u0026hellip;\n两种方式的区别\n方式一支持子查询\ninsert into 表名 (select * from 表名 where \u0026hellip;) 方式一支持一次插入多行,方式二不支持\ninsert into 表名 values (\u0026hellip;),(\u0026hellip;) \u0026hellip; 修改单表的记录 update 表名 set 字段=值 , 字段= 值 where 筛选条件\n修改多表的记录 update 表名 别名 join 表名 别名 on 连接条件 set 字段=值 , 字段 = 值 where 筛选语句\n删除 方式一使用delete 删除单表的记录\ndelete from 表名 where 筛选条件 [limit 条目数]\nmysql\u0026gt; select * from copy_girls ; +----+--------+------+---------------------+-------------+--------------+--------------+ | id | name | sex | borndate | phone | photo | boyfriend_id | +----+--------+------+---------------------+-------------+--------------+--------------+ | 1 | 柳岩 | 女 | 1988-02-03 00:00:00 | 18209876577 | NULL | 2 | | 2 | 苍老师 | 女 | 1987-12-30 00:00:00 | 18219876577 | NULL | 2 | | 4 | 热巴 | 女 | 1993-02-03 00:00:00 | 18209876579 | NULL | 2 | | 5 | 周冬雨 | 女 | 1992-02-03 00:00:00 | 18209179577 | NULL | 2 | mysql\u0026gt; delete from copy_girls limit 1 ; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; select * from copy_girls ; +----+--------+------+---------------------+-------------+--------------+--------------+ | id | name | sex | borndate | phone | photo | boyfriend_id | +----+--------+------+---------------------+-------------+--------------+--------------+ | 2 | 苍老师 | 女 | 1987-12-30 00:00:00 | 18219876577 | NULL | 2 | | 4 | 热巴 | 女 | 1993-02-03 00:00:00 | 18209876579 | NULL | 2 | 删除多表的记录\ndelete 表1 别名1, 表2 别名2 from 表名 别名 join 表名 别名 on 连接条件 where 筛选条件\n方式二使用truncate\n两种方式的区别\ndelete不会让自增列归零,从断点开始,truncate会让自增列归零\ndelete可以加筛选条件,truncate 不能加筛选条件\ntruncate 效率较高\ntruncate 没有返回值,delete可以返回受影响的行数\ntruncate不可以回滚,delete可以回滚\nDDL语言 库的管理 创建库\ncreate database [if not exists] 库名 [character set 字符集名] ;\n修改库\nalter database 库名 character set 字符集名 ;\n修改库名很少用,不行就换个库呗何必呢,如果实在要改,就先net stop mysql80 然后到mysql8.0下的data文件夹中重命名某个数据库名,然后net start mysql80 ,刷新数据库管理工具\n删除库\ndrop database [if exists] 库名 ;\n表的管理\n创建表\ncreate table [if not exists] 表名(字段名 类型 [约束], 字段名 类型 [约束] \u0026hellip;) ;\n修改表\n添加列\nalter table 表名 add column 列名 列的类型 [first|after 字段名];\nmysql\u0026gt; create table test_add_column ( -\u0026gt; t1 int , -\u0026gt; t2 int , -\u0026gt; t3 int ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; desc test_add_column ; +-------+------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+------+------+-----+---------+-------+ | t1 | int | YES | | NULL | | | t2 | int | YES | | NULL | | | t3 | int | YES | | NULL | | +-------+------+------+-----+---------+-------+ 3 rows in set (0.01 sec) mysql\u0026gt; alter table test_add_column add column t11 bigint first ; Query OK, 0 rows affected (0.04 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc test_add_column ; +-------+--------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------+------+-----+---------+-------+ | t11 | bigint | YES | | NULL | | | t1 | int | YES | | NULL | | | t2 | int | YES | | NULL | | | t3 | int | YES | | NULL | | +-------+--------+------+-----+---------+-------+ 修改列的类型或者约束\nalter table 表名 modify column 列名 新类型[新约束] ;\n修改列名\nalter table 表名 change column 旧列名 新列名 类型;\n删除列名\nalter table 表名 drop column 列名 ;\n修改表名\nalter table 表名 rename to 新表名\n删除表\ndrop table [if exists] 表名;\n复制表 可以跨库\n仅仅复制表的结构 create table 表名 like 原表 ;\n复制表的结构+数据\ncreate table 表名 select * from 原表 ;\ncreate table 表名 select 特定字段 from 原表 where 筛选条件\n数据类型 数值型\n整型 tinyint smallint mediumint int integer bigint 1 2 3 4 8 特点 都可以设置无符号和有符号 默认是有符号 ,通过 unsigned设置无符号 如果超出范围,out of range 异常,mysql5.0 和 8.0 不同 长度可以不指定,默认会有一个长度 长度代表的是显示的最大宽度,而不是只有2的长度位那个范围,但需要搭配zerofill,搭配之后将默认变为无符号整型 浮点型 定点数 decimal(m,d) 默认为(10,0) 浮点数 float(m,d) 4位字节 double(m,d) 8位字节 默认为可变的 特点 m代表整数+小数部位的个数,d代表小数部位 如果超出范围,则报out of range异常,并且插入临界值 m和d都可以省略,但对于定点数,m默认为10,d默认为0 如果精度要求较高,则有限考虑使用定点数 字符型\nchar varchar binary varbinary enum set text blob\nchar:固定长度的字符,写法为char(M) ,最大长度不能超过M ,其中M可以省略,默认为1\nvarchar:可变长度的字符 写法varchar(M),最大长度不能超过M,其中M不可以省略\n日期型\nyear 年\ndate 日期\ndatetime 日期+时间 8\ntime 时间\ntimestamp 时间戳 4 1970-2038 比较容易受到时区,语法模式,版本的影响,更能反映当前时区的真实时间\n新的一杰克 常见约束 含义 : 一种限制 , 用于限制表中的数据,为了保证表中的数据的准确和可靠性\n分类 六大约束\nNOT NULL 非空 用于保证该字段的值不能为空 比如姓名/学号等等\ndefault 默认 , 用于保证该字段有默认值\nPRIMARY KEY 主键 用于保证该字段的值具有唯一性,并且非空,如学号,工号\nUNIQUE 唯一,用于保证该字段的值具有唯一性,可以为空 如座位号/老婆\nCHECK 检查约束 [mysql 不支持] 比如性别 只能男和女 或者青年人年龄\nFOREIGN KEY 外键,用于限制两个表的关系,用于保证该字段的值必须来自于主表的关联列的值 在从表添加外键约束,用于引用主表中的某列的值 例如学生表的专业编号,员工表的部门编号,员工表的工种编号\n添加约束的时机:\n创建表时 修改表时 约束的添加分类:\n列级约束 NOT NULL DEFAULT PRIMARY KEY UNIQUE CHECK FOREIGN KEY 六大约束语法上都支持,但是外键约束没有效果 表级约束 除了非空/默认,其他的都支持 create table 表( 字段名 字段类型 列级约束, 字段名\t字段类型, 表级约束 ) 创建表时添加约束\n添加列级约束\n语法:直接在字段名和类型后面追加约束类型即可\n只支持:默认/非空/主键\nmysql\u0026gt; create database students ; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; use students ; Database changed #创建列级约束 mysql\u0026gt; create table stuinfo ( id int primary key , stuName varchar(20) not null , gender char(1) check(gender=\u0026#39;男\u0026#39; or gender=\u0026#39;女\u0026#39;) ,seat int unique,age int default 18,majorId int references major(id)); Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; desc stuinfo ; +---------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+-------------+------+-----+---------+-------+ | id | int | NO | PRI | NULL | | | stuName | varchar(20) | NO | | NULL | | | gender | char(1) | YES | | NULL | | | seat | int | YES | UNI | NULL | | | age | int | YES | | 18 | | | majorId | int | YES | | NULL | | +---------+-------------+------+-----+---------+-------+ 6 rows in set (0.00 sec) #查看索引 唯一/主键/外键都可以查看 mysql\u0026gt; show index from stuinfo ; 添加表级约束\n语法:在各个字段的最下面\n[constraint 约束名] 约束类型(字段名) \u0026hellip;\nmysql\u0026gt; create table stuinfo(id int , stuname varchar(20),gender char(1),seat int , age int ,majorid int ,constraint pk primary key(id),constraint uq unique(seat) , constraint ck check(gender in (\u0026#39;男\u0026#39;,\u0026#39;女\u0026#39;)),constraint fk_stuinfo_major foreign key(majorid) references major(id)) ; Query OK, 0 rows affected (0.04 sec) mysql\u0026gt; show index from stuinfo ; image-20211001160138048\rconstraint 约束名 可以去掉\nmysql\u0026gt; create table stuinfo(id int , stuname varchar(20),gender char(1),seat int , age int ,majorid int ,primary key(id),unique(seat),check(gender in (\u0026#39;男\u0026#39;,\u0026#39;女\u0026#39;)),foreign key(majorid) references major(id)) ; Query OK, 0 rows affected (0.06 sec) image-20211001160643505\r通用写法\ncrete table if not exists stuinfo( id int primary key , stuname varchar(20) not null , sex char(1) age int default 18, seat int unique , majorid int , constraint fk_stuinfo_major foreign key(majroid) references major(id) ) 主键和唯一的大对比\n保证唯一性 是否允许为空 一个表中可以有几个 是否允许组合键 主键 对 不对 一个表中至多有一个 是,但不推荐 唯一 对 对 可以有多个 是,但不推荐 primar key (id,stuname) unique (seat,majorid) 外键:\n要求在从表设置外键关系 从表的外键列的类型和主表的关联列一致或兼容,名称无所谓 主表的关联咧必须是一个key或者唯一键 插入数据时,先插入主表,再插入从表 删除数据时,先删除从表,再删除主表 修改表时添加约束\n添加列级约束 alter table 表名 mofidy column 字段名 字段类型 新约束 ; 添加表级约束 alter table 表名 add [constraint 约束名] 约束类型(字段名) [外键的引用] ; 添加非空约束\n添加列级约束\nmysql\u0026gt; drop table if exists stuinfo ; Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; create table stuinfo(id int,stuname varchar(20),gender char(1),seat int,age int,majorid int); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; alter table stuinfo modify column stuname varchar(20) not null ; Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc stuinfo; +---------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+-------------+------+-----+---------+-------+ | id | int | YES | | NULL | | | stuname | varchar(20) | NO | | NULL | | | gender | char(1) | YES | | NULL | | | seat | int | YES | | NULL | | | age | int | YES | | NULL | | | majorid | int | YES | | NULL | | +---------+-------------+------+-----+---------+-------+ 6 rows in set (0.00 sec) mysql\u0026gt; alter table stuinfo modify column age int defeault 18 ; mysql\u0026gt; alter table stuinfo modify column age int default 18 ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; alter table stuinfo modify column id int primary key ; Query OK, 0 rows affected (0.04 sec) Records: 0 Duplicates: 0 Warnings: 0 添加表级约束\nmysql\u0026gt; alter table stuinfo add unique(seat); Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 添加外键\nmysql\u0026gt; alter table stuinfo add constraint fk_studentinfo_major foreign key(majorid) references major (id) ; Query OK, 0 rows affected (0.05 sec) Records: 0 Duplicates: 0 Warnings: 0 修改表时删除约束\n#取消非空约束 mysql\u0026gt; alter table stuinfo modify column stuname varchar(20) null ; Query OK, 0 rows affected (0.04 sec) Records: 0 Duplicates: 0 Warnings: 0 #取消默认约束 mysql\u0026gt; alter table stuinfo modify column age int ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 #删除主键 mysql\u0026gt; alter table stuinfo drop primary key ; Query OK, 0 rows affected (0.04 sec) Records: 0 Duplicates: 0 Warnings: 0 #删除唯一键 mysql\u0026gt; alter table stuinfo drop index seat ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; show index from stuinfo ; +---------+------------+----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +---------+------------+----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | stuinfo | 1 | fk_studentinfo_major | 1 | majorid | A | 0 | NULL | NULL | YES | BTREE | | | YES | NULL | +---------+------------+----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 1 row in set (0.01 sec) #删除外键 mysql\u0026gt; alter table stuinfo drop foreign key fk_studentinfo_major ; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 练习一下 #添加主键约束 mysql\u0026gt; create table emp2 (id int,constraint my_emp_id_pk primary key(id)); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; use test ; Database changed #添加主键约束 mysql\u0026gt; alter table dept2 add constraint my_dept_id_pk primary key(department_id); Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 #拷贝数据和结构 mysql\u0026gt; create table emp2 select * from students.emp2 ; Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; show tables ; +-------------------+ | Tables_in_test | +-------------------+ | dept1 | | dept2 | | emp2 | | emp5 | | int_zerofill | | tab_char | | tab_date | | tab_float | | tab_float_default | | tab_int | | tab_set | | test_add_column | +-------------------+ 12 rows in set (0.00 sec) mysql\u0026gt; alter table emp2 add column dept_id int ; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 #添加外键约束 mysql\u0026gt; alter table emp2 add foreign key(dept_id) references dept2(department_id); Query OK, 0 rows affected (0.04 sec) Records: 0 Duplicates: 0 Warnings: 0 表级约束和列级约束的区别\n​\t位置\t支持的约束类型\t是否可以起约束名\n列级约束 列的后面 支持所有语法,但是外键没有效果\t不可以起约束名\n表级约束 所有列的下面 默认和非空不支持,其他支持\t可以起约束名\n标识列 又称为自增长列\n可以不用手动的插入值，系统提供默认的序列值\n创建表时设置标识列\n特点\n标识列必须和主键搭配吗？不一定，但要求是一个key 一个表可以有多少个标识列？至多一个 标识列的类型只能是数值型 一般是int 标识列可以通过 set auto_increment =3 ;设置步长 标识列可以通过手动的方式设置起始值 mysql\u0026gt; create table tab_identity(id int primary key , name varchar(20) ) ; Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into tab_identity value (1,\u0026#39;john\u0026#39;) ; Query OK, 1 row affected (0.01 sec) #不是自增的话，搞不定 会主键重复的 mysql\u0026gt; insert into tab_identity value (1,\u0026#39;john\u0026#39;) ; ERROR 1062 (23000): Duplicate entry \u0026#39;1\u0026#39; for key \u0026#39;tab_identity.PRIMARY\u0026#39; mysql\u0026gt; drop table if exists tab_identity ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; create table tab_identity (id int primary key auto_increment , name varchar(20)) ; Query OK, 0 rows affected (0.02 sec) #可以给他不设置列值 mysql\u0026gt; insert into tab_identity(name) values (\u0026#39;john\u0026#39;) ; Query OK, 1 row affected (0.01 sec) #或者可以给他设置为null就好了 mysql\u0026gt; insert into tab_identity values (null , \u0026#39;jwt\u0026#39;) ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into tab_identity values (null , \u0026#39;jwt\u0026#39;) ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into tab_identity values (null , \u0026#39;jwt\u0026#39;) ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from tab_identity ; +----+------+ | id | name | +----+------+ | 1 | john | | 2 | jwt | | 3 | jwt | | 4 | jwt | +----+------+ 4 rows in set (0.00 sec) mysql不支持设置起始的数值，但是可以通过取巧的办法手动设置\n#查看自增长变量 mysql\u0026gt; show variables like \u0026#39;%auto_increment%\u0026#39; ; +--------------------------+-------+ | Variable_name | Value | +--------------------------+-------+ | auto_increment_increment | 1 | | auto_increment_offset | 1 | +--------------------------+-------+ 2 rows in set, 1 warning (0.00 sec) #设置自增长的步长 mysql\u0026gt; set auto_increment_increment = 3 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show variables like \u0026#39;%auto_increment%\u0026#39; ; +--------------------------+-------+ | Variable_name | Value | +--------------------------+-------+ | auto_increment_increment | 3 | | auto_increment_offset | 1 | +--------------------------+-------+ 2 rows in set, 1 warning (0.00 sec) mysql\u0026gt; insert into tab_identity values (null , \u0026#39;jwt\u0026#39;) ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from tab_identity ; +----+------+ | id | name | +----+------+ | 1 | john | | 2 | jwt | | 3 | jwt | | 4 | jwt | | 7 | jwt | +----+------+ 5 rows in set (0.00 sec) #手动设置起始值 这样就可以达到效果了 mysql\u0026gt; insert into tab_identity values (100, \u0026#39;jwt\u0026#39;) ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from tab_identity ; +-----+------+ | id | name | +-----+------+ | 1 | john | | 2 | jwt | | 3 | jwt | | 4 | jwt | | 7 | jwt | | 100 | jwt | +-----+------+ 6 rows in set (0.00 sec) mysql\u0026gt; insert into tab_identity values (null , \u0026#39;jwt\u0026#39;) ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from tab_identity ; +-----+------+ | id | name | +-----+------+ | 1 | john | | 2 | jwt | | 3 | jwt | | 4 | jwt | | 7 | jwt | | 100 | jwt | | 103 | jwt | +-----+------+ 7 rows in set (0.00 sec) 修改表时设置标识列\nalter table tab_identity modify column id int primary key auto_increment ; 修改表时删除标识列\nalter table tab_identity modify column id int ; TCL Transaction Control Languaue 事务控制语言\n事务 一个或者一组sql语句组成一个执行单元,这个执行单元要么全部执行,要么全部不执行\n事务的特点\nACID\n原子性 一个事务不可再分割,要么执行要么都不执行 一致性 一个事务执行会使数据从一个一致状态切换到另一个一致状态 持久性 一个事务的执行不受其他事务的干扰 隔离性 一个事务一旦提交,则会永久的改变数据库的数据 案例 转账\n事务:事务由单独单元的一个或多个语句组成,在这个单元中,每个mysql语句是相互以来的.而整个单独单元作为一个不可分割的整体,如果单元中某条sql语句一旦执行失败或产生错误,整个单元将会回滚.所有受到影响的数据将返回到事务开始以前的状态;如果单元中的所有sql语句均执行成功,则事务被顺利执行.\n存储引擎 概念:在mysql中的数据用各种不同的技术存储在文件(或内存)中 通过show engines 来查看mysql支持的存储引擎 在mysql中用的最多的存储引擎有 innodb myisam memory 等 其中innodb支持事务,而myisam/memory等不支持事务 mysql\u0026gt; show engines ; +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ | Engine | Support | Comment | Transactions | XA | Savepoints | +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ | MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO | | MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO | | CSV | YES | CSV storage engine | NO | NO | NO | | FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL | | PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO | | MyISAM | YES | MyISAM storage engine | NO | NO | NO | | InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES | | BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO | | ARCHIVE | YES | Archive storage engine | NO | NO | NO | +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ 9 rows in set (0.00 sec) 事务的ACID属性\n原子性A 事务是一个不可分割的工作单位,事务中的操作要么都发生,要么都不发生 持久性D 持久性是指一个事务一旦被提交,它对数据库中数据的改变就是永久性的,接下来的其他操作和数据库故障不应该对其有任何影响 隔离性I 事务的隔离性是指一个事务的执行不能被其他事务干扰,即一个事务内部的操作及使用的数据对并发的其他事务是隔离的,并发执行的各个事务之间不能互相干扰 一致性C 事务必须使数据库从一个一致性状态变换到另一个一致性状态 事务的创建\n隐式事务:事务没有明显的开启和结束的标记 比如insert / update / delete 语句\nmysql\u0026gt; show variables like \u0026#39;autocommit\u0026#39; ; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | autocommit | ON | +---------------+-------+ 1 row in set, 1 warning (0.00 sec) 显式事务:事务具有明显的开启和结束标记 前提是必须先设置自动提交功能为禁用 #只是针对当前事务有效 所以每次开启显式事务的时候都要手动的关闭自动提交功能 set autocommit = 0 ; 步骤1 : 开启事务\nset autocommit = 0\nstart transaction ; 可选的\n步骤2 : 编写事务中的sql语句 select insert update delete \u0026hellip;\n语句1\n语句2\n\u0026hellip;\n步骤3 : 结束事务\ncommit ; 提交事务\nrollback ; 回滚事务\nsavepoint 节点名 ; 设置保存点\nmysql\u0026gt; create table account(id int primary key auto_increment , username varchar(20), balance double) ; Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; insert into account (username,balance) values (\u0026#39;张无忌\u0026#39;,1000) , (\u0026#39;赵敏\u0026#39;,1000) ; Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | 张无忌 | 1000 | | 4 | 赵敏 | 1000 | +----+----------+---------+ 2 rows in set (0.00 sec) #禁用自动提交 开启事务 mysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.00 sec) #开启事务 mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; update account set balance =500 where username = \u0026#39;张无忌\u0026#39; ; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 #在navicat里查看好像是1000 1000 mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | 张无忌 | 500 | | 4 | 赵敏 | 1000 | +----+----------+---------+ 2 rows in set (0.00 sec) #回滚试了试 mysql\u0026gt; rollback ; Query OK, 0 rows affected (0.00 sec) #是可以的 mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | 张无忌 | 1000 | | 4 | 赵敏 | 1000 | +----+----------+---------+ 2 rows in set (0.00 sec) #体验一下事务 mysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; update account set balance = 500 where username = \u0026#39;张无忌\u0026#39; ; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; update account set balance = 1500 where username = \u0026#39;赵敏\u0026#39; ; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 #提交 mysql\u0026gt; commit ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | 张无忌 | 500 | | 4 | 赵敏 | 1500 | +----+----------+---------+ 2 rows in set (0.00 sec) 数据库的隔离级别 对于同时运行的多个事务,当这些事务访问数据库中相同的数据时,如果没有采取必要的隔离机制,就会导致各种并发问题\n脏读:对于两个事务T1 , T2 ,T1读取了已经被T2更新,但是还没有被提交的字段,之后,若T2回滚,T1读取的内容就是临时且无效的 不可重复读:对于两个事务T1 , T2 , T1 读取了一个字段,然后T2 更新了该字段.之后,T1再次读取同一个字段,值就不同了 幻读:对于两个事务T1 , T2 , T1从一个表中读取了一个字段,然后T2在该表中插入了一些新的行.之后,如果T1再次读取同一个条,就会多出几行. 数据库事务的隔离性:数据库系统必须具有隔离并发运行各个事务的能力,使他们不会互相影响,避免各种并发问题.\n一个事务与其他事务隔离的程度称为隔离级别.数据库规定了多种事务隔离级别,不同隔离级别对应不同的干扰程度,隔离级别越高,数据一致性就越好,但并发性就越弱\n数据库提供的4中隔离级别\nread uncommitted(读未提交数据) 允许事务读取未被其他事务提交的变更.脏读/不可重复读/幻读的问题都会出现 read commit(读已经提交的数据) 只允许事务读取已经被其他事务提交的变更,可以避免脏读,但不可重复度和幻读的问题仍然可能出现 repeatable read(可重复读) 确保事务可以多次从一个字段中读取相同的值,在这个事务持续期间,禁止其他事务对这个字段进行更新.可以避免脏读和不可重复读,但幻读的问题仍然存在. serializable(串行化) 确保事务可以从一个表中读取相同的行.在这个事务持续期间,禁止其他事务对该表执行插入,更新和删除操作.所有并发问题都可以避免,但性能十分低下 oracle支持的2种事务隔离级别:read commited , serializable . oracle默认的事务隔离级别为:read commited\nmysql支持4种事务隔离级别 mysql默认的事务隔离级别为 repeatable read\n测试一下read uncommitted\n#重启服务可以保证恢复默认的隔离级别吧好像 PS C:\\Users\\Administrator.YOURTREEDAD\u0026gt; net stop mysql 80 此命令的语法是: NET STOP service PS C:\\Users\\Administrator.YOURTREEDAD\u0026gt; net start mysql80 请求的服务已经启动。 请键入 NET HELPMSG 2182 以获得更多的帮助。 PS C:\\Users\\Administrator.YOURTREEDAD\u0026gt; mysql -u root -p Enter password: ****** #查看隔离级别 mysql\u0026gt; select @@transaction_isolation ; +-------------------------+ | @@transaction_isolation | +-------------------------+ | REPEATABLE-READ | +-------------------------+ 1 row in set (0.00 sec) #设置隔离级别为 read uncommitted 读未提交数据 这样会导致脏读/不可重复读/幻读 mysql\u0026gt; set session transaction isolation level read uncommitted ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @@transaction_isolation ; +-------------------------+ | @@transaction_isolation | +-------------------------+ | READ-UNCOMMITTED | +-------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; set autocommit= 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.00 sec) #看! 还没提交 mysql\u0026gt; update account set username = \u0026#39;john\u0026#39; where id = 1 ; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; 在另一个界面打开设置隔离级别为 read uncommitted\n就可以看到脏读的数据\nimage-20211002112133588\r假若原来的回滚了,那就离谱了\nmysql\u0026gt; rollback ; Query OK, 0 rows affected (0.00 sec) image-20211002112511055\r所以会出现脏读幻读不可重复读都可能出现在这种隔离级别下\n测试一下 read committed\nmysql\u0026gt; set session transaction isolation level read committed ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set autocommit =0 ; Query OK, 0 rows affected (0.00 sec) #还没提交 mysql\u0026gt; update account set username =\u0026#39;john\u0026#39; where id = 1 ; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 image-20211002113519057\r这边也确实在第二个事务中没有看到还没提交的数据\n但是!!! 但是 说明这可以避免脏读,但是不可重复读和幻读 嘿嘿!不行!\nimage-20211002113728187\r**测试一下 repeatable read **\nmysql\u0026gt; select @@transaction_isolation ; +-------------------------+ | @@transaction_isolation | +-------------------------+ | REPEATABLE-READ | +-------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | john | 500 | | 4 | 赵敏 | 1500 | +----+----------+---------+ 2 rows in set (0.01 sec) mysql\u0026gt; show variables like \u0026#39;autocommit\u0026#39; ; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | autocommit | ON | +---------------+-------+ 1 row in set, 1 warning (0.01 sec) mysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.00 sec) #更新还未提交 mysql\u0026gt; update account set username = \u0026#39;刘备\u0026#39; where id = 1 ; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 image-20211002151741957\r完全没问题,避免了脏读\n#提交之后在看看 mysql\u0026gt; commit ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | 刘备 | 500 | | 4 | 赵敏 | 1500 | +----+----------+---------+ 2 rows in set (0.00 sec) image-20211002151946236\r下面演示一下为什么这种隔离级别会出现幻读\ncmd中开启事务,插入一条数据\nimage-20211002152534283\rpowershell中开启事务,查询数据\nmysql\u0026gt; set autocommit =0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.00 sec) #暂时没查到 mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | 刘备 | 500 | | 4 | 赵敏 | 1500 | +----+----------+---------+ 2 rows in set (0.00 sec) cmd中commit了\nimage-20211002152659690\r#sql中也没有问题 保证数据一致性 所以么有出现不可重复读 不会多出来刚刚插入的那条数据 mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | 刘备 | 500 | | 4 | 赵敏 | 1500 | +----+----------+---------+ 2 rows in set (0.00 sec) #但是 ! 但是! 下面出问题了 本来希望在事务的开始的时候,表里有两条数据,我希望把两条数据的username改一下,但是这时候另一个事务中插入了一条 在更新的时候把插入的也更新了username 这样的话就裂开了 出现幻读 mysql\u0026gt; update account set username = \u0026#39;mmm\u0026#39;; Query OK, 3 rows affected (0.00 sec) Rows matched: 3 Changed: 3 Warnings: 0 mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | mmm | 500 | | 4 | mmm | 1500 | | 5 | mmm | 1000 | +----+----------+---------+ 3 rows in set (0.00 sec) image-20211002153254274\r测试一下 serializable powershell中尝试开启事务 并且更新数据\nmysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set session transaction isolation level serializable ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @@transaction_isolation ; +-------------------------+ | @@transaction_isolation | +-------------------------+ | SERIALIZABLE | +-------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | mmm | 500 | | 4 | mmm | 1500 | | 5 | mmm | 1000 | +----+----------+---------+ 3 rows in set (0.00 sec) mysql\u0026gt; update account set username =\u0026#39;www\u0026#39; ; 这时还没有更新,cmd中开启了一个事务尝试往这张表中插入数据\nimage-20211002154329103\r这就会将表锁住,因为上一个事务在使用这张表,为了防止数据库出现幻读的操作,该隔离级别将表锁住了,这样子完全插入不了,做更新的时候就可以保证更新的数据条目和查出来的数据条目是一致的了.\nimage-20211002154520024\r在mysql中设置隔离级别 每启动一个mysql程序,就会获得一个单独的数据库连接.每个数据库连接都有一个全局变量@@tx_isolation,表示当前的事务隔离级别 查看当前的隔离级别: select @@tx_isolation ; 设置当前mysql连接的隔离级别: set transaction isolation level read committed ; 设置数据库系统的全局的隔离级别: set global transaction isolation level read committed ; 事务的隔离级别 脏读 不可重复读 幻读 read uncommitted 会 会 会 read committed 不会 会 会 repeated read 不会 不会 会 serializable 不会 不会 不会 mysql中默认的是repeated read ;\noracle中默认的是read committed\n查看 select @@transaction_isolation ;\n设置 set session/global transaction isolation level serilizable\u0026hellip;\ndelete和truncate的区别 mysql\u0026gt; show variables like \u0026#39;autocommit\u0026#39;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | autocommit | OFF | +---------------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.00 sec) #删除数据 mysql\u0026gt; delete from account ; Query OK, 3 rows affected (0.00 sec) #回滚 mysql\u0026gt; rollback ; Query OK, 0 rows affected (0.01 sec) #数据还在 mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | mmm | 500 | | 4 | mmm | 1500 | | 5 | mmm | 1000 | +----+----------+---------+ 3 rows in set (0.00 sec) mysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.00 sec) #删除数据 mysql\u0026gt; truncate account ; Query OK, 0 rows affected (0.03 sec) #回滚 mysql\u0026gt; rollback ; Query OK, 0 rows affected (0.00 sec) #无法恢复 mysql\u0026gt; select * from account ; Empty set (0.01 sec) savepoint的使用\nmysql\u0026gt; set autocommit = 0 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start transaction ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; delete from account where id =1 ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; delete from account where id = 2; Query OK, 1 row affected (0.00 sec) #设置保存点 mysql\u0026gt; savepoint a ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; delete from account where id =3 ; Query OK, 1 row affected (0.00 sec) #回到保存点 mysql\u0026gt; rollback to a ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 3 | 关羽 | 3000 | +----+----------+---------+ 1 row in set (0.00 sec) #还可以再回滚 mysql\u0026gt; rollback ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from account ; +----+----------+---------+ | id | username | balance | +----+----------+---------+ | 1 | 刘备 | 1000 | | 2 | 张飞 | 2000 | | 3 | 关羽 | 3000 | +----+----------+---------+ 3 rows in set (0.00 sec) 视图 虚拟表,和普通表一样使用,通过普通表动态生成的数据\nmysql5.1开始提供视图功能.一种虚拟存在的表,行和列的数据来自定义视图的查询中使用的表,并且是在使用视图时动态生成的,只保存了sql逻辑,不保存查询结果\n应用场景 多个地方用到了同样的查询结果 该查询结果使用的sql语句较为复杂 创建视图\n语法 create view 视图名 as 查询语句\nmysql\u0026gt; create view info as select e.last_name,d.department_name,j.* from employees e join departments d on e.department_id = d.department_id join jobs j on j.job_id = e.job_id ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from info where last_name like \u0026#39;%a%\u0026#39;; +------------+-----------------+------------+---------------------------------+------------+------------+ | last_name | department_name | job_id | job_title | min_salary | max_salary | +------------+-----------------+------------+---------------------------------+------------+------------+ | Kochhar | Exe | AD_VP | Administration Vice President | 15000 | 30000 | | De Haan | Exe | AD_VP | Administration Vice President | 15000 | 30000 | #查询各部门的平均工资级别 mysql\u0026gt; select a.department_id , g.grade_level , a.平均工资 from (select e.department_id , avg(salary) 平均工资 from employees e group by department_id )a join job_grades g on a.平均工资 between lower_sal and highest_sal ; +---------------+-------------+--------------+ | department_id | grade_level | 平均工资 | +---------------+-------------+--------------+ | NULL | C | 7000.000000 | | 10 | B | 4400.000000 | | 20 | C | 9500.000000 | #如果用视图来做简化一点点 mysql\u0026gt; create view myv2 as select e.department_id , avg(salary) 平均工资 from employees e group by e.department_id ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select m.*,j.grade_level from myv2 m join job_grades j on m.平均工资 between j.lower_sal and j.highest_sal ; +---------------+--------------+-------------+ | department_id | 平均工资 | grade_level | +---------------+--------------+-------------+ | NULL | 7000.000000 | C | | 10 | 4400.000000 | B | #查询平均工资最低的部门信息 mysql\u0026gt; select * from departments d where d.department_id = (select department_id from employees e group by e.department_id order by avg(salary) asc limit 1); +---------------+-----------------+------------+-------------+ | department_id | department_name | manager_id | location_id | +---------------+-----------------+------------+-------------+ | 50 | Shi | 121 | 1500 | +---------------+-----------------+------------+-------------+ #使用视图 mysql\u0026gt; select * from departments where department_id = (select department_id from myv2 order by 平均工资 limit 1); +---------------+-----------------+------------+-------------+ | department_id | department_name | manager_id | location_id | +---------------+-----------------+------------+-------------+ | 50 | Shi | 121 | 1500 | +---------------+-----------------+------------+-------------+ #可以使用视图套视图 视图的优点\n重用sql语句 简化复杂的sql操作,不知道他的查询细节 保护数据,提高安全性 视图的修改\n方式一 create or replace view 视图名 as 查询语句 ;\n方式二 alter view 视图名 as 查询语句;\n视图的删除\ndrop view 视图名,视图名,\u0026hellip;\nmysql\u0026gt; drop view emp_v1,emp_v2,info,myv2 ; Query OK, 0 rows affected (0.01 sec) 查看视图\ndesc 视图名 ;\n查看具体的过程 show create view 视图名 ;\n练习一下 mysql\u0026gt; create or replace view emp_v1 as select last_name , salary , email from employees where phone_number like \u0026#39;011%\u0026#39; ; Query OK, 0 rows affected (0.01 sec) #创建视图要求查询部门的最高工资高于12000的部门信息 mysql\u0026gt; create or replace view emp_v2 as select d.* from departments d join employees e on e.department_id = d.department_id group by e.department_id having max(salary) \u0026gt;12000 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from emp_v2 ; +---------------+-----------------+------------+-------------+ | department_id | department_name | manager_id | location_id | +---------------+-----------------+------------+-------------+ | 90 | Exe | 100 | 1700 | | 80 | Sal | 145 | 2500 | | 20 | Mar | 201 | 1800 | +---------------+-----------------+------------+-------------+ 视图的更新\n视图的插入\nmysql\u0026gt; create or replace view myv1 as select last_name , email from employees; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from myv1 ; +-------------+----------+ | last_name | email | +-------------+----------+ | K_ing | SKING | | Kochhar | NKOCHHAR | #原始表也插入了张飞这条数据了 mysql\u0026gt; insert into myv1 values(\u0026#39;张飞\u0026#39;, \u0026#39;101@qq.com\u0026#39;); Query OK, 1 row affected (0.01 sec) 视图的更新\nmysql\u0026gt; update myv1 set last_name = \u0026#39;张无忌\u0026#39; where last_name = \u0026#39;张飞\u0026#39; ; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 #都会修改原始表 视图的删除\nmysql\u0026gt; delete from myv1 where last_name = \u0026#39;张无忌\u0026#39; ; Query OK, 1 row affected (0.01 sec) #都会修改原始表 通常情况下不会对视图进行增删改的操作的\n备注: 视图的可更新性和视图中查询的定义有关系,以下类型的视图是不能更新的\n包含以下关键字的sql语句:分组函数/distinct/group by/having/union/union all 常量视图 select中包含子查询 join from一个不能更新的视图 where子句的子查询引用了from子句中的表 #关键字的sql语句的视图不可以被更新 mysql\u0026gt; create or replace view myv2 as select max(salary) m ,department_id from employees group by department_id ; Query OK, 0 rows affected (0.01 sec) #想想也是,怎么能简单的更新一下max(salary)呢,聚合函数的值是算出来的 mysql\u0026gt; update myv2 set m =9000 where department_id = 10 ; ERROR 1288 (HY000): The target table myv2 of the UPDATE is not updatable #常量视图不能修改 mysql\u0026gt; create or replace view myv3 as select \u0026#39;john\u0026#39; name ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from myv3 ; +------+ | name | +------+ | john | +------+ 1 row in set (0.00 sec) mysql\u0026gt; update myv3 set name = \u0026#39;lucy\u0026#39; ; ERROR 1288 (HY000): The target table myv3 of the UPDATE is not updatable #select中包含子查询的不能修改视图 mysql\u0026gt; create or replace view myv4 as select (select max(salary) from employees) 最高工资 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from myv4 ; +----------+ | 最高工资 | +----------+ | 24000.00 | +----------+ 1 row in set (0.01 sec) mysql\u0026gt; update myv4 set 最高工资 = 10000 ; ERROR 1288 (HY000): The target table myv4 of the UPDATE is not updatable #join中不能更新视图 mysql\u0026gt; create or replace view myv5 as select last_name ,department_name from employees e join departments d on e.department_id = d.department_id ; Query OK, 0 rows affected (0.01 sec) #可以更新 mysql\u0026gt; update myv5 set last_name = \u0026#39;张飞\u0026#39; where last_name= \u0026#39;Whalen\u0026#39; ; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 #不能插入 , 可能是因为两个视图中有一个是department_id是主键叭 mysql\u0026gt; insert into myv5 values (\u0026#39;陈真\u0026#39;,\u0026#39;xxxx\u0026#39;) ; ERROR 1394 (HY000): Can not insert into join view \u0026#39;myemployees.myv5\u0026#39; without fields list #由一个不可更新的视图构成的视图不可更新 mysql\u0026gt; create or replace view myv6 as select * from myv4 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from myv6 ; +----------+ | 最高工资 | +----------+ | 24000.00 | +----------+ 1 row in set (0.01 sec) mysql\u0026gt; update myv6 set 最高工资 = 20000 ; ERROR 1288 (HY000): The target table myv6 of the UPDATE is not updatable #where子句的子查询引用了from子句中的表 相当于自连接 mysql\u0026gt; create or replace view myv7 as select last_name , email , salary from employees where employee_id in(select manager_id from employees where manager_id is not null) ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from myv7 ; +-----------+----------+----------+ | last_name | email | salary | +-----------+----------+----------+ | K_ing | SKING | 24000.00 | | De Haan | LDEHAAN | 17000.00 | | Hunold | AHUNOLD | 9000.00 | | Kochhar | NKOCHHAR | 17000.00 | | Greenberg | NGREENBE | 12000.00 | | Raphaely | DRAPHEAL | 11000.00 | | Weiss | MWEISS | 8000.00 | | Fripp | AFRIPP | 8200.00 | | Kaufling | PKAUFLIN | 7900.00 | | Vollman | SVOLLMAN | 6500.00 | | Mourgos | KMOURGOS | 5800.00 | | Russell | JRUSSEL | 14000.00 | | Partners | KPARTNER | 13500.00 | | Errazuriz | AERRAZUR | 12000.00 | | Cambrault | GCAMBRAU | 11000.00 | | Zlotkey | EZLOTKEY | 10500.00 | | Hartstein | MHARTSTE | 13000.00 | | Higgins | SHIGGINS | 12000.00 | +-----------+----------+----------+ 18 rows in set (0.00 sec) mysql\u0026gt; update myv7 set salary =10000 where last_name = \u0026#39;K_ing\u0026#39; ; ERROR 1288 (HY000): The target table myv7 of the UPDATE is not updatable 视图和表的对比 创建语法的关键字 是否实际占用物理空间 使用 视图 create view 只是保存了sql逻辑 增删改查,只是一般不能增删改 表 create table 保存了数据 增删改查 delete和truncate在事务使用时的区别 delete可以回滚 truncate不能回滚 练习一下 #添加约束 创建表 但是这样 列级约束中外键是不起作用的 mysql\u0026gt; create table Book ( bid int primary key , bname varchar(200) not null unique , price float default(10),btypeId int references booktype(id)); Query OK, 0 rows affected (0.03 sec) #这里发现索引只有 主键和唯一键 mysql\u0026gt; show index from book ; +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | book | 0 | PRIMARY | 1 | bid | A | 0 | NULL | NULL | | BTREE | | | YES | NULL | | book | 0 | bname | 1 | bname | A | 0 | NULL | NULL | | BTREE | | | YES | NULL | +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 2 rows in set (0.01 sec) #所以要改成这样 mysql\u0026gt; create table Book ( bid int primary key , bname varchar(200) not null unique , price float default(10),btypeId int , foreign key(btypeId) references bookType(id)); Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; show index from book ; +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression | +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ | book | 0 | PRIMARY | 1 | bid | A | 0 | NULL | NULL | | BTREE | | | YES | NULL | | book | 0 | bname | 1 | bname | A | 0 | NULL | NULL | | BTREE | | | YES | NULL | | book | 1 | btypeId | 1 | btypeId | A | 0 | NULL | NULL | YES | BTREE | | | YES | NULL | +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+ 3 rows in set (0.01 sec) mysql\u0026gt; create or replace view myvbook as select bname , name from book b join booktype t on b.btypeid = t.id where price \u0026gt;100 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; create or replace view myvbook1 as select bname , price from book where price between 90 and 120 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; drop view myvbook , myvbook1 ; Query OK, 0 rows affected (0.01 sec) 复习前一天内容 DDL语言\n常见的约束\nNOT NULL 非空,该字段的值必填\nDEFAULT 默认,该字段的值不用手动插入有默认值\nCHECK 检查 mysql不支持\nPRIMARY KEY 主键 该字段的值不可重复并且非空 unique+not null\nFOREIGN KEY 外键 该字段的值引用了另外的表的字段\nUNIQUE 唯一 该字段的值不可重复\n主键和唯一的区别\n一个表至多有一个主键 , 但可以有多个唯一键 主键不允许为空 , 唯一可以为空 都具有唯一性,都支持组合键 , 但不推荐 外键\n用于限制两个表的关系,从表的字段引用了主表的某字段值 要求外键列和主表的被引用列要求类型一致,意义一样,名称无要求 主表的被引用列要求是一个key(一般就是主键) 插入数据,先插入主表 删除数据,先删除从表 级联删除\n实际上就是在删除主表里的数据的时候,把从表里相关的带有该数据的行也一并删除\n#级联删除 alter table stuinfo add constraint fk_stu_major foreign key(majorid) references major(id) on delete cascade ; 级联置空\n实际上就是在删除主表里的数据的时候,把从表里相关的带有该数据的行的对应字段置为空\n#级联置空 alter table stuinfo add constraint fk_stu_major foreign key(majorid) references major(id) on delete set null ; 创建表时添加约束\ncreate table 表名( 字段名 字段类型 not null , 字段名 字段类型 primary key , 字段名 字段类型 unique , 字段名 字段类型 default , constraint 约束名 foreign key(字段名) references 主表(被引用列) ) **注意:\t**\n支持类型 可以起约束名字 列级约束 除了外键 不可以 表级约束 除了默认,非空 可以,但是对主键无效 列级约束可以在一个字段上追加多个,中间用空格隔开,没有顺序要求\n修改表时添加或删除约束\n非空\nalter table 表名 modify column 字段名 字段类型 not null ;\n删除非空\nalter table 表名 modify column 字段名 字段类型 ;\n默认\nalter table 表名 modify column 字段名 字段类型 default 值 ;\n删除默认\nalter table 表名 modify column 字段名 字段类型;\n主键\nalter table 表名 add primary key (字段名) ;\n删除主键\nalter table 表名 drop primary key ;\n唯一\nalter table 表名 add unique (字段名) ;\n删除\nalter table 表名 drop index 索引名 ;\n外键\nalter table 表名 add foreign key (字段名) references 主表 (被引用列) ;\n删除外键\nalter table 表名 drop foreign key 约束名 ;\n自增长列\n特点\n不用手动插入值 , 可以自动提供序列值,默认从1开始,步长为1 auto_increament_increment 如果要更改起始值:手动插入值 如果要更改步长:更改系统变量 set auto_increment_increment = 值 ; 一个表至多有一个自增长列 自增长列只能支持数值型 自增长列必须为一个key 创建表时设置自增长列\ncreate table 表\n修改表时设置自增长列\ncreate table 表 modify column 字段名 字段类型 约束 auto_increment ;\n删除自增长列\nalter table 表 modify column 字段名 字段类型 约束\nTCL语言\n事务:一条或多条sql语句组成一个执行单位,一组sql句要么都执行要么都不执行\n特点(ACID)\n原子性 一个事务是不可再分割的整体,要么都执行要么都不执行 一致性 一个事务可以使数据从一个一致状态切换到另一个一致的状态 隔离性 一个事务不受其他事务的干扰,多个事务互相隔离的 持久性 一个事务一旦提交了,则永久的持久化到本地 事务的使用步骤\n了解:\n隐式事务(自动事务) 没有明显的开始和结束,本事就是一条事务可以自动提交,比如insert update delete 显式事务 具有明显的开启和结束 使用显式事务\n开启事务 set autocommit = 0 start transacton ; 可以省略 编写逻辑sql语句 一条或者多条 注意 不包含create alter drop 只支持insert update delete select 设置回滚点 savepoint 回滚点名 ; 结束事务 提交 commit 回滚 rollback 回滚点 rollback to 回滚点名; 并发事务 事务的并发问题是如何发生的 多个事务同时操作同一个数据库的相同数据时\n并发问题有哪些 脏读 一个事务读取了其他事务还没有提交的数据 读到的是其他事务\u0026quot;更新\u0026quot;的数据 不可重复读 一个事务多次读取结果不一样 重复读取可能造成数据不一致的现象 幻读 一个事务读取了其他事务还没有提交的数据 只是读到的是 其他事务\u0026quot;插入\u0026quot;的数据 如何解决并发问题 通过设置隔离级别来解决 隔离级别 脏读 不可重复读 幻读 read uncommitted 读未提交 会 会 会 read committed 读已提交 不会 会 会 (oracle默认) repeatted read 可重复读 不会 不会 会 (msyql默认) serializable 串行化 不会 不会 不会 视图 含义 mysql5.1版本出现的新特性 , 本身是一个虚拟表,是通过表数据动态生成的,查看时动态生成\n好处\n简化sql语句 封装重用 保护了基表的数据,提高了安全性 创建\ncreate or replace view 视图名 as select \u0026hellip;\u0026hellip;\n修改\ncreate or replace view 视图名 as select \u0026hellip;..\nalter view 视图名 as select \u0026hellip;.\n删除\ndrop view 视图名,视图名\u0026hellip;\n查看\ndesc 视图名\nshow create view 视图名\n使用\ninsert delete update select\n**注意:\t**视图一般用于查询的,而不是更新的,所以具备以下的视图都不允许更新\n带有 group by 分组函数 union having where后的子查询用到了from中的表 常量视图 从不可更新的视图中生成的视图 join 视图和表的区别\nview 和 table 视图占用较少物理空间 表占用实际数据 视图一般用于查询 表用于增删改查 变量 系统变量 全局变量 会话变量 自定义变量 用户变量 局部变量 系统变量 说明:变量由系统提供,不是用户定义,属于服务器层面\n使用的语法:\n查看所有的系统变量 show golbal/session variables ; session是默认的 查看满足条件的部分系统变量 show global/session variables like \u0026lsquo;%char%\u0026rsquo; ; 查看指定的某个系统变量的值 select @@global/session.系统变量名字 ; session是默认的 为某个系统变量赋值 方式一 set global/session 系统变量名 = 值 ; 方式二 set @@global/session.系统变量名 = 值; show global variables ; mysql\u0026gt; select @@transaction_isolation ; +-------------------------+ | @@transaction_isolation | +-------------------------+ | REPEATABLE-READ | +-------------------------+ 1 row in set (0.00 sec) 注意\n如果是全局级别,则需要加global , 如果是会话级别,则需要加session , 如果不写, 则默认\n全局变量\n作用域:服务器每次启动将为所有的全局变量赋初始值,针对所有的会话连接有效,但不能跨重启\nshow gloabl variables ;\n查看部分的全局变量\nshow global variables ; show variables like \u0026lsquo;%char%\u0026rsquo; ;\n查看指定的全局变量的值\nselect @@global.autocommit ;\n为某个指定的全局变量赋值\nmysql\u0026gt; set @@global.autocommit = 0 ; Query OK, 0 rows affected (0.00 sec)\n会话变量\n作用域:仅仅针对于当前会话(连接)有效\n查看所有的会话变量\nshow session variables ;\nshow variables ;\n查看部分的会话变量\nshow variables like \u0026lsquo;%char%\u0026rsquo; ;\nshow session variables like \u0026lsquo;%char%\u0026rsquo; ;\n查看指定的某个会话变量\nselect @@transaction_isolation ;\nselect @@session.transaction_isolation ;\n为某个会话变量赋值\n方式一\nmysql\u0026gt; set @@session.transaction_isolation = \u0026lsquo;read-committed\u0026rsquo; ; Query OK, 0 rows affected (0.00 sec)\n方式二\nmysql\u0026gt; set session transaction isolation level read uncommitted ; Query OK, 0 rows affected (0.00 sec)\n方式三\nset session transaction_isolation = \u0026lsquo;serializable\u0026rsquo; ;\nmysql\u0026gt; show variables like \u0026#39;%char%\u0026#39; ; +--------------------------+---------------------------------------------------------+ | Variable_name | Value | +--------------------------+---------------------------------------------------------+ | character_set_client | gbk | | character_set_connection | gbk | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | gbk | | character_set_server | utf8mb4 | | character_set_system | utf8mb3 | | character_sets_dir | C:\\Program Files\\MySQL\\MySQL Server 8.0\\share\\charsets\\ | +--------------------------+---------------------------------------------------------+ 8 rows in set, 1 warning (0.00 sec) mysql\u0026gt; show session variables like \u0026#39;%char%\u0026#39; ; +--------------------------+---------------------------------------------------------+ | Variable_name | Value | +--------------------------+---------------------------------------------------------+ | character_set_client | gbk | | character_set_connection | gbk | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | gbk | | character_set_server | utf8mb4 | | character_set_system | utf8mb3 | | character_sets_dir | C:\\Program Files\\MySQL\\MySQL Server 8.0\\share\\charsets\\ | +--------------------------+---------------------------------------------------------+ 8 rows in set, 1 warning (0.00 sec) mysql\u0026gt; select @@transaction_isolation ; +-------------------------+ | @@transaction_isolation | +-------------------------+ | REPEATABLE-READ | +-------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select @@session.transaction_isolation ; +---------------------------------+ | @@session.transaction_isolation | +---------------------------------+ | REPEATABLE-READ | +---------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; set session transaction isolation level read uncommitted ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set @@session.transaction_isolation = \u0026#39;read-committed\u0026#39; ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @@transaction_isolation ; +-------------------------+ | @@transaction_isolation | +-------------------------+ | READ-COMMITTED | +-------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; set session transaction_isolation = \u0026#39;serializable\u0026#39; ; Query OK, 0 rows affected (0.00 sec) 自定义变量 说明:变量是用户自定义的,不是由系统生成的\n使用步骤:声明=\u0026gt;赋值=\u0026gt;使用(查看/比较/运算等)\n用户变量\n作用域:针对当前会话(连接)有效,同于会话变量的作用域 , 应用在任何地方,也就是begin end里面或者begin end 外面\n赋值操作符 =或者 :=\n声明并初始化 set @用户变量名 = 值 | set@用户变量名 :=值 | select @用户变量名:=值\n赋值\n方式一 set @用户变量名 = 值 | set@用户变量名 :=值 | select @用户变量名:=值 方式二 通过 select into select 字段 into 变量名 from 表 使用\nselect @用户变量名\nmysql\u0026gt; set @name := \u0026#39;ljs\u0026#39; ; Query OK, 0 rows affected (0.00 sec) #弱类型 mysql\u0026gt; set @name = 1997 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set @count = 1 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; use myemployees ; Database changed #方式二 mysql\u0026gt; select count(*) into @count from employees ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select @name ; +-------+ | @name | +-------+ | 1997 | +-------+ 1 row in set (0.00 sec) mysql\u0026gt; select @count ; +--------+ | @count | +--------+ | 107 | +--------+ 1 row in set (0.00 sec) 局部变量 作用域:仅仅在定义它的begin end中有效\n应用在begin end 中的第一句话!!!\n声明\ndeclare 变量名 类型 ;\ndeclare 变量名 类型 default 值;\n赋值\n方式一\nset 局部变量名 = 值;\n方式二\nset 局部变量名 := 值 ;\n方式三\nselect @局部变量名 := 值 ;\n方式四\nselect 值 into @局部变量名 from 表 ;\n使用\nselect 局部变量名 ;\n对比用户变量和局部变量\n作用域 定义和使用的位置 语法 用户变量 当前会话 会话中的任何地方 需要加上@符号,不用限定类型 局部变量 begin end 中 只能在begin end中,且为第一句话 一般不用加上@符号,除非select,需要限定类型 #使用用户变量 mysql\u0026gt; set @a := 1 ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select b1 into @b from (select 1 b1)b ; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select @b+@a ; +-------+ | @b+@a | +-------+ | 2 | +-------+ #只能在begin end中才行 mysql\u0026gt; declare m int default 1 ; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;declare m int default 1\u0026#39; at line 1 存储过程和函数 存储过程和函数:类似与java中的方法\n好处:\n提高代码的重用性 简化操作 存储过程\n含义:一组预先编译豪的sql语句的集合,理解成批处理语句\n好处:\n提高了代码的重用性 简化操作 减少了编译次数并减少了和数据库服务器的连接次数,提高了效率 创建语法\ncreate procedure 存储过程名(参数列表)\nbegin\n​\t存储过程体(一组合法的sql语句)\nend\n注意:\n参数列表包含三部分 参数模式 参数名 参数类型\nIN stuname varchar(20) 参数模式 IN 该参数可以作为输入,也就是该参数需要调用方传入值 OUT 该参数可以作为输出,也就是该参数可以作为返回值 INOUT 该参数既可以作为输入又可以作为输出,也就是该参数既需要传入值,又可以返回值 如果存储过程体仅仅只有一句话 , begin end 可以省略\n存储过程体中的每条sql语句的结尾要求必须加分号;\n存储过程的结尾可以使用 DELIMITER重新设置\n语法:\nDELIMITER 结束标记\nDELIMITER $\n调用语法\nCALL 存储过程名 (实参列表) 结束标记;\n空参列表 #实现批量插入数据 mysql\u0026gt; show procedure status like \u0026#39;myp1\u0026#39;; +-------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+ | Db | Name | Type | Definer | Modified | Created | Security_type | Comment | character_set_client | collation_connection | Database Collation | +-------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+ | girls | myp1 | PROCEDURE | root@localhost | 2021-10-10 10:19:11 | 2021-10-10 10:19:11 | DEFINER | | gbk | gbk_chinese_ci | utf8_general_ci | +-------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+ 1 row in set (0.01 sec) mysql\u0026gt; use girls ; Database changed #写错了 就把存储过程删了重来 mysql\u0026gt; drop procedure myp1 ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; show procedure status like \u0026#39;myp1\u0026#39; ; Empty set (0.01 sec) mysql\u0026gt; delimiter $ mysql\u0026gt; create procedure myp1() -\u0026gt; begin -\u0026gt; insert into admin(username ,password) -\u0026gt; values (\u0026#39;ljs\u0026#39;,\u0026#39;11\u0026#39;),(\u0026#39;jwt\u0026#39;,\u0026#39;22\u0026#39;),(\u0026#39;lje\u0026#39;,\u0026#39;33\u0026#39;),(\u0026#39;fyz\u0026#39;,\u0026#39;44\u0026#39;),(\u0026#39;wzr\u0026#39;,\u0026#39;55\u0026#39;) ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; show procedure status like \u0026#39;myp1\u0026#39; $; +-------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+ | Db | Name | Type | Definer | Modified | Created | Security_type | Comment | character_set_client | collation_connection | Database Collation | +-------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+ | girls | myp1 | PROCEDURE | root@localhost | 2021-10-10 11:33:35 | 2021-10-10 11:33:35 | DEFINER | | gbk | gbk_chinese_ci | utf8_general_ci | +-------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+ 1 row in set (0.01 sec) #执行存储过程 mysql\u0026gt; CALL myp1() $ ; Query OK, 5 rows affected (0.00 sec) mysql\u0026gt; select * from admin $ ; +----+----------+----------+ | id | username | password | +----+----------+----------+ | 1 | john | 8888 | | 2 | lyt | 6666 | | 3 | ljs | 11 | | 4 | jwt | 22 | | 5 | lje | 33 | | 6 | fyz | 44 | | 7 | wzr | 55 | +----+----------+----------+ 7 rows in set (0.00 sec) 创建带IN模式参数的存储过程 #查看女神的男朋友 mysql\u0026gt; DELIMITER $ ; mysql\u0026gt; create procedure myp2 (IN girlName varchar(20)) -\u0026gt; begin -\u0026gt; select bo.* from boys bo right join beauty b on bo.id = b.boyfriend_id -\u0026gt; where b.name = girlName ; -\u0026gt; end $ ; Query OK, 0 rows affected (0.01 sec) -\u0026gt; $ ERROR 1065 (42000): Query was empty mysql\u0026gt; CALL myp2(\u0026#39;柳岩\u0026#39;); -\u0026gt; $ +------+---------+--------+ | id | boyName | userCP | +------+---------+--------+ | 2 | 张飞 | 10 | +------+---------+--------+ 1 row in set (0.01 sec) Query OK, 0 rows affected, 1 warning (0.01 sec) #传入多个参数,判断用户是否登陆成功 方式一 mysql\u0026gt; DELIMITER $ mysql\u0026gt; create procedure myp3(IN username varchar(20),IN password varchar(20)) -\u0026gt; begin -\u0026gt; select case when count(*) \u0026gt; 0 then \u0026#39;登陆成功\u0026#39; else \u0026#39;未登陆\u0026#39; end 登陆状态 from admin where admin.username =username and admin.password = password ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; call myp3(\u0026#39;john\u0026#39;,\u0026#39;8888\u0026#39;)$; +----------+ | 登陆状态 | +----------+ | 登陆成功 | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; call myp3(\u0026#39;john\u0026#39;,\u0026#39;8887\u0026#39;)$; +----------+ | 登陆状态 | +----------+ | 未登陆 | +----------+ 1 row in set (0.00 sec) #方式二 使用局部变量 mysql\u0026gt; DELIMITER $ mysql\u0026gt; create procedure myp4(in username varchar(20) , in password varchar(20)) -\u0026gt; begin -\u0026gt; declare result varchar(20) default \u0026#39;\u0026#39;; -\u0026gt; select count(*) into result from admin where admin.username = username and admin.password = password ; -\u0026gt; select if(result =\u0026#39;0\u0026#39;,\u0026#39;未登陆\u0026#39;,\u0026#39;登陆成功\u0026#39;); -\u0026gt; end $ ; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; CALL myp4(\u0026#39;john\u0026#39;,\u0026#39;8888\u0026#39;)$; +-------------------------------------+ | if(result =\u0026#39;0\u0026#39;,\u0026#39;未登陆\u0026#39;,\u0026#39;登陆成功\u0026#39;) | +-------------------------------------+ | 登陆成功 | +-------------------------------------+ 1 row in set (0.00 sec) Query OK, 0 rows affected, 2 warnings (0.00 sec) mysql\u0026gt; CALL myp4(\u0026#39;john\u0026#39;,\u0026#39;88887\u0026#39;)$; +-------------------------------------+ | if(result =\u0026#39;0\u0026#39;,\u0026#39;未登陆\u0026#39;,\u0026#39;登陆成功\u0026#39;) | +-------------------------------------+ | 未登陆 | +-------------------------------------+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.01 sec) 创建带out模式的存储过程 #根据女神名,返回对应男神名 mysql\u0026gt; DELIMITER $ mysql\u0026gt; CREATE procedure myp5(in beautyname varchar(20),out boyname varchar(20)) -\u0026gt; begin -\u0026gt; select bo.boyname into boyname from boys bo where bo.id in (select boyfriend_id from beauty where name = beautyname) ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) #不用初始化也是可以的 mysql\u0026gt; set @boyname := \u0026#39;\u0026#39;; -\u0026gt; call myp5(\u0026#39;柳岩\u0026#39;,@boyname)$; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @boyname ; -\u0026gt; $ +----------+ | @boyname | +----------+ | 张飞 | +----------+ 1 row in set (0.00 sec) #多个out返回值 , 返回男朋友的名字和魅力值 mysql\u0026gt; DELIMITER $ mysql\u0026gt; create procedure myp6(in girlname char(20) , out boyname char(20) , out soulIndex int) -\u0026gt; begin -\u0026gt; select bo.boyname , bo.usercp into boyname , soulIndex from boys bo join beauty b on b.boyfriend_id = bo.id where b.name = girlname ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; call myp6(\u0026#39;柳岩\u0026#39;,@boyname,@soulIndex)$; Query OK, 1 row affected, 2 warnings (0.00 sec) mysql\u0026gt; select @boyname $ +----------+ | @boyname | +----------+ | 张飞 | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; select @soulIndex $ +------------+ | @soulIndex | +------------+ | 10 | +------------+ 1 row in set (0.00 sec) 创建带INOUT模式参数的存储过程 mysql\u0026gt; DELIMITER $ mysql\u0026gt; CREATE procedure myp7 (inout a int , inout b int ) -\u0026gt; begin -\u0026gt; set a = a*2 ; -\u0026gt; set b = b*2 ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; set @a:=1 ; -\u0026gt; set @b:=2 ; -\u0026gt; CALL myp7(@a,@b)$; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @a,@b; -\u0026gt; $ +------+------+ | @a | @b | +------+------+ | 2 | 4 | +------+------+ 1 row in set (0.00 sec) 练习一下\n#传入用户名密码,插入admin表 mysql\u0026gt; DELIMITER $ mysql\u0026gt; create procedure myp8(in username varchar(20),in password varchar(20)) -\u0026gt; begin -\u0026gt; insert into admin(admin.username , admin.password ) values (username,password); -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; CALL myp8(\u0026#39;wlz\u0026#39;,\u0026#39;hellouu\u0026#39;)$ Query OK, 1 row affected, 2 warnings (0.00 sec) #查询传入女神编号 , 返回女神名称和女神电话 mysql\u0026gt; DELIMITER $ mysql\u0026gt; create procedure myp9(in id int , out girlname varchar(20) , out phone varchar(11)) -\u0026gt; begin -\u0026gt; select b.name , b.phone into girlname , phone from beauty b where b.id = id ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; CALL myp9(1,@girlname , @phone)$ Query OK, 1 row affected, 2 warnings (0.00 sec) mysql\u0026gt; select @girlname , @phone $ +-----------+-------------+ | @girlname | @phone | +-----------+-------------+ | 柳岩 | 18209876577 | +-----------+-------------+ 1 row in set (0.00 sec) #比较两个日期大小 并返回大小关系 mysql\u0026gt; DELIMITER $ mysql\u0026gt; create procedure myp10(in birth1 datetime , in birth2 datetime , out result int ) -\u0026gt; begin -\u0026gt; select if(datediff(birth1,birth2)\u0026gt;0,1,if(datediff(birth1,birth2)\u0026lt;0,-1,0)) into result ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; CALL myp10(\u0026#39;1997-11-21\u0026#39;,\u0026#39;1998-11-21\u0026#39;,@result)$ Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select @result $ +---------+ | @result | +---------+ | -1 | +---------+ 1 row in set (0.00 sec) 删除存储过程\ndrop procedure 存储过程名 一次只能删除一次\n查看存储过程的信息\nshow create proceduce 存储过程名\n修改存储过程\n比较麻烦,通常不这么做\n练习一下\n#传入日期,转换成xx年xx月xx日并返回 mysql\u0026gt; create procedure myptest1(in mydate datetime , out strDate varchar(50)) -\u0026gt; begin -\u0026gt; select date_format(mydate,\u0026#39;%y年%m月%d日\u0026#39;) into strDate ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; CALL myptest1(\u0026#39;1997-11-21\u0026#39;,@strDate); -\u0026gt; select @strDate $ Query OK, 1 row affected, 1 warning (0.00 sec) +--------------+ | @strDate | +--------------+ | 97年11月21日 | +--------------+ 1 row in set (0.00 sec) #传入女神名字 输出 女神名字 and 男生名字 最好使用右连接 另外concat和null拼接永远都是null 所以要用ifnull的函数防止出问题 mysql\u0026gt; delimiter $ mysql\u0026gt; create procedure myptest2(inout girlName varchar(50)) -\u0026gt; select concat(b.name ,\u0026#39; AND \u0026#39;,bo.boyName) into girlName from beauty b join boys bo on b.boyfriend_id = bo.id where b.name = girlName ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; set @name :=\u0026#39;柳岩\u0026#39; ; -\u0026gt; CALL MYPTEST2(@name); -\u0026gt; select @name $ Query OK, 0 rows affected (0.00 sec) Query OK, 1 row affected (0.00 sec) +---------------+ | @name | +---------------+ | 柳岩 AND 张飞 | +---------------+ 1 row in set (0.00 sec) #传入条目数和起始索引,查询beauty表的记录 limit offset,size 是从offset的下一条开始的 mysql\u0026gt; delimiter $ mysql\u0026gt; create procedure myptest3(in size int , in startIndex int) -\u0026gt; begin -\u0026gt; select * from beauty limit startIndex,size ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; CALL myptest3(5,3) $ +----+--------+------+---------------------+-------------+--------------+--------------+ | id | name | sex | borndate | phone | photo | boyfriend_id | +----+--------+------+---------------------+-------------+--------------+--------------+ | 5 | 周冬雨 | 女 | 1992-02-03 00:00:00 | 18209179577 | NULL | 2 | | 7 | 岳灵珊 | 女 | 1987-12-30 00:00:00 | 18219876577 | NULL | 2 | | 9 | 双儿 | 女 | 1993-02-03 00:00:00 | 18209876579 | NULL | 2 | | 11 | 夏雪 | 女 | 1993-02-03 00:00:00 | 18209876579 | NULL | 2 | | 13 | 唐艺昕 | 女 | 1990-04-23 00:00:00 | 18988888 | NULL | 2 | +----+--------+------+---------------------+-------------+--------------+--------------+ 5 rows in set (0.00 sec) Query OK, 0 rows affected (0.02 sec) 函数 含义:一组预先编译豪的sql语句的集合,理解成批处理语句\n好处:\n提高了代码的重用性 简化操作 减少了编译次数并减少了和数据库服务器的连接次数,提高了效率 区别:\n存储过程:可以有0个返回,也可以有多个返回,适合做批量插入/批量更新\n函数:有且仅有1个返回,适合做处理数据后返回一个结果\n创建语法\ncreate function 函数名 (参数列表) return 返回类型\nbegin\n​\t函数体\nend\n注意:\n参数列表 包含两部分\n参数名 参数类型\n函数体:肯定会有return语句,如果没有会报错\n如果return语句没有放在函数体的最后也不报错,但不建议\nreturn 值;\n函数体中仅有一句话,则可以省略begin end\n使用delimeter语句作为设置结束标记\n调用语法\nselect 函数名(参数列表)\n无参有返回\n#返回公司的员工个数 #和存储过程不一样 这里要声明局部变量 最后一句需要return一下 #mysql中要改一下全局变量 这是我们开启了bin-log, 我们就必须指定我们的函数是否是 mysql\u0026gt; set global log_bin_trust_function_creators=1; -\u0026gt; $ Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; delimiter $ mysql\u0026gt; create function myf1() returns int -\u0026gt; begin -\u0026gt; declare count int default 0 ; -\u0026gt; select count(*) into count from employees ; -\u0026gt; return count ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) #使用的时候用select关键字 mysql\u0026gt; select myf1()$ +--------+ | myf1() | +--------+ | 107 | +--------+ 1 row in set (0.00 sec) 有参有返回\n#根据员工名,返回他的工资 mysql\u0026gt; delimiter $ mysql\u0026gt; create function myf3(departmentname varchar(20)) returns double(10,2) -\u0026gt; begin -\u0026gt; set @avgsalary := 0 ; -\u0026gt; select avg(salary) into @avgsalary from employees group by department_id having department_id in (select department_id from departments where department_name = departmentname ); -\u0026gt; return @avgsalary ; -\u0026gt; end $ Query OK, 0 rows affected, 1 warning (0.01 sec) mysql\u0026gt; select myf3(\u0026#39;Adm\u0026#39;); -\u0026gt; $ +-------------+ | myf3(\u0026#39;Adm\u0026#39;) | +-------------+ | 4400.00 | +-------------+ 1 row in set (0.00 sec) 查看函数 show create function myf3;\n删除函数\ndrop function myf3 ;\n存储过程和函数都在information_schema中的routines表中\nimage-20211010170437148\r练习一下\n#传入两个float的值 返回一个和 mysql\u0026gt; delimiter $ mysql\u0026gt; create function test_func1(a float , b float) returns float -\u0026gt; begin -\u0026gt; declare sum float default 0 ; -\u0026gt; set sum = a+b ; -\u0026gt; return sum ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select test_func1(1,2) $ +-----------------+ | test_func1(1,2) | +-----------------+ | 3 | +-----------------+ 1 row in set (0.00 sec) mysql\u0026gt; select test_func1(1.1,-1.1) $ +----------------------+ | test_func1(1.1,-1.1) | +----------------------+ | 0 | +----------------------+ 1 row in set (0.00 sec) 流程控制结构 顺序结构:程序从上往下依次执行\n分支结构:程序从两条或多条路径中选择一条去执行\n循环结构:程序在满足一定条件的基础上,重复执行一段代码\n分支结构 if函数 功能:实现简单的双分支\n语法:\nif(表达式1,表达式2,表达式3)\n如果表达式1成立,则if函数返回表达式2的值,否则返回表达式3的值\n应用:任何地方\ncase结构 情况1:类似于java中的switch语句,一般用于实现等值判断\ncase 表达式|字段|变量\nwhen 要判断的值 then \u0026hellip; 或语句1 ;\nwhen 要判断的值 then \u0026hellip; 或语句2 ;\nelse \u0026hellip; 或语句n ;\nend case ;\n情况2:类似于java中的多重if语句,一般用于实现区间判断\ncase\nwhen 要判断的条件1 then \u0026hellip; 或语句1 ;\nwhen 要判断的表达式2 then \u0026hellip; 或语句2 ;\nelse \u0026hellip; 或语句n ;\nend case ;\n特点:\n可以作为表达式,嵌套在其他语句中使用,可以放在任何地方,begin end 中或者begin end 的外面 可以作为独立的语句去使用,只能放在begin end 中 如果when中的值或条件成立,则执行对应的then后面的语句,并且结束case 如果都不满足,则执行else中的语句或值 else可以省略,如果else省略了,并且所有when条件都不满足,则返回null image-20211010203810756\rimage-20211010203829794\r案例\n#90-100 显示A 80-90 显示B 60-80显示C 其余显示D mysql\u0026gt; create procedure test_case(in score int) -\u0026gt; begin -\u0026gt; case when score \u0026gt;=90 and score \u0026lt;=100 -\u0026gt; then select \u0026#39;A\u0026#39; ; -\u0026gt; when score \u0026gt;=80 and score \u0026lt;90 -\u0026gt; then select \u0026#39;B\u0026#39; ; -\u0026gt; when score \u0026gt;=60 and score \u0026lt;80 -\u0026gt; then select \u0026#39;C\u0026#39; ; -\u0026gt; else select \u0026#39;D\u0026#39; ; -\u0026gt; end case ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; call test_case (95) $ +---+ | A | +---+ | A | +---+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) if结构 功能:实现多重分支\n语法:\nif 条件1 then 语句1 ;\nelse if 条件2 then 语句2 ;\n\u0026hellip;\nelse 语句n ;\nend if ;\n应用在begin end 中\n案例\n#90-100 返回A 80-90 返回B 60-80返回C 其余返回D #方式一 可以这样直接return mysql\u0026gt; create function test_if(score int) returns varchar(20) -\u0026gt; begin -\u0026gt; if score \u0026gt;=90 and score \u0026lt;=100 -\u0026gt; then return \u0026#39;A\u0026#39; ; -\u0026gt; elseif score \u0026gt;80 -\u0026gt; then return \u0026#39;B\u0026#39; ; -\u0026gt; elseif score \u0026gt;60 -\u0026gt; then return \u0026#39;C\u0026#39; ; -\u0026gt; else -\u0026gt; return \u0026#39;D\u0026#39; ; -\u0026gt; end if ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) #或者用原始的这样 这里注意 end if 一定要有封号!!!! mysql\u0026gt; create function test_id1(score int) returns varchar(20) -\u0026gt; begin -\u0026gt; set @grade :=\u0026#39;\u0026#39; ; -\u0026gt; if score \u0026gt;=90 and score \u0026lt;100 -\u0026gt; then set @grade = \u0026#39;A\u0026#39; ; -\u0026gt; elseif score \u0026gt;80 -\u0026gt; then set @grade = \u0026#39;B\u0026#39; ; -\u0026gt; elseif score \u0026gt;60 -\u0026gt; then set @grade = \u0026#39;C\u0026#39; ; -\u0026gt; else -\u0026gt; set @grade = \u0026#39;D\u0026#39; ; -\u0026gt; end if ; -\u0026gt; return @grade ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) 循环结构 分类:\nwhile loop repeat 循环控制:\niterate类似于continue ,结束本次循环,继续下一次\nleave 类似于 break , 跳出,结束当前所在的循环\nwhile [标签:] while 循环条件 do\n​\t循环体\nend while [标签]\nloop [标签:] loop\n​\t循环体\nend loop [标签]\n可以用来模拟简单的死循环\nrepeat [标签:] repeat\n​\t循环体\nuntil 结束循环的条件\nend repeat [标签]\n案例\n#批量插入 根据次数插入到admin中多条记录 mysql\u0026gt; create procedure pro_while1(in insertcount int ) -\u0026gt; begin -\u0026gt; declare i int default 0; -\u0026gt; while i\u0026lt;insertcount do -\u0026gt; insert into admin(id,username,password) values (null,concat(\u0026#39;rose\u0026#39;,i),666); -\u0026gt; set i = i+1 ; -\u0026gt; end while ; -\u0026gt; end $ Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; call pro_while1(3) $ Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from admin ; -\u0026gt; $ +----+----------+----------+ | id | username | password | +----+----------+----------+ | 1 | john | 8888 | | 2 | lyt | 6666 | | 9 | rose0 | 666 | | 10 | rose1 | 666 | | 11 | rose2 | 666 | +----+----------+----------+ 11 rows in set (0.00 sec) #添加leave语句 #批量插入 , 根据次数插入到admin表中多条记录 , 如果次数\u0026gt;20 就停止 注意安全 if语句没写好 一直在循环插入了300w条数据 mysql\u0026gt; create procedure test_whileleave(in insertcount int ) -\u0026gt; begin -\u0026gt; declare i int default 0 ; -\u0026gt; a:while i \u0026lt; insertcount do -\u0026gt; if i=20 then leave a ; -\u0026gt; end if ; -\u0026gt; insert into admin(username,password) values (concat(\u0026#39;xiaohua\u0026#39;,i),\u0026#39;0000\u0026#39;) ; -\u0026gt; set i = i + 1 ; -\u0026gt; end while a ; -\u0026gt; end # Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; call test_whileleave(30) # Query OK, 1 row affected (0.03 sec) #添加iterate ##批量插入 , 根据次数插入到admin表中多条记录 , 并且插入奇数 mysql\u0026gt; create procedure test_iterate(in insertcount int) -\u0026gt; begin -\u0026gt; declare i int default 1 ; -\u0026gt; a:while i \u0026lt;= insertcount do -\u0026gt; if mod(i,2) !=1 then set i = i+ 1 ; iterate a ; -\u0026gt; else -\u0026gt; insert into admin (username, password) values (concat(\u0026#39;jishu\u0026#39;,i),\u0026#39;1111\u0026#39;); -\u0026gt; set i = i + 1; -\u0026gt; end if ; -\u0026gt; end while a ; -\u0026gt; end # Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; call test_iterate(20) # Query OK, 1 row affected (0.02 sec) image-20211010222825964\r练习一下 #新建表 然后像该表插入指定个数的 , 随机字符串 mysql\u0026gt; create table if not exists stringcontent (id int primary key auto_increment , content varchar(20)); Query OK, 0 rows affected, 1 warning (0.01 sec) mysql\u0026gt; create procedure test_randstr_insert(in insertcount int) -\u0026gt; begin -\u0026gt; declare i int default 0 ; -\u0026gt; declare str varchar(26) default \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39;; -\u0026gt; declare startIndex int default 1 ; -\u0026gt; declare len int default 1 ; -\u0026gt; while i\u0026lt;insertcount do -\u0026gt; set startIndex = floor(rand()*26+1) ; -\u0026gt; set len = floor(rand()*(20-startindex+1)+1) ; -\u0026gt; insert into stringcontent(content) values (substr(str,startIndex,len)); -\u0026gt; set i = i + 1; -\u0026gt; end while ; -\u0026gt; end # Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; call test_randstr_insert(10)# Query OK, 1 row affected (0.02 sec) mysql\u0026gt; select * from stringcontent # +----+--------------+ | id | content | +----+--------------+ | 1 | klm | | 2 | hijklmn | | 3 | pqr | | 4 | no | | 5 | rs | | 6 | abcde | | 7 | bcdefghijklm | | 8 | | | 9 | f | | 10 | lmn | +----+--------------+ 10 rows in set (0.00 sec) 复习一下 分类:\n系统变量\n说明:变量由系统提供的,不用自定义\n语法:\n查看系统变量 show global|session variables ;如果没有显式声明,那默认是session 查看指定的系统变量的值 select @@global|session.变量名 ; 为系统变量赋值 set gloabl|session 变量名 = 值 ; set @@global.变量名 = 值 ; set @@变量名 = 值; 全局变量 服务器层面上的,必须拥有super权限才能为系统变量赋值,作用域为整个服务器,也就是针对于所有连接(会话)有效,服务器重启后失效(除非修改配置) 会话变量 服务器为每一个连接的客户端都提供了系统变量,作用域为当前的连接(会话) 自定义变量\n说明:\n用户变量\n作用域：针对于当前连接(会话)生效\n位置:begin end 里面, 也可以放在外面\n使用\n声明并赋值\nset @变量名 = 值; set @变量名:= 值; select @变量名:=值 ; 更新值\nset @变量名 = 值; set @变量名:= 值; select @变量名:=值 ; select xx into @变量名 from 表 ; 使用\nselect @变量名 ; 局部变量\n作用域:仅仅在定义它的begin end 中有效 位置:只能放在begin end 中， 而且只能放在第一句 create procedure pro1() begin declare i int default 1 ; \u0026hellip; end 声明 declare 变量名 类型 default 值; 赋值或更新 set 变量名=值; set 变量名:= 值; select @变量名 := 值; select xx into 变量名 from 表 ; 使用 select 变量名 ; 存储过程和函数\n说明:都类似于java中的方法,将一组完成特定功能的逻辑语句包装起来,对外暴露名字\n好处:\n提高重用性 sql语句简单 减少了和数据库服务器连接的次数,提高了效率 创建\ncreate procedure 存储过程名 (参数模式 参数名 参数类型)\nbegin\n存储过程体\nend\n注意:参数模式 in out inout 其中IN可以省略 存储过程体中的每一条sql语句都需要分号结尾 调用\nCALL 存储过程名(实参列表)\n调用in模式的参数 call sp1(\u0026lsquo;值\u0026rsquo;) ;\n调用out模式的参数 set @name :=\u0026quot;\u0026quot; ; call sp1(@name) ;\n调用inout模式的参数 set @name = 值 ; call sp1(@name) ; select @name ;\n查看存储过程\nshow create procedure 存储过程名 ;\n删除存储过程\ndrop procedure 存储过程名 ;\n函数\n创建\ncreate function 函数名 (参数名 参数类型) returns 返回值类型\nbegin\ndeclare a int default 0 ;\n\u0026hellip;\nreturn a ;\nend\n**注意:\t**函数体中肯定需要有return语句\n调用\nselect 函数名 (实参列表) ;\n查看 show create function 函数名 ;\n删除\ndrop functioon 函数名 ;\n流程控制结构\n顺序结构 :程序从上往下依次执行 ;\n分支结构:: 程序按条件进行选择执行, 从两条或多条路径中选择一条执行 ;\n循环结构: 程序满足一定条件下,重复执行一组语句\n分支结构\nif函数 功能:简单实现双分支 if(条件, 值1 , 值2 ) 位置:任何位置 case 结构 功能:实现多分支 case 表达式字段 when 值1 then \u0026hellip; when 值2 then \u0026hellip; else \u0026hellip; end [case]; 位置:可以放在任何位置, 如果放在begin end 外面,作为表达式结合着其他语句使用 , 如果放在begin end 里面, 一般作为独立的语句使用 if结构 功能:实现多分支 if 条件1 then \u0026hellip;; elseif 条件2 then \u0026hellip;; else then \u0026hellip; ; end if ; 位置: 只能放在begin end中 循环结构\n注意:只能放在begin end 中\n特点:都能实现循环结构\n对比:\n这三种循环都可以省略名称,但如果循环中添加了循环控制语句(leave或iterate)则必须添加名称 loop 一般用于实现简单的死循环 while先判断后执行 repeat 先执行后判断,无条件至少执行一次 while\n[标签:] while 循环条件 do\n循环体\nend while [标签] ;\nloop\n[标签:] loop\n循环体\nend loop [标签]\nrepeat\n[标签:] repeat\n循环体\nuntil 结束条件\nend repeat [名称]\n循环控制语句\nleave:类似于 break , 用于跳出所在的循环\niterate:类似于continue , 用于结束本次循环, 继续下一次\n完结撒花😋😜💕🤣\n","date":"2021-10-10T23:44:44+08:00","permalink":"https://linjianshu.github.io/p/mysql%E5%9F%BA%E7%A1%80/","title":"Mysql基础"},{"content":"致中山樵 ​\t我想告诉你\n​\t任何故土的消息\n​\t好也罢坏也罢\n​\t我想告诉你\n​\t碧云寺的彩塑依旧\n​\t钟山却已初秋\n​\t我想告诉你\n​\t故国的消息\n​\t风也好雨也好\n​\t祖国已思念她的游子多时\n​\t殊不知你已与这片大地相濡以沫\n​\t我想告诉你\n​\t才人的汹涌\n​\t如山间的松涛\n​\t一年胜过一年\n​\t我想告诉你\n​\t这盛世已定\n​\t你若在\n​\t太容易泪湿满襟\n​\t姓名:林健树\n​\t学院:机械工程学院\n​\t年级:20级033班\n​\t专业:工业工程与管理\n​\t学生类别:全日制\n😜💖💕😋\n","date":"2021-10-09T10:57:55+08:00","permalink":"https://linjianshu.github.io/p/%E8%AE%B0%E8%BE%9B%E4%BA%A5%E9%9D%A9%E5%91%BD110%E5%91%A8%E5%B9%B4%E5%A4%A7%E4%BC%9A%E6%9C%89%E6%84%9F/","title":"记辛亥革命110周年大会有感"},{"content":"Go web编程 Chapter_1 Go_And_Web_Application first_web_app package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func handler(writer http.ResponseWriter, request *http.Request) { fmt.Fprintf(writer, \u0026#34;Hello World, %s!\u0026#34;, request.URL.Path[1:]) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, handler) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } ","date":"2021-10-01T12:11:37+08:00","permalink":"https://linjianshu.github.io/p/go-web%E7%BC%96%E7%A8%8B-chapter1/","title":"Go Web编程 Chapter1"},{"content":"数据结构与算法 解决问题方法的效率，跟数据的组织方式有关。\n循环和递归\n解决问题方法的效率，跟空间的利用效率有关。\nimage-20210818161452286\rimage-20210818162018882\r解决问题方法的效率，跟算法的巧妙程度有关\n数据结构 数据对象在计算机中的组织方式\n逻辑结构：线性结构和树结构、图结构 物理存储结构：数组、链表 数据对象必定与一系列加在其上的操作相关联\n完成这些操作所用的方法就是算法\n抽象数据类型(Abstract Data Type) 数据类型 数据对象集 数据集合相关联的操作集 抽象：描述数据类型的方法不依赖于具体实现 与存放数据的机器无关 与数据存储的物理结构无关 与实现操作的算法和编程语言均无关 只描述数据对象集和相关操作集是什么，并不涉及如何做到的问题\n抽象 image-20210818163548512\r算法 一个有限指令集 接收一些输入（有些情况下不需要输入） 产生输出 一定在有限步骤之后终止 每一条指令必须 有充分明确的目标，不可以有歧义 计算机能处理的范围之内 描述应不依赖与任何一种计算机语言以及具体的实现手段 image-20210818164049310\r什么是好算法 空间复杂度sn 根据算法写成的程序在执行时占用存储单元的长度。这个长度往往与输入数据的规模有关。空间复杂度过高的算法可能导致使用的内存超限，造成程序非正常中断。\n时间复杂度Tn 根据算法写成的程序在执行时耗费时间的长度。这个长度往往也与输入数据的规模有关。时间复杂度过高的低效算法可能导致我们在有生之年都等不到运行结果。\n递归的时候会占用内存，因为递归下一层的时候要暂存上一层的结果\nSn = C*N\nimage-20210818164648695\r加减比乘除算的快\nimage-20210818164842726\r在分析一般算法的效率时，我们经常关注下面两种复杂度\n最坏情况复杂度T worst(n) 平均复杂度T avg(n) 基本上就是第一种：最坏情况复杂度\nimage-20210818165255964\rimage-20210818165445992\rimage-20210818165457903\rimage-20210818165643710\rimage-20210818165759487\rimage-20210818191956566\rimage-20210818193405280\rimage-20210818193945679\rimage-20210818194726647\r什么是线性表 多项式表示问题的启示 同一个问题可以有不同的表示（存储）方法 有一类共性问题：有序线性序列的组织和管理 线性表 由同类型数据元素构成有序序列的线性结构\n表中元素个数成为线性表的长度 线性表没有元素时，称为空表 表起始位置称表头，表结束位置称表尾 image-20210818195144256\r链式存储实现\nimage-20210818200032485\r广义表 广义表是线性表的推广 对于线性表而言，n个元素都是基本的单元素 广义表中，这些元素不仅可以是单元素也可以是另一个广义表 image-20210818201230986\r多重链表 多重链表：链表中的节点可能同时隶属于多个链\n多重链表中结点的指针域会有多个，如前面例子包含了netx和sublist两个指针域 但包含两个指针域的链表并不一定是多重链表，比如在双向链表不是多重链表 多重链表有广泛的用途：\n基本上如树、图这样相对复杂的数据结构都可以采用多重链表方式实现存储\n堆栈 image-20210818203628155\r堆栈stack ：具有一定操作约束的线性表\n只有一端（栈顶，top）做插入、删除 插入数据：push入栈 删除数据：pop出栈 后入先出：LIFO image-20210818203949646\rimage-20210818204030156\r中缀表达式转成后缀表达式\nimage-20210818210009984\r堆栈的其他应用：\n函数调用及递归实现 深度优先搜索 回溯算法 队列及实现\n队列：queue具有一定操作约束的线性表\n插入和删除操作：只能在一端插入，而在另一端删除 数据插入 入队列 AddQ 数据删除 出队列DeleteQ 先来先服务 先进先出 FIFO image-20210819200815843\rimage-20210819200925663\rimage-20210819201437552\rimage-20210819201758339\rimage-20210819202139270\rimage-20210819202326934\rimage-20210819203439780\rimage-20210819203707397\r什么是树 分层次组织在管理上具有更高的效率\n数据管理的基本操作之一：查找\n如何实现有效率的查找\nsearching\nimage-20210819205601090\rimage-20210819205951769\r二分查找\nimage-20210819210521234\rimage-20210819211054628\rimage-20210819212247115\rimage-20210819212402458\rimage-20210819212620945\rimage-20210819212737409\rimage-20210819213128752\rimage-20210819213227642\rimage-20210819213322280\rimage-20210819213454497\rimage-20210819214643681\rimage-20210819214812719\rimage-20210819215245013\rimage-20210819215345900\rimage-20210819215519052\rimage-20210819220012636\rDBEFAGHCI\nimage-20210819220312388\rDEFBHGICA\nimage-20210819220547376\r路线是一样的， 第一次碰到就输出的叫做先序、第二次的叫做中序、第三次的叫做后序\nimage-20210819220744178\rimage-20210822092825462\rimage-20210822093926951\r​\timage-20210822094347290\rimage-20210822094920689\rimage-20210822095028474\rimage-20210822095125615\rimage-20210822095254235\rimage-20210822095400071\rimage-20210822095400133\rimage-20210822095600852\rimage-20210822095753944\rimage-20210822095955430\rimage-20210822100108869\rimage-20210822100248441\r判断同构\nimage-20210822100435562\rimage-20210822100843208\rimage-20210822101301912\r判断有没有哪个节点没有被指向 哪个节点就是根\n例如231被指向了,那么意思就是0这个节点是根节点\nimage-20210822101644943\rimage-20210822101656356\rimage-20210822102023363\r使用check来判断根节点\nimage-20210822102155154\rimage-20210822102200845\rimage-20210822102407846\rimage-20210822102550689\rimage-20210822102618697\rimage-20210822102638201\rimage-20210822102736696\r尾递归可以用循环实现\nimage-20210822102824536\r查找的效率决定于树的高度\nimage-20210822102911459\rimage-20210822102930132\rimage-20210822103127572\rimage-20210822103450196\r​\timage-20210822103701343\rimage-20210822103721215\rimage-20210822103850804\rimage-20210822104154455\rimage-20210822104407357\rimage-20210822104658392\rimage-20210822105311867\rimage-20210822105726331\r所以走台阶问题我大概懂了\n只能一次走一阶台阶或者一次走两阶台阶\n一阶台阶有1种走法\n二阶台阶有2种走法\n那么三阶台阶无非就是1阶台阶的走法+走2阶的走法(2)\n或者2阶台阶的走法+走1阶的走法(1)\n那么四阶台阶无非就是2阶台阶的走法+走2阶的走法(2)\n或者3阶台阶的走法+走1阶的走法(1)\n所以也就是斐波那契数列的性质\nF(n)=F(n-1)+1+F(n-2)+2\nimage-20210822110716637\rimage-20210822111522588\rimage-20210822112334232\rimage-20210822112657646\r必须保证是查找树 也就是左边小右边大\nimage-20210822113538123\rimage-20210822113732802\rimage-20210822113938703\rimage-20210822114002650\rimage-20210822114101318\rimage-20210822114324854\rimage-20210822114521287\rimage-20210822114826316\rimage-20210822115039320\rimage-20210822151804901\rimage-20210822151947780\rimage-20210822152334294\rimage-20210822152933725\rimage-20210822153108950\rimage-20210822153304689\rimage-20210822153425949\rimage-20210822153713250\rimage-20210822153929001\r实现堆用完全二叉树\n根节点是最大的完全二叉树\nimage-20210822154053219\rimage-20210822154254474\rimage-20210822154337334\rimage-20210822154516519\rimage-20210822154705009\rimage-20210822154842548\ri/2就是完全二叉树的父节点\nimage-20210822155046618\rimage-20210822155243748\r因为是完全二叉树,所以要用最后一个元素替补删除掉的那个元素,才能满足完全二叉树的性质\nimage-20210822155357876\r时间复杂性就是树的高度 log2n\nimage-20210822160108019\rimage-20210822160408516\rimage-20210822160720461\r从倒数第二层开始建立堆,建完之后逐层往上建立,\nimage-20210822160834924\rimage-20210822160855127\rimage-20210822161110159\rimage-20210822161247647\rimage-20210822161303788\r如何根据节点不同的查找效率构造更有效的搜索树\nimage-20210822161422536\rimage-20210822161529534\rimage-20210822161639103\rimage-20210822161818080\rimage-20210822161934722\r由于度为1的节点就是只有一个儿子的节点\n没有度为1的节点\n那么就是n2+n1+n0=n0-1+0+n0=2n0-1\nimage-20210824222513996\rimage-20210824222657220\r第二种的意思是, 我用2的三次方也就是8种不同的符号来表示7个字符绰绰有余\nimage-20210824222809811\rimage-20210824222844586\r当所以的值都在叶节点上的时候就不可能出现一个字符的编码是另一个字符的前缀\nimage-20210824223228402\rimage-20210824223351755\rimage-20210824223520102\rimage-20210824223656627\r用数组实现\nimage-20210824223823443\rimage-20210824224033563\rimage-20210824224257684\rimage-20210824224312615\r这样做会导致一边倒,会让高度增加 find操作很难效率查\n可以尝试把集合小的挂到集合大的下面\nimage-20210824224547703\rimage-20210824225642477\rimage-20210824230108245\rimage-20210824230311976\r直接简化成把值为3对应为下标为3的数组中的,数组里存的值是他的父节点\nimage-20210824230758030\rimage-20210824231016070\rimage-20210824231230324\rimage-20210824231506693\rimage-20210824231623358\rimage-20210824232012169\rimage-20210824232158793\rimage-20210824232344637\rimage-20210824232443313\rimage-20210824232956745\rimage-20210824233747366\rimage-20210824233929998\rimage-20210827150052047\rimage-20210827150132906\rimage-20210827150336396\r无向图 对称 那么会不会空间浪费呢\nimage-20210827151040590\rimage-20210827161401937\rimage-20210827161523060\rimage-20210827161721941\rimage-20210827161814110\rimage-20210827162026003\r访问完所有的之后一定是原路返回\nimage-20210827162605593\r利用堆栈\nimage-20210827163115572\r明白为啥是深度优先了\nimage-20210827163414973\r会走的比较深\n一圈一圈的搜索\nimage-20210827163440795\rimage-20210827163728923\rimage-20210827163907704\rimage-20210827164150229\rimage-20210827164252208\rimage-20210827164800507\rimage-20210827165034266\rimage-20210827165238415\r六度空间\nimage-20210827165619918\rimage-20210827165905518\r","date":"2021-09-01T00:22:19+08:00","permalink":"https://linjianshu.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"数据结构与算法学习文档"},{"content":"Go语言学习 alt+enter\nctrl+space\nctrl+shift+space\nctrl+alt+L\nctrl+alt+M重构\nF2查看错误\nalt+6查看问题\nctrl+shift+/\nalt+F8 评估表达式\nctrl+F8 切换断点\n环境搭建，编译之后生成可执行exe文件，就可以直接使用了\nimage-20210725102106105\rimage-20210725102139391\r编译\n使用 go build\n1.在项目目录下执行go build\n2.在其他路径下执行go build ，需要在后面加上项目的路径（项目路径从gopath/src后开始写起，编译之后的可执行文件就保存在当前目录下）\n3.go build -o hello.exe\ngo run\n像执行脚本文件一样执行go代码\ngo install\n分为两步：\n1.先编译得到一个可执行文件\n2.将可执行文件拷贝到gopath的bin目录\n交叉编译，可以跨平台跑程序\n例如在windows平台编译一个能在linux平台上执行的可执行文件\n这个似乎要在源文件位置处使用cmd命令操作,并且要用大写!!!\nE:\\project\\GOproject\\code.oldboyedu.com\\day1\u0026gt;SET CGO_ENABLE=0 E:\\project\\GOproject\\code.oldboyedu.com\\day1\u0026gt;SET GOOS=linux E:\\project\\GOproject\\code.oldboyedu.com\\day1\u0026gt;SET GOARCH=amd64 E:\\project\\GOproject\\code.oldboyedu.com\\day1\u0026gt;go build image-20210725103733683\rgo语言的基本结构\npackage main //导入的包 import \u0026#34;fmt\u0026#34; //程序的入口函数 //函数外部只能放置标识符（变量、常量、函数、类型）的声明 func main() { fmt.Println(\u0026#34;hello world\u0026#34;) } 变量和常量\ngo语言中的变量必须先声明后使用\nvar s1 string :声明一个保存字符串数据的变量\nvar name string\nvar age int\nvar isOk bool\npackage main import \u0026#34;fmt\u0026#34; var name string var age int var isOk bool //批量声明 var ( name1 string age1 int isOk1 bool ) func main() { fmt.Println(name1) fmt.Println(age1) fmt.Println(isOk1) name1 = \u0026#34;linjianshu\u0026#34; age1 = 16 isOk1 = true //go语言中推荐使用驼峰命名 //go语言中非全局变量声明必须使用，不用就编译不过去 fmt.Println(name1) fmt.Println(age1) fmt.Println(isOk1) fmt.Printf(\u0026#34;name:%s\u0026#34;,name1) //%s占位符，使用name1这个变量去替换这个占位符 //声明变量同时赋值 var studentName string = \u0026#34;ljs\u0026#34; //类型推导 var studentName1 = \u0026#34;ljs\u0026#34; fmt.Println(studentName) fmt.Println(studentName1) //简短变量声明 := 只能在函数里面使用 studentName2 := \u0026#34;jwt\u0026#34; fmt.Println(studentName2) x,_ :=foo() fmt.Println(x) x1 := 0 x1,_ =foo() fmt.Println(x1) } func foo() (int, string) { return 10,\u0026#34;ljs\u0026#34; } 匿名变量 用_来接收，表示我不用这个变量，匿名变量不占用命名空间，不会分配内存，所以匿名变量不存在重复声明\n注意：1.函数外的每个语句都必须以关键字开始2.同一个作用域{}中不能重复声明同名的变量\n常量\niota\nioto是go语言的常量计数器，只能在常量表达式中使用\niota在const关键字出现的时候被重置为0. const中每新增一行常量声明将使iota计数一次iota可理解为const语句块中的行索引 使用iota能简化定义，在定义枚举时很有用\npackage main import \u0026#34;fmt\u0026#34; //常量 const pi = 3.1415926 //常量定义了之后不能修改 //在程序运行期间不会改变 //批量声明常量时，如果某一行没有赋值，默认就和上一行一致 const ( pi1 = pi pi2 pi3 ) const ( i1 = iota i2 i3 ) const ( n1 = iota n2 _ n3 ) //插队 const ( k1 = iota k2 = 100 k3 k4 =iota k5 ) const ( p1,p2 = iota+1,iota+2 p3,p4 = iota+1,iota+2 ) //定义数量级 const ( _ = iota KB = 1\u0026lt;\u0026lt;(10 * iota) MB = 1\u0026lt;\u0026lt;(10 * iota) GB = 1\u0026lt;\u0026lt;(10 * iota) TB = 1\u0026lt;\u0026lt;(10 * iota) ) func main() { // 不可以 pi = 12.3 fmt.Println(\u0026#34;pi2:\u0026#34;,pi2) fmt.Println(\u0026#34;i1:\u0026#34;,i1) fmt.Println(\u0026#34;i2:\u0026#34;,i2) fmt.Println(\u0026#34;i3:\u0026#34;,i3) fmt.Println(\u0026#34;n1:\u0026#34;,n1) fmt.Println(\u0026#34;n2:\u0026#34;,n2) fmt.Println(\u0026#34;n3:\u0026#34;,n3) fmt.Println(\u0026#34;k1:\u0026#34;,k1) fmt.Println(\u0026#34;k2:\u0026#34;,k2) fmt.Println(\u0026#34;k3:\u0026#34;,k3) fmt.Println(\u0026#34;k4:\u0026#34;,k4) fmt.Println(\u0026#34;k5:\u0026#34;,k5) fmt.Println(\u0026#34;p1:\u0026#34;,p1) fmt.Println(\u0026#34;p2:\u0026#34;,p2) fmt.Println(\u0026#34;p3:\u0026#34;,p3) fmt.Println(\u0026#34;p4:\u0026#34;,p4) fmt.Println(\u0026#34;kb:\u0026#34;,KB) fmt.Println(\u0026#34;mb:\u0026#34;,MB) fmt.Println(\u0026#34;gb:\u0026#34;,GB) fmt.Println(\u0026#34;tb:\u0026#34;,TB) } 关键字和标识符\ngo语言有25个关键字\nbreak default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var\n基本数据类型\n整型\n整型分为以下两大类：按长度分为：int8 , int16 , int32 ,int64 对应的无符号整型：uint8 , uint16 ,uint32\n其中，uint8就是我们熟知的byte型，int16对应C语言中的short型，int64对应C语言中的long型\n特殊整型\nuint根据电脑位数来搞\nint根据电脑位数来搞\nuintptr无符号整数，用于存放一个指针\npackage main import \u0026#34;fmt\u0026#34; func main() { i1 := 10 fmt.Printf(\u0026#34;%d\\n\u0026#34;,i1) fmt.Printf(\u0026#34;%o\\n\u0026#34;,i1) //把十进制转成8进制 fmt.Printf(\u0026#34;%b\\n\u0026#34;,i1) //把十进制转成2进制 fmt.Printf(\u0026#34;%x\\n\u0026#34;,i1) //把十进制转成16进制 //八进制 i2 := 077 fmt.Printf(\u0026#34;%d\\n\u0026#34;,i2) //十六进制 i3:= 0x123 fmt.Printf(\u0026#34;%d\\n\u0026#34;,i3) fmt.Printf(\u0026#34;%T\\n\u0026#34;,i1) //声明一个int8类型的 要明确指定类型，都则就是int类型 i4:= int8(9) fmt.Println(i4) } 浮点型\npackage main import \u0026#34;fmt\u0026#34; //float func main() { //maxFloat32 := math.MaxFloat32 最大值 f1:=1.23 //默认go语言中的小数都是float64类型 fmt.Printf(\u0026#34;%T\\n\u0026#34;,f1) //显式声明float32类型 f2:=float32(1.23) fmt.Printf(\u0026#34;%T\\n\u0026#34;,f2) f1 = float64(f2) //不能隐式转换 } 布尔值\ngo语言中以bool类型进行声明，只有true和false\n注意：\n布尔类型变量默认为false go语言中不允许将整型强制转换为布尔型 布尔型无法参与数值运算，也无法与其他类型进行转换 package main import \u0026#34;fmt\u0026#34; func main() { //布尔值 b:=true var b1 bool = false fmt.Printf(\u0026#34;%v\u0026#34;,b) fmt.Println() fmt.Printf(\u0026#34;%v\u0026#34;,b1) fmt.Println() fmt.Printf(\u0026#34;Type:%T,Value:%v\u0026#34;,b,b) } 复习\npackage main import \u0026#34;fmt\u0026#34; func main() { //fmt占位符 %s %d %x %o %b %T %v i :=2 fmt.Printf(\u0026#34;%T\\t\u0026#34;,i) fmt.Printf(\u0026#34;%v\\t\u0026#34;,i) fmt.Printf(\u0026#34;%b\\t\u0026#34;,i) fmt.Printf(\u0026#34;%d\\t\u0026#34;,i) fmt.Printf(\u0026#34;%o\\t\u0026#34;,i) fmt.Printf(\u0026#34;%x\\t\u0026#34;,i) s:=\u0026#34;linjianshu\u0026#34; fmt.Printf(\u0026#34;%s\\t\u0026#34;,s) fmt.Printf(\u0026#34;%v\\t\u0026#34;,s) fmt.Printf(\u0026#34;%#v\\t\u0026#34;,s) } 字符串 go语言中字符串是用双引号包裹的！\ngo语言中单引号包裹的是字符！！\n//字符串 s:=\u0026#34;hello ljs\u0026#34; //单独的字母、汉字、符号表示一个字符 c1 := \u0026#39;h\u0026#39; c2 := \u0026#39;1\u0026#39; c3 := \u0026#39;啥\u0026#39; //字节：1字节=8Bit（8个二进制位） //一个字符 \u0026#39;A\u0026#39; = 1个字节 //一个utf8编码的汉字‘啥’ = 一般占3个字节 字符串转义符\nGo语言的字符串常见转义符包含回车、换行、单双引号、制表符等\n\\r \\n \\t ' \\\u0026quot; \\\\\npackage main import \u0026#34;fmt\u0026#34; func main() { //fmt占位符 %s %d %x %o %b %T %v i :=2 fmt.Printf(\u0026#34;%T\\t\u0026#34;,i) fmt.Printf(\u0026#34;%v\\t\u0026#34;,i) fmt.Printf(\u0026#34;%b\\t\u0026#34;,i) fmt.Printf(\u0026#34;%d\\t\u0026#34;,i) fmt.Printf(\u0026#34;%o\\t\u0026#34;,i) fmt.Printf(\u0026#34;%x\\t\u0026#34;,i) s:=\u0026#34;linjianshu\u0026#34; fmt.Printf(\u0026#34;%s\\t\u0026#34;,s) fmt.Printf(\u0026#34;%v\\t\u0026#34;,s) fmt.Printf(\u0026#34;%#v\\t\u0026#34;,s) } 多行字符串\ngo语言中要定义一个多行字符串时，就必须使用反引号 字符``\ns:= ` a b c ` 字符串的常用操作\nlen(str) 求长度 +或者fmt.Strintf 拼接字符串 strings.Split 分割 strings.contains 判断是否包含 strings.HasPrefix, strings.HasSuffx 前缀、后缀判断 strings.Index(), strings.LastIndex 子串出现的位置 strings.Join(a[] string , sep string) join操作 package main import ( fmt \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { path := \u0026#34;\\\u0026#34;C:\\\\Users\\\\Sweetie\\\\Desktop\\\\车间级MES\\\u0026#34;\u0026#34; fmt.Printf(\u0026#34;%s\\t\u0026#34; , path) s := ` 世情薄 人情恶 雨送黄昏花易落 ` fmt.Printf(\u0026#34;%s\\r\u0026#34;,s) s3:=`C:\\Users\\Sweetie\\Desktop\\车间级MES` fmt.Printf(\u0026#34;%s\\n\u0026#34;,s3) //字符串相关操作 fmt.Printf(\u0026#34;%d\\n\u0026#34;,len(s3)) //字符串拼接 name := \u0026#34;ljs\u0026#34; world := \u0026#34;shuaibi\u0026#34; describtion := name+world fmt.Printf(\u0026#34;%v\\n\u0026#34;,describtion) describtion1 := fmt.Sprintf(\u0026#34;%s%s\u0026#34;,name,world) fmt.Printf(\u0026#34;%s\\n\u0026#34;,describtion1) //分割 s1 := strings.Split(s3,\u0026#34;\\\\\u0026#34;) fmt.Println(s1) for i := 0; i \u0026lt; len(s1); i++ { fmt.Println(s1[i]) } //包含 fmt.Println(strings.Contains(describtion, name)) fmt.Printf(\u0026#34; \u0026#39;%s\u0026#39; Contains \u0026#39;%s\u0026#39; ? result:%v\u0026#34;,describtion1,name,strings.Contains(describtion, name)) fmt.Println() //前缀、后缀 fmt.Println(strings.HasPrefix(describtion, \u0026#34;ljs\u0026#34;)) fmt.Println(strings.HasSuffix(describtion, \u0026#34;shuaibi\u0026#34;)) //索引 查找 s4:=\u0026#34;abcdeb\u0026#34; fmt.Println(strings.Index(s4,\u0026#34;b\u0026#34;)) fmt.Println(strings.LastIndex(s4,\u0026#34;b\u0026#34;)) //拼接 var sJoin = strings.Join(s1,\u0026#34;+\u0026#34;) fmt.Println(sJoin) } byte和rune类型\n组成每个字符串的元素叫做‘字符’，可以通过遍历或者单个获取字符串元素获得字符。字符用单引号‘ 包裹起来，如：\nvar a:=\u0026lsquo;中\u0026rsquo;\nvar b:=\u0026lsquo;x\u0026rsquo;\nGo语言的字符有以下两种：\n1.uint8类型，或者叫byte型，代表了ascii码的一个字符\n2.rune类型，代表一个utf-8字符\n当需要处理中文、日文或者其他符合字符时，则需要用到rune类型。rune类型实际是一个int32\nGo使用了特殊的rune类型来处理unicode，让基于unicode的文本处理更方便，也可以使用byte型进行默认字符串处理，性能和扩展性都有照顾\n因为utf8编码下一个中文汉字由3-4个字节组成，所有我们不能简单的按照字节去遍历一个包含中文的字符串，否则就会出现上面输出中的第一行结果\n字符串底层是一个byte数据，所以可以和[]byte 类型相互转换，字符串是不能修改的 字符是由byte字节组成，所以字符串的长度是byte字节的长度 rune类型用来表示utf8字符，一个rune字符由一个或多个byte组成\n修改字符串\n要修改字符串，需要先将其转换成[]rune或 []byte ，完成后再转换为string ，都会重新分配内存，并复制字节数组\n注:rune是一个别名 实际上是类型int32 所以 \u0026lsquo;中\u0026rsquo;的类型是int32\nbyte是一个别名 实际上是类型uint8 所以\u0026rsquo;c\u0026rsquo;的类型是uint8\n类型转换\nGo语言中只有强制类型转换，没有隐式类型转换。该语法只能在两个类型之间支持相互转换的时候使用。\n强制类型转换的基本语法如下：\nT(表达式)\n其中，T表示要转换的类型。表达式包括变量、复杂算子和函数返回值等\n比如计算直角三角形的斜边长使用math包的sqrt()函数，该函数接收的是float64类型的参数，而变量a和b都是int类型，这个时候就将a和b强制类型转换为float64类型\n总结：\ngo语言的基本类型： int8 int16 int32 int64 uint8 uint16 uint32 uint64 float32 float64 bool string\nif语句\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { //if 条件判断 age:=19 if age\u0026gt;18 { fmt.Println(\u0026#34;性感荷官在线发牌\u0026#34;) }else { fmt.Println(\u0026#34;好好学习，以后赌博\u0026#34;) } if age \u0026gt;= 35 \u0026amp;\u0026amp; age \u0026lt; 80 { fmt.Println(\u0026#34;人到中年，不得不服\u0026#34;) }else if age \u0026gt; 18 { fmt.Println(\u0026#34;年轻力壮，不怕困难\u0026#34;) }else { fmt.Println(\u0026#34;好好学习，少吃点苦\u0026#34;) } if name := \u0026#34;linjianshu\u0026#34;; strings.Contains(name, \u0026#34;lin\u0026#34;) { fmt.Println(\u0026#34;确实确实\u0026#34;) }else { fmt.Println(\u0026#34;不敢不敢\u0026#34;) }\t} for range(键值循环)\ngo语言中可以使用for range 遍历数据、切片、字符串、map及通道channel 通过for range 遍历返回值有以下规律：\n数组、切片、字符串返回索引和值 map返回键和值 通道channel 只返回通道内的值 内容回顾 go安装\ngopath\ngo env\nimage-20210726100638960\rgopath/bin 添加到环境变量：go install 命名会把生成的二进制可执行文件拷贝到gopath/bin\ngo 命令 go build 编译go程序\ngo build -o \u0026ldquo;xxx.exe\u0026rdquo; 指定名称\ngo run main.go 像执行脚本一样执行mai.go\ngo install 先编译后拷贝\ngo语言文件基础语法 存放go源代码的文件后缀名 .go\n文件第一行：package main 声明包名\n如果要编译可执行文件，必须要有main包和main函数（入口函数）\n单行注释和多行注释\ngo语言函数外的语句必须以关键字开头\n函数内部定义的变量必须使用\n变量 3种声明方式：\nvar name string name:=\u0026ldquo;ljs\u0026rdquo; var name = \u0026ldquo;ljs\u0026rdquo; 函数内部专属 匿名变量（哑元变量）\n当有些数据必须用变量接收但是又不使用它时，就可以用_ 来接收这个值\n常量 const PI = 3.1415926\nconst UserNotExistErr = 1000\niota 实现枚举 实际上就是行索引\n三个要点：\nconst关键字出现时重置为0 每新增一行常量声明，iota累加1 流程控制 if\nif 条件 { } else if 条件{ } else { } for循环\n标准for循环 变种没有i初始 变种没有i限定 变种没有i增量 for i := 0; i \u0026lt; 10; i++ { fmt.Println(i) } i:=5 for ; i \u0026lt;10 ; i++ { fmt.Println(i) } fmt.Println(i) var i1 = 3 for i1\u0026lt;10 { fmt.Println(i1) i1++ } for\t{ fmt.Println(\u0026#34;hello world\u0026#34;) break } for i, v := range \u0026#34;hello world\u0026#34; { fmt.Printf(\u0026#34;index:%d\\t,value:%c\\n\u0026#34;,i,v) } s:=\u0026#34;hello world\u0026#34; for i, _ := range s { fmt.Printf(\u0026#34;index:%d\\t,value:%c\\n\u0026#34;,i,s[i]) } //哑元变量，不想用到的都直接给_ for _, v := range s { fmt.Printf(\u0026#34;%c\\n\u0026#34;,v) } for i := 1; i \u0026lt;10 ; i++ { for j := 1; j \u0026lt;=10-i ; j++ { fmt.Printf(\u0026#34;%d x %d = %d\\t\u0026#34; , i , j , i*j) } fmt.Println() } for i := 1; i \u0026lt; 10; i++ { for j := i; j \u0026gt;0; j-- { fmt.Printf(\u0026#34;%d x %d = %d\\t\u0026#34; , i,j,i*j) } fmt.Println() } 基本数据类型 整型\n​\t无符号整型：uint8 uint16 uint32 uint64\n​\t有符号整型：int8 int16 int32 int64\n​\tuint int 具体是32位还是64位看操作系统\n​\tuintptr 表示指针\n其他进制数\ngo语言中没办法直接定义二进制数\n八进制数 %o\n二进制数 %b\n十六进制数 %x\n浮点型 float32 float64 默认64位，转成32需要强制转换\n布尔型 true\u0026amp;false 不能和其他的类型做转换\n字符串型\n常用方法\n字符串不能修改\n复数\ncomplex128和complex64\nbyte和rune类型\n是类型别名\n字符串、字符、字节都是什么 字符串：双引号包裹的是字符串\n字符：单引号包裹的是字符，单个字母、日文、韩文、中文、单个符号\n字节： 1byte = 8bit\ngo语言中字符串都是UTF8编码，UTF8编码中一个常用汉字一般占用3个字节\nswitch 表达式 switch还可以使用表达式，这时候switch语句后买呢不需要再跟判断变量。例如\nfallthrough 语法可以执行满足条件的case的下一个case，是为了兼容c语言中的case设计的\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { score:=68 switch score { case 68: fmt.Println(\u0026#34;及格\u0026#34;) default: fmt.Println(\u0026#34;未知\u0026#34;) } //简化代码 作用域问题 switch i:=3 ;i{ case 1: fmt.Println(\u0026#34;wumingzhi\u0026#34;) case 2: fmt.Println(\u0026#34;zhongzhi\u0026#34;) case 3: fmt.Println(\u0026#34;damuzhi\u0026#34;) } //同时声明几种情况 switch i:=10;i{ case 1, 3, 5, 7, 9: fmt.Println(\u0026#34;this is 奇数\u0026#34;) case 2, 4, 6, 8, 10: fmt.Println(\u0026#34;this is 偶数\u0026#34;) } score1:=68 switch { case score1\u0026gt;60\u0026amp;\u0026amp;score1\u0026lt;=100: fmt.Println(\u0026#34;及格\u0026#34;) case score1\u0026lt;60: fmt.Println(\u0026#34;挂了呀\u0026#34;) } } goto表达式 break只能退出当前for语句的循环\npackage main import \u0026#34;fmt\u0026#34; func main() { flag:=false for i := 0; i \u0026lt; 10; i++ { for j := 0; j \u0026lt; 10; j++ { if j==2 { flag = true break } fmt.Printf(\u0026#34;%d-%d\\n\u0026#34;,i,j) } if flag { break } } //for i := 0; i \u0026lt; 10; i++ { //\tfor j := 0; j \u0026lt; 10; j++ { //\tif j == 2 { //\tgoto breakTag //\t} //\tfmt.Printf(\u0026#34;%v-%v\\n\u0026#34;,i,j) //\t} //} //return //breakTag: //\tfmt.Println(\u0026#34;结束for循环\u0026#34;) } 运算符 go语言内置的运算符有：\n算术运算符+ - * / % 关系运算符 逻辑运算符 位运算符 赋值运算符 关系运算符 ==、！= 、\u0026gt; 、 \u0026gt;= 、\u0026lt; 、 \u0026lt;=\n逻辑运算符 \u0026amp;\u0026amp; || !\n位运算 位运算符对整数在内存中的二进制位进行操作。\n\u0026amp; 参与运算的两数各对应的二进制位相与\n| 参与运算的两位各对应的二进制位相或\n^ 参与运算的两数各对应的二进制位相异或，当两对应的二进制位相异时，结果为1\n\u0026laquo; 左移n位就是乘以2的n次方 高位丢弃，低位补0\n》》右移n位就是除以2的n次方 a\u0026raquo;b就是a右移b位\npackage main import \u0026#34;fmt\u0026#34; func main() { //运算符 var( a=5 b=2 ) //算术运算符 fmt.Println(a+b) fmt.Println(a-b) fmt.Println(a*b) fmt.Println(a/b) fmt.Println(a%b) a++ //单独的语句，不能放在=的右边赋值 b++ //关系运算符 fmt.Println(a==b) //go语言是强类型，相同类型的变量才能比较 fmt.Println(a!=b) fmt.Println(a\u0026gt;b) fmt.Println(a\u0026lt;b) age:=22 if age \u0026gt; 18 \u0026amp;\u0026amp; age \u0026lt; 60 { fmt.Println(\u0026#34;上班族\u0026#34;) }else { fmt.Println(\u0026#34;不用上班\u0026#34;) } if age \u0026gt; 60 || age \u0026lt; 18 { fmt.Println(\u0026#34;不用上班\u0026#34;) }else { fmt.Println(\u0026#34;上班族\u0026#34;) } //not取反 b2:=true fmt.Println(!b2) //位运算：针对的是二进制数 //5的二进制表示 101 //2的二进制表示 010 //按位与 fmt.Println(101\u0026amp;010) fmt.Println(5\u0026amp;2) //按位或 fmt.Println(101|10) fmt.Println(5|2) //^按位异或 fmt.Println(101^010) //这个有点奇怪 这个是109答案？？？ fmt.Println(5^2) //左移右移运算 *2 和 \\2 fmt.Println(5\u0026lt;\u0026lt;2) //101=\u0026gt;10100 fmt.Println(1\u0026lt;\u0026lt;10) fmt.Println(5\u0026gt;\u0026gt;1) //101=\u0026gt;10 //注意别溢出了 m:=int8(1) fmt.Println(m\u0026lt;\u0026lt;10) fmt.Println(1\u0026lt;\u0026lt;2+1) //192.168.1.1 //权限 文件操作会将位运算实际的应用 //0644 //赋值运算符，用来给变量赋值的 var x int x = 10 fmt.Println(x) x+=1 fmt.Println(x) x-=1 fmt.Println(x) x*=2 fmt.Println(x) x/=2 fmt.Println(x) x\u0026lt;\u0026lt;=2 fmt.Println(x) x\u0026gt;\u0026gt;=2 fmt.Println(x) fmt.Printf(\u0026#34;%b\u0026#34;,x) fmt.Println() x\u0026amp;=2 fmt.Println(x) fmt.Printf(\u0026#34;%b\u0026#34;,x) x|=2 x\u0026lt;\u0026lt;=2 x\u0026gt;\u0026gt;=2 x^=2 } 数组 array数组\n数组是同一种数据类型元素的集合。在go语言中，数组从声明时就确定，使用时可以修改数组成员，但是数组大小不可变化。基本语法：\npackage main import \u0026#34;fmt\u0026#34; func main() { //数组 //存放元素的容器 //必须指定存放的元素的类型和容量（长度） //数组的长度是数组类型的一部分 也就是尽管类型一致但是长度不一致也不是同一个数组类型 var a1 [3]bool var a2 [4]bool fmt.Printf(\u0026#34;a1:type%T, a2:type%T\u0026#34;,a1,a2) fmt.Println() //数组的初始化 //如果不初始化：默认元素都是零值(布尔值就是false，整型和浮点型都是0，字符串就是“”) fmt.Println(a1,a2) //1.初始化方式1 b1 :=[3]bool{true,true,true} fmt.Println(b1) //2.初始化方式2 根据初始值自动推断数组的长度是多少 b2 :=[...]int{1,3,4,2,6,2,73,12} fmt.Println(b2) fmt.Println(len(b2)) //3.初始化方式3 根据索引初始化 b3:=[5]int{1,2} fmt.Println(b3) b3=[5]int{0:1,4:2} fmt.Println(b3) //数组的遍历 citys :=[...]string{\u0026#34;北京\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;深圳\u0026#34;} //1.for range for _, v := range citys { fmt.Println(v) } for i, _ := range citys { fmt.Println(citys[i]) } //2.根据索引遍历 for i := 0; i \u0026lt; len(citys); i++ { fmt.Println(citys[i]) } //多维数组 c1:=[3][2]int{0:[2]int{2,3},1:[2]int{4,5}} fmt.Println(c1) c2:=[3][2]int {{1,2},{3,4}} fmt.Println(c2) //多维数组的遍历 //var b11:=[2][3]string{{\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;},{\u0026#34;d\u0026#34;,\u0026#34;e\u0026#34;,\u0026#34;f\u0026#34;}} //可以这么记 go语言中 实际数组展示使用空格来区分的，但是声明的时候需要用逗号隔开 for _, v := range c1 { fmt.Println(v) for _, v1 := range v { fmt.Printf(\u0026#34;%d \u0026#34;,v1) } fmt.Println() } for i := 0; i \u0026lt; len(c2); i++ { fmt.Println(c2[i]) for j := 0; j \u0026lt; len(c2[j]); j++ { fmt.Printf(\u0026#34;%d \u0026#34;,c2[i][j]) } fmt.Println() } //数组是值类型 d1:=[...]int{1,2,3} d2:=d1 d2[0]=100 fmt.Println(d1) fmt.Println(d2) //练习 e:=[...]int{1,3,5,7,8} sum:=0 for _, v := range e { sum+=v } fmt.Println(sum) for i, _ := range e { for j := i+1; j \u0026lt; len(e); j++ { if e[i]+e[j] == 8 { fmt.Printf(\u0026#34;(%d %d)\u0026#34;,i,j) break } } fmt.Println() } } 数组定义 var 数组变量名 [元素数量]T\n[5]int 和 [10]int 是不同的类型\n切片 切片slice是一个拥有相同类型元素的可变长度的序列。他是基于数组类型做的一层封装。他非常灵活，支持自动扩容。切片是一个引用类型，他的内部结构包含地址 、 长度 和 容量 。切片一般用于快速地操作一块数据集合。\n切片的定义\n声明切片类型的基本语法如下：\nvar name []T 其中，name是变量名字， T是元素类型\n切片的容量和长度 切片拥有自己的长度和容量，我们可以通过使用内置的len函数求长度，使用内置的cap函数求切片的容量\n基于数组定义切片 由于切片的底层就是一个数组，所以我们可以基于数组定义切片\n还支持如下方式\npackage main import \u0026#34;fmt\u0026#34; func main() { //切片的定义 var s1 []int //定义一个存放int类型元素的切片 var s2 []string fmt.Println(s1,s2) fmt.Println(s1==nil) fmt.Println(s2==nil) //初始化 s1 = []int{1,2,3} s2 = []string{\u0026#34;沙河\u0026#34;,\u0026#34;张江\u0026#34;,\u0026#34;平山村\u0026#34;} fmt.Println(s1,s2) fmt.Println(s1==nil) fmt.Println(s2==nil) //长度和容量 fmt.Printf(\u0026#34;len:%d,cap:%d\\n\u0026#34;, len(s1), cap(s1)) fmt.Printf(\u0026#34;len:%d,cap:%d\\n\u0026#34;, len(s2), cap(s2)) //2.由数组定义切片 a :=[]int{1,3,5,7,9,11,13} fmt.Println(cap(a)) b :=a[1:4] //[3 5 7] 左闭右开 基于一个数组进行切割 fmt.Println(b) b1 :=a[:4] //0-4 fmt.Println(b1) b2 :=a[2:] // fmt.Println(b2) b3 :=a[:] fmt.Println(b3) //切片的长度就是元素的个数，切片的容量就是底层数组从切片第一个元素到最后一个元素的数量 fmt.Println(len(b),cap(b)) //3.切片再切片 b4:=b[1:2] //[5 7] 但是b的容量已经是6了 这时候切的b从第一位切起 那么容量应该是5 fmt.Println(b4, len(b4), cap(b4)) fmt.Println(b) a[2] = 10 //这里说明了切片是引用类型，都指向了底层的数组，修改了底层数组，那么上层的切片值肯定会变化 fmt.Println(b) fmt.Println(b4) } 切片指向了一个底层的数组\n切片的长度就是它元素的个数\n切片的容量是底层数组从切片的第一个元素到最后一个元素的数量\nimage-20210729000908993\rimage-20210729000949711\r使用make函数构造切片 我们上面都是基于数组来创建的切片，如果需要动态的创建一个切片，我们就需要使用内置的make函数\nmake([]T , size ,cap) 其中：T：切片的元素类型 size：切片中元素的数量 cap：切片的容量\n上面的代码中a的内部存储空间已经分配cap个，但是实际上只是使用了len个，容量并不会影响当前元素的个数，所以len返回使用了几个，cap返回切片的容量\n切片的本质 切片就是一个框，框住了一块连续的内存。属于引用类型，真正的数据都是保存在底层数组里的。\n切片不能直接比较 切片之间是不能比较的，我们不能使用==操作符来判断两个切片是否含有全部相等元素。切片唯一合法的比较操作是和nil比较。一个nil值的切片并没有底层数组，一个nil值的切片的长度和容量都是0.但是我们不能说一个长度和容量都是0的切片一定是nil\npackage main import \u0026#34;fmt\u0026#34; func main() { //make函数创造切片 s1:=make([]int,3,10) fmt.Printf(\u0026#34;s1=%v,len(s1)=%d,cap(s1)=%d,s1==nil?:%v\\n\u0026#34;,s1,len(s1),cap(s1),s1==nil) var s2 []int fmt.Printf(\u0026#34;s2=%v,len(s2)=%d,cap(s2)=%d,s2==nil?:%v\\n\u0026#34;,s2,len(s2),cap(s2),s2==nil) s3:=[]int{} fmt.Printf(\u0026#34;s3=%v,len(s3)=%d,cap(s3)=%d,s3==nil?:%v\\n\u0026#34;,s3,len(s3),cap(s3),s3==nil) s4:=make([]int,0) fmt.Printf(\u0026#34;s4=%v,len(s4)=%d,cap(s4)=%d,s4==nil?:%v\\n\u0026#34;,s4,len(s4),cap(s4),s4==nil) //切片的赋值 s5:=[]int {1,3,5,7} s6:=s5 //s5 和 s6都指向了同一个底层数组 fmt.Println(s5,s6) s5[0]=100 fmt.Println(s5,s6) //切片的遍历 //1.索引遍历 for i := 0; i \u0026lt; len(s5); i++ { fmt.Printf(\u0026#34;%d \u0026#34;,s5[i]) } fmt.Println() //2.forrange遍历 for _, v := range s5 { fmt.Printf(\u0026#34;%d \u0026#34;,v) } } 所以要判断一个切片是否是空的，要使用len(s)==0来判断\nappend方法为切片添加元素 go语言的内置函数append可以为切片动态添加元素，每个切片会指向一个底层数组，这个数组能容纳一定数量的元素。当底层数组不能容纳新增的元素时，切片就会自动按照一定的策略进行扩容，此时该切片指向的底层数组就会更换。扩容操作往往发生在append函数调用时。\n切片的扩容策略就不说了\npackage main import \u0026#34;fmt\u0026#34; func main() { //append 为切片追加元素 s1:=[]string{\u0026#34;北京\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;深圳\u0026#34;} fmt.Printf(\u0026#34;s1=%v len(s1)=%d cap(s1)=%d\\n\u0026#34;,s1,len(s1),cap(s1)) //s1[3] = \u0026#34;广州\u0026#34; //错误的写法 会导致编译错误：索引越界 //调用append函数必须使用原来的切片变量接收返回值 s1= append(s1, \u0026#34;广州\u0026#34;) //append追加元素 原来的底层数组放不下的时候 go底层就会把底层数组换一个 //必须用变量接收append的返回值 fmt.Printf(\u0026#34;s1=%v len(s1)=%d cap(s1)=%d\\n\u0026#34;,s1,len(s1),cap(s1)) s1 = append(s1,\u0026#34;杭州\u0026#34;,\u0026#34;成都\u0026#34;) fmt.Printf(\u0026#34;s1=%v len(s1)=%d cap(s1)=%d\\n\u0026#34;,s1, len(s1), cap(s1)) s2:=[]string{\u0026#34;武汉\u0026#34;,\u0026#34;西安\u0026#34;,\u0026#34;苏州\u0026#34;} s1 = append(s1,s2...) //...表示拆开 fmt.Printf(\u0026#34;s1=%v len(s1)=%d cap(s1)=%d\\n\u0026#34;,s1, len(s1), cap(s1)) } 使用copy复制切片 由于切片是引用类型，a和b其实是指向了同一块内存地址，所以如果单纯的赋值的话，修改了b的值的同时a的值也会发生变化\ngo语言内建的copy函数可以迅速地将一个切片的数据复制到另一个切片空间\ncopy (destSlice , srcSlice[] T) 从切片中删除元素 go语言中并没有删除切片元素的专用方法，我们可以使用切片 本身的特性来删除元素。\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { a1:=[]int {1,3,5} a2:=a1 var a3=[]int{} //这样声明没办法复制进去 var a4 []int\t//这样声明也没办法复制进去 var a5=make([]int,len(a1), cap(a1)) copy(a3,a1) copy(a4,a1) copy(a5,a1) fmt.Println(a1,a2,a3,a4,a5) a1[0] = 100 fmt.Println(a1,a2,a3,a4,a5) //删除第二个元素 a5 = append(a5[:1],a5[2:]...) fmt.Println(a5) fmt.Println(cap(a5)) //验证 //1.切片不保存具体的值 //2.切片对应一个底层数组 //3.底层数组都是占用一块连续的内存 x1:=[...]int{1,3,5} //数组 x2:=x1[:] //切片 切片指向底层数组 fmt.Println(x2,len(x2),cap(x2)) fmt.Printf(\u0026#34;%p\\n\u0026#34;,\u0026amp;x1[0]) x2 = append(x1[:1],x1[2:]...) //切片截取底层数组 重新定义了底层数组的索引的值 fmt.Printf(\u0026#34;%p\\n\u0026#34;,\u0026amp;x2[0]) //说明指向的底层数组地址没变 变了的是地址里的值 fmt.Println(x2) //切片的索引的值 fmt.Println(x1) //被修改后的底层数组的索引和值 } 练习\npackage main import \u0026#34;fmt\u0026#34; func main() { a1:=[...]int{1,3,5,7,9,11,13,15,17} a2:=a1[:] a2=append(a1[:1],a1[2:]...) fmt.Println(a2) fmt.Println(a1) } 指针 go语言中不存在指针操作，只需要记住两个符号\n\u0026amp; 取地址 * 根据地址取值 go语言中的指针不能进行偏移和运算，是安全指针。\n要搞明白go语言中的指针需要先知道3个概念，指针地址，指针类型和指针取值\ngo语言中的函数传参都是值拷贝，当我们想要修改某个变量的时候，我们可以创建一个指向该变量地址的指针变量。传递数据使用指针，而无需拷贝数据。类型指针不能进行偏移和运算。go语言中的指针操作非常简单，只需要记住两个符号：\u0026amp; 取地址 *根据地址取值\n指针地址和指针类型 每个变量在运行时都拥有一个地址，这个地址代表变量在内存中的位置。go语言中使用\u0026amp;字符放在变量前面对变量进行取地址操作。go语言中的值类型int / float / bool / string / array / struct 都有对应的指针类型 *int / *int64 / *string\n总结：取地址操作符\u0026amp; 和取值操作符*是一对互补操作，\u0026amp;取出地址， *根据地址取出地址指向的值，变量、指针地址、指针变量、取地址、取值的相互关系如下\n对变量进行取地址\u0026amp;操作，可以获得这个变量的指针变量 指针变量的值是指针地址 对指针变量进行取值*操作，可以获得指针变量指向的原变量的值 package main import \u0026#34;fmt\u0026#34; func main() { //1.\u0026amp;取地址 //2.*根据地址取值 n:=18 fmt.Println(\u0026amp;n) p:=\u0026amp;n fmt.Printf(\u0026#34;%T\\n\u0026#34;,p) //*int表示int类型的指针 m:=*p fmt.Printf(\u0026#34;%v\\n\u0026#34;,m) fmt.Printf(\u0026#34;%T\\n\u0026#34;,m) var a *int fmt.Println(a) //nil 赋值会报错 空指针异常 var a1 = new(int) //使用new关键字会分配内存块 不会造成空指针 fmt.Println(a1) fmt.Println(*a1) *a1 = 100 fmt.Println(*a1) } make make也是用于内存分配的，区别于new，它只用于slice、map以及chan的内存创建，而且它返回的类型就是这三个类型本身，而不是她们的指针类型，因为这三种类型就是引用类型，没有必要返回她们的指针了。make函数的函数签名\nfunc make (t Type,size ... IntergerType) Type make函数是无可替代的，我们在使用slice、map以及channel的时候，都需要使用make进行初始化，然后才可以对她们进行操作。这个我们在上一章中都有说明，关于channel我们会在后续的章节中详细说明\nmake和new的区别 make和new都是用来申请内存的 new很少用，一般用来给基本数据类型申请内存，string / int 返回的是对应类型的指针，例如*string . *int。 make是用来给slice 、 map 、 chan申请内存的，make函数返回的是对应的这三个类型本身 map go语言中提供的映射关系容器为map，其内部使用散列表hash实现\nmap是一种无序的基于key-value的数据结构，go语言中的map是引用类型，必须初始化才能使用\nmap[KeyType]valueType map类型的变量默认初始值为nil，需要使用make函数来分配内存\nmake(map[keyType] valueType,[cap]) 判断某个键是否存在 特殊写法\nvalue,ok:=map[key] 遍历map 使用for range即可\n使用delete函数删除键值对 类型为map的切片\n值的类型为切片的map\npackage main import \u0026#34;fmt\u0026#34; func main() { //map和slice的组合 a:=[]map[string]int{} //元素类型为map的切片 var a1 = make([]map[string]int,10,10) //没有对内部的map做初始化 a1[0] = make(map[string]int,10) a1[0][\u0026#34;ljs\u0026#34;] = 9 a1[0][\u0026#34;jwt\u0026#34;] = 8 fmt.Println(a) fmt.Println(a1) //值为切片类型的map var a2 = make(map[string][]string,10) a2[\u0026#34;ljs\u0026#34;] = make([]string,10,10) a2[\u0026#34;ljs\u0026#34;] = []string{\u0026#34;giegie\u0026#34;} fmt.Println(a2) a2[\u0026#34;ljs\u0026#34;] = append(a2[\u0026#34;ljs\u0026#34;],[]string{\u0026#34;jiejie\u0026#34;,\u0026#34;didi\u0026#34;}...) fmt.Println(a2) } 内容回顾 运算符 算术运算符\n逻辑运算符\n赋值运算符+= -= *= /= \u0026amp;= |= ^=\n位运算符 \u0026raquo; \u0026laquo; | \u0026amp; ^\n比较运算符\n数组array [\u0026hellip;]int{3,5} 数组包含元素的类型和元素的个数 数组的长度属于数组类型的一部分\n数组是值类型\n多维数组\npackage main import \u0026#34;fmt\u0026#34; func main() { var name string name = \u0026#34;ljs\u0026#34; fmt.Println(name) var ages [30]int ages[0] = 1 ages = [30]int{2,3,5} fmt.Println(ages) ages1:=[...]int{2,3,6,8,9} fmt.Println(ages1) ages2:=[...]int{1:1,99:99} fmt.Println(ages2) //二维数组 a:=[3][2]string{} a[0][1] = \u0026#34;ljs\u0026#34; a[0][0] = \u0026#34;jwt\u0026#34; fmt.Println(a) //多维数组是值类型 a1:=[3][2]string{{\u0026#34;ljs\u0026#34;,\u0026#34;jwt\u0026#34;},{\u0026#34;fyz\u0026#34;,\u0026#34;lje\u0026#34;}} fmt.Println(a1) var a2 =[3][2]int{[2]int{1,2},[2]int{3,4}} fmt.Println(a2) //数组是值类型 a3:=[3]int{1,2,3} fmt.Println(a3) f1(a3) fmt.Println(a3) a4:=[]int{1,2,3} fmt.Println(a4) f2(a4) fmt.Println(a4) } func f1(a [3]int) { //go语言中函数传递的都是值 ctrl+c ctrl+v a[1] = 100 } func f2(a []int) { a[1] =100 } 切片 切片不存值，像一个框，在底层的数组里取值\n切片的定义：指针、长度、容量\nvar name []T\n切片的扩容策略\n如果申请的容量大于原来的2倍，那就直接扩容至新申请的容量 如果小于1024，那么就直接两倍 如果大于1024，就按照1.25倍去扩容 具体存储的值类型不同，扩容策略也有一定的不同 a4:=[]int{1,2,3} fmt.Println(a4) f2(a4) fmt.Println(a4) //切片 a5:=[]int{} fmt.Println(a5) fmt.Println(a5==nil) //没有分配内存 零切片声明 nil var a6 []int fmt.Println(a6) fmt.Println(a6==nil) //make初始化 分配内存 a7 := make([]int, 5, 5) fmt.Println(a7) fmt.Println(a7==nil) s1 :=[]int{1,2,3} s2:=s1 fmt.Println(s1) s2[1] = 100 fmt.Println(s2) fmt.Println(s1) //切片不存值 指向同一个数组 var s3 []int //append将自动初始化分配内存+扩容 s3 = append(s3,1) fmt.Println(s3) var s4 []int s4 = make([]int,1,1) copy(s4,s3) //copy函数必须先将dest切片声明好并且初始化好分配好内存和长度 fmt.Println(s4) 指针 //指针 //go里面的指针只能读不能修改 addr:=\u0026#34;沙河\u0026#34; addrpointer:=\u0026amp;addr fmt.Println(addrpointer) fmt.Printf(\u0026#34;%T\\n\u0026#34;,addrpointer) fmt.Printf(*addrpointer) map map存储的是键值对的数据。他也是需要申请内存的\n//map var m map[string]int m = make(map[string]int,5) m[\u0026#34;ljs\u0026#34;] = 99 m[\u0026#34;jwt\u0026#34;] = 98 fmt.Println(m) fmt.Println(m[\u0026#34;jiwuming\u0026#34;]) //如果不存在key ，返回的将是value类型的默认值 score,ok:=m[\u0026#34;jiwuming\u0026#34;] if ok { println(score) }else{ println(\u0026#34;查无此人\u0026#34;) } delete(m,\u0026#34;lalala\u0026#34;) //如果没有的话，什么都不干，不报错 delete(m, \u0026#34;jwt\u0026#34;) fmt.Println(m) 复习 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;unicode\u0026#34; ) func main() { s1:=\u0026#34;hello沙河\u0026#34; sum:=0 for _, v := range s1 { //if v \u0026gt;= 128 { //\tsum++ //} if unicode.In(v, unicode.Han) { sum++ } } fmt.Println(sum) s2:=\u0026#34;how do you do\u0026#34; s3:= strings.Split(s2,\u0026#34; \u0026#34;) fmt.Println(s3) m:= make(map[string]int, 5) for _, v := range s3 { //if m[v] == 0 { //\tm[v] =1 //}\telse { //\tm[v] ++ //} if _,ok := m[v];!ok{ m[v]=1 }else { m[v]++ } } fmt.Println(m) //回文判断 //字符串从左往右读和从右往左读是一样的，就是回文 //黄山落叶松叶落山黄 s4:=\u0026#34;黄山落叶松叶落山黄\u0026#34; s5:= make([]string, len(s4)) for i, v:= range s4 { s5[len(s4)-i-1]=string(v) //fmt.Println(i, string(v)) fmt.Println(s5) } var s6 string s6 = strings.Join(s5,\u0026#34;\u0026#34;) fmt.Println(s6) fmt.Println(s6==s4) runes:= make([]rune, 0, len(s4)) for _, rune := range s4 { runes =append(runes, rune) } fmt.Println(\u0026#34;rune[] :\u0026#34;,runes) for i := 0; i \u0026lt; len(runes)/2; i++ { if runes[i]!=runes[len(runes)-i-1] { return } } println(\u0026#34;回文\u0026#34;) } 函数func package main import \u0026#34;fmt\u0026#34; func main() { println(f4(1, 2, 3, 4)) } func f1() { fmt.Println(\u0026#34;hello 沙河\u0026#34;) } func f2(name string) { fmt.Println(\u0026#34;hello\u0026#34;,name) } func f3(x, y int) int { return x+y //y是一个可变长度的切片类型 } func f4(x int, y ...int) int { sum:=x for _, v := range y { sum+=v } return sum } func f5(x, y int) (sum int) { sum = x+y return } func f6(x, y int) (x1, y1 int) { x1=x y1=y return } defer语句 go语言中的defer语句会将其后面跟随的语句进行延迟处理，在defer归属的函数即将返回时，将延迟处理的语句按照defer定义的逆序进行执行，也就是说先被defer的语句最后被执行，后被defer的语句最先被执行\ndefer执行时机 在go语言的函数中，return语句在底层并不是原子性操作，他分为给返回值赋值和ret指令两步。而defer语句执行的实际就是在返回值赋值操作后，ret指令执行前，具体如图\nimage-20210731151015069\rpackage main import \u0026#34;fmt\u0026#34; //go语言中的函数的return不是原子操作，在底层是分为两步来执行 //第一步：返回值赋值 //第二步：真正的return返回 //函数中如果存在defer，那么defer执行的时机是在第一步和第二步之间 func main() { fmt.Println(f1()) //5 fmt.Println(f2()) //6 fmt.Println(f3()) //5 fmt.Println(f3_1()) //[100 2] } func f1() int { x :=5 defer func() { x++ //修改的是x不是返回值 }() return x } func f2() (x int) { defer func() { x++ }() return 5 //返回值是x x又++了 所以返回6 } func f3() (y int) { x:=5 defer func() { x++ //是因为int是值类型 所以y是拷贝值而不是拷贝地址的原因吗 }() return x } func f3_1() (y []int) { x:=[]int{1,2} defer func() { x[0]=100 //因为[]int 切片是引用类型 所以y拷贝的是地址而不是值 }() return x } func f4() (x int) { defer func(x int) { x++ //改变的是函数的副本 }(x) //(x)代表的是传入参数 return 5 } 变量 全局变量 局部变量 局部变量又分为两种，函数内定义的变量无法在该函数外使用\n如果局部变量和全局变量重名，优先访问局部变量\n语句块作用域 函数类型和变量 我们可以使用type关键字来定义一个函数类型\ntype calculation func(int,int) int 定义了一个函数类型，这种函数接收两个int类型的参数并且返回一个int类型的返回值\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Printf(\u0026#34;%T \\n\u0026#34;,f1) fmt.Printf(\u0026#34;%T \\n\u0026#34;,f2) fmt.Printf(\u0026#34;%T \\n\u0026#34;,f3) f3(f2) a := f4(f2) fmt.Printf(\u0026#34;%T\\n\u0026#34;,a) } func f1() { fmt.Println(\u0026#34;hello 沙河\u0026#34;) } func f2() int { return 5 } //函数也可以作为参数的类型 func f3(x func() int) { fmt.Println(x()) } //函数还可以作为返回值的类型 func f4(x func() int) func(int,int) int { return f5 } func f5(x, y int) int { return x+y } 今日内容 函数 函数的定义 基本格式 参数的格式\n有参数的函数\n参数类型简写\n可变参数\n返回值的格式 有返回值\n无返回值\n命名返回值\n变量的作用域 全局作用域 函数作用域 先在函数内部找变量，找不到往外层找 函数内部的变量，外部访问不到 代码块作用域 高阶函数 函数也是一种类型，它可以作为一种参数，也可以作为返回值\n匿名函数 没有名字的函数\npackage main import \u0026#34;fmt\u0026#34; func main() { println(a(10)) //但是通常匿名函数不是这么用的 通常是由于函数内部不允许定义函数，所以使用匿名函数现写现用 a:= func(x,y int) int { return x+y } println(a(10, 20)) //如果只是调用一次的函数，还可以简写成立即执行函数 i := func(x, y int) int { return x * y }(10, 20) fmt.Println(i) } var a = func (x int) int { return x } 闭包 package main import \u0026#34;fmt\u0026#34; func main() { f1(f3(1,2)) f1(f4(1, 2)) f1(f5(f2,1,2)) } func f1(f func()) { fmt.Println(\u0026#34;this is f1\u0026#34;) f() } func f2(x, y int) { fmt.Println(\u0026#34;this is f2\u0026#34;) fmt.Println(x+y) } //如何让f1调用的时候执行f2 也就是两个同事写的代码相互兼容 //由于f1的形参是一个无形参无返回值的函数类型，因此需要构造一个函数，让其返回值是无形参无返回值的函数类型f3 //当然为了兼容f2，f3的形参需要和f2的形参相匹配，这样一来在执行f3的时候，内部调用了f2，并且返回类型满足f1所需 func f3(x,y int) func() { func(x,y int) { f2(x,y) }(x,y) return func() { } } func f4(x, y int) func() { return func() { f2(x,y) } } func f5(f func(int, int), x, y int) func() { //把原来需要传递两个int类型的参数包装成一个不需要传参的函数 return func() { f(x,y) } } 闭包=函数 + 外部变量的引用\npackage main import \u0026#34;fmt\u0026#34; func main() { //闭包是什么 //闭包是一个函数，这个函数包含了他外部作用域的一个变量 //底层 //1.函数可以作为返回值 //2.函数内部查找变量的顺序，先在自己内部找，找不到往外层找 ret := adder(100) i:= ret(200) fmt.Println(i) } func adder(x int) func(int) int { return func(y int) int { x +=y return x } } package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { suffixFunc:= makeSuffixFunc(\u0026#34;.jpg\u0026#34;) f := makeSuffixFunc(\u0026#34;.txt\u0026#34;) fmt.Println(suffixFunc(\u0026#34;text\u0026#34;)) fmt.Println(f(\u0026#34;text\u0026#34;)) } func makeSuffixFunc(suffix string) func(string2 string) string{ return func(name string) string { if !strings.HasSuffix(name, suffix) { return name+suffix } return name } } package main import \u0026#34;fmt\u0026#34; func main() { f, f2 := calc(10) fmt.Println(f(1),f2(2)) //11 9 fmt.Println(f(3),f2(4))\t//12 8 fmt.Println(f(5),f2(6))\t//13 7 } func calc(base int) (func(int)int ,func(int)int) { add :=func(i int)int{ base+=i return base } sub := func(i int)int{ base-=i return base } return add,sub } defer进阶 package main import ( \u0026#34;fmt\u0026#34; ) func main() { a:=1 b:=2 defer calc(\u0026#34;1\u0026#34;,a,calc(\u0026#34;10\u0026#34;,a,b)) a=0 defer calc(\u0026#34;2\u0026#34;,a,calc(\u0026#34;20\u0026#34;,a,b)) b=1 //defer会先把预定的值先算出来等着最后执行函数 //defer calc(\u0026#34;1\u0026#34;,1,calc(\u0026#34;10\u0026#34;,1,2)) //输出 \u0026#34;10\u0026#34; 1 2 3 //defer calc(\u0026#34;1\u0026#34;,1,3) //a=0 //defer calc(\u0026#34;2\u0026#34;,1,calc(\u0026#34;20\u0026#34;,0,2)) //输出 \u0026#34;20\u0026#34; 0 2 2 //defer calc(\u0026#34;2\u0026#34;,0,2) //b=1 //程序退出 //执行 defer calc(\u0026#34;2\u0026#34;,0,2) //输出 \u0026#34;2\u0026#34; 0 2 2 //执行 defer calc(\u0026#34;1\u0026#34;,1,3) //输出 \u0026#34;1\u0026#34; 1 3 4 } func calc(index string, a, b int) int { ret :=a+b fmt.Println(index,a,b,ret) return ret } 内置函数介绍 close 主要用来关闭channel\nlen 用来求长度 string array slice map channel\nnew 用来分配内存，主要用来分配值类型，比如int struct 返回的是指针\nmake 用来分配内存，主要用来分配引用类型，比如chan map slice\nappend 用来追加元素到数组 slice中\npanic和recover 用来做错误处理\npanic/recover go语言中目前是没有异常机制的，但是使用panic/recover模式来处理错误。panic可以在任何地方引发，但recover只有在defer调用的函数中有效。\n程序运行期间funcB如果引发了panic导致的程序崩溃，异常退出了。这个时候我们就可以通过recover将程序恢复回来，继续往后执行。\npackage main import \u0026#34;fmt\u0026#34; func main() { A() B() C() } func A() { fmt.Println(\u0026#34;A\u0026#34;) } func B() { //假设此时打开了个数据库连接 defer func() { error := recover() fmt.Println(error) fmt.Println(\u0026#34;要尝试在出错的时候释放数据库连接...\u0026#34;) }() panic(\u0026#34;fatal error!\u0026#34;) //程序奔溃退出 fmt.Println(\u0026#34;B\u0026#34;) } func C() { fmt.Println(\u0026#34;C\u0026#34;) } 注意：\nrecover必须搭配defer使用 defer一定要在可能引发panic的语句之前定义 go语言fmt.printf使用指南 fmt fmt包实现了类似C语言printf和scanf的格式化I/O 主要分为向外输出内容和获取输入内容两大部分\n向外输出 print 直接输出\nprintln输出带换行符\nprintf格式化输出\n占位符 说明 %v 值的默认格式 %+v 类似%v,但输出结构体时会添加字段名 %#v 值的go语法表示 %T 打印值的类型 %% 百分号 %t 布尔值 %b 对于整型而言，是二进制数，对于浮点数而言，是二进制指数的科学计数法 %c %d %o %x %X %U %q %e 科学计数法 %E 科学计数法 %f %F %g 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） %G %s %q %x 每个字节用两字符十六进制数表示 %9f 宽度9，默认精度 %9.2f 宽度9，精度2 %5.2s 一共5个 保留2个 %-5s 有空格补在前面 获取输入 fmt.scan fmt.scanf fmt.scanln\nscan从标准输入扫描文本，读取由空白符分割的值保存到传递给本函数的参数中，换行符视为空白符 本函数返回成功扫描的数据个数和遇到的任何错误，如果读取的数据个数比提供的参数少，会返回一个错误报告原因 sprint\nsprint系列函数会把传入的数据生成并返回一个字符串\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Print(\u0026#34;hello world\u0026#34;) fmt.Println(\u0026#34;hello world\u0026#34;) fmt.Printf(\u0026#34;%p\u0026#34;,\u0026#34;helloworld\u0026#34;) //%d 十进制 //%v 值 //%o 八进制 //%x 十六进制 //%T 类型 //%s 字符串 //%p 指针 //%b 二进制 //%c 字符s //%f 浮点数 //%t 布尔值 fmt.Println() var m map[string]int m= make(map[string]int) m[\u0026#34;ljs\u0026#34;]=98 fmt.Printf(\u0026#34;%v\\n\u0026#34;,m) fmt.Printf(\u0026#34;%#v\\n\u0026#34;,m) fmt.Printf(\u0026#34;%q\\n\u0026#34;,65) printfPersentage(98) fmt.Printf(\u0026#34;%b\\n\u0026#34;,5.6) n:=12.34 fmt.Printf(\u0026#34;%f\\n\u0026#34;,n) fmt.Printf(\u0026#34;%9f\\n\u0026#34;,n) fmt.Printf(\u0026#34;%.2f\\n\u0026#34;,n) fmt.Printf(\u0026#34;%9.2f\\n\u0026#34;,n) fmt.Printf(\u0026#34;%9.f\\n\u0026#34;,n) s:=\u0026#34;小王子\u0026#34; fmt.Printf(\u0026#34;%s\\n\u0026#34;,s) fmt.Printf(\u0026#34;%5s\\n\u0026#34;,s) fmt.Printf(\u0026#34;%-5s\\n\u0026#34;,s) fmt.Printf(\u0026#34;%5.7s\\n\u0026#34;,s) fmt.Printf(\u0026#34;%-5.7s\\n\u0026#34;,s) //一共5个 只留2个 fmt.Printf(\u0026#34;%5.2s\\n\u0026#34;,s) fmt.Printf(\u0026#34;%05s\\n\u0026#34;,s) var s1 string fmt.Scan(\u0026amp;s1) fmt.Println(s1) var ( name string age int class string ) //fmt.Scanf(\u0026#34;%s %d %s\\n\u0026#34;,\u0026amp;name,\u0026amp;age,\u0026amp;class) fmt.Printf(\u0026#34;%s %d %s\\n\u0026#34;,name,age,class) fmt.Scanln(\u0026amp;name,\u0026amp;age,\u0026amp;class) fmt.Printf(\u0026#34;%s %d %s\\n\u0026#34;,name,age,class) } func printfPersentage(a int) { fmt.Printf(\u0026#34;%d%%\\n\u0026#34;,a) } 今日难点 函数的定义 高阶函数 函数类型 闭包 defer panic/recover image-20210802002337782\r结构体 struct 方法\n实际上类似于类\n内容回顾 函数的定义\nfunc name () 返回值 {}\n函数进阶\n​\t高阶函数：函数可以作为参数，也可以作为返回值\n​\t闭包：函数和其外部变量的引用\n​\tdefer：延迟调用 多用于处理资源释放\n​\t内置函数：\n​\tpanic/recover 递归 package main import \u0026#34;fmt\u0026#34; func main() { //递归:自己调用自己 //递归适合处理那种问题相同但是规模越来越小的场景 //递归一定要有一个明确的退出条件 println(Factorial(7)) fmt.Println(taijie(4)) } func Factorial(n int) (result int) { if n == 1 { return 1 } else{ result =n * Factorial(n-1) return } } //上台阶面试题 //n个台阶 一次可以走1步 一次可以走2步 有多少种走法 func taijie(n int) (result int) { if n == 1 { result =1 //如果只有1个台阶就一种走法 return }else if n == 2 { return 2 } return taijie(n-1)+taijie(n-2) } 自定义类型和类型别名 在go语言中有一些基本的数据类型，如string bool int float等数据类型，go语言中可以使用type关键字来定义自定义类型\n自定义类型是定义了一个全新的类型。我们可以基于内置的基本类型定义，也可以通过struct定义\n类型别名规定typealias只是type的别名，本质上是一个类型，这些名字都指向一个类型\n区别 ： 自定义类型编译后类型是自定义的 类型别名只会在代码中存在，编译完成只会有原类型\nimage-20210806225811170\rpackage main import \u0026#34;fmt\u0026#34; //type后面跟的是类型 type myInt int //自定义类型 type yourInt = int //类型别名 func main() { //自定义类型和类型别名 var n myInt n = 100 fmt.Println(n) fmt.Printf(\u0026#34;%T\\n\u0026#34;,n) var m yourInt m = 100 fmt.Println(m) fmt.Printf(\u0026#34;%T\\n\u0026#34;,m) var r rune r = \u0026#39;中\u0026#39; fmt.Printf(\u0026#34;%c\\n\u0026#34;,r) fmt.Printf(\u0026#34;%T\\n\u0026#34;,r) } 结构体 go语言中没有类的概念，也不支持类的继承等面向对象的概念。go语言中通过结构体的内嵌再配合接口比面向对象具有更高的扩展性和灵活性。\ngo语言中的基础数据类型可以表示一些事务的基本属性，但是当我们想表达一个事务的全部或者部分属性时，这时候再用一些基本数据类型明显就无法满足需求了，go语言提供了一种自定义数据类型，可以封装多个基本数据类型，这种数据类型叫结构体，英文名称struct 也就是我们可以通过struct来定义自己的类型\ngo语言中通过struct来实现面向对象\n结构体的定义 使用type和struct关键字来定义结构体\npackage main import \u0026#34;fmt\u0026#34; //结构体 type person struct { name string age int hobby []string gender string } func main() { //声明一个person类型的变量 var f person //通过字段赋值 f.gender = \u0026#34;男\u0026#34; f.hobby = make([]string,10) f.hobby[0] =\u0026#34;football\u0026#34; f.hobby[1] =\u0026#34;basketball\u0026#34; f.age = 18 f.name = \u0026#34;ljs\u0026#34; fmt.Println(f) fmt.Printf(\u0026#34;%T\\n\u0026#34;,f) fmt.Println(f.hobby) var f1 person f1.name = \u0026#34;jwt\u0026#34; fmt.Println(f1) } //匿名结构体 多用于临时场景 s := struct { name string age int }{age: 18,name: \u0026#34;fyz\u0026#34;} fmt.Println(s) var s1 = struct { name string sex int }{sex : 1,name:\u0026#34;lje\u0026#34;} fmt.Println(s1) 结构体是值类型\n在Go语言中只存在值传递（要么是该值的副本，要么是指针的副本），不存在引用传递。之所以对于引用类型的传递可以修改原内容数据，是因为在底层默认使用该引用类型的指针进行传递，但是也是使用指针的副本，依旧是值传递。 image-20210807001149451\r创建指针类型结构体 取结构体地址实例化 结构体初始化 使用键值对初始化 使用值的列表初始化 package main import ( \u0026#34;fmt\u0026#34; ) type person struct { name string sex string } func main() { //结构体是值类型 p :=person{ name: \u0026#34;ljs\u0026#34;, sex: \u0026#34;男\u0026#34;, } fmt.Println(p) var p1 person p1.name =\u0026#34;lje\u0026#34; p1.sex = \u0026#34;nan\u0026#34; var p2 person p2 = p1 p2.name =\u0026#34;fyz\u0026#34; fmt.Println(p2) fmt.Println(p1) func(x person){ x.sex = \u0026#34;女\u0026#34; //传的是值 }(p2) fmt.Println(p2) func(x *person){ (*x).sex = \u0026#34;nv\u0026#34; //传的是地址 //x.sex = \u0026#34;nv\u0026#34; //语法糖 一样的同上 }(\u0026amp;p2) fmt.Println(p2) //创建一个指针类型的person var p3 = new (person) //new 返回的是指针地址 这个类型 p3.sex = \u0026#34;nan\u0026#34; (*p3).name = \u0026#34;www\u0026#34; //语法糖 一样的同上 fmt.Println(p3) fmt.Printf(\u0026#34;%T\\n\u0026#34;,p3) fmt.Printf(\u0026#34;%p\\n\u0026#34;,p3) //返回的是这个指针的值 p3保存的值就是一个内存地址 fmt.Printf(\u0026#34;%v\\n\u0026#34;,p3) fmt.Printf(\u0026#34;%T\\n\u0026#34;,\u0026amp;p3) fmt.Printf(\u0026#34;%p\\n\u0026#34;,\u0026amp;p3) //返回的是这个指针类型的值的地址 //key value 初始化 var p4 =\u0026amp;person{ name: \u0026#34;lll\u0026#34;, } fmt.Println(p4) //使用值 列表的形式初始化 顺序保持一致 p5:=person{ \u0026#34;nv\u0026#34;, \u0026#34;slkdjf\u0026#34;, } fmt.Println(p5) } package main import \u0026#34;fmt\u0026#34; func main() { var a int a = 100 b := \u0026amp;a fmt.Printf(\u0026#34;%T %p\\n\u0026#34;,\u0026amp;a,\u0026amp;a) fmt.Printf(\u0026#34;%T %p\\n\u0026#34;,b,b) //b的值 fmt.Printf(\u0026#34;%T %v\\n\u0026#34;,b,b) //b的值 fmt.Printf(\u0026#34;%T %p\\n\u0026#34;,\u0026amp;b,\u0026amp;b) //b的内存地址 } 结构体的内存布局 占用连续内存\npackage main import \u0026#34;fmt\u0026#34; type x struct { a ,b ,c int8 } func main() { //结构体占用一块连续的内存空间 x :=x{ a: 10, b: 20, c: 30, } fmt.Printf(\u0026#34;%p\\n\u0026#34;,\u0026amp;(x.a)) fmt.Printf(\u0026#34;%p\\n\u0026#34;,\u0026amp;(x.b)) fmt.Printf(\u0026#34;%p\\n\u0026#34;,\u0026amp;(x.c)) } 结构体是值类型 赋值的时候是拷贝\n构造函数：返回一个结构体变量的函数\n构造函数和方法\n方法和接收者 go语言中的方法method是一种作用于特定类型变量的函数。这种特定类型变量叫做接收者receiver 接收者的概念就类似于其他语言中的this或者self\nfunc (接收者变量 接收者类型) 方法名(参数列表) (返回参数) { 函数体 } package main import \u0026#34;fmt\u0026#34; //标识符：变量名、函数名、类型名、方法铭 //go语言中如果标识符首字母是大写的，就表示对外部包可见（暴露的，公有的） //Dog 这是一个狗的结构体注释 type Dog struct { name string } func newDog(name string) Dog { return Dog{ name: name, } } type person struct { name string age int } func newPerson(name string, age int) person { return person{ name: name, age: age, } } //方法是作用于特定类型的函数 //接受者表示的是调用该方法的具体类型变量，多用类型变量首字母小写表示 func (d Dog) wangwang() { fmt.Println(d.name+\u0026#34;汪汪汪\u0026#34;) } //使用值接收者：传拷贝进去 func (p person) guonian() { p.age++ } //操作指针 指针接收者：传地址进去 func (p *person) guonian1() { (*p).age++ } func main() { newDog(\u0026#34;jwt\u0026#34;).wangwang() p := newPerson(\u0026#34;ljs\u0026#34;, 18) fmt.Println(p.age) p.guonian() fmt.Println(p.age) p1:=newPerson(\u0026#34;jwt\u0026#34;,19) fmt.Println(p1.age) p1.guonian1() fmt.Println(p1.age) } 什么时候应该使用指针类型接收者 需要修改接收者中的值 接收者是拷贝代价比较大的大对象 保证一致性，如果有某个方法使用了指针接收者，那么其他的方法也应该使用指针接收者 任意类型添加方法 package main import \u0026#34;fmt\u0026#34; //给自定义类型添加方法 //不能给别的包里面的类型添加方法，只能给自己的包里的类型添加方法 type myInt int func (i myInt) hello() { fmt.Println(\u0026#34;this is a int\u0026#34;+(string(i))) } func main() { var i myInt i= 10 i.hello() } 结构体的匿名字段 package main import \u0026#34;fmt\u0026#34; //匿名字段 type person struct { string int } func main() { a:=person{ \u0026#34;ljs\u0026#34;, 10, } fmt.Println(a.string) fmt.Println(a.int) } 结构体嵌套 实际上就是包含关系或者继承嘛感觉\n匿名嵌套结构体 匿名嵌套结构体的字段冲突\npackage main import \u0026#34;fmt\u0026#34; type person struct { name string age int addr address } type company struct { name string address //匿名嵌套结构体 可以直接拿到匿名结构体里面的字段 } type address struct { province string city string } func main() { p1:=person{ name: \u0026#34;ljs\u0026#34;, age: 18, addr: address{city: \u0026#34;fuzhou\u0026#34;,province: \u0026#34;fujian\u0026#34;}, } fmt.Println(p1.addr.province) c1:=company{ name: \u0026#34;alibaba\u0026#34;, address: address{province: \u0026#34;zhejiang\u0026#34;,city: \u0026#34;hangzhou\u0026#34;}, } fmt.Println(c1.city) //先在自己结构体找这个字段 找不到就去匿名嵌套的结构体中查找该字段 } 结构体的“继承” go语言中使用结构体也可以实现其他编程语言中面向对象的继承\npackage main import \u0026#34;fmt\u0026#34; type animal struct { name string } func (a animal) move() { fmt.Println(string(a.name)+\u0026#34;会动\u0026#34;) } type dog struct { feet byte animal } func (d dog) wang() { fmt.Println(d.name+\u0026#34;wangwangwang\u0026#34;) } func newDog(a animal, feet byte) dog { return dog{ feet,a, } } func newAnimal(name string) animal { return animal{name:name} } func main() { //结构体模拟实现其他语言中的继承 newDog(newAnimal(\u0026#34;jwt\u0026#34;),4).wang() d1:=dog{ 4, animal{name: \u0026#34;ljs\u0026#34;}, } d1.move() //只能匿名嵌套结构体才能实现类似于继承的效果 如果有名字好像就调用不了 } 结构体与json package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { //结构体与json //1.序列化 把go语言中的结构体变量 --\u0026gt; json格式的字符串 //2.反序列化 把json格式的字符串 --\u0026gt; go语言中能够识别的结构体变量 p1:=person{ Name: \u0026#34;ljs\u0026#34;, Age: 18, } //序列化 v,err:=json.Marshal(p1) if err != nil { fmt.Println(\u0026#34;marshal fail \u0026#34;) fmt.Println(err) fmt.Printf(\u0026#34;%v %T\\n\u0026#34;,err,err) return } fmt.Println(v) fmt.Printf(\u0026#34;%v %T\\n\u0026#34;,string(v),v) //反序列化 传指针进去 var v1 person err1 := json.Unmarshal(v, \u0026amp;v1) if err1 != nil { fmt.Println(err1) return } fmt.Println(v1) fmt.Println(v1.Age) fmt.Println(v1.Name) s:=`{\u0026#34;name\u0026#34;:\u0026#34;ljs\u0026#34;,\u0026#34;age\u0026#34;:18}` var v2 person //传指针进去 json.Unmarshal([]byte(s),\u0026amp;v2) fmt.Printf(\u0026#34;%#v\\n\u0026#34;,v2) } type person struct { Name string `json:\u0026#34;name\u0026#34; db:\u0026#34;dbname\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } day05内容回顾 自定义类型和类型别名 type myInt int 自定义类型 type myInt1 = int 类型别名 在编译过程中 类型别名只在代码编写过程中有效，编译完之后就不存在，内置的byte和rune都属于类型别名\n结构体 基本数据类型 ：表示现实中的物体有局限性\n结构体是一种数据类型，一种我们可以自己造的可以保存多个维度的类型\ntype person struct{ name string age int addr address } 匿名结构体 多用于了临时场景\n结构体的初始化 构造函数 方法和接收者 方法是有接收者的函数，接收者指的是哪个类型的变量可以调用这个函数\n接收者可以是指针 结构体是值类型\n结构体的嵌套 结构体的匿名字段 JSON序列化与反序列化 经常出现的问题\n结构体内部的字段要大写 不然别人是访问不到的 反序列化时要传递指针 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type temp struct { X int `json:\u0026#34;x\u0026#34;` Y int `json:\u0026#34;y\u0026#34;` } func main() { var a = struct { x int y int }{x:2,y: 1} fmt.Println(a) var a1 temp a1.X = 1 a1.Y = 2 a2:=temp{ X: 0, Y: 0, } fmt.Println(a2) //调用构造函数 a3:=newTemp(1,2) fmt.Println(a3) a3.dream() a3.exchange() fmt.Println(a3) marshal, err := json.Marshal(a3) if err != nil { fmt.Println(err) } fmt.Println(string(marshal)) s1:=`{\u0026#34;x\u0026#34;:2,\u0026#34;y\u0026#34;:4}` var a4 temp err1 := json.Unmarshal([]byte(s1), \u0026amp;a4) if err1 != nil { fmt.Println(err1) } fmt.Println(a4) } //构造函数 返回值是对应的结构体类型 func newTemp(x, y int) temp { return temp{ X: x, Y: y, } } //接收者是用对应类型的首字母小写 //指定接收者之后 只有该类型的变量才有资格调用 func (t temp) dream() { fmt.Println(\u0026#34;temp也有梦想\u0026#34;) fmt.Println(t.X+t.Y) } //指针接收者 //1.需要修改结构体变量的值时需要使用指针接收者 //2.结构体本身比较大，拷贝的内存开销比较大时也要使用指针接收者 //3.保持一致性：如果有一个方法使用了指针接收者，其他的方法为了统一也要使用指针接收者 func (t *temp) exchange() { temp:=t.X t.X = t.Y t.Y = temp } type addr struct { city , province string } type student struct { name string addr //匿名嵌套结构体，就是用类型名字作为名称 } 接口interface 接口是一种类型，是一种特殊的类型，他规定了变量有哪些方法\n在编程中会遇到一下场景\n我不关心一个变量是什么类型，我只关心能调用他的什么方法\npackage main import \u0026#34;fmt\u0026#34; //引出接口的实例 type cat struct { } type dog struct { } func (c cat) speak() { fmt.Println(\u0026#34;miaomiaomiao~\u0026#34;) } func (d dog) speak() { fmt.Println(\u0026#34;wangwangwang~\u0026#34;) } type speaker interface { speak() //只要实现了speak方法的变量都是speaker类型 } func fuck(a speaker) { a.speak() } func main() { c:=cat{} d:=dog{} fuck(c) fuck(d) var ss1 speaker //定义一个接口类型 ：speaker的变量 ss1=d ss1.speak() ss:=speaker(c) ss.speak() } 接口的定义 type name interface{ methodname(参数1，参数2) (返回值1，返回值2) ... } 用来给变量/参数/返回值 等设置类型\n接口的实现 一个变量如果实现了接口中规定的所有的方法，那么这个变量就实现了这个接口，可以理解称为接口类型的变量。\nimage-20210808151410287\rimage-20210808151514714\r接口类型的变量 接口类型变量能够存储所有实现了该接口的实例\n值接收者和指针接收者实现接口的区别 前者可以传值，也可以传指针\n后者只能传指针\npackage main import ( \u0026#34;fmt\u0026#34; ) //使用值接收者和指针接收者的区别 type animal interface { move() eat(string) } type cat struct { name string feet int } ////使用值接收者实现了接口的所有方法 //func (c cat) move() { // fmt.Println(\u0026#34;走猫步\u0026#34;) //} // //func (c cat) eat(a string) { // fmt.Println(\u0026#34;猫吃\u0026#34;+a) //} //使用指针接收者实现了接口的所有方法 func (c *cat) move() { fmt.Println(\u0026#34;走猫步\u0026#34;) } func (c *cat) eat(a string) { fmt.Println(\u0026#34;猫吃\u0026#34;+a) } func main() { var a1 animal c1:=cat{ name: \u0026#34;tom\u0026#34;, feet: 4, } c2:=\u0026amp;cat{ name: \u0026#34;假老练\u0026#34;, feet: 4, } a1=\u0026amp;c1 fmt.Println(a1) a1.eat(\u0026#34;bianbian\u0026#34;) a1=c2 fmt.Println(a1) a1.eat(\u0026#34;大便便\u0026#34;) } 类型与接口的关系 多个类型可以实现同一个接口\n一个类型可以实现多个接口\n接口可以嵌套接口\npackage main import \u0026#34;fmt\u0026#34; //接口还可以嵌套 type animal interface { mover eater } //同一个结构体可以实现多个接口 type mover interface { move() } type eater interface { eat(string) } type cat struct { name string feet byte } //一个结构体可以实现多个接口 func (c *cat) move() { fmt.Println(c.name+\u0026#34; is moving\u0026#34;) } func (c *cat) eat(something string) { fmt.Println(c.name+\u0026#34; is eating \u0026#34;+something) } func main() { c1:=cat{ name: \u0026#34;tom\u0026#34;, feet: 4, } mover.move(\u0026amp;c1) eater.eat(\u0026amp;c1,\u0026#34;猫粮\u0026#34;) } 空接口 type xxx interface{ } interface{} //既然是空接口 那就不需要名字了 所有的类型都实现了空接口这种类型，也就是任意类型的变量都能保存到空接口中。\n空接口的应用\n作为函数的参数 作为map的值 package main import \u0026#34;fmt\u0026#34; //空接口 func main() { m1 := make(map[interface{}]interface{},10) m1[1]=\u0026#34;hello world\u0026#34; m1[\u0026#34;hello world\u0026#34;] = 1 m1[false] =[...]string{\u0026#34;1\u0026#34;,\u0026#34;2\u0026#34;,\u0026#34;3\u0026#34;} m1[[...]int{1,2}]=[]bool{true,false} fmt.Println(m1) show(m1) } func show(a interface{}) { fmt.Printf(\u0026#34;%T %v\\n\u0026#34;,a,a) } 类型断言 package main import ( \u0026#34;fmt\u0026#34; ) //类型断言 func main() { assert(\u0026#34;100\u0026#34;) assert(float32(32.1)) } func assert(a interface{}) { fmt.Printf(\u0026#34;%T %v\\n\u0026#34;,a,a) s,ok := a.(string) //类型断言 if !ok { fmt.Println(\u0026#34;error \u0026#34;) return } fmt.Println(s) switch i:=a.(type) { case string: fmt.Printf(\u0026#34;this is a string %T %v\\n\u0026#34;,i,i) case int: fmt.Printf(\u0026#34;this is a int %T %v\\n\u0026#34;,i,i) case bool: fmt.Printf(\u0026#34;this is a bool %T %v\\n\u0026#34;,i,i) case float64,float32: fmt.Printf(\u0026#34;this is a float %T %v\\n\u0026#34;,i,i) } } 接口的注意事项 只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要定义接口。不要为了接口而写接口，那样只会增加不必要的抽象，导致不必要的运行时消耗\n包package 包是多个go源码的集合，是一种高级的代码复用方案，go语言为我们提供了很多内置包，如fmt、os、io等\n定义包\npackage 包名 注意：\n一个文件夹下只能有一个包，同样一个包的文件不能在多个文件夹下 包名可以不和文件夹的名字一样，包名不能包含符号 - 包名为main的包为程序的入口包，编译时不包含main包的源代码是不会得到可执行文件的 包的导入 import导入语句通常放在文件开头包声明语句的下面 导入的包名需要使用双引号包裹起来 包名是从 $gopath/src/后开始计算的 ， 使用 / 路径进行分割 go语言禁止循环导入包 单行导入 、 多行导入、自定义导入、匿名导入包 _\ninit()初始化函数 在go语言程序执行时导入包语句会自动触发包内部init（）函数的调用\ninit()函数没有参数也咩有返回值 init()函数在程序运行时自动被调用执行 不能在代码中主动调用它\nimage-20210808175802083\rimage-20210808175917585\r文件操作 自己写一个日志库\n接口：用处？日志可以输出到终端，可以输出到文件，输出到卡夫卡\n文件操作\n打开和关闭文件 os.Open函数能够打开一个文件 返回一个*File 和一个err ，对得到的文件实例调用close()方法能够关闭文件\n为了防止文件忘记关闭 我们通常使用defer注册文件关闭语句\nfile.Read() bufio读取文件 ioutil读取整个文件 文件写入操作 os.openfile()函数能够以指定模式打开文件，从而实现文件写入相关功能\nfunc OpenFile(name string , flag int , perm FileMode) (*File,error){ } flag是文件打开的模式\nos.O_WRONLY os.O_CREATE os.O_RDONLY os.O_RDWR os.O_TURNC os.O_APPEND perm：文件权限，一个八进制数。r读 o4 w写 o2 x执行 o1\nfile.write\nfile.writestring\nwriter:= bufio.NewWriter(file) ioutil.WriteFile package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) func readFromFile1() { fileObj,err:=os.Open(\u0026#34;./main.go\u0026#34;) if err != nil { fmt.Println(\u0026#34;open file failed...\u0026#34;) return } //记得关闭文件 defer fileObj.Close() var b =make([]byte,128) for { n,err:=fileObj.Read(b) if err == io.EOF { fmt.Println(\u0026#34;读完了\u0026#34;) return } if err != nil { fmt.Println(\u0026#34;read from file failed , error\u0026#34;) return } fmt.Println(n) fmt.Println(string(b)) if n \u0026lt;128 { return } } } //利用bufio这个包读取文件 func readFromFileByBufio() { fileObjFile,err :=os.Open(\u0026#34;./main.go\u0026#34;) if err != nil { fmt.Printf(\u0026#34;err, %v\u0026#34;,err) return } defer fileObjFile.Close() reader:=bufio.NewReader(fileObjFile) for { string,err:=reader.ReadString(\u0026#39;\\n\u0026#39;) if err==io.EOF { return } if err != nil { fmt.Printf(\u0026#34;read line failed , err : %v\u0026#34;,err) return } fmt.Print(string) } } func readFromFileByIoutil() { file, err := ioutil.ReadFile(\u0026#34;./main.go\u0026#34;) if err != nil { fmt.Printf(\u0026#34;err , cause: %v\\n\u0026#34;,err) } fmt.Println(string(file)) } //打开文件 func main() { //readFromFile1() //readFromFileByBufio() readFromFileByIoutil() } package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) func write() { fileObj , err :=os.OpenFile(\u0026#34;./xx.txt\u0026#34;,os.O_WRONLY|os.O_CREATE|os.O_TRUNC,0644) if err != nil { fmt.Printf(\u0026#34;err cause: %v\\n\u0026#34;,err) return } //write fileObj.Write([]byte{97,98,99}) fileObj.Write([]byte(\u0026#34;this is a b c \u0026#34;)) fileObj.WriteString(\u0026#34;hello world!\u0026#34;) defer fileObj.Close() } func writeByBufIo() { file, err := os.OpenFile(\u0026#34;./xx.txt\u0026#34;, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0644) if err != nil { fmt.Printf(\u0026#34;err cause : %v\\n\u0026#34;,err) return } writer:= bufio.NewWriter(file) writer.WriteString(\u0026#34;comeon baby!\u0026#34;) //bufio是做了一个缓存 writer.Flush() defer file.Close() } func writeByIoutil() { str:=\u0026#34;hello 北京\u0026#34; err := ioutil.WriteFile(\u0026#34;./xx.txt\u0026#34;, []byte(str), 0666) if err != nil { fmt.Printf(\u0026#34;error cause : %v\\n\u0026#34;,err) return } } func main() { //write() //writeByBufIo() writeByIoutil() } 拷贝文件 可以借助io.copy()实现一个拷贝文件函数\npackage main import ( \u0026#34;io/ioutil\u0026#34; ) func main() { copyFile(\u0026#34;./xxcopy.txt\u0026#34;,\u0026#34;./xx.txt\u0026#34;) } func copyFile(dstName,srcName string) (written int64,err error) { //以读的方式打开文件 //file, err := os.OpenFile(srcName, os.O_RDONLY, 0644) //if err != nil { //\treturn 0, err //} //reader:= bufio.NewReader(file) readFile, err := ioutil.ReadFile(srcName) if err != nil { return 0, err } err1 := ioutil.WriteFile(dstName, readFile, 0644) if err1 != nil { return 0, err1 } return 1,nil } 通过文件操作获取终端输入\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { //useScan() ioscan() } func useScan() { fmt.Println(\u0026#34;请输入内容！\u0026#34;) var s string fmt.Scanln(\u0026amp;s) fmt.Printf(\u0026#34;你输入的内容是 %v\\n\u0026#34;,s) } func ioscan() { fmt.Println(\u0026#34;请输入内容！\u0026#34;) var s string reader := bufio.NewReader(os.Stdin) s,_=reader.ReadString(\u0026#39;\\n\u0026#39;) fmt.Println(s) } 日志库作业 需求：\n可以往不同的输出位置记录日志 日志可以分为五种级别 内容回顾 包 包的定义 package，包名通常是和目录名一致，不能包含-\n一个文件夹就是一个包 文件夹里面放的都是.go文件 包的导入 import\n​\t单行导入 和 多行导入 ​ 包导入路径是从gopath\\src后面的路径开始写起 ​ 给导入的包起别名 匿名导入 \u0026mdash;\u0026gt; sql包导入时会讲 不支持循环导入 包中标识符(变量名、函数名、结构体、接口、常量\u0026hellip;) 可见性 标识符首字母大写\ninit()\n包导入的时候会自动执行 一个包里只有一个init() init()没有参数也没有返回值也不能调用他 多个包的init执行顺序 一般用于初始化操作\u0026hellip; 接口 接口是一种类型，一种抽象的类型\n接口就是你要实现的方法的清单\n接口的定义 type mover interface{ 方法签名(参数)(返回值) } 接口的实现 实现了接口的所有方法就实现了这个接口\n实现了接口就可以当成这个接口类型的变量\n接口的变量 实现了一个变量，可以保存所有实现了我这个接口类型的值\n通常作为函数的参数出现\n空接口 接口中没有定义任何方法，也就是所任意类型都实现了空接口==\u0026gt;任何类型的变量都可以存到这个空接口变量中\ninterface {} 作为函数参数fmt.println()\nmap[string]interface{}\n接口底层 动态类型 动态值 类型断言 做类型断言的前提是 一定要是一个接口类型的变量\nx.(T)\n使用switch来做类型断言\n文件操作 打开文件和关闭文件 image-20210810185410507\r缓冲区\nimage-20210810185806983\rread\nbufio\nioutil\n写文件 os.openfile()\nwrite 和 writestring\nbufio.newwriter\nioutil\n在文件中插入东东\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { //OpenFile() InsertFile() } func InsertFile() { //打开文件 file, err := os.OpenFile(\u0026#34;./sb.txt\u0026#34;, os.O_RDWR, 0644) if err != nil { fmt.Printf(\u0026#34;err cause : %v\\n\u0026#34;,file) return } defer file.Close() //读首两个字节 var b = [2]byte{} n, _ := file.Read(b[:]) //创建文件 写首两个字节 openFile, _ := os.OpenFile(\u0026#34;./sbinsert.txt\u0026#34;, os.O_CREATE|os.O_WRONLY, 0644) openFile.Write(b[:n]) defer openFile.Close() //尝试移动光标 _, err1 := file.Seek(2, 0) //光标移动 if err1 != nil { return } //尝试写要插入的数据 openFile.Write([]byte{\u0026#39;c\u0026#39;}) //尝试读光标下一个字节的数据 var a [128]byte read, err2 := file.Read(a[:]) if err2 != nil { return } fmt.Println(string(a[:read])) openFile.Write(a[:read]) os.Rename(\u0026#34;./sbinsert.txt\u0026#34;,\u0026#34;./sb.txt\u0026#34;) //writer := bufio.NewWriter(file) //writer.WriteString(\u0026#34;c\u0026#34;) //writer.Flush() } func OpenFile() { open, err := os.Open(\u0026#34;./xx.txt\u0026#34;) if err != nil { fmt.Printf(\u0026#34;err cause: %v\\n\u0026#34;,open) return } defer open.Close() var b [128]byte for { read, err1 := open.Read(b[:]) if err1 != nil { fmt.Printf(\u0026#34;read err cause: %v\\n\u0026#34;,err1) return } fmt.Println(string(b[:])) if read \u0026lt;128 { return } } } 今日内容 time标准库 时间类型\ntime.time类型表示时间 我们可以通过time.now() 函数获取当前的时间对象 然后获取时间对象的年月日时分秒等信息。示例代码如下：\n时间戳 时间间隔 add sub equal before after 定时器time.tick 时间格式化 时间类型有一个自带的方法Format进行格式化，需要注意的是go语言中格式化时间模版不是常见的y-m-d h:/m:/s 而是使用go诞生的时间2006 1 2 3 4\n补充：如果想要格式化为12小时方式，需要指定PM\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { f2() } func f1() { now := time.Now() fmt.Printf(\u0026#34;%v \\n\u0026#34;,now) fmt.Printf(\u0026#34;%v \\n\u0026#34;,now.Year()) fmt.Printf(\u0026#34;%v \\n\u0026#34;,now.Month()) fmt.Printf(\u0026#34;%v \\n\u0026#34;,now.Day()) fmt.Printf(\u0026#34;%v \\n\u0026#34;,now.Hour()) fmt.Printf(\u0026#34;%v \\n\u0026#34;,now.Minute()) fmt.Printf(\u0026#34;%v \\n\u0026#34;,now.Second()) fmt.Println(now.Date()) //时间戳 fmt.Println(now.Unix()) fmt.Println(now.UnixNano()) //time.Unix() unix:= time.Unix(now.Unix(), 0) fmt.Println(unix) //时间间隔 fmt.Println(time.Second) //now +24 hours fmt.Println(time.Now().Add(time.Hour*24)) //定时器 //tick := time.Tick(time.Second) //for i := range tick { // fmt.Println(i) //} //格式化时间 把语言中时间对象 转换成字符串类型的时间 //2021/08/10 fmt.Println(time.Now().Format(\u0026#34;2006/01/02\u0026#34;)) fmt.Println(time.Now().Format(\u0026#34;2006-1-2 15:04:05\u0026#34;)) fmt.Println(time.Now().Format(\u0026#34;2006-1-2 03:04:05\u0026#34;)) fmt.Println(time.Now().Format(\u0026#34;2006-1-2 15:04:05 PM\u0026#34;)) fmt.Println(time.Now().Format(\u0026#34;2006:01:02 15:04:05.000 PM\u0026#34;)) //按照对应的格式 解析字符串类型的时间 value, err := time.Parse(\u0026#34;2006-01-02\u0026#34;, \u0026#34;2019-05-20\u0026#34;) if err != nil { fmt.Println( \u0026#34; err \u0026#34;,err) return } fmt.Println(value) fmt.Println(time.Now().Sub(time.Now().Add(-time.Hour))) fmt.Println(\u0026#34;beginning\u0026#34;) //sleep time.Sleep(time.Second*2) fmt.Println(\u0026#34;ending...\u0026#34;) } func f2() { now:= time.Now() //获取的是当前时区的时间 fmt.Println(now) //按照东八区的时区和格式解析一个字符串格式的时间 time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2021-08-11 21:33:05\u0026#34;) //根据字符加载时区 location, err := time.LoadLocation(\u0026#34;Asia/Shanghai\u0026#34;) if err!=nil { fmt.Printf(\u0026#34;load loc failed , err :%v\\n\u0026#34;,err) return } //按照指定时区解析时间 parseInLocation, err := time.ParseInLocation(\u0026#34;2006-01-02 15:05:05\u0026#34;, \u0026#34;2021-08-11 21:33:05\u0026#34;, location) fmt.Println(time.Now().Sub(parseInLocation)) } 日志库 需求分析\n支持往不同的地方输出日志\n分级别输出\ndebug info warning error fatal 日志要支持开关控制，比如说开发的时候什么级别的日志都能输出，但是上线之后只有INFO级别往下才能输出\n完整的日志记录要包含日志要有时间、行号、文件名、日志级别、日志信息\n日志文件要切割\n按文件大小切割 每次记录日志之前都判断一下当前写的这个文件的文件大小 按日期切割 在日志结构体中设置一个字段记录上一次切割的小时数 在写日志之前检查一下当前时间的小时数和之前保存的是否一致，不一致就要切割 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;time\u0026#34; ) func main() { consoleLogger := NewConsoleLogger(ERROR) Logger.Debug(consoleLogger,\u0026#34;hello world\u0026#34;) Logger.Info(consoleLogger,\u0026#34;hello world\u0026#34;) Logger.Warning(consoleLogger,\u0026#34;hello world\u0026#34;) Logger.Error(consoleLogger,\u0026#34;hello world%d\u0026#34;,10) Logger.Fatal(consoleLogger,\u0026#34;hello world\u0026#34;) fileLogger := NewFileLogger(ERROR, \u0026#34;.\u0026#34;, \u0026#34;logdemo.txt\u0026#34;, \u0026#34;logdemoerr.txt\u0026#34;, 128) Logger(fileLogger).Debug(\u0026#34;hello world %d\u0026#34;,10) Logger(fileLogger).Error(\u0026#34;fatal error %v\u0026#34;,\u0026#34;某树被榨干了...\u0026#34;) } type Logger interface { Debug(string,...interface{}) Info(string,...interface{}) Warning(string,...interface{}) Error(string,...interface{}) Fatal(string,...interface{}) } type ConsoleLogger struct { LogLevel MODE } type MODE = int const ( DEBUG MODE =iota INFO WARNING ERROR FATAL ) func NewConsoleLogger(logLevel MODE) ConsoleLogger { return ConsoleLogger{ LogLevel: logLevel, } } func (m ConsoleLogger) Debug(s string,a...interface{}) { if m.LogLevel\u0026gt;=DEBUG { var msg string if a == nil { msg=s } else { msg=fmt.Sprintf(s,a) } fmt.Printf(\u0026#34;[%v] [DEBUG] this is a debug log, value :%v\\n\u0026#34;,time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;),msg) fmt.Println(getInfo(2)) } } func (m ConsoleLogger) Info(s string,a ...interface{}) { if m.LogLevel\u0026gt;=INFO { var msg string if a == nil { msg=s } else { msg=fmt.Sprintf(s,a) } fmt.Printf(\u0026#34;[%v] [INFO] this is a info log, value :%v\\n\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Println(getInfo(2)) } } func (m ConsoleLogger) Warning(s string , a ...interface{}) { if m.LogLevel\u0026gt;=WARNING { var msg string if a == nil { msg=s } else { msg=fmt.Sprintf(s,a) } fmt.Printf(\u0026#34;[%v] [WARNING] this is a warning log, value :%v\\n\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Println(getInfo(2)) } } func (m ConsoleLogger) Error(s string,a ...interface{}) { if m.LogLevel\u0026gt;=ERROR { var msg string if a == nil { msg=s } else { msg=fmt.Sprintf(s,a) } fmt.Printf(\u0026#34;[%v] [ERROR] this is a error log, value :%v \\n\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Println(getInfo(2)) } } func (m ConsoleLogger) Fatal(s string,a...interface{}) { if m.LogLevel\u0026gt;=FATAL { var msg string if a == nil { msg=s } else { msg=fmt.Sprintf(s,a) } fmt.Printf(\u0026#34;[%v] [FATAL] this is a fatal log, value :%v\\n\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Println(getInfo(2)) } } func getInfo(n int) string { caller, file, line, ok := runtime.Caller(n) if !ok { return \u0026#34;error\u0026#34; } name:= runtime.FuncForPC(caller).Name() return \u0026#34;fileLocation: \u0026#34;+path.Base(file)+\u0026#34;, method: \u0026#34;+name+\u0026#34;, line: \u0026#34;+strconv.Itoa(line) } type FileLogger struct { LogLevel MODE fileName string //日志文件的名称 filePath string\t//日志文件的路径 errFileName string //错误日志单独记录 maxFileSize int64 fileObj *os.File errFileObj *os.File } func NewFileLogger(logLevel MODE,filePath, fileName , errFileName string , maxFileSize int64)*FileLogger { file, err := os.OpenFile(path.Join(filePath,fileName), os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0644) if err != nil { fmt.Println(err) return nil } errfile, err := os.OpenFile(path.Join(filePath,errFileName),os.O_CREATE|os.O_APPEND|os.O_WRONLY,0644) if err != nil { return nil } return \u0026amp;FileLogger{ LogLevel: logLevel, fileName: fileName, filePath: filePath, errFileName: errFileName, maxFileSize: maxFileSize, fileObj: file, errFileObj: errfile , } } func (f *FileLogger) Close() { f.fileObj.Close() f.errFileObj.Close() } func (f *FileLogger) checkSize(fileObj *os.File) bool { stat, err := fileObj.Stat() if err != nil { return false } if stat.Size() \u0026gt; f.maxFileSize { return true }else{ return false } } func (f *FileLogger)SplitLogFile() { //需要切割文件 //1.关闭当前文件 f.fileObj.Close() //2.rename 备份一下 xx.log -\u0026gt; xx.log.bak201908031709 nowStr:=time.Now().Format(\u0026#34;20060102150405000\u0026#34;) bakFilePath := path.Join(f.filePath, f.fileName)+\u0026#34;.bak\u0026#34;+nowStr err := os.Rename(path.Join(f.filePath, f.fileName), bakFilePath) if err != nil { return } //3.打开一个新的日志文件 newFile, err := os.OpenFile(path.Join(f.filePath, f.fileName), os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0644) if err != nil { return } //4.将打开的新日志文件对象赋值给 f.fileObj f.fileObj = newFile } func (f *FileLogger) Debug(s string, a ...interface{}) { if f.LogLevel\u0026gt;=DEBUG { if f.checkSize(f.fileObj) { f.SplitLogFile() } msg := fmt.Sprintf(s, a) msg = fmt.Sprintf(\u0026#34;[%v] [DEBUG] this is a debug log, value :%v\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Fprintln(f.fileObj) fmt.Fprintln(f.fileObj,msg) fmt.Fprintln(f.fileObj,getInfo(2)) f.Close() } } func (f *FileLogger) Info(s string, a ...interface{}) { if f.LogLevel\u0026gt;=INFO { msg := fmt.Sprintf(s, a) msg = fmt.Sprintf(\u0026#34;[%v] [INFO] this is a info log, value :%v\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Fprintln(f.fileObj) fmt.Fprintln(f.fileObj,msg) fmt.Fprintln(f.fileObj,getInfo(2)) f.Close() } } func (f *FileLogger) Warning(s string, a ...interface{}) { if f.LogLevel\u0026gt;=WARNING { msg := fmt.Sprintf(s, a) msg = fmt.Sprintf(\u0026#34;[%v] [WARNING] this is a warning log, value :%v\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Fprintln(f.fileObj) fmt.Fprintln(f.fileObj,msg) fmt.Fprintln(f.fileObj,getInfo(2)) f.Close() } } func (f *FileLogger) Error(s string, a ...interface{}) { if f.LogLevel\u0026gt;=ERROR { msg := fmt.Sprintf(s, a) msg = fmt.Sprintf(\u0026#34;[%v] [ERROR] this is a error log, value :%v\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Fprintln(f.fileObj) fmt.Fprintln(f.fileObj,msg) fmt.Fprintln(f.fileObj,getInfo(2)) fmt.Fprintln(f.errFileObj) fmt.Fprintln(f.errFileObj,msg) fmt.Fprintln(f.errFileObj,getInfo(2)) f.Close() } } func (f *FileLogger) Fatal(s string, a ...interface{}) { if f.LogLevel\u0026gt;=FATAL { msg := fmt.Sprintf(s, a) msg = fmt.Sprintf(\u0026#34;[%v] [FATAL] this is a Fatal log, value :%v\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15-04-05\u0026#34;), msg) fmt.Fprintln(f.fileObj) fmt.Fprintln(f.fileObj,msg) fmt.Fprintln(f.fileObj,getInfo(2)) fmt.Fprintln(f.errFileObj) fmt.Fprintln(f.errFileObj,msg) fmt.Fprintln(f.errFileObj,getInfo(2)) f.Close() } } 反射 反射是指在程序运行期间对程序本身进行访问和修改的能力。程序在编译时，变量被转换为内存地址，变量名不会被编译器写入到可执行部分。在运行程序时，程序无法获取自身的信息。\n支持反射的语言可以在程序编译期将变量的反射信息，如字段名称、类型名称、结构体信息等整合到可执行文件中，并给程序提供接口访问反射信息，这样就可以在程序运行期获取类型的反射信息，并且有能力修改她们。\ngo程序在运行期使用reflect包访问程序的反射信息。\n空接口可以存储任意类型的变量，那么我们如何知道空接口保存的数据是什么呢？反射就是在运行时动态的获取一个变量的类型信息和值信息。\nreflect包 在go语言的反射机制中，任何接口值都是由一个具体类型和具体类型的值两部分组成的。在go语言中反射的相关功能有内置的reflect包提供，任意接口值在反射中都可以理解为有reflect.Type 和 reflect.Value 两部分组成，并且reflect包提供了reflect.TypeOf 和 reflect.ValueOf两个函数来获取任意对象的value和type\ntypeof\nvalueof\ntype name 和 type kind 在反射中关于类型还划分为两种：类型type和种类kind 在go语言中我们可以使用type关键字构造很多种自定义类I型那个，而种类kind就是指底层的类型，但在反射中，当需要区分指针、结构体等大品种的类型时，就会用到种类kind\nvalueof package main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { reflectType(int64(8)) reflectType(int32(8)) reflectType(\u0026#34;hello world\u0026#34;) reflectType(map[interface{}]interface{}{1:\u0026#34;hello\u0026#34; , \u0026#34;hello world\u0026#34;:[]bool{true}}) reflectType(cat{name: \u0026#34;tomcat\u0026#34;}) reflectValue(int64(8)) b:=int64(20) //reflectSetValue1(b) //这样不行会引发panic错误 reflectSetValue2(\u0026amp;b) fmt.Println(b) var a *int fmt.Println(reflect.ValueOf(a).IsNil()) fmt.Println(reflect.ValueOf(a).IsValid()) c := cat{name: \u0026#34;tomcat\u0026#34;} fmt.Println(reflect.ValueOf(c).FieldByName(\u0026#34;name\u0026#34;)) fmt.Println(reflect.ValueOf(c).MethodByName(\u0026#34;name\u0026#34;).IsValid()) m:=map[string]int{\u0026#34;娜扎\u0026#34;:1} fmt.Println(reflect.ValueOf(m).MapIndex(reflect.ValueOf(\u0026#34;娜扎\u0026#34;)).IsValid()) } func reflectType(a interface{}) { v := reflect.TypeOf(a) fmt.Printf(\u0026#34;%T %v\\n\u0026#34;,v,v) fmt.Printf(\u0026#34;type %v kind %v \\n\u0026#34;,v.Name(),v.Kind()) } func reflectValue(a interface{}) { v:=reflect.ValueOf(a) kind := v.Kind() switch kind { case reflect.Int64: fmt.Printf(\u0026#34;type is int64,value is %d\\n\u0026#34;,int64(v.Int())) case reflect.Float32: fmt.Printf(\u0026#34;type is float32, value is %f\\n\u0026#34;,float32(v.Float())) } } func reflectSetValue1(x interface{}) { value := reflect.ValueOf(x) if value.Kind() == reflect.Int64 { value.SetInt(200) //修改的是副本 reflect包会引发panic } } func reflectSetValue2(x interface{}) { value :=reflect.ValueOf(x) if value.Elem().Kind() == reflect.Int64 { value.Elem().SetInt(200) } } type cat struct { name string } 通过反射设置变量的值 想要在函数中通过反射修改变量的值，需要注意函数参数传递的是值拷贝，必须传递变量地址才能修改变量值。而反射中使用专有的elem()方法来获取指针对应的值\nisNil和isValid 报告持有的值是否为nil，持有的值的分类必须是通道、函数、接口、映射、指针、切片之一，否则会导致panic\nisvalid返回v是否持有一个值，如果v是value的零值就会返回假，如果v除了isvalid、string、kind之外的方法都会导致panic\n区别 isnil常被用于判断指针是否为空，isvalid常被用于判定返回值是否有效\npackage main import ( json2 \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { s:=student{ Name: \u0026#34;xwz\u0026#34;, Score: \u0026#34;90\u0026#34;, } //最终要得到 {\u0026#34;name\u0026#34;:\u0026#34;xwz\u0026#34;,\u0026#34;score\u0026#34;:90} typeof := reflect.TypeOf(s) json:=`{` for i := 0; i \u0026lt; typeof.NumField(); i++ { fmt.Println(typeof.FieldByIndex([]int{i}).Name) //fmt.Println(typeof.Field(i).Name) fmt.Println(typeof.FieldByIndex([]int{i}).Tag.Get(\u0026#34;json\u0026#34;)) json+=\u0026#34;\\\u0026#34;\u0026#34;+typeof.Field(i).Tag.Get(\u0026#34;json\u0026#34;)+\u0026#34;\\\u0026#34;\u0026#34;+\u0026#34;:\u0026#34; structField, b := typeof.FieldByName(typeof.Field(i).Name) fmt.Println(structField.Name) fmt.Println(structField.Type) fmt.Println(structField.Index) valueof:= reflect.ValueOf(s) fmt.Println(valueof.Field(i)) sprint := fmt.Sprint(valueof.Field(i)) if b { json+=\u0026#34;\\\u0026#34;\u0026#34;+sprint+\u0026#34;\\\u0026#34;\u0026#34;+\u0026#34;,\u0026#34; } } s2 := json[:len(json)-1] json = s2 json+=\u0026#34;}\u0026#34; fmt.Println(json) var s1 student json2.Unmarshal([]byte(json),\u0026amp;s1) fmt.Println(s1) //反序列化实例 } type student struct { Name string `json:\u0026#34;name\u0026#34;` Score string `json:\u0026#34;score\u0026#34;` } 内容回顾 time 时间类型 time.Time : Time.Now() 时间戳: time.Now().Unix() time.Now().UnixNano():1971.1.1到现在的纳秒数 时间间隔类型 time.Duration ：时间间隔类型 time.Second time.Hour time.Minute 时间操作 时间对象+-一个时间间隔对象\nafter 、 before\n时间格式化 format\n定时器 //定时器 //tick := time.Tick(time.Second) //for i := range tick { // fmt.Println(i) //} 解析字符串格式的时间（时区） now:= time.Now() //获取的是当前时区的时间 fmt.Println(now) //按照东八区的时区和格式解析一个字符串格式的时间 time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2021-08-11 21:33:05\u0026#34;) //根据字符加载时区 location, err := time.LoadLocation(\u0026#34;Asia/Shanghai\u0026#34;) if err!=nil { fmt.Printf(\u0026#34;load loc failed , err :%v\\n\u0026#34;,err) return } //按照指定时区解析时间 parseInLocation, err := time.ParseInLocation(\u0026#34;2006-01-02 15:05:05\u0026#34;, \u0026#34;2021-08-11 21:33:05\u0026#34;, location) fmt.Println(time.Now().Sub(parseInLocation)) 日志库 time\n文件操作\nruntime.caller()\n反射 接口类型的变量分为两部分，动态类型和动态值。\n反射的应用：json等数据解析 ORM等工具\u0026hellip;\n反射的两个方法： reflect.Typeof() reflect.Valueof() 今日内容 strconv标准库介绍 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { str:=\u0026#34;1000\u0026#34; parseInt, err := strconv.ParseInt(str, 10, 64) //10进制 int64 if err != nil { return } fmt.Printf(\u0026#34;%T %v\\n\u0026#34;,parseInt,parseInt) parseInt1, err := strconv.ParseInt(str,10,0) if err != nil { return } fmt.Printf(\u0026#34;%T %v\\n\u0026#34;,parseInt1,parseInt1) atoi,_:=strconv.Atoi(\u0026#34;1000\u0026#34;)//go语言继承c语言而来的 a是array 因为string底层实际上是array的byte数组 i是int fmt.Println(atoi) i :=97 fmt.Println(string(i)) //a sprint := fmt.Sprint(i) //97 //字符串中解析出bool值 s2:=\u0026#34;true\u0026#34; parseBool, _ := strconv.ParseBool(s2) fmt.Println(parseBool) fmt.Println(strconv.ParseFloat(\u0026#34;2.14\u0026#34;,32)) fmt.Println(sprint) } 并发 并发是编程里面一个非常重要的概念，go语言在语言层面天生支持并发，这也是go语言流行的一个很重要的原因。\ngo语言的并发编程 并发与并行 并发：同一时间段内执行多个任务\n并行：同一时刻执行多个任务\ngo语言的并发通过goroutine实现。goroutine类似于线程，属于用户态的线程.我们可以根据需要创建成千上万个goroutine个并发工作。goroutine由go语言的运行时runtime调度完成，而线程是由操作系统调度完成的。\ngo语言还提供channel在多个goroutine间进行通信。goroutine和channel是go语言秉承CSP communication sequential process 并发模式的重要实现基础.\ngoutine 在java和c++中我们要实现并发编程的时候,我们通常要自己维护一个线程池,并且需要自己去包装一个又一个任务,同时需要自己去调度线程执行任务并维护上下文切换,这一切通常会耗费程序员大量的心智.那么能不能有一种机制,程序员只需要定义很多个任务,让系统去帮助我们吧这些任务分配到CPU上实现并发执行呢?\ngo语言中的goroutine就是这样一种机制,goroutine的概念类似于线程,但goroutine是由go的运行时runtime调度和管理的.go程序会智能地将goroutine中的任务合理的分配给每个cpu.go语言之所以被成为现代化的编程语言,就是因为他在语言层面已经内置了调度和上下文切换的机制.\n在go语言变成中你不需要自己去写进线程/线程/协程,你的技能包里只有一个技能 \u0026mdash;- goroutine,当你需要让某个任务并发执行的时候,你只需要把这个任务包装成一个函数,开启一个goroutine去执行这个函数就可以了,就是这么简单粗暴.\n使用goroutine go语言中使用goroutine非常简单,只需要在调用函数的时候在前面加上go关键字,就可以为一个函数创建一个goroutine\n一个goroutine必定对应一个函数,可以创建多个goroutine去执行相同的函数\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) //程序启动之后会创建一个主goroutine去执行 func main() { for i := 0; i \u0026lt; 10; i++ { //go hello(i) //开启一个单独的goroutine去执行hello函数（任务） //匿名 //go func() { // fmt.Println(i) //}() //闭包 会出现i外层是1 内部输出1 外部这时候已经跑到10了 那么这时候内部就输出10 // go func(i int) { fmt.Println(i) //用的是函数参数的那个i ， 不再是外面的那个i了 }(i) } fmt.Println(\u0026#34;main\u0026#34;) //main函数结束了 由main函数启动的goroutine也都结束了 time.Sleep(time.Second) } func hello(i int) { fmt.Println(\u0026#34;hello\u0026#34;,i) } goroutine什么时候结束 goroutine对应的函数执行结束 goroutine就结束了\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { //waitGroup //f1() for i := 0; i \u0026lt;10 ; i++ { wg.Add(1) go f2(i) } //如何知道这10个goroutine都结束了 wg.Wait() //等待wg的计数器减为0 } var wg sync.WaitGroup func f1() { rand.Seed(time.Now().UnixNano()) for i := 0; i \u0026lt; 5; i++ { i1 := rand.Int() i2 := rand.Intn(10) //左开右闭 fmt.Println(i1,i2) } } func f2(i int) { time.Sleep(time.Millisecond*time.Duration(rand.Intn(300))) fmt.Println(i) defer wg.Done() } rand func f1() { rand.Seed(time.Now().UnixNano()) for i := 0; i \u0026lt; 5; i++ { i1 := rand.Int() i2 := rand.Intn(10) //左开右闭 fmt.Println(i1,i2) } } goroutine与线程 可增长的栈 OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB），一个goroutine的栈在其生命周期开始时只有很小的栈（典型情况下2KB），goroutine的栈不是固定的，他可以按需增大和减小，goroutine的栈大小限制可以达到1GB，虽然极少会用到这么大，所以在go语言中一次创建10w左右的goroutine也是可以的。\ngoroutine调度 GMP是go语言运行时runtime层面的实现，是go语言自己实现的一套调度系统。区别与操作系统调度OS线程。\nG很好理解，就是个goroutine的，里面除了存放goroutine信息外 还有与所在P的绑定等信息 M machine是Go运行时runtine对操作系统内核线程的虚拟，M与内核线程一般是一一映射的关系，一个goroutine最终是要放到M上执行的 P管理着一组goroutine队列，P里面会存储当前goroutine运行的上下文环境（函数指针、堆栈地址及地址边界），P会对自己管理的goroutine队列做一些调度（比如把占用CPU时间较长的goroutine暂停、运行后续的goroutine等等）当自己的队列消费完了就去全局队列里取，如果全局队列里也消费完了会去其他P的队列里抢任务。 P与M一般也是一一对应的。她们关系是：P管理着一组G挂载在M上运行。当一个G长久的阻塞在一个M上时，runtime会新建一个M，阻塞G所在的P会把其他的G挂载在新建的M上。当旧的G阻塞完成或者认为其已经死掉时，回收掉旧的M\nP的个数是通过runtime.GOMAXPROCS设定的，最大为256 go1.5版本之后默认为物理线程数。在并发量大的时候会增加一些P和M，但不会太多，切换太频繁的话会得不偿失\n单从线程调度讲，Go语言相比起来其他语言的优势在于OS线程是有OS内核来调度的。goroutine则是由Go运行时 runtime自己的调度器调度的。这个调度器使用一个成为m：n调度技术（复用/调度m个goroutine到n个OS线程）其一大特点是goroutine的调度是在用户态下完成的，不涉及内核态与用户态之间的频繁切换，包括内存的分配与释放都是在用户态维护着一大块的内存池，不直接调用系统的malloc函数（除非内存池需要改变），成本比调度OS线程低很多。另一方面充分利用了多核的硬件资源，近似的吧若干goroutine均分在物理线程上，再加上本身goroutine的超轻量，以上种种保证了go调度方面的性能。\nGOMAXPROCS go运行时的调度使用gomaxprocs参数来确定需要使用多少个OS线程来同时执行go代码。默认值是机器上的CPU核心数。例如在一个8核心的机器上，调度器会把go代码同时调度到8个OS线程上(GOMAXPROCS是m：n调度中的n)\ngo语言中可以通过runtime.gomaxprocs()函数来设定当前程序并发时占用的CPU逻辑核心数\ngo1.5版本之前，默认使用的是单核心执行。go1.5版本之后，默认使用全部的CPU逻辑核心数\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;sync\u0026#34; ) var wg sync.WaitGroup func main() { runtime.GOMAXPROCS(2) //默认CPU的逻辑核心数，默认跑满整个CPU fmt.Println(runtime.NumCPU()) wg.Add(2) go a() go b() wg.Wait() } func a() { for i := 0; i \u0026lt; 10; i++ { fmt.Printf(\u0026#34;A:%d\\n\u0026#34;,i) } defer wg.Done() } func b() { for i := 0; i \u0026lt; 10; i++ { fmt.Printf(\u0026#34;B:%d\\n\u0026#34;,i) } defer wg.Done() } go语言中的操作系统线程和goroutine的关系 一个操作系统线程对应用户态多个goroutine go程序可以同时使用多个操作系统线程 goroutine和OS线程是多对多的关系，即m:n goroutine调度模型 GMP\nm：n\ngoroutine初始栈的大小是2k\nchannel 单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行的意义\n虽然可以使用共享内存进行数据交换，但是共享内存在不同的goroutine中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，但这种做法势必造成性能问题。\ngo语言的并发模型是CSP communication sequential processes 提倡通过通信共享内存而不是通过共享内存而实现通信\n如果说goroutine是go程序并发的执行体，channel就是他们之间的连接。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制\ngo语言中的通道channel是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出fifo的规则，保证收发数据的顺序。每一个通道都是具体类型的导管，也就是声明channel的时候需要为其指定元素类型。\nchannel类型 var 变量 chan 元素类型 通道必须使用make函数初始化才能使用\n发送 将一个值发送到通道中\nch \u0026lt;- 10 //把10发送到ch 接收 从一个通道接收值\nx := \u0026lt;- ch //从ch中接收值并赋值 \u0026lt;- ch //从ch中接收值，忽略结果 关闭 我们通过调用内置的close函数来关闭通道\nclose(ch) 关于关闭通道需要注意的事情是，只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。通道是可以被垃圾回收机制回收的，他和关闭文件不一样，在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。\n关闭后的通道有以下特点：\n对一个关闭的通道再发送值就会导致panic 对一个关闭的通道进行接收就会一直获取直到通道为空 对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值 关闭一个已经关闭的通道会导致panic 无缓冲通道 无缓冲的通道又称为阻塞的通道。无缓冲的通道只在有人接收值的时候才能发送值。无缓冲通道上的发送操作会阻塞，直到另一个goroutine在该通道上执行接收操作，这个值才能发送成功，两个goroutine将继续执行。相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个goroutine在该通道上发送一个值。使用无缓冲通道进行通信将导致发送和接收的goroutine同步化。因此，无缓冲通道也被成为同步通道\n有缓冲通道 在使用make初始化的时候为其指定通道的容量\n只要通道的容量大于零，那么该通道就是有缓冲的通道，通道的容量表示通道中能存放元素的数量。\n我们可以使用内置的len函数获取通道内元素的数量，使用cap函数获取通道的容量\n如何优雅的从通道循环取值 当通过通道发送有限的数据时，我们可以通过close函数关闭通道来告知从该通道接收值的goroutine停止等待。当通道被关闭时，往该通道发送值会引发panic，从该通道里接收的值一直都是类型的零值。那么如何判断一个通道是否被关闭了呢？\n单向通道 有的时候我们会将通道作为参数在多个任务函数间传递，很多时候我们在不同的任务函数中使用通道都会对其进行限制，比如只能发送或只能接收。go语言中提供了单向通道来处理这种情况。\nvar ch1 \u0026lt;-chan //只能取值 var ch2 chan\u0026lt;- //只能存值 image-20210813220847452\rworker pool （goroutine池） 编写代码实现一个计算随机数的每个位置数字之和的程序。要求使用goroutine和channel构建生产者和消费者模式，可以指定启动的goroutine数量-worker pool模式\n在工作中我们通常会用worker pool模式，控制goroutine数量，防止goroutine泄漏和暴涨\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) var jobs chan int var results chan int func main() { jobs = make(chan int , 100) results = make(chan int , 100) for i := 1; i \u0026lt;= 3; i++ { go worker(i,jobs,results) } for i := 1; i \u0026lt;= 5; i++ { jobs\u0026lt;-i } for i := 0; i \u0026lt; 5; i++ { \u0026lt;-results } //for result := range results { // fmt.Println(result) //} } func worker(id int, jobs \u0026lt;-chan int, results chan\u0026lt;- int) { for j := range jobs { fmt.Println(\u0026#34;worker \u0026#34;,id,\u0026#34; start job \u0026#34;,j) time.Sleep(time.Second) results\u0026lt;-2*j fmt.Println(\u0026#34;worker \u0026#34;,id,\u0026#34; end job\u0026#34; , j) } } 练习 select多路复用 在某些场景下我们需要同时从多个通道接收数据。通道在接收数据时，如果没有数据可以接收将会发生阻塞。你也许会写出如下代码使用遍历的方式来实现\nimage-20210813232439809\r这种方式虽然可以实现从多个通道接收值的要求，但是运行性能会差很多。为了应对这种场景，go内置了select关键字，可以同时响应多个通道的操作。select的使用类似于switch语句，他有一些case分支和一个默认的分支。每个case会对应一个通道的通信（接收或发送）过程。select会一直等待，直到某个case的通信操作完成时，就会执行case分支对应的语句。\nimage-20210813232707904\r使用select语句能提高可读性\n可处理一个或多个channel的发送/接收操作 如果有多个case同时满足，select会随机选择一个 对于没有case的select{}会一直等待，可用于阻塞main函数 package main import \u0026#34;fmt\u0026#34; func main() { ch:=make(chan int , 1) for i := 0; i \u0026lt; 10; i++ { select { case x:=\u0026lt;-ch: fmt.Println(x) case ch\u0026lt;-i: default: fmt.Println(\u0026#34;hiahiahia\u0026#34;) } } } 并发安全和锁 作业 日志库中channel怎么用 什么时候起后台的goroutine去写日志到文件中 day08 今日内容 并发のgoroutine 并发和并行的区别\ngoroutine的启动 go\n将并发执行的任务包装成一个函数，调用函数的时候前面加上go关键字，就能够开启一个goroutine去执行该函数\ngoroutine对应的函数执行完，该goroutine就结束了\n程序启动的时候会自动的创建一个goroutine去执行main函数，main函数结束了那么程序就结束了所有开启的goroutine也都结束了\nsync.waitGroup 等待组\nvar wg waitGroup wg.add(1):计数器+1 wg.done()：计数器-1 wg.wait()：等待 goroutine的本质 goroutine的调度模型GMP\nm：n 把m个goroutine分配给n个操作系统的线程\ngoroutine与操作系统线程（OS）的区别 goroutine是用户态的线程，比内核态的线程更轻量级一点，初始值2Kb\nruntime.GOMAXPROCS() go1.5之后模式就是操作系统的逻辑核心数,默认跑满cpu\nruntime.GOMAXPROCS(1)只占用一个核心\nwork pool 模式 开启一定数据的goroutine去干活。\nchannel为什么需要 想通过channel实现多个goroutine的通信\nCSP ：通过通信来共享内存\nchannel是一种类型，一种引用类型。make函数初始化才能使用（slice / map /channel）\nchannel的声明 var ch chan int\nchannel的初始化 make(chan 元素类型，[缓冲区大小])\nchannel的操作：\n发送\u0026lt;-\n接收\u0026lt;-\n关闭close\n带缓冲区的通道和无缓冲区的通道\n单向通道 通常是用做函数的参数，只读和只写\nselect 同一时刻有多个通道要操作的场景，使用select\nsync包 互斥锁 互斥锁是一种常用的控制共享资源访问的方法，他能够保证同时只有一个goroutine可以访问资源，go语言中使用sync包的mutex类型来实现互斥锁。使用互斥锁来修复上面的代码\n使用互斥锁能够保证同一时间有且只有一个goroutine进入临界区，其他的goroutine则在等待锁，当互斥锁释放后，等待的goroutine才可以获取锁进入临界区，多个goroutine同时等待一个锁时，唤醒的策略是随机的\n读写互斥锁 互斥锁是完全互斥的，但是很多实际场景下是读多写少的，当我们并发的去读取一个资源不涉及资源修改的时候是没有必要加锁的，这种场景下使用读写锁是更好的一种选择。读写锁在go语言中使用sync包中的rwmutex类型。\n读写锁分为两种：读锁和写锁。当一个goroutine获取读锁之后，其他的goroutine如果是获取读锁会继续获取锁，如果是获取写锁就会等待；当一个goroutine获取写锁之后，其他的goroutine无论是获取读锁还是写锁都会等待。\nsync.waitgroup 在代码中生硬的使用time.sleep肯定是不合适的，go语言中可以使用sync.waitgroup来实现并发任务的同步\nwg.add\nwg.done\nwg.wait\nsync.waitgroup内部维护着一个计数器，计数器的值可以增加和减少。当我们启动了n个并发任务，就将计数器增加n，每个任务完成时通过调用done方法将计数器减一，通过调用wait来等待并发任务执行完，当计数器为0时，表示所有并发任务已经完成。\nsync.once 在编程的很多场景下我们需要确保某些操作在高并发的场景下只执行一次，例如只加载一次配置文件、只关闭一次通道等\ngo语言中的sync包中提供了一个针对只执行一次场景的解决方案\u0026ndash;sync.once\nsync.once只有一个do方法\nfunc (o *Once) Do (f func()) {} 备注：如果要执行的函数f需要传递参数就需要搭配闭包来使用\nsync.map map并发多了之后执行就会报fatal error: concurrent map writes 错误\n像这种场景下就需要为map加锁来保证并发的安全性了，go语言的sunc包中提供了一个开箱即用的并发安全版map\u0026mdash;-sync.map 开箱即用表示不用向内置map一样使用make函数初始化就能直接使用。同时sync.map内置了诸如store 、 load 、 loadorstore 、 delete 、 range等操作方案\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) var wg = sync.WaitGroup{} var m = sync.Map{} func main() { for i := 0; i \u0026lt; 20; i++ { wg.Add(1) go func(i int) { key:=strconv.Itoa(i) set(key,i) //必须使用sync.map内置的store方法设置键值对 fmt.Printf(\u0026#34;k=%v v=%v\\n\u0026#34;,key,get(key)) //必须使用sync.map内置的load方法根据key取值 wg.Done() }(i) } wg.Wait() } func set(key string , value int) { m.Store(key,value) } func get(key string) interface{} { value,_:=m.Load(key) return value } atomic包 func loadint32\nfunc storeint32\nfunc addint32\nfunc swapint32\nfunc compareandswapint32\n网络编程 如何才能让我们的程序通过网络互相通信呢？本文只是演示了如何使用net包进行tcp和udp通信。\n互联网协议介绍 互联网的核心是一系列协议，总称为互联网协议internet protocol suite ， 正是这些协议规定了电脑如何连接和组网。我们理解了这些协议，就理解了互联网的原理。由于这些协议太过复杂和庞大，只能介绍日常开发中接触较多的几个协议\n互联网分层模型 互联网的逻辑实现被分为好几层。每一层都有自己的功能。互联网按照不同的模型划分会有不同的分层，但是不论是按照什么模型去划分，越往上的层越靠近用户，越往下的层越靠经硬件。在软件开发中我们使用最多的是将互联网划分为五个分层的模型。\nimage-20210815154839385\r物理层 我们的电脑要与外界互联网通信，需要先把电脑连接网络，我们可以用双绞线、光纤、 无线电波等方式。这就叫做“实物理层”，他就是把电脑连接起来的物理手段。他主要规定了网络的一些电气特性，作用是负责传送0和1的电信号。\n数据链路层 单纯的0和1没有任何意义，所以我们使用者会为其赋予一些特定的含义，规定解读电信号的方式：多少个电信号算一组？每个信号为有何意义？这就是数据链路层的功能，他在物理层的上方，确定了物理层传输0和1的分组方式及代表的意义。早起的时候，每家公司都有自己的电信号分组方式。逐渐的，一种叫做以太网ethernet的协议占据了主导地位。\n以太网规定，一组电信号构成一个数据包，叫做帧frame。每一帧分为两部分：标头head和数据data。其中表头包含数据包的一些说明项，比如发送者、接收者、数据类型等等。数据则是数据包的具体内容。标头的长度固定为18字节。数据的长度最短为46字节，最长为1600字节。因此，整个帧最短为64字节，最长为1518字节。如果数据很长，就必须分割成多个帧进行发送。\n那么，发送者和接收者是如何标识的呢？以太网规定，连入网络的所有设备都必须具有网卡接口。数据包必须是从一块网卡，传送到另一块网卡。网卡的地址，就是数据包的发送地址和接收地址，这叫做MAC地址。每块网卡出厂的时候，都有一个全世界独一无二的MAC地址，长度是48个二进制位，通常用12个十六进制数来表示。前6个十六进制是厂商编号，后6个是该厂商的网卡流水号。有了MAC地址，就可以定位网卡和数据包的路径了。\n我们会通过ARP协议来获取接收方的MAC地址，有了MAC地址之后，如何把数据准确的发送给接收方呢？ 其实这里以太网采用了一种很原始的方式，他不是把数据准确的送到接收方，而是向本网络内所有的计算机都发送，让每台计算机读取这个包的标头，找到接收方的MAC地址，然后与自身的MAC地址相比较，如果两者相同，就接受这个包，做进一步处理，否则就丢弃这个包。这种发送方式就叫做广播broadcast\n网络层 按照以太网协议的规则我们可以依靠MAC 地址来向外发送数据。理论上依靠MAC地址，你电脑的网卡就可以找到身在师姐另一个儿角落的某台电脑的网卡了，但是这种做法有一个重大缺陷就是以太网采用广播方式发送数据包，所有成员人手一包，不仅效率低，而且发送的数据只能局限在发送者所在的子网络。也就是说如果两台计算机不在同一个子网络，广播是传不过去的。这种设计是合理且必要的，因为如果互联网上每一台计算机都会收到互联网上收发的所有数据包，那是不现实的。\n因此，必须找到一种方法区分那些MAC地址属于同一个子网络，那些不是。如果是同一个子网络，就采用广播方式发送，否则就采用路由方式发送。这就导致了网络层的诞生。他的作用是引进一套新的地址，使得我们能够区分不同计算机是否属于同一个子网络。这套地址就叫做网络地址，简称网址\n网络层出现以后，每台计算机有了两种地址，一种是MAC地址，另一种是网址。两种地址之间没有任何联系，MAC地址是绑定在网卡上的，网络地址则是网络管理员分配的。网络地址帮助我们确定计算机所在的子网络,MAC地址则将数据包发送到该子网络中的目标网卡上。因此，从逻辑上可以推断，必定是先处理网络地址，然后在处理MAC地址。\n规定网络地址的协议，叫做IP协议。它所定义的地址，就被称为IP地址。目前，广泛采用的是IP协议第四版，简称IPv4.IPv4这个版本规定，网络地址由32个二进制为组成，我们通常习惯用分成四段的十进制数表示IP地址，从0.0.0.0一直到255.255.255.255\n根据IP协议发送的数据，就叫做IP数据包。IP数据包也分为标头和数据两个部分：标头部分主要包括版本、长度、IP地址等信息，数据部分则是IP数据包的具体内容，IP数据包的标头部分的长度为20到60字节，整个数据包的总长度最大为65535字节。\n传输层 有了MAC地址和IP地址，我们已经可以在互联网上任意两台主机上建立通信。但问题是同一台主机会有许多程序都需要用网络收发数据，比如QQ和浏览器这两个程序都需要连接互联网并收发数据，我们如何区分某个数据包到底是归哪个程序呢？也就是说，我们还需要一个参数，表示这个数据包到底供哪个程序（进程）使用。这个参数就叫做端口port，他其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。\n端口是0到65535之间的整数，正好是16个二进制位。0到1023的端口被系统占用，用户只能选用大于1023的端口。 有了IP和端口我们就能实现唯一确定互联网上的一个程序，进而实现网络间的程序通信。\n我们必须在数据包中加入端口信息，这就是需要新的协议。最简单的实现叫做UDP协议，他的格式几乎就是在数据的前面，加上端口号。UDP数据包，也就是由标头和数据两部分组成：标头部分主要定义了发出端口和接收端口，数据部分就是具体的内容。UDP数据包非常简单，标头部分一共只有8个字节，总长度不超过65535字节，正好放进一个IP数据包。\nUDP协议的优点是比较简单，容易实现，但是缺点是可靠性较差，一旦数据包发出，无法知道对方是否收到。为了解决这种问题，提高网络可靠性，TCP协议就诞生了。TCP协议能够确保数据不会遗失。他的缺点是过程复杂、实现困难、消耗较多的资源、TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。\n应用层 应用程序收到传输层的数据，接下来就要对数据进行解包。由于互联网是开放架构，数据来源五花八门，必须事先规定好通信的数据格式，否则接收方根本无法获得真正发送的数据内容。应用层的作用就是规定应用程序使用的数据格式，例如我们TCP协议之上常见的Email、HTTP、FTP等协议，这些协议就组成了互联网协议的应用层。\n如图，发送方的HTTP数据经过互联网的传输过程中会依次添加各层协议的标头信息，接收方收到数据包之后再依次根据协议解包得到数据。\rimage-20210815163841064\rsocket编程 socket是BSD UNIX的进程通信机制，通常也称为套接字，用于描述IP地址和端口，是一个通信链的句柄。socket可以理解为TCP/IP网络的API，它定义了许多函数或例程，程序员可以用它们来开发TCP/IP网络上的应用程序。电脑上运行的应用程序通常通过套接字向网络发出请求或者应答网络的请求。\nsocket图解 socket是应用层与TCP/IP协议族通信的中间软件抽象层。在设计模式中，socket其实就是一个门面模式，他把复杂的TCP/IP协议族隐藏在socket后面，对用户来说只需要调用socket规定的相关函数，让socket去组织符合指定的协议数据然后进行通信。\nimage-20210815165946914\rgo语言实现TCP通信 TCP协议 TCP/IP transmission control protocol 、 internet protocol即传输控制协议/网间协议，是一种面向连接（连接导向）的、可靠的、基于字节流的传输层（Transport layer）通信协议，因为是面向连接的协议，数据就像水流一样传输，会存在粘包问题。\nTCP服务端 一个TCP服务端可以同时连接很多个客户端，例如世界各地的用户使用自己电脑上的浏览器访问淘宝网。因为go语言中创建多个goroutine实现并发非常方便和高效，所以我们可以每建立一次链接就创建一个goroutine去处理。\nTCP服务端程序的处理流程：\n监听端口 接收客户端请求建立链接 创建goroutine处理连接 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) //tcp server端 func main() { //1.本地端口启动服务 listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:20000\u0026#34;) if err != nil { fmt.Println(\u0026#34;start server on 127.0.0.1:20000 failed , err : \u0026#34;,err) return } for { //2.等待别人来跟我连接 accept, err := listen.Accept() if err != nil { fmt.Println(\u0026#34;build connect failed , err : \u0026#34;,err) return } go func(conn net.Conn) { for { //3.与客户端通信 var temp [128]byte read, err := conn.Read(temp[:]) if err != nil { fmt.Println(\u0026#34;attemp read failed , err : \u0026#34;,err) return } fmt.Println(string(temp[:read])) } }(accept) } } client\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) //tcp client func main() { //1.与server建立连接 dial, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:20000\u0026#34;) if err != nil { fmt.Println(\u0026#34;dial 127.0.0.1:20000 failed , err : \u0026#34;,err) return } //2.发送数据 //var write1 = make([]byte,100) //if len(os.Args)\u0026lt;2 { // write1 = []byte(\u0026#34;hello world\u0026#34;) //}else { // write1 = []byte(os.Args[1]) //} for { reader := bufio.NewReader(os.Stdin) //dial.Write(write1) line, _ := reader.ReadString(\u0026#39;\\n\u0026#39;) if string(line)==\u0026#34;exit\u0026#34; { break } dial.Write([]byte(line)) } dial.Close() } TCP黏包 黏包可发生在发送端也可发生在接收端：\n由Nagle算法造成的发送端的黏包：nagle算法是一种改善网络传输效率的算法。简单来说就是当我们提交一段数据给TCP发送时，TCP并不立刻发送此段数据，而是等待一小段时间看看在等待期间是否还有要发送的数据，如有会一次把这两段数据发送出去。 接收端接收不及时造成的接收端黏包：TCP会把接收到的数据存在自己的缓冲区中，然后通知应用层取数据。当应用层由于某些原因不能及时的把TCP的数据取出来，就会造成TCP缓冲区中存放了几段数据。 image-20210816200320281\rserver\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { dial, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:30000\u0026#34;) if err != nil { fmt.Println(\u0026#34;dial failed , error : \u0026#34;,err) return } defer dial.Close() for i := 0; i \u0026lt; 20; i++ { dial.Write([]byte(\u0026#34;how are you , hello !\u0026#34;)) } } server\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; ) func main() { listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:30000\u0026#34;) if err != nil { fmt.Println(\u0026#34;listen port failed , err : \u0026#34;,err) return } defer listen.Close() for { accept, err := listen.Accept() if err != nil { fmt.Println(\u0026#34;connect accept failed , err :\u0026#34;, err) return } go func(conn net.Conn) { defer conn.Close() for { var b [1024]byte read, err := conn.Read(b[:]) if err == io.EOF { break } if err != nil { fmt.Println(\u0026#34;try to read failed , err : \u0026#34;,err) return } fmt.Println(\u0026#34;received data : \u0026#34;,string(b[:read])) } }(accept) } } 解决方法 出现黏包的关键在于接收方不确定将要传输的数据包的大小，因此我们可以对数据包进行封包和拆包的操作。\n封包：封包就是给一段数据加上包头，这样一来数据包就分为包头和包体两部分内容了（过滤非法包时封包会加入”包尾“内容）。包头部分的长度是固定的，并且他存储了包体的长度，根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据包。\n我们可以自己定义一个协议，比如数据包的前四个字节为包头，里面存储的是发送的数据的长度。\n大端小端模式\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;src/code.oldboyedu.com/day8/11nianbao_jiejue/protocol\u0026#34; ) func main() { dial, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:30000\u0026#34;) if err != nil { fmt.Println(\u0026#34;dial failed , error : \u0026#34;,err) return } defer dial.Close() for i := 0; i \u0026lt; 20; i++ { encode, err := protocol.Encode(\u0026#34;how are you , hello!\u0026#34;) if err != nil { return } dial.Write(encode) //dial.Write([]byte(\u0026#34;how are you , hello !\u0026#34;)) } } protocol\npackage protocol import ( \u0026#34;bufio\u0026#34; \u0026#34;bytes\u0026#34; \u0026#34;encoding/binary\u0026#34; ) //Encode 将消息编码 func Encode(message string )([]byte,error) { //读取消息的长度，转换为int32 length := int32(len(message)) pkg := new(bytes.Buffer) //写入消息头 err := binary.Write(pkg, binary.LittleEndian, length) if err != nil { return nil, err } //写入消息体 err1 := binary.Write(pkg, binary.LittleEndian, []byte(message)) if err1 != nil { return nil, err1 } return pkg.Bytes(),err } //Decode 解码消息 func Decode(reader *bufio.Reader) (string, error) { //读取消息的长度 peek, err := reader.Peek(4) if err != nil { return \u0026#34;\u0026#34;, err } //读取前四个字节的数据 buffer := bytes.NewBuffer(peek) var length int32 err1 := binary.Read(buffer, binary.LittleEndian, \u0026amp;length) if err1 != nil { return \u0026#34;\u0026#34;, err1 } //Buffered 返回缓冲区中现有的可读取的字节数 if int32(reader.Buffered()) \u0026lt; length+4 { return \u0026#34;\u0026#34; , err } //读取真正的消息数据 pack:=make([]byte,int(4+length)) _,err2:=reader.Read(pack) if err2!=nil { return \u0026#34;\u0026#34;,err2 } return string(pack[4:]),nil } server\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;src/code.oldboyedu.com/day8/11nianbao_jiejue/protocol\u0026#34; ) func main() { listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:30000\u0026#34;) if err != nil { fmt.Println(\u0026#34;listen port failed , err : \u0026#34;,err) return } defer listen.Close() for { accept, err := listen.Accept() if err != nil { fmt.Println(\u0026#34;connect accept failed , err :\u0026#34;, err) return } go func(conn net.Conn) { defer conn.Close() for { reader := bufio.NewReader(conn) decode, err := protocol.Decode(reader) if err != nil { return } fmt.Println(\u0026#34;received data : \u0026#34;,decode) } }(accept) } } UDP协议 UDP协议 user datagram protocol中文名称是用户数据报协议，是OSI open system interconnection ， 开放式系统互联，参考模型中一种无连接的传输层协议，不需要建立连接就能直接进行数据发送和接收，属于不可靠的，没有时序的通信，但是UDP协议的实时性比较好，通常用于视频直播相关领域\nUDP服务端 server\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;strings\u0026#34; ) func main() { udp, err := net.ListenUDP(\u0026#34;udp\u0026#34;,\u0026amp;net.UDPAddr{ IP: net.IPv4(127,0,0,1), Port: 40000, }) if err != nil { fmt.Println(\u0026#34;listen failed , error : \u0026#34;,err) return } //不需要建立链接，直接收发数据 var b [1024]byte defer udp.Close() for { n, addr, err := udp.ReadFromUDP(b[:]) if err != nil { fmt.Println(\u0026#34;read from udp failed , err: \u0026#34; , err) return } fmt.Println(b[:n]) reply:=strings.ToUpper(string(b[:n])) //发送数据 udp.WriteToUDP([]byte(reply),addr) } } client\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) func main() { //UDP client socket, err := net.DialUDP(\u0026#34;udp\u0026#34;,nil,\u0026amp;net.UDPAddr{ IP: net.IPv4(127, 0, 0, 1), Port: 40000, }) if err != nil { fmt.Println(\u0026#34;dial failed , error : \u0026#34;,err) return } defer socket.Close() reader := bufio.NewReader(os.Stdin) var reply [1024]byte for { readString, err := reader.ReadString(\u0026#39;\\n\u0026#39;) if err != nil { return } socket.Write([]byte(readString)) //收回复的数据 n, adder, err := socket.ReadFromUDP(reply[:]) if err != nil { return } fmt.Println(\u0026#34;received data: ,addr : \u0026#34;,string(reply[:n]),adder) } } day09 日志收集项目\ngin框架和微服务\ndocker和k8s\n今日分享 注释/日志/单元测试\n今日内容 context\n单元测试\npprof调试工具\n内容回顾 互斥锁 sync.mutex\n是一个结构体 是值类型 。给函数传参数的时候要传指针\nlock 和 unlock\n为什么要用锁 防止同一时刻多个goroutine操作同一资源\n读写互斥锁 适用于读多写少的场景下,才能提高程序的执行效率\n特点:\n如果是读的人来获取的是读锁,后续的goroutine能读不能写 如果是写的goroutine来了,获取的是写锁,后续的goroutine不管是读还是写,都要等待获取锁 rwlock.rlock()\nrwlock.wlock()\nrwlock.lock()\nrwlock.unlock()\n等待组 sync.waitgroup\n用来等goroutine执行完再继续\n是一个结构体,是值类型,给函数传参数的时候要传指针\nwg.add()\nwg.done()\nwg.wait()\nsync.Once 使用场景\n某些函数只需要执行一次的时候，就可以使用sync.once\nonce.Do(func ( ) )\n接收无参数无返回值的函数参数\nsync.Map 使用场景\n并发操作一个map的时候，内置的map不是并发安全的\n使用，是一个开箱即用的(不需要make）并发安全的map\nvar map sync.Map\nload()\nstore()\nloadorstore()\ndelete()\nrange()\n原子操作 go语言内置了一些针对内置的基本数据类型的一些并发安全的操作\nvar i int64 =10 atomic.addint64(\u0026amp;i,1) 网络编程 互联网协议 OIS七层模型\n应用层 表示层 会话层 传输层 网络层 数据链路层 物理层\nHTTP客户端和服务端 go语言内置的net/http包提供了http客户端和服务端的实现\nHTTP协议 超文本传输协议HTTP hypertext transfer protocol 是互联网上应用最为广泛的一种网络传输协议，所有www文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。\nHTTP客户端 使用net / http 包编写一个简单的发送HTTP请求的client端\nimage-20210817000221229\rHTTP：超文本传输协议\n规定了：浏览器和网站服务器之间通信的规则\nHTML：超文本标记语言\n学的就是标记的符号、标签\nCSS：层叠样式表\n规定了HTML中标签的具体样式（颜色、背景、大小、位置、浮动\u0026hellip;）\nJS：一种跑在浏览器上的编程语言\nhttp_server\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; ) //net / http server func main() { http.HandleFunc(\u0026#34;/posts/go/15_socket/\u0026#34;,f1) http.HandleFunc(\u0026#34;/xxx/\u0026#34;,f2) http.ListenAndServe(\u0026#34;127.0.0.1:9090\u0026#34;,nil) } func f2(writer http.ResponseWriter, request *http.Request) { //对于get请求 参数都放在URL上 （query param）请求体中是没有数据的 fmt.Println(request.URL) fmt.Println(request.Method) fmt.Println(ioutil.ReadAll(request.Body)) writer.Write([]byte(\u0026#34;ok!\u0026#34;)) queryParam :=request.URL.Query() fmt.Println(queryParam) name:=queryParam.Get(\u0026#34;name\u0026#34;) fmt.Println(name) age:=queryParam.Get(\u0026#34;age\u0026#34;) fmt.Println(age) } func f1(w http.ResponseWriter, r *http.Request) { file, err := ioutil.ReadFile(\u0026#34;./xx.txt\u0026#34;) if err != nil { w.Write([]byte(fmt.Sprintf(\u0026#34;%v\u0026#34;,err))) return } w.Write(file) } http_client\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/url\u0026#34; ) //net/http client func main() { f1() f2() f3() } //构造一个client var client= http.Client{ Transport: \u0026amp;http.Transport{ DisableKeepAlives:false}} func f3() { //构造参数 urlparams := url.Values{} urlparams.Add(\u0026#34;name\u0026#34;,\u0026#34;ljs\u0026#34;) urlparams.Add(\u0026#34;score\u0026#34;,\u0026#34;100\u0026#34;) //构造头部 urlParse, _ := url.ParseRequestURI(\u0026#34;http://127.0.0.1:9090/xxx\u0026#34;) //拼接url urlParse.RawQuery = urlparams.Encode() //构造一个请求 request request, _ := http.NewRequest(\u0026#34;get\u0026#34;, urlParse.String(), nil) response, _ := client.Do(request) defer response.Body.Close() ioutil.ReadAll(response.Body) } func f2() { //构造请求 uri, _ := url.ParseRequestURI(\u0026#34;http://127.0.0.1:9090/xxx\u0026#34;) data:=url.Values{} data.Set(\u0026#34;name\u0026#34;,\u0026#34;林の树\u0026#34;) data.Set(\u0026#34;age\u0026#34;,\u0026#34;18\u0026#34;) urlStr := data.Encode() fmt.Println(urlStr) uri.RawQuery=urlStr fmt.Println(uri) request, err := http.NewRequest(\u0026#34;Get\u0026#34;, uri.String(), nil) if err != nil { fmt.Println(\u0026#34;request failed ,error : \u0026#34;,err) return } //发请求 response, err := http.DefaultClient.Do(request) if err != nil { return } defer response.Body.Close() //一定要记得关闭resp.body all, err := ioutil.ReadAll(response.Body) if err != nil { return } fmt.Println(string(all)) } func f1() { response, err := http.Get(\u0026#34;http://127.0.0.1:9090/xxx?name=ljs\u0026amp;age=18\u0026#34;) if err != nil { fmt.Println(\u0026#34;get failed , error : \u0026#34;,err) return } //从response中吧服务端返回的数据读出来 read, err := ioutil.ReadAll(response.Body) if err != nil { fmt.Println(\u0026#34;read failed , error : \u0026#34;,err ) return } fmt.Println(string(read)) } http.get\nhttp.post\nhttp.postform\n单元测试 开发自己给自己的代码写测试\ngo语言中的测试依赖go test命令。编写测试代码和编写普通的go代码过程是类似的，并不需要学习新的语法、规则或工具。\ngo test命令是一个按照一定约定和组织的测试代码的驱动程序。在包目录内，所有以_test.go为后缀名的源代码文件都是go test测试的一部分，不会被go build 编译到最终的可执行文件中。\n在*_test.go文件中有三种类型的函数，单元测试函数、基准测试函数和示例函数。\n类型 格式 作用 测试函数 函数名前缀为test 测试程序的一些逻辑行为是否正确 基准函数 函数名前缀为benchmark 测试函数的性能 示例函数 函数名前缀为example 为文档提供实力文档 go test命令会遍历所有的*_test.go文件中符合上述命名规则的函数，然后生成一个临时的main包用于调用相应的测试函数，然后构建并运行、报告测试结果，最后清理测试中生成的临时文件\n测试函数 测试函数的格式 每个测试函数必须导入testing包，基本格式如下：\nfunc TestName (t *testing.T) { } //testing.T拥有的方法如下 Error Errorf Fail FailNow Failed Fatal Fatalf Log Logf Name Parallel Run Skip SkipNow Skipf Skipped 测试用例和测试组和子测试 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) var m = make([]string,4) //Split 切割字符串 a b c =\u0026gt; [a c] func Split(str ,sep string) []string { i:=0 judge(str,sep,i) return m } func judge(s string,sep string,i int) { if !strings.Contains(s,sep){ return } index:=strings.Index(s,sep) if s[:index] != \u0026#34;\u0026#34; { m[i] = s[:index] }else { m[i]=s[index+1:] } if s[index+1:]!=\u0026#34;\u0026#34; { m[i+1] = s[index+1:] } judge(m[i+1],sep,i+1) } func main() { got:=Split(\u0026#34;abcb\u0026#34;,\u0026#34;b\u0026#34;) fmt.Println(got) } 测试用例写\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;testing\u0026#34; ) func TestSplit(t *testing.T) { got:=Split(\u0026#34;abcb\u0026#34;,\u0026#34;b\u0026#34;) want:=[]string{\u0026#34;a\u0026#34;,\u0026#34;c\u0026#34;,\u0026#34; \u0026#34;} if !reflect.DeepEqual(got, want) { fmt.Println(\u0026#34;测试用例失败\u0026#34;) t.Errorf(\u0026#34;want %v but got %v\\n\u0026#34;,want,got) } } func TestSplit2(t *testing.T) { got:=Split(\u0026#34;a:b:c\u0026#34;,\u0026#34;:\u0026#34;) want:=[]string{\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;} if !reflect.DeepEqual(got, want) { t.Errorf(\u0026#34;want %v but got %v\\n\u0026#34;,want,got) } } //测试组 func TestSplitGroup(t *testing.T) { type TestCase struct { str string sep string got string want []string } testCase :=[]TestCase{ { str: \u0026#34;abcb\u0026#34;, sep: \u0026#34;b\u0026#34;, want: []string{\u0026#34;a\u0026#34;,\u0026#34;c\u0026#34;,\u0026#34;\u0026#34;}, }, { str:\u0026#34;a:b:c\u0026#34;, sep: \u0026#34;:\u0026#34;, want:[]string{\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;}, }, } for _, v := range testCase { if !reflect.DeepEqual(Split(v.str,v.sep),v.want){ t.Errorf(\u0026#34;want %v but got %v\\n\u0026#34;,v.want,Split(v.str,v.sep)) } } } func TestSingle(t *testing.T) { type TestCase struct { str string sep string got string want []string } testCase:=map[string]TestCase{ \u0026#34;case1\u0026#34;:{ str: \u0026#34;abcb\u0026#34;, sep: \u0026#34;b\u0026#34;, want: []string{\u0026#34;a\u0026#34;,\u0026#34;c\u0026#34;,\u0026#34;\u0026#34;}, }, \u0026#34;case2\u0026#34;:{ str:\u0026#34;a:b:c\u0026#34;, sep: \u0026#34;:\u0026#34;, want:[]string{\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;}, }, } for name, v := range testCase { t.Run(name, func(t *testing.T) { got:=Split(v.str,v.sep) if !reflect.DeepEqual(got, v.want) { t.Errorf(\u0026#34;want %v but got %v\\n\u0026#34;,v.want,got) } }) } } 尝试新的跨平台 PowerShell https://aka.ms/pscore6 PS E:\\project\\GOproject\\src\\code.oldboyedu.com\\day9\\02splitString\u0026gt; go test -run=TestSingle/case2 --- FAIL: TestSingle (0.00s) --- FAIL: TestSingle/case2 (0.00s) split_test.go:77: want [a b c] but got [a b c ] FAIL exit status 1 FAIL src/code.oldboyedu.com/day9/02splitString 0.240s 测试覆盖率 go test -cover\n函数覆盖率100%\n代码覆盖率60%\n基准测试 基准测试就是在一定的工作负载之下检测程序性能的一种方法。基准测试的基本格式如下：\nfunc BenchName(b *testing.B)\nimage-20210818211645228\r性能比较测试 默认情况下每个基准测试至少运行1s，如果在benchmark函数 返回时没有到1s，则b.N的值会按1,2,5,50\u0026hellip;增加,并且函数再次运行\n可以指定benchtime\n重置时间 b.ResetTimer之前的处理不会放到执行时间里，也不会输出到报告中，所以可以在之前做一些不计划作为测试报告的操作。\n并行测试 runparallel会以并行的方式执行给定的基准测试\n可以调用setparallelism来确定cpu核数\nsetUp和teardown 测试程序有时需要在测试之前进行额外的设置setup或者在测试之后进行拆卸teardown\n示例函数 ExampleName\nprof调试工具 go语言项目中的性能优化主要有以下几个方面：\nCPU profile：报告程序的CPU使用情况，按照一定频率去采集应用程序在CPU和寄存器上面的数据 Memory Profile (Heap Profile) :报告程序的内存使用情况 Block Profiling: 报告goroutines不在运行状态的情况，可以用来分析和查找死锁等性能瓶颈 Goroutine Profiling:报告goroutines的使用情况，有那些goroutine，她们的调用关系是怎么样的 采集性能数据 go语言内置了获取程序的运行数据的工具，包括一下两个标准库\nruntime/pprof:采集工具型应用运行数据进行分析 net/http/pprof:采集服务型应用运行时数据进行分析 pprof开机后，每个一段时间10ms就会收集当前的堆栈信息，获取各个函数占用的cpu以及内存资源；最后通过对这些采样数据进行分析，形成一个性能分析报告。\n注意，我们只应该在性能测试的时候才在代码中引入pprof\nCPU性能分析 pprof.StartCPUProfile(w io.Writer)\npprof.stopCPUPorfile()\n应用执行结束后，就会生成一个文件，保存了我们的CPUprofiling数据。得到采样数据之后，使用go tool pprof工具进行CPU性能分析\n等待30s\n内存性能优化 pprof.WriteHeapProfile(w io.Writer)\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/pprof\u0026#34; \u0026#34;time\u0026#34; ) func main() { var isCPUPprof bool //是否开启cpuprofile标志位 var isMemPprof bool //是否开启内存profile标志位 flag.BoolVar(\u0026amp;isCPUPprof,\u0026#34;cpu\u0026#34;,false,\u0026#34;turn cpu pprof on\u0026#34;) flag.BoolVar(\u0026amp;isMemPprof,\u0026#34;mem\u0026#34;,false,\u0026#34;turn mem pprof on\u0026#34;) flag.Parse() if isCPUPprof { create, err := os.Create(\u0026#34;./cpu.pprof\u0026#34;) if err != nil { fmt.Println(\u0026#34;create file failed , error : \u0026#34;,err) return } pprof.StartCPUProfile(create) //往文件中记录cpu profile信息 defer create.Close() defer pprof.StopCPUProfile() } for i := 0; i \u0026lt; 6; i++ { go logicCode() } time.Sleep(20*time.Second) if isMemPprof{ create, err := os.Create(\u0026#34;./mem.pprof\u0026#34;) if err != nil { fmt.Println(\u0026#34;create file failed , error : \u0026#34;,err) return } pprof.WriteHeapProfile(create) defer create.Close() } } func logicCode() { var c chan int //nil for { select { case v:=\u0026lt;-c: //阻塞 fmt.Printf(\u0026#34;received from chan , value : %v\\n\u0026#34;,v) default: time.Sleep(time.Millisecond*500) } } } 命令行交互界面 使用go工具链里的pprof来分析一下\n服务型应用 flag 通过flag.string or flag.stringvar 定义好命令行flag参数后，需要通过调用flag.parse()来对命令行参数进行解析\n支持的命令行参数格式有以下几种\n-flage xxx \u0026ndash;flag xxx -flag=xxx \u0026ndash;flag=xxx 其中，布尔类型的参数必须使用等号方式指定\nflag解析在第一个非flag参数之前停止 或者在终止符-之后停止\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) //flag 获取命令行参数 func main() { //创建一个标志位参数flag name :=flag.String(\u0026#34;name\u0026#34;,\u0026#34;ljs\u0026#34;,\u0026#34;请输入名字\u0026#34;) age :=flag.Int(\u0026#34;age\u0026#34;,100,\u0026#34;请输入年龄\u0026#34;) married :=flag.Bool(\u0026#34;married\u0026#34;,false,\u0026#34;结婚了么\u0026#34;) cTime:=flag.Duration(\u0026#34;duration\u0026#34;,time.Second,\u0026#34;有多快\u0026#34;) //使用flag //flag.Parse() fmt.Println(*name) fmt.Println(*age) fmt.Println(*married) fmt.Println(*cTime) var name1 string flag.StringVar(\u0026amp;name1,\u0026#34;name1\u0026#34;,\u0026#34;name1\u0026#34;,\u0026#34;请输入name1\u0026#34;) flag.Parse() fmt.Println(name1) fmt.Println(flag.NArg()) //返回除了规定的参数之外的命令行参数有几个 fmt.Println(flag.NFlag()) //返回规定的flag命令行参数有几个 fmt.Println(flag.Args()) //返回除了规定的参数之外的命令行参数具体是 } 面试题 image-20210819001237778\r本周复习 两个面试题\nleetcode刷题每天一道题\n数据结构和算法很重要，要找机会抓紧补上\n内容回顾 net/http包的用法 如何发请求\n当需要频繁发送请求的时候（每5s从阿里云接口同步数据）：定义一个全局的client，后续发请求的操作都使用这个全局的client\n单元测试 xxx/ccc.go\n单元测试的文件名必须是xxx/ccc_test.go\ngo内置的单元测试工具：\ngo test 单元测试函数\n//Test开头后接函数名 func TestSplit(t *testing.T) { } 性能测试/基准测试 函数格式\nfunc BenchmarkSplit(b *testing.B) { //b.N:被测试函数执行的次数 } 执行命令：\ngo test -bench=Split -v 并行测试 setup和teardown pprof 记录cpu和内存的快照信息\nflag标准库 os.Args\nflag.stringvar()返回的是一个指针变量\n必须调用flag.parse()\n./xxx -name = \u0026#34;lsj\u0026#34; -age=90 flag.args\nflag.nargs\nflag.nflag\n今日内容 Mysql：主流的关系型数据库 类似的还有postgreSQL\nredis：kv数据库\nnsq:go语言开发的分布式消息队列\n包的依赖管理go module go1.1之后官方出的依赖管理工具\nMySql 数据库\n常见的数据库：oracle sqlite文件数据库 mysql sqlserver\n关系型数据库：用表来存一类数据\n表结构设计的三大范式《漫画数据库》\nmysql知识点\nsql语句：结构化查询语言\n存储引擎 mysql支持插件式的存储引擎\n常见的存储引擎：myisam、innodb\nmyisam：\n查询速度快 只支持表锁 不支持事务 innodb：\n整体速度快 支持表锁和行锁 支持事务 事务：把多个操作当成一个整体\n事务的特点：\nACID\n原子性：事务要么成功，要么失败，没有中间状态 一致性：数据库的完整性没有被破坏 持久性：事务操作的结果是不会被丢失的 隔离性：事务之间是相互隔离的 隔离级别 读未提交 读提交 可重复读 串行化 索引 索引的原理是：B树和B+树\n索引类型：\n索引的命中\n分库分表\nSQL注入\nSQL慢查询优化\nMysql主从：binlog\nMysql读写分离\nGo操作MySql 连接 go语言中的database/sql包提供了保证SQL或类SQL数据库的泛用接口，并不提供具体的数据库驱动。使用database/sql包时必须注入至少一个数据库驱动。\n我们常用的数据库基本上都有完整的第三方实现。\ndatabase/sql 原生支持连接池，是并发安全的\n这个标准库没有具体实现，只是列出了一些需要第三方库实现的具体内容。\n下载依赖 go get -u github.com/go-sql-driver/mysql\n使用Mysql驱动 func Open(driverName , dataSourceName string)(*DB , error)\nopen一个drivername指定的数据库，datasourcename指定数据源，一般包至少包括\nimage-20210820105514841\rgo get包的路径就是下载第三方的依赖\n将第三方的依赖默认保存在$gopath/src/\n使用驱动 package main import ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;log\u0026#34; ) func main() { //go连接mysql实例 //数据库源信息 dsn:=\u0026#34;root:123456@tcp(127.0.0.1:3306)/tset\u0026#34; //连接数据库 db, err := sql.Open(\u0026#34;mysql\u0026#34;, dsn) //不会校验用户名和密码是否正确 if err != nil { log.Printf(\u0026#34;dsn %s invalid , err : %v\\n\u0026#34;,dsn,db) return } err = db.Ping() if err != nil { log.Printf(\u0026#34;open %s failed , err : %v\\n\u0026#34;,dsn , err) return } fmt.Println(db,\u0026#34;连接数据库成功!\u0026#34;) } github上的mysql驱动如何关联到database/sql这个包里呢？\nimage-20210820123021805\r单行查询 单行查询db.queryrow()执行一次查询，并期望返回最多一行结果row。queryrow总是返回非nil值，直到返回值的scan方法被调用时，才会返回被延迟的错误（如未找到）\nsetmaxopenconns方法 设置与数据库连接池的最大连接数\nsetmaxidleconns方法 setmaxidleconnes设置连接池中的最大闲置连接数。如果n大于最大开启连接数，则新的最大闲置连接数会减小到匹配最大开启连接数的限制。如果n\u0026lt;=0 不会保留闲置连接\n多行查询 多行查询db.query()执行一次查询，返回多行结果（rows），一般用于执行select命令。参数args表示query中的占位参数\n插入数据 插入、更新和删除操作都使用方法 Exec\n删除也是一样的\nMySQL预处理 什么是预处理 普通sql语句执行过程:\n客户端对SQL语句进行占位符替换得到完整的SQL语句 客户端发送完整的SQL语句到MySQL服务端 mysql服务端执行完整的sql语句并将结果返回给客户端 预处理执行过程:\n把sql语句分成两部分,命令部分与数据部分 先把命令部分发送给mysql服务端,mysql服务端进行sql预处理 然后吧数据部分发送给mysql服务端,mysql服务端对sql语句进行占位符替换 mysql服务端执行完整的sql语句并将结果返回给客户端 为什么要预处理 1.优化mysql服务器重复执行sql的方法,可以提升服务器性能,提前让服务器编译,一次编译多次执行,节省后续编译的成本\n2.避免sql注入的问题\ngo实现mysql预处理 prepare方法会先将sql语句发送给mysql服务端,返回一个准备好的状态用于之后的查询和命令.返回值可以同时执行多个查询和命令\npackage main import ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;log\u0026#34; ) type student struct { sno ,sname,ssex string sage int } var db *sql.DB //是一个连接池对象 func main() { initDB() //queryOne(\u0026#34;2016210867\u0026#34;) //queryMany() //insert() //update() prepareSelect() } func initDB() (err error) { dsn:=\u0026#34;root:123456@tcp(127.0.0.1:3306)/tset\u0026#34; db,err =sql.Open(\u0026#34;mysql\u0026#34;,dsn) if err != nil { log.Printf(\u0026#34;dsn %s is invalid , error : %v\\n\u0026#34;,dsn,err) } err = db.Ping() if err != nil { log.Printf(\u0026#34;open %s failed , err : %v\\n\u0026#34;,dsn,err) return err } //设置数据库连接池最大连接数 如果超过了就会阻塞等待其他的程序 db.SetMaxOpenConns(10) //最大空闲连接数 db.SetMaxIdleConns(5) return nil } func queryOne(sno string) { var s student //查找 row := db.QueryRow(\u0026#34;select * from student where sno = ?\u0026#34;,sno) //从连接池中拿一个连接出来去数据库查询单挑记录 //扫描+释放连接 必须对rowobj调用scan方法 row.Scan(\u0026amp;s.sno,\u0026amp;s.sname,\u0026amp;s.ssex,\u0026amp;s.sage) var sname string db.QueryRow(\u0026#34;select sname from student where sno = ?\u0026#34;,sno).Scan(\u0026amp;sname) fmt.Printf(\u0026#34;student: %v \\n\u0026#34;,s) fmt.Println(sname) } func queryMany() { rows, err := db.Query(\u0026#34;select sno , sname , ssex , sage from student \u0026#34;) if err != nil { fmt.Println(\u0026#34;db query failed , error : %v\\n\u0026#34;,err) return } //非常重要 一定要关闭rows defer rows.Close() //循环取值 for rows.Next(){ var s student rows.Scan(\u0026amp;s.sno,\u0026amp;s.sname,\u0026amp;s.ssex,\u0026amp;s.sage) fmt.Println(s) } } func insert() { sql:=\u0026#34;insert into student values (\u0026#39;2020170281\u0026#39;,\u0026#39;ljs\u0026#39;,\u0026#39;man\u0026#39;,23)\u0026#34; exec, err := db.Exec(sql) if err != nil { fmt.Println(\u0026#34;exec insert %s failed , err : %v\\n\u0026#34;,sql,err) return } //如果是插入数据的操作,能够拿到插入数据的id id, err := exec.LastInsertId() if err != nil { fmt.Println(\u0026#34;get id failed ,err : %v\\n\u0026#34;, err) return } fmt.Println(\u0026#34;id:\u0026#34;,id) } func update() { exec, err := db.Exec(\u0026#34;update student set sname = \u0026#39;ljsnew\u0026#39; where sno=\u0026#39;2020170281\u0026#39; \u0026#34;) if err != nil { fmt.Println(err) return } fmt.Println(exec.RowsAffected()) } //预处理方式select多条数据 func prepareSelect() { prepare, err := db.Prepare(\u0026#34;select * from student where sno like ? \u0026#34;)//吧sql语句先发给mysql预处理一下 if err != nil { return } rows, err := prepare.Query(\u0026#34;%2016%\u0026#34;) //后续只需要传值就行了 if err != nil { return } defer prepare.Close() defer rows.Close() for rows.Next () { var s student rows.Scan(\u0026amp;s.sno,\u0026amp;s.sname,\u0026amp;s.ssex,\u0026amp;s.sage) fmt.Println(s) } } go语言实现mysql事务 事务相关方法:begin / commit / rollback\nsqlx使用 第三方库 sqlx 能够简化操作,提高开发效率\n安装 go get github.com/jmoiron/sqlx\n注意事项 SQL中的占位符 不同数据库中,SQL语句使用的占位符语法不尽相同\n数据库 占位符语法 Mysql ? postgresql $1,$2 sqlite ?和$1 oracle :name sql注入 我们任何时候都不应该自己拼接sql语句\npackage main import ( \u0026#34;fmt\u0026#34; _\u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;github.com/jmoiron/sqlx\u0026#34; ) func main() { sqlInjectDemo(\u0026#34;xxx\u0026#39;or 1=1#\u0026#34;) sqlInjectDemo(\u0026#34;xxx\u0026#39; union select * from student #\u0026#34;) } var db *sqlx.DB type student struct { SNO , SNAME , SSEX string SAGE int } func sqlInjectDemo(name string) { //自己拼接sql语句 sqlStr:=fmt.Sprintf(\u0026#34;select * from student where sname =\u0026#39;%s\u0026#39;\u0026#34;,name) fmt.Println(sqlStr) var err error db, err = sqlx.Connect(\u0026#34;mysql\u0026#34;, \u0026#34;root:123456@tcp(127.0.0.1:3306)/tset\u0026#34;) if err != nil { fmt.Println(err) return } err = db.Ping() if err != nil { fmt.Println(err) return } var s []student err = db.Select(\u0026amp;s, sqlStr) if err != nil { fmt.Println(err) return } fmt.Println(s) } image-20210820163242826\rredis kv数据库\nredis的用处\ncache缓存 简单的队列 排行榜 redis是一个开源的内存数据库,redis提供了多种不同类型的数据结构,很多业务场景下的问题都可以很自然地映射到这些数据结构上.除此之外,通过复制/持久化和客户端分片等特性,我们可以很方便的将redis扩展成为一个能够包含数百GB数据/每秒处理上百万次请求的系统\nredis支持的数据结构 redis支持诸如字符串strings 哈希hashes 列表lists 集合sets 带范围查询的排序集合 sorted sets 位图bitmaps hyperloglogs 带半径查询和流的地理空间索引等数据结构 geospatial indexes\nredis应用场景 缓存系统,减轻主数据库mysql的压力 计数场景,比如微博/抖音中的关注数和粉丝数 热门排行榜,需要排序的场景特别适合使用zset 利用list可以实现队列的功能 redis与memcached比较 memcache中的值只支持简单的字符串,redis支持更丰富的5种数据结构类型.redis的性能比memcache好很多.redis支持rdb持久化和aof持久化.redis支持master/slave模式\n安装 go语言中使用第三方库连接redis数据库并进行操作.使用以下命令下载并安装\ngo get -u github.com/go-redis/redis\nget和set zset package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-redis/redis\u0026#34; ) var redisDb *redis.Client func main() { err := initRedis() if err != nil { fmt.Println(err) return } fmt.Println(\u0026#34;连接redis成功\u0026#34;) redisExample() redisExample2() } func initRedis() (err error) { redisDb = redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;127.0.0.1:6379\u0026#34;, Password: \u0026#34;\u0026#34;, DB: 0, }) result, err := redisDb.Ping().Result() if err != nil { return err } fmt.Println(result) return } func redisExample() { err := redisDb.Set(\u0026#34;score\u0026#34;, 100, 0).Err() if err != nil { fmt.Println(err) return } val1, err := redisDb.Get(\u0026#34;score\u0026#34;).Result() if err != nil { return } fmt.Println(\u0026#34;scoer\u0026#34;,val1) val2, err := redisDb.Get(\u0026#34;name\u0026#34;).Result() if err == redis.Nil { fmt.Println(\u0026#34;name does not exist\u0026#34;) } else if err != nil { fmt.Println(err) return }else { fmt.Println(val2) } } func redisExample2() { //zset key:=\u0026#34;rank\u0026#34; items:=[]redis.Z{ redis.Z{ Score: 99, Member: \u0026#34;php\u0026#34;, }, redis.Z{ Score: 96, Member: \u0026#34;golang\u0026#34;, }, redis.Z{ Score: 97, Member: \u0026#34;python\u0026#34;, }, redis.Z{ Score: 99, Member: \u0026#34;java\u0026#34;, }, } fmt.Println(items) //把元素都追加到key中 num, err := redisDb.ZAdd(key,items...).Result() if err != nil { return } fmt.Println(num) //加分数 newScore, err := redisDb.ZIncrBy(key, -1, \u0026#34;java\u0026#34;).Result() if err != nil { return } fmt.Println(newScore) //取分数最高的 scoreList, err := redisDb.ZRevRangeWithScores(key,0,3).Result() if err != nil { return } for _, z := range scoreList { fmt.Println(z.Member,z.Score) } //取95到100分的 option := \u0026amp;redis.ZRangeBy{ Min: \u0026#34;95\u0026#34;, Max: \u0026#34;100\u0026#34;, } ret, err := redisDb.ZRangeByScoreWithScores(key,*option).Result() if err != nil { return } for _, z := range ret { fmt.Println(z.Member,z.Score) } } NSQ NSQ是目前比较流行的一个分布式的消息队列,本文主要介绍了NSQ及go语言如何操作NSQ\nNSQ介绍 NSQ是go语言编写的一个开源的实时分布式内存消息队列,其性能十分优异.NSQ的优势有:\nNSQ提倡分布式和分散的拓扑,没有单点故障,支持容错和高可用性,并提供可靠的消息交付保证 NSQ支持横向扩展,没有任何集中式代理 NSQ易于配置和部署,并且内置了管理界面 NSQ的应用场景 通常来说,消息队列都适用于以下场景\n异步处理 利用消息队列把业务流程中的非关键流程异步化,从而显著降低业务请求的响应时间\nimage-20210820235216910\r应用解耦 通过使用消息队列将不同的业务逻辑解耦,降低系统间的耦合,提高系统的健壮性.后续有其他业务要使用订单数据可直接订阅消息队列,提高系统的灵活性\nimage-20210820235428939\r流量削峰 类似秒杀等场景下,某一时间可能会产生大量的请求,使用消息队列能够为后端处理请求提供一定的缓冲区,保证后端服务的稳定性\nimage-20210820235659875\rNSQ组件 nsqd nsqd是一个守护进程,它接收/排队并向客户端发送消息\n启动nsqd,指定-broadcast-address=127.0.0.1来配置广播地址\n如果是在搭配nsqdlookupd使用的模式下还需要指定nsqdlookupd地址\n如果是部署了多个nsqlookupd节点的集群,那还可以指定多个-lookupd-tcp-address\nnsqlookupd nsqlookupd是维护所有nsqd状态/提供服务发现的守护进程.他能为消费者查找特定topic下的nsqd提供了运行时的自动发现服务.他不是维持持久状态,也不需要与任何其他的nsqdlookupd实例协调以满足查询.因此根据系统的冗余要求尽可能多地部署nsqlookupd节点.她们消耗的资源很少,可以与其他服务共存,我们的建议是为每个数据中心运行至少三个集群\nnsqadmin\n一个实时监控集群状态/执行各种管理任务的web管理平台,启动nsqdadmin,指定nsqlookupd地址\n我们可以使用浏览器打开http://127.0.0.1:4171访问管理界面\nimage-20210821104437565\rtopic和channel 每个nsqd实例旨在一次处理多个数据流.这些数据流成为topics,一个topic具有一个或者多个channels,每个channel都会收到topic所有消息的副本,实际上上下游的服务是通过对应的channel来消费topic消息\ntopic和channel不是预先设置的.topic在首次使用时创建,方法是将其发布到指定topic,或者订阅指定topic上的channel. channel是通过订阅指定的channel在第一次使用时创建的\ntopic和channel都互相独立地缓冲数据,防止缓慢的消费者导致其他channel的积压(同样适用于topic级别)\nchannel可以并且通常会连接多个客户端.假设所有连接的客户端都处于准备接收消息的状态,则每条消息将被传递到随机客户端\n总而言之,消息是从topic-\u0026gt;channel(每个channel接收该topic的所有消息的副本) 多播的,但是从channel-\u0026gt;consumers均匀分布(每个消费者接收到该channel的一部分消息)\nimage-20210821105522944\rimage-20210821105528935\rNSQ特性 消息默认不持久化,可以配置成持久化模式. nsq采用的方式是内存+硬盘的模式,当内存达到一定程度时就会将数据持久化到硬盘上. 如果将 \u0026ndash;mem-queue-size 设置为0 服务器重启时也会将当时在内存中的消息持久化 每条消息至少传递一次 消息不保证有序 go操作nsq day11课上笔记 今日内容 依赖管理go module context 服务端agent开发 日志项目架构设计 kafka和zookeeper tailf介绍 为什么需要依赖管理 最早的时候,go所依赖的所有第三方库 放在gopath这个目录下面.这就导致了同一个库只能保存一个版本的代码.如果不同的项目依赖同一个第三方的库的不同版本,应该怎么解决\ngodep go语言从v1.5开始引入vendor模式,如果项目目录下有vendor目录,那么go工具链会优先使用vendor内的包进行编译/测试 等等\ngodep是一个通过vendor模式实现的go语言的第三方依赖管理工具,类似的还有由社区维护准官方包管理工具dep\ngo module go1.11之后退出的官方版本管理工具,从go1.13版本开始,go module将是go语言默认的依赖管理工具\ngo111module\n要启用go module 支持首先要设置环境变量 go111module,通过他可以开启和关闭模块支持,他可以有三个可选值:\noff on auto 默认值是auto\noff就是禁用模块支持,编译时会从gopath和vendor文件夹中查找包\non就是启用模块支持,编译时会忽略gopath和vendor文件夹,只根据go.mod下载依赖\nauto就是当gopath外有go.mod文件时,开启模块支持\n简单来说,设置on之后就可以使用go module了\n使用go module管理依赖后会在项目根目录下生成两个文件go.mod和go.sum\ngoproxy go1.11之后设置goproxy命令,由于国内无法访问,所以建议设置goproxy\ngo mod命令 go mod download go mod edit go mod graph go mod init go mod tidy go mod vendor go mod verify go mod why go.mod go.mod文件记录了项目所有的依赖信息,其结构大致如下\n其中:\nmodule用来定义包名 require用来定义依赖包及版本 indirect表示简介引用 go.sum 详细包和版本信息\ngo get 下载依赖包,并且还可以指定下载的版本\ngo mod edit 因为我们可以手动修改go.mod文件,所以有时候需要格式化该文件/添加依赖项/移除依赖项\n在项目中使用go module 既有项目 如果需要对一个已经存在的项目启用go module,可以按照以下步骤\n在项目目录下执行go mod init , 生成一个go.mod文件 执行go get , 查找并记录当前项目的依赖,同时生成一个go. sum记录每个依赖库的版本和哈希值 新项目 执行go mod init 项目名 , 在当前项目文件夹下创建一个go.mod文件 手动编辑go.mod中的require依赖项或执行go get自动发现/维护依赖 context 非常重要!!!\n如何优雅的控制子goroutine退出\n在go http包的server中,每一个请求在都有一个对应的goroutine去处理,请求处理函数通常会启动额外的goroutine用来访问后端服务,比如数据库和rpc服务.用来处理一个请求的goroutine,通常需要访问一些与请求特定的数据,比如终端用户的身份认证信息/验证相关的token/请求的截止时间.当一个请求被取消或超时时,所有用来处理该请求的goroutine都应该迅速退出,然后系统才能释放这些goroutine占用的资源\n使用全局变量 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) //第一种就是通过全局变量 来控制goroutine退出 var notify bool var wg sync.WaitGroup //为什么需要context func main() { wg.Add(1) go f() //如何通知子goroutine退出 time.Sleep(time.Second) notify=true wg.Wait() } func f() { defer wg.Done() for !notify { fmt.Println(\u0026#34;ljs\u0026#34;) time.Sleep(time.Millisecond*500) } } 使用通道 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var i = make(chan bool,1) var wg sync.WaitGroup //为什么需要context func main() { wg.Add(1) go f() //如何通知子goroutine退出 time.Sleep(time.Second) i\u0026lt;-true wg.Wait() } func f() { defer wg.Done() LOOP: for { fmt.Println(\u0026#34;ljs\u0026#34;) time.Sleep(time.Millisecond*500) select { case \u0026lt;-i: break LOOP default: } } } 使用context package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var wg sync.WaitGroup func main() { ctx, cancel := context.WithCancel(context.Background()) wg.Add(2) go f(ctx) //如何通知子goroutine退出 time.Sleep(time.Second) //通知子goroutine退出 cancel() wg.Wait() } func f(ctx context.Context) { defer wg.Done() go f2(ctx) LOOP: for { fmt.Println(\u0026#34;ljs\u0026#34;) time.Sleep(time.Millisecond*500) select { case \u0026lt;-ctx.Done(): break LOOP default: } } } func f2(ctx context.Context) { defer wg.Done() LOOP: for { fmt.Println(\u0026#34;jwt\u0026#34;) time.Sleep(time.Millisecond*250) select { case\u0026lt;-ctx.Done(): break LOOP default: } } } context初识 go1.7加入了一个新的标准库context,他定义了context类型,专门用来简化对于处理单个请求的多个goroutine之间与请求域的数据/取消信号/截止时间等相关操作,这些操作可能涉及多个api调用\n对服务器传入的请求应该创建上下文,而对服务器的传出调用应该接受上下文.她们之间的函数调用链必须传递上下文,或者可以使用withcancle/withdeadline/withtimeout或withvalue创建的派生上下文,当一个上下文被取消时,他派生的所有上下文也被取消\n其中:\ndeadline方法需要返回当前context被取消的时间,也就是完成工作的截至时间(deadline) done方法需要返回一个channel,这个channel会在当前工作完成或者上下文被取消之后关闭,多次调用done方法会返回同一个channel err方法会返回当前context结束的原因,他只会在done返回的channel被关闭时才会返回非空的值 如果当前context被取消就会返回canceled错误 如果当前context超市就会返回deadlineexceeded value方法会从context中返回键对应的值,对于同一个上下文来说,多次调用value并传入相同的key会返回相同的结果,该方法仅用于传递跨api和进程间跟请求域的数据 background和todo go内置两个函数:background和todo,这两个函数分别返回了一个实现了context接口的background和todo.我们代码中最开始都是以这两个内置的上下文对象作为最顶层的parent context,衍生出更多的子上下文对象\nbackground主要用于main函数/初始化以及测试代码中,作为context这个树结构的最顶层的context,也就是根的context\ntodo,它目前还不知道具体的使用场景,如果我们不知道该使用什么context的时候,可以使用这个\nbackground和todo本质上都是emptyctx结构体类型,是一个不可取消,没有设置截止时间,没有携带任何值的context\nwith系列函数 withcancel func withcancel (parent context) (ctx context , cancel cancelFunc) withcancel返回带有新done通道的父节点的副本.当调用返回的cancel函数或当关闭父上下文的done通道时,将关闭返回上下文的done通道,无论先发生什么情况.\n取消此上下文将释放与其关联的资源\nwithdeadline func withdeadline(parent context , deadline time.time) (context , cancelfunc) 返回父上下文的副本,并将deadline调整为不迟于d.如果父上下文的deadline已经早于d,则withdeadline(parent,d)在语义上等同于父上下文,当截止日过期时,当调用返回的cancel函数时,或者当父上下文的done通道关闭时,返回上下文的done通道将被关闭,以最先发生的情况为准\n取消此上下文将释放与其关联的资源,因此代码应该在此上下文中运行的操作完成后立即调用cancel\nwithtimeout withtimeout的函数签名如下\nfunc WithTimeout (parent context ,timeout time.Duration) (context , cancelfunc) withtimeout返回withdeadline(parent,time.now().add(timeout))\n取消此上下文将释放与其相关的资源,因此代码应该在此上下文中运行的操作完成后立即调用cancel,通常用于数据库或者网络连接的超时控制\nwithvalue withvalue函数能够将请求作用域的数据与context对象建立关系\nfunc WithValue(parent context , key , val interface{}) context withvalue 返回父节点的副本,其中与key关联的值为val\n仅对api和进程间传递请求域的数据使用上下文值,而不是使用他来传递可选参数给函数\n所提供的键必须是可比较的,并且不应该是string类型或任何其他内置类型,以避免使用上下文在包之间发生冲突.withvalue的用户应该为键自己定义自己的类型.为了避免在分配给interface{}时进行分配,上下文键通常使用具体类型struct{}.或者导出的上下文关键变量的静态类型应该是指针或接口\ngo.sum文件 详细的包名和版本信息\n常见的命令 go mod init //初始化项目 go mod tidy //检查代码里的依赖去更新go.mod文件中的依赖 go get go mod download 日志收集项目 image-20210823155422863\rimage-20210823155631862\r组件介绍： logagent：日志收集客户端，用来收集服务器上的日志\nkafka：高吞吐量的分布式队列（linkin开发，apache顶级开源项目）\nElasticSearch：开源的搜索引擎，提供基于http restful 的web接口\nkibana：开源的ES数据分析和可视化工具\nhadoop：分布式计算框架，能够对大量数据进行分布式处理的平台\nstorm：一个免费并开源的分布式实时计算系统\n消息队列的通信模式 点对点模式queue 消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并消费消息。一条消息被消费以后，queue中就没有了，不存在重复消费。\n发布/订阅topic 消息生产者（发布）将消息发布到topic中，同时 有多个消息消费者（订阅）消费该消息。和点对点模式不同，发布到topic的消息会被所有订阅者消费（类似于关注了微信公众号的人都能收到推送的文章）\n补充：发布订阅模式下，当发布者消息量很大时，显然单个订阅者的处理能力是不足的。实际上现实场景中是多个订阅者节点组成一个订阅组负载均衡消费topic消息即分组订阅，这样订阅者很容易实现消费能力的线性扩展。可以看成是一个topic下有多个queue，每个queue是点对点的方式，queue之间是发布订阅方式\nkafka apache kafka最初用来设计解决海量日志传输等问题。kafka使用scala编写。是一个分布式数据流平台，可以运行在单台服务器上，也可以在多台服务器上部署形成集群。它提供了发布和订阅功能，使用者可以发送数据到kafka中，也可以从kafka中读取数据（以便进行后续的处理）。kafka具有高吞吐量、低延迟、高容错等特点。\nimage-20210823161642535\rimage-20210823161731945\rimage-20210823161916638\rimage-20210823162018291\rimage-20210823162112407\rimage-20210823162150526\rimage-20210823162256871\rkafka kafka集群的架构 broker topic partition分区，把同一个topic分成不同的分区，提高负载 leader：分区的主节点，boss flower：分区的从节点 consumer group 生产者往kafka发送数据的流程 获取集群的leader 生产者发送给leader leader落盘 follower从leader拉取 follower落盘回复ack leader回复生产者 kafka选择分区的模式 指定往哪个分区写 指定key，kafka根据key做hash然后决定写哪个分区 轮询 生产者往kafka发送数据的模式 0 把数据发给leader就成功，效率最高、安全性最低 1 把数据发给leader，等待leader回ack all 把数据发给leader，follower拉取后回ack，leader再回ack，安全性最高 为什么快？ 落盘的时候不是随机的而是顺序的 image-20210823163451045\rimage-20210823163547230\rimage-20210823163621907\rimage-20210823163708974\rimage-20210823163926776\rimage-20210823164008727\rimage-20210823164021727\r启动zookeeper 下载kafka\nkafka内置zookeeper\n修改config下zookeeper.properties配置文件\rimage-20210823191107893\r命令行启动zookeeper\nD:\\Softwares\\kafka_2.12-2.8.0\u0026gt;bin\\windows\\zookeeper-server-start.bat config\\zookeeper.properties 修改config下kafka.properties配置文件\rimage-20210823192529505\r命令行启动kafka\nD:\\Softwares\\kafka_2.12-2.8.0\u0026gt;bin\\windows\\kafka-server-start.bat config\\server.properties 要用管理员身份打开命令行\nzookeeper image-20210823192857710\r类似于consul 服务注册与发现\ntail第三方日志库demo tail作用 尝试读取某个log日志文件\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/nxadm/tail\u0026#34; \u0026#34;time\u0026#34; ) func main() { //tail用法 fileName:=\u0026#34;./my.log\u0026#34; config:=tail.Config{ Location: \u0026amp;tail.SeekInfo{Offset: 0,Whence: 2}, //从文件的那个地方开始读 ReOpen: true, //重新打开 MustExist: false, //文件不存在不报错 Poll: true, Pipe: false, Follow: true, //是否跟随 MaxLineSize: 0, RateLimiter: nil, Logger: nil, } tails, err := tail.TailFile(fileName, config) if err != nil { fmt.Println(\u0026#34;tail file failed , err: \u0026#34;,err) return } var ( line *tail.Line ok bool ) for { line, ok =\u0026lt;-tails.Lines if !ok { fmt.Printf(\u0026#34;tail file close reopen , filename :%s\\n\u0026#34;,tails.Filename) time.Sleep(time.Second) continue } fmt.Println(\u0026#34;msg: \u0026#34;,line.Text) } } sarama第三方库demo 作用:向kafka发送消息\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/Shopify/sarama\u0026#34; ) func main() { config := sarama.NewConfig() //tailf包使用 config.Producer.RequiredAcks= sarama.WaitForAll //发送完数据需要 leader 和 follower 都确认 config.Producer.Partitioner = sarama.NewRandomPartitioner //新选出一个 partitioner config.Producer.Return.Successes = true //成功交付的消息将在success channel 返回 //构造一个消息 msg:= \u0026amp;sarama.ProducerMessage{} msg.Topic = \u0026#34;web_log\u0026#34; msg.Value = sarama.StringEncoder(\u0026#34;this is a test blog\u0026#34;) //连接kafka client, err := sarama.NewSyncProducer([]string{\u0026#34;127.0.0.1:9092\u0026#34;}, config) if err != nil { fmt.Println(\u0026#34;producer closed, err : \u0026#34;, err) return } defer client.Close() //发送消息 pid, offSet, err := client.SendMessage(msg) if err != nil { fmt.Println(\u0026#34;send msg failed , err : \u0026#34;, err) return } fmt.Printf(\u0026#34;pid:%v offSet:%v\\n\u0026#34;,pid,offSet) } image-20210823202230801\rimage-20210823202240537\r索引\n接下来就是日志收集项目 初始化sarama 让他连接上kafka 以便给kafka发送消息 初始化tail 让他能够读取日志文件 使用初始化好的sarama 将tail读取到的东西发送给kafka kafka模块代码\npackage kafka import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/Shopify/sarama\u0026#34; ) //专门往kafka写日志的模块 var ( client sarama.SyncProducer //声明一个全局的连接kafka的生产者client ) //Init 初始化client func Init(address []string)(err error) { config := sarama.NewConfig() //tailf包使用 config.Producer.RequiredAcks= sarama.WaitForAll //发送完数据需要 leader 和 follower 都确认 config.Producer.Partitioner = sarama.NewRandomPartitioner //新选出一个 partitioner config.Producer.Return.Successes = true //成功交付的消息将在success channel 返回 //连接kafka client, err = sarama.NewSyncProducer(address, config) if err != nil { fmt.Println(\u0026#34;producer closed, err : \u0026#34;, err) return } return } func SendToKafka(topic, msg string) { //构造一个消息 saramaMsg:= \u0026amp;sarama.ProducerMessage{} saramaMsg.Topic = topic saramaMsg.Value = sarama.StringEncoder(msg) //发送消息 pid, offSet, err := client.SendMessage(saramaMsg) if err != nil { fmt.Println(\u0026#34;send msg failed , err : \u0026#34;, err) return } fmt.Printf(\u0026#34;pid:%v offSet:%v\\n\u0026#34;,pid,offSet) } tail模块代码\npackage tail import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/nxadm/tail\u0026#34; ) var tails *tail.Tail //Init 专门收集日志 func Init(address string) (err error){ //tail用法 fileName:=address config:=tail.Config{ Location: \u0026amp;tail.SeekInfo{Offset: 0,Whence: 2}, //从文件的那个地方开始读 ReOpen: true, //重新打开 MustExist: false, //文件不存在不报错 Poll: true, Pipe: false, Follow: true, //是否跟随 MaxLineSize: 0, RateLimiter: nil, Logger: nil, } tails, err = tail.TailFile(fileName, config) if err != nil { fmt.Println(\u0026#34;tail file failed , err: \u0026#34;,err) return } return } func ReadLog() \u0026lt;-chan *tail.Line { return tails.Lines } main模块代码\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;src/code.oldboyedu.com/logAgent/kafka\u0026#34; tail \u0026#34;src/code.oldboyedu.com/logAgent/tail_log\u0026#34; \u0026#34;time\u0026#34; ) func main() { //1.初始化kafka连接 err := kafka.Init([]string{\u0026#34;127.0.0.1:9092\u0026#34;}) if err != nil { fmt.Println(\u0026#34;init kafka failed, err : \u0026#34; ,err) return } fmt.Println(\u0026#34;init kafka success!\u0026#34;) //2.打开日志文件准备收集日志 err = tail.Init(\u0026#34;./my.log\u0026#34;) if err != nil { fmt.Println(\u0026#34;init taillog failed, err : \u0026#34;,err) return } fmt.Println(\u0026#34;init tail success!\u0026#34;) run() } func run() { //1.收集日志 for { select { case line:=\u0026lt;-tail.ReadLog(): //2.发送给kafka kafka.SendToKafka(\u0026#34;web_log\u0026#34;,line.Text) default: time.Sleep(time.Second) } } } 定义消费者\nbin\\windows\\kafka-console-consumer.bat --bootstrap-server=127.0.0.1:9092 --topic=web_log --from-beginning image-20210823210549292\r优化版配置文件中读取\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;gopkg.in/ini.v1\u0026#34; \u0026#34;src/code.oldboyedu.com/logAgent/kafka\u0026#34; tail \u0026#34;src/code.oldboyedu.com/logAgent/tail_log\u0026#34; \u0026#34;time\u0026#34; ) type appConf struct { KafkaConf `ini:\u0026#34;Kafka\u0026#34;` TailLogConf `ini:\u0026#34;Taillog\u0026#34;` } type KafkaConf struct { Address string `ini:\u0026#34;Address\u0026#34;` Topic string `ini:\u0026#34;Topic\u0026#34;` } type TailLogConf struct { FileName string `ini:\u0026#34;Filename\u0026#34;` } var appCfg =new(appConf) func main() { //0.加载配置文件 获取ip:端口 日志文件 发送的topic err := ini.MapTo(appCfg, \u0026#34;./config.ini\u0026#34;) if err != nil { fmt.Println(\u0026#34;config init failed, err : \u0026#34;,err) return } //1.初始化kafka连接 fmt.Println(appCfg.KafkaConf.Address) fmt.Println(appCfg.KafkaConf.Topic) fmt.Println(appCfg.TailLogConf.FileName) err = kafka.Init([]string{appCfg.KafkaConf.Address}) if err != nil { fmt.Println(\u0026#34;init kafka failed, err : \u0026#34; ,err) return } fmt.Println(\u0026#34;init kafka success!\u0026#34;) //2.打开日志文件准备收集日志 err = tail.Init(appCfg.TailLogConf.FileName) if err != nil { fmt.Println(\u0026#34;init taillog failed, err : \u0026#34;,err) return } fmt.Println(\u0026#34;init tail success!\u0026#34;) run() } func run() { //1.收集日志 for { select { case line:=\u0026lt;-tail.ReadLog(): //2.发送给kafka kafka.SendToKafka(appCfg.KafkaConf.Topic,line.Text) default: time.Sleep(time.Second) } } } 内容复习 go module 依赖管理工具\ncontext goroutine管理\ncontext.Context\n两个根节点 context.todo context.background\n四个方法 context.withTimeout() context.withCancel() context.withdeadline() context.withvalue()\n日志收集项目 ELK:部署的时候麻烦,每一个filebeat都需要配置一个配置文件\n使用etcd来管理被收集的日志项\n项目的架构 image-20210824195131980\r上节课项目进度 kafka:消息队列 tailf:从文件里读日志 sarama:向kafka发送数据 go-ini:解析配置文件 今日内容 etcd 使用etcd优化日志收集项目 image-20210824195924259\rraft协议\n选举 日志复制机制 异常处理 zookeeper的zad协议和raft协议的区别\nimage-20210824201151410\rimage-20210824201255712\rimage-20210824201531623\rimage-20210824201641847\rimage-20210824201859917\rimage-20210824201921279\rimage-20210824202013396\rimage-20210824202041613\rimage-20210824202051395\rimage-20210824202203749\rimage-20210824202403398\r清华学神尹成\nimage-20210826231049867\rimage-20210826231828312\rLogTransfer 从kafka里面把日志取出来,写入ES\nElastic Search ES是一个基于lucene构建的开源的/分布式/restful接口的全文搜索引擎.elastic search还是一个分布式文档数据库,其中每个字段均可被索引,而且每个字段的数据均可被搜索,ES能够横向扩展至数以百计的服务器存储以及处理PB级的数据.可以在极短的时间内存储/搜索和分析大量的数据.通常作为具有复杂搜索场景情况下的核心发动机.\nElasticSearch能做什么 当你经营一家网上商店,你可以让你的客户搜索你卖的商品.在这种情况下,你可以使用Elastic search来存储你的整个产品目录和库存信息,为客户提供精准搜索,可以为客户推荐相关商品. 当你想收集日志或者交易数据的时候,需要分析和挖掘这些数据,寻找趋势,进行统计,总结,或者发现异常.在这种情况下,你可以使用logstash或者其他工具来进行收集数据,当这引起数据存储到elastic search中.你可以搜索和汇总这些数据,找到任何你感兴趣的信息 对于程序员来说,比较有名的案例是github.github的搜索是基于elasticsearch构建的,在github.com/search页面,你可以搜索项目,用户/issue/pull request,还有代码.公有40-50个索引库,分别用于索引网站需要跟踪的各种数据,虽然只索引项目的主分支master,但这个数据量依然巨大,包括20亿个索引文档,30TB的索引文件. ElasticSearch基本概念 near realtime 几乎实时 elasticsearch是一个几乎实时的搜索凭条,意思是,从索引一个文档到这个文档可以被搜索只需要一点点的延迟,这个时间一半为毫秒级\ncluster集群 集群是一个或者多个节点服务器的集合,这些节点共同保存整个数据,并在所有节点上提供联合索引和搜索功能.一个集群由一个唯一集群ID确定,并指定一个集群名(默认为elasticsearch).该集群名非常重要,因为节点可以通过这个集群名加入集群,一个节点只能是集群的一部分.\n确保在不同的环境中不要使用相同的集群名称,否则可能会导致连接错误的集群节点,例如你可以使用logging\u0026ndash;dev/ logging-stage/ logging-prod 分别为开发/阶段产品/生产集群做记录.\nnode节点 节点是单个服务器实例\nindex索引 索引是具有相似特性的文档集合\ntype类型 在索引中,可以定义一个或者多个类型,类型是索引的逻辑类别/分区,其语义完全取决于你.\ndocument文档 文档是可以被索引的信息的基本单位.例如,你可以为单个客户提供一个文档,单个产品提供另一个文档,以及单个订单提供另一个文档.\nshards\u0026amp;replicas分片与副本 ES基本概念与关系型数据库的比较 ES概念 关系型数据库 index索引支持全文检索 database数据库 type类型 table表 document文档,不同文档可以有不同的字段集合 row数据行 field字段 column数据列 mapping映射 schema模式 ES API 下载安装\nimage-20210902001925922\r查看\nimage-20210902001948107\r查看心跳\nimage-20210902002107349\r查询当前es集群中所有的indices\ncurl -X get 127.0.0.1:9200/_cat/indices?v\nimage-20210902002202915\rgin学习 hello world demo\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { //1.创建路由 engine := gin.Default() //2.绑定路由规则,执行的函数 //gin.context , 封装了request和response engine.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK,\u0026#34;hello world!!!\u0026#34;) }) //3.监听端口 默认在8080端口 engine.Run(\u0026#34;:8000\u0026#34;) } gin路由 基本路由 gin框架中采用的路由库是基于tprouter做的 地址为:https://github.com/julienschmidt/httprouter restful风格的API gin支持restful风格的API 即representational state transfer 的缩写 直接翻译是表现层状态转化,是一种互联网应用程序的api设计理念,url定位资源,用http描述操作 获取文章 /blog/getxxx get blog/xxx\n添加 /blog/addxxx\tpost blog/xxx\n修改 /blog/updatexxx put blog/xxx\n删除 /blog/delxxx delete blog/xxx\nAPI参数 可以通过context的param方法来获取api参数 localhost:8000/xxx/zhangsan localhost:8000/user/zhangsan/lisi\nURL参数 URL参数可以通过defaultquery()或者query()方法来取 defaultquery()若参数不存在,返回默认值 query()若参数不存在,返回空字符串 localhost:8000/welcome?name=yourtreedad\n表单参数 表单传输为post请求,http常见的传输格式化为四种 application/json json传参 application/x-www-urlencoded 表单传参 application/xml xml传参 multipart/form-data 表单上传文件 表单参数可以通过postform()方法获取,该方法默认解析的是x-www-form-urlencoded 或 from-data格式的参数 上传单个文件 multipart/form-data格式用于文件上传 gin 文件上传与原生的net/http 方法类似,不同在于gin把原生的request封装到了c.Request中 上传多个文件 MultipartForm使用这个方法获得所有文件的\n使用multipartForm.File[\u0026ldquo;files\u0026rdquo;]来取所有文件指针\n遍历, 然后存着就行了\nroutes Group routes Group 是为了管理一些相同的URL 路由原理 httprouter 会将所有路由规则构造成一个前缀树 命令行也可以尝试传post和get指令\nimage-20210828214026568\rpackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { //1.创建路由 //默认使用了2个中间件 Logger(), Recovery() engine := gin.Default() //engine:=gin.New()也可以的 //2.绑定路由规则,执行的函数 //gin.context , 封装了request和response //路由组 实际上就是便于管理 少写点东西 routerGroup := engine.Group(\u0026#34;/Get\u0026#34;) routerGroup.GET(\u0026#34;/v1\u0026#34;, func(context *gin.Context) { query := context.DefaultQuery(\u0026#34;name\u0026#34;, \u0026#34;getParam\u0026#34;) context.String(http.StatusOK,query) }) group := engine.Group(\u0026#34;/Post\u0026#34;) group.POST(\u0026#34;/v1\u0026#34;, func(context *gin.Context) { postParam := context.DefaultPostForm(\u0026#34;name\u0026#34;, \u0026#34;postParam\u0026#34;) context.String(http.StatusOK,postParam) }) //index 界面 engine.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK,\u0026#34;hello world!!!\u0026#34;) }) //api参数 用 : 来取 engine.GET(\u0026#34;/user/:name/*action\u0026#34;, func(context *gin.Context) { // name:= context.Param(\u0026#34;name\u0026#34;) action := context.Param(\u0026#34;action\u0026#34;) context.String(http.StatusOK,name+\u0026#34; is \u0026#34;+action) }) //url参数 ?name=\u0026#34;xxx\u0026#34; engine.GET(\u0026#34;/welcome\u0026#34;, func(context *gin.Context) { query := context.DefaultQuery(\u0026#34;name\u0026#34;, \u0026#34;Jack\u0026#34;) context.String(http.StatusOK,fmt.Sprintf(\u0026#34;Hello %s !\u0026#34;,query)) }) //form表单传参 engine.POST(\u0026#34;/PostForm\u0026#34;, PostFormParams) //from上传单个文件 engine.POST(\u0026#34;/Upload\u0026#34;,UploadFile) //限制表单上传大小 8mb,默认值为32mb engine.MaxMultipartMemory = 8\u0026lt;\u0026lt;20 //form上传多个文件 engine.POST(\u0026#34;UploadFiles\u0026#34;,UploadFiles) engine.PUT(\u0026#34;/xxxput\u0026#34;) //3.监听端口 默认在8080端口 engine.Run(\u0026#34;:8000\u0026#34;) } func UploadFiles(context *gin.Context) { multipartForm, err := context.MultipartForm() if err != nil { fmt.Println(\u0026#34;received multiple files failed , err :\u0026#34;,err) context.String(http.StatusBadRequest,fmt.Sprintf(\u0026#34;get err %s \u0026#34;,err.Error())) return } //获取所有文件 files := multipartForm.File[\u0026#34;files\u0026#34;] //遍历所有files for _, file := range files { //逐个存 err := context.SaveUploadedFile(file, file.Filename) if err != nil { context.String(http.StatusBadRequest,fmt.Sprintf(\u0026#34;upload err %s \u0026#34;,err.Error())) return } } context.String(200,fmt.Sprintf(\u0026#34;upload ok %d files!\u0026#34;, len(files))) } func UploadFile(context *gin.Context) { //从表单中取文件 file, err := context.FormFile(\u0026#34;file\u0026#34;) if err != nil { fmt.Println(\u0026#34;receive file error, cause : \u0026#34;,err) return } log.Println(file.Filename) //传到项目的根目录, 名字就用本身的就好 err = context.SaveUploadedFile(file, file.Filename) if err != nil { fmt.Println(\u0026#34;file save failed , error : \u0026#34;,err) return } //打印信息 context.String(200,fmt.Sprintf(\u0026#34;\u0026#39;%s\u0026#39; has already uploaded!\u0026#34;,file.Filename)) } func PostFormParams(context *gin.Context) { //表单参数 设置默认值 type1 := context.DefaultPostForm(\u0026#34;type\u0026#34;, \u0026#34;alert\u0026#34;) //接收其他的 userName := context.PostForm(\u0026#34;username\u0026#34;) password := context.PostForm(\u0026#34;password\u0026#34;) //多选框 hobbys := context.PostFormArray(\u0026#34;hobby\u0026#34;) context.String(http.StatusOK,fmt.Sprintf(\u0026#34;type is %s, username is %s, password is %s , hobbys is %v\u0026#34;,type1,userName,password,hobbys)) } html前端界面\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;登陆\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;http://127.0.0.1:8000/PostForm\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;application/x-www-form-urlencoded\u0026#34;\u0026gt; 用户名:\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34;\u0026gt; \u0026lt;br\u0026gt; 密\u0026amp;nbsp\u0026amp;nbsp码: \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;\u0026gt; \u0026lt;br\u0026gt; 兴\u0026amp;nbsp\u0026amp;nbsp趣: \u0026lt;input type=\u0026#34;checkbox\u0026#34; value=\u0026#34;run\u0026#34; name=\u0026#34;hobby\u0026#34;\u0026gt;跑步 \u0026lt;input type=\u0026#34;checkbox\u0026#34; value=\u0026#34;game\u0026#34; name=\u0026#34;hobby\u0026#34;\u0026gt;游戏 \u0026lt;input type=\u0026#34;checkbox\u0026#34; value=\u0026#34;money\u0026#34; name=\u0026#34;hobby\u0026#34;\u0026gt;金钱 \u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;登陆\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;br\u0026gt; \u0026lt;br\u0026gt; \u0026lt;br\u0026gt; \u0026lt;form action=\u0026#34;http://127.0.0.1:8000/Upload\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; 头像: \u0026lt;input type=\u0026#34;file\u0026#34; name=\u0026#34;file\u0026#34;\u0026gt; \u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;form action=\u0026#34;http://127.0.0.1:8000/UploadFiles\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; 上传多个文件: \u0026lt;input type=\u0026#34;file\u0026#34; name=\u0026#34;files\u0026#34; multiple\u0026gt; \u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; gin数据解析和绑定 json数据解析和绑定 客户端传参,后端接收并解析到结构体 使用ShouldBindJSON来解析到结构体\nengine.GET(\u0026#34;loginJSON\u0026#34;, func(context *gin.Context) { //声明接收的变量 var json Login //将request的body中的数据,自动按照json格式解析到结构体 err := context.ShouldBindJSON(\u0026amp;json) if err != nil { //返回错误信息 //gin.H 封装了生成json数据的工具 context.JSON(http.StatusBadRequest,gin.H{\u0026#34;error \u0026#34;:err.Error()}) return } //判断用户名密码是否正确 if json.User!=\u0026#34;2020170281\u0026#34;||json.Password!=\u0026#34;lalala123\u0026#34; { context.JSON(http.StatusBadRequest,gin.H{\u0026#34;status\u0026#34;:\u0026#34;304\u0026#34;}) return } context.JSON(http.StatusOK,gin.H{\u0026#34;status\u0026#34;:\u0026#34;200\u0026#34;}) }) image-20210828224803650\r表单数据解析和绑定 使用Bind来解析结构体\nengine.GET(\u0026#34;loginForm\u0026#34;, func(context *gin.Context) { var form Login //bind()默认解析并绑定form格式 //根据请求头中的content-type自动推断 err := context.Bind(\u0026amp;form) if err != nil { context.JSON(http.StatusBadRequest,gin.H{\u0026#34;error\u0026#34;:err.Error()}) return } if form.User!=\u0026#34;2020170281\u0026#34;||form.Password!=\u0026#34;lalala123\u0026#34;{ context.JSON(http.StatusBadRequest,gin.H{\u0026#34;status\u0026#34;:\u0026#34;304\u0026#34;}) return } context.JSON(http.StatusOK,gin.H{\u0026#34;status\u0026#34;:\u0026#34;200\u0026#34;}) }) html界面\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;登陆\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;http://127.0.0.1:8000/loginForm\u0026#34; method=\u0026#34;get\u0026#34; enctype=\u0026#34;application/x-www-form-urlencoded\u0026#34;\u0026gt; 用户名:\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34;\u0026gt; \u0026lt;br\u0026gt; 密\u0026amp;nbsp\u0026amp;nbsp码: \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;\u0026gt; \u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;登陆\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;br\u0026gt; \u0026lt;br\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; URI数据解析和绑定 使用shouldbinduri方法\nengine.GET(\u0026#34;loginURI/:user/:password\u0026#34;, func(context *gin.Context) { var URI Login err := context.ShouldBindUri(\u0026amp;URI) if err != nil { context.JSON(http.StatusBadRequest,gin.H{\u0026#34;error\u0026#34;:err.Error()}) return } if URI.User!=\u0026#34;2020170281\u0026#34;||URI.Password!=\u0026#34;lalala123\u0026#34; { context.JSON(http.StatusBadRequest,gin.H{\u0026#34;status\u0026#34;:304}) return } context.JSON(http.StatusOK,gin.H{\u0026#34;status\u0026#34;:200}) }) image-20210828231200951\r响应类型 xml json protobuf yaml package main\rimport (\r\u0026#34;github.com/gin-gonic/gin\u0026#34;\r\u0026#34;github.com/gin-gonic/gin/testdata/protoexample\u0026#34;\r\u0026#34;net/http\u0026#34;\r)\r//多种响应方式\rfunc main() {\r//1.创建路由\r//2.默认使用了2个中间件logger recovery\rengine := gin.Default()\r//1.json\rengine.GET(\u0026#34;/someJson\u0026#34;, func(context *gin.Context) {\rcontext.JSON(http.StatusOK,gin.H{\u0026#34;message\u0026#34;:\u0026#34;someJson\u0026#34;,\u0026#34;Status\u0026#34;:200})\r})\r//2.结构体响应\rengine.GET(\u0026#34;someStruct\u0026#34;, func(context *gin.Context) {\rcontext.JSON(http.StatusOK, struct {\rName , Message string\rNumber int\r}{\u0026#34;root\u0026#34;,\u0026#34;message\u0026#34;,123})\r})\r//3.XML响应\rengine.GET(\u0026#34;/someXML\u0026#34;, func(context *gin.Context) {\rcontext.XML(http.StatusOK,gin.H{\u0026#34;message\u0026#34;:\u0026#34;xml\u0026#34;})\r})\r//4.yaml响应\rengine.GET(\u0026#34;/someYaml\u0026#34;, func(context *gin.Context) {\rcontext.YAML(http.StatusOK,gin.H{\u0026#34;name\u0026#34;:\u0026#34;YAML\u0026#34;})\r})\r//5.protobuf格式 副歌开发的高校存储读取的工具\rengine.GET(\u0026#34;/someProtoBuf\u0026#34;, func(context *gin.Context) {\rreps:=[]int64{1,2}\r//定义返回数据\rlabel:=\u0026#34;protobuf\u0026#34;\rdata:=\u0026amp;protoexample.Test{\rLabel: \u0026amp;label,\rReps: reps,\r}\rcontext.ProtoBuf(http.StatusOK,data)\r})\rengine.Run(\u0026#34;:8000\u0026#34;)\r} HTML 模版渲染 gin支持加载html模版,然后根据模版参数进行配置并返回相应的数据,本质上就是字符串的替换 loadhtmlglob()方法可以加载模版文件 func main() { engine:= gin.Default() //加载模版文件 engine.LoadHTMLGlob(\u0026#34;templates/*\u0026#34;) //以下这种方式也可以啦 //engine.LoadHTMLFiles(\u0026#34;templates/index.tmpl\u0026#34;) engine.GET(\u0026#34;/index\u0026#34;, func(context *gin.Context) { //根据文件名渲染 //最终json将title替换 context.HTML(http.StatusOK,\u0026#34;index.tmpl\u0026#34;,gin.H{\u0026#34;title\u0026#34;:\u0026#34;我的标题\u0026#34;}) }) engine.Run(\u0026#34;:8000\u0026#34;) } image-20210828234359001\r重定向 func main() { engine := gin.Default() engine.GET(\u0026#34;/redirect\u0026#34;, func(context *gin.Context) { //支持内部和外部的重定向 context.Redirect(http.StatusMovedPermanently,\u0026#34;http://www.baidu.com\u0026#34;) }) engine.Run(\u0026#34;:8000\u0026#34;) } 同步异步 goroutine机制可以方便地实现异步处理 另外,在启动新的goroutine时,不应该使用原始上下文,必须使用他的只读副本 unc main() { engine := gin.Default() //1.异步 engine.GET(\u0026#34;/long_async\u0026#34;, func(context *gin.Context) { //需要搞一个只读的副本 copyContext := context.Copy() //模仿异步处理 go func() { time.Sleep(3 *time.Second) log.Println(\u0026#34;异步执行...\u0026#34;+copyContext.Request.URL.Path) }() }) //2.同步 engine.GET(\u0026#34;/long_sync\u0026#34;, func(context *gin.Context) { time.Sleep(3*time.Second) log.Println(\u0026#34;同步执行...\u0026#34;+context.Request.URL.Path) }) engine.Run(\u0026#34;:8000\u0026#34;) } gin中间件 image-20210828235642323\rgin可以构建中间件,但它只对注册过的路由函数起作用 对于分组路由,嵌套使用中间件,可以限定中间件的作用范围 中间件分为全局中间件,单个路由中间件和群组中间件 gin中间件必须是一个gin.handlerfunc类型 全局中间件 所有请求都经过此中间件 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) //定义全局中间件 func MiddleWare() gin.HandlerFunc { return func(context *gin.Context) { t:=time.Now() fmt.Println(\u0026#34;中间件开始执行了...\u0026#34;) //设置变量到context的key中,可以通过get取 context.Set(\u0026#34;request\u0026#34;,\u0026#34;中间件\u0026#34;) //执行函数 context.Next() //中间件执行完后续的一些事情 status := context.Writer.Status() fmt.Println(\u0026#34;中间件执行完毕\u0026#34;,status) fmt.Println(\u0026#34;用时 : \u0026#34;,time.Now().Sub(t)) } } func main() { engine:= gin.Default() //注册中间件 engine.Use(MiddleWare()) { engine.GET(\u0026#34;/middleware\u0026#34;, func(context *gin.Context) { //取值 request, _ := context.Get(\u0026#34;request\u0026#34;) fmt.Println(request) //页面接收 context.JSON(http.StatusOK,gin.H{\u0026#34;request\u0026#34;:request}) }) } engine.Run(\u0026#34;:8000\u0026#34;) } next()方法 看原码 实际上就是遍历了注册的所有中间件的个数,\n局部中间件 //如此就是在这个路由之下定义了新的中间件,可以视为单个中间件 engine.GET(\u0026#34;/middlewareDouble\u0026#34;,MiddleWare(), func(context *gin.Context) { //取值 request, _ := context.Get(\u0026#34;request\u0026#34;) fmt.Println(request) //页面接收 context.JSON(http.StatusOK,gin.H{\u0026#34;request\u0026#34;:request}) }) 练习 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;time\u0026#34; ) func middleTimer() gin.HandlerFunc { return func(context *gin.Context) { now := time.Now() context.Next() fmt.Println(\u0026#34;用时: \u0026#34;,time.Now().Sub(now)) } } func main() { engine := gin.Default() engine.Use(middleTimer()) group := engine.Group(\u0026#34;/timer\u0026#34;) group.GET(\u0026#34;/countTimer\u0026#34;, func(context *gin.Context) { time.Sleep(3*time.Second) }) group.GET(\u0026#34;/counTimer1\u0026#34;, func(context *gin.Context) { time.Sleep(5*time.Second) }) engine.Run(\u0026#34;:8000\u0026#34;) } 会话控制 cookie是什么 http是无状态协议,服务器不能记录里浏览器的访问状态,也就是说服务器不能区分两次请求是否是由同一个客户端发出的 cookie就是解决http协议无状态的方案之一,中文是小甜饼的意思 cookie实际上就是服务器保存在浏览器上的一段信息,浏览器有了cookie之后,每次向服务器发送请求时都会同时将该信息发送给服务器,服务器收到请求后,就可以根据该信息处理请求 cookie由服务器创建,并发送给浏览器,最终由浏览器保存 cookie用途 保持登陆状态 京东购物车 cookie的使用 服务端发送cookieid cookie练习 模拟实现权限验证中间件 有两个路由,login用来设置cookie home用来访问 package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func MiddleWareAuth() gin.HandlerFunc { return func(context *gin.Context) { cookie, err := context.Cookie(\u0026#34;loginToken\u0026#34;) if err != nil { //返回错误 context.JSON(http.StatusOK, gin.H{\u0026#34;error\u0026#34;: \u0026#34;StatusUnauthorized\u0026#34;}) context.Abort() return } if cookie == \u0026#34;true\u0026#34; { context.Next() } } } func main() { engine := gin.Default() engine.GET(\u0026#34;/login\u0026#34;, func(context *gin.Context) { http.SetCookie(context.Writer, \u0026amp;http.Cookie{ Name: \u0026#34;loginToken\u0026#34;, Value: \u0026#34;true\u0026#34;, }) context.String(http.StatusOK, \u0026#34;Login successful\u0026#34;) }) engine.GET(\u0026#34;/home\u0026#34;, MiddleWareAuth(), func(context *gin.Context) { context.JSON(http.StatusOK, gin.H{\u0026#34;data\u0026#34;: \u0026#34;home\u0026#34;}) }) engine.Run(\u0026#34;:8000\u0026#34;) } cookie的缺点 不安全 明文 增加带宽消耗 可以被禁用 cookie有上限 session是什么 session可以弥补cookie的不足,session必须依赖于cookie才能使用,生成一个sessionid放在cookie里传给客户端就可以了 image-20210829104620811\rimage-20210829104914310\rsession存在服务端中\nsession中间件开发 设计一个通用的session服务,支持内存存储和redis存储\nsession模块设计\n本质上是k-v系统,通过key来进行增删改查 session可以存储在内存或者redis(2个版本) image-20210829105225472\rsession接口设计 set get del save session存储,redis的实现延迟加载 sessionmgr接口设计 init 初始化 加载redis地址 createsession 创建一个新的session getsession 通过sessionid获取对应的session对象 memorysession设计 定义memorysession对象 字段sessionid 存kv的map 读写锁 构造函数 为了获取对象 sessionmgr设计 定义memorysessionmgr对象 字段存放所有的session的map,读写锁 构造函数 init cretesession getsession redisression设计 定义redissession对象 ssionid字段 存kv的map 读写锁 redis连接池 记录内存中map否被修改的标记 构造函数 set将session存到内存中的map get取数据实现延迟加载 del save 将session存到redis redissessionmgr设计 定义redissessionmgr对象 image-20210829110208079\r这里还是要重申一下 http传参啊\n首先 传参可以分为网址传参和表单传参\n网址传参又分为api传参和url传参\napi传参使用/book/:name\nname:= context.Param(\u0026#34;name\u0026#34;) url传参使用/book\nquery := context.Query(\u0026#34;name\u0026#34;) 表单传参\n分为get和post get的话我们发现 get的method最终会变成url\nquery := context.Query(\u0026#34;searchThing\u0026#34;) post就使用\nsearchThing, ok := context.GetPostForm(\u0026#34;searchThing\u0026#34;) form := context.PostForm(\u0026#34;searchThing\u0026#34;) Elastic Search image-20210903210305686\r查看健康 curl -X GET127.0.0.1:9200/_cat/health?v\n创建索引 curl -X PUT 127.0.0.1:9200/www\n删除索引 curl -X DELETE 127.0.0.1:9200/www\n插入数据 image-20210903210614663\r检索数据 image-20210903211123288\rgo操作ES 微服务 注册中心选型 consul / zookeeper / etcd / euerka\n选项设计模式 package main import \u0026#34;fmt\u0026#34; func main() { newOptions(\u0026#34;str1\u0026#34;, \u0026#34;str2\u0026#34;, \u0026#34;str3\u0026#34;, 1, 2, 3) newOptionsNew(WithStrOption(\u0026#34;str1\u0026#34;)) } type OptionsNew struct { strOption1 string strOption2 string strOption3 string intOption1 int intOption2 int intOption3 int } // Option 先声明一个函数类型,用于传参 type Option func(option *OptionsNew) // WithStrOption 定义具体给某个字段赋值的方法 返回一个方法 通过这个方法给结构体赋值 func WithStrOption(str string) Option { return func(option *OptionsNew) { option.strOption1 = str } } //初始化结构体 func newOptionsNew(otions ...Option) { options :=\u0026amp;OptionsNew{} //遍历otions,得到每一个函数 for _, fun:= range otions { //调用函数, 在函数里,给传进去的对象赋值 fun(options) } fmt.Printf(\u0026#34;init options %#v\\n\u0026#34;,options) } type Options struct { strOption1 string strOption2 string strOption3 string intOption1 int intOption2 int intOption3 int } func newOptions(strOption1, strOption2, strOption3 string, intOption1, intOption2, intOption3 int) { options := Options{ strOption1: strOption1, strOption2: strOption2, strOption3: strOption3, intOption1: intOption1, intOption2: intOption2, intOption3: intOption3, } fmt.Printf(\u0026#34;init option %#v\\n\u0026#34;, options) } 注册组件接口开发 目标 支持多注册中心,既支持consul又支持etcd 支持可扩展 提供基于名字的插件管理函数,用来注册插件 image-20210903224236637\r流行RPC框架的对比 dubbo / motan / thrift / grpc\ngRPC简介 pc语言中立/平台中立/开源的远程过程调用系统 grpc由客户端和服务端可以在多种环境中运行和交互,例如写一个java服务端,可以用go语言写客户端调用 grpc与protobuf介绍 微服务架构中,由于每个服务对应的代码库是独立运行的,无法直接调用,彼此间的通信就是个大问题 grpc可以实现微服务,将大的项目拆分为多个小且独立的业务模块,也就是服务,各服务之间使用高校的protobuf协议进行rpc调用,grpc默认使用protocol buffers,这个google开源的一套成熟的结构数据序列化机制(当然也可以使用其他数据格式如json) 可以用proto files 创建grpc服务,用message类型来定义方法参数和返回类型 安装grpc和protubuf git clone https://github.com/grpc/grpc-go.git $GOPATH/src/google.golang.org/grpc\ngit clone https://github.com/golang/net.git $GOPATH/src/golang.org/x/net\ngit clone https://github.com/golang/text.git $GOPATH/src/golang.org/x/text\ngo get -u github.com/golang/protobuf/{proto,protoc-gen-go}\ngit clone https://github.com/google/go-genproto.git $GOPATH/src/google.golang.org/genproto\n进入src,并install cd $GOPATH/src/\ngo install google.golang.org/grpc\n","date":"2021-08-24T00:17:57+08:00","permalink":"https://linjianshu.github.io/p/go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0/","title":"Go语言学习"},{"content":"docker学习 docker概述\ndocker安装\ndocker命令\n镜像命令 容器命令 操作命令 \u0026hellip; docker镜像\n容器数据卷\ndockerfile\ndocker网络原理\nidea整合docker\n以上单机版本docker\n集群 docker compose docker swarm 简化版k8s ci/cd jenkins docker概述\n开发\u0026ndash;上线 两套环境 应用环境，应用配置\n开发人员 运维人员\n开发即运维！\n环境配置麻烦，每个机器都要部署环境（集群redis、es、hadoop\u0026hellip;）费事费力\n发布项目 jar（redis mysql jdk es） war\njar带上环境进行发布，项目能不能带上环境安装打包\n之前在服务器配置一个应用的环境 redis mysql jdk es hadoop ，配置超麻烦，不能跨平台\nwindows与linux\n传统：开发提供jar 运维部署环境\n现在：开发打包部署上线，一套流程做完\ndocker给以上的问题，提出解决方案\njava\u0026mdash;apk\u0026mdash;发布（应用商店） \u0026mdash;张三使用apk \u0026mdash;安装即可用\njava\u0026mdash;jar（环境）\u0026mdash;打包项目带上环境（镜像） \u0026mdash;-docker仓库：商店 \u0026mdash;- 下载我们发布的镜像 \u0026ndash;直接运行即可\ndocker思想就来自于集装箱！\njre\u0026mdash;多个应用 （端口冲突）\u0026mdash;原来都是交叉的\n隔离：Docker核心思想，打包装箱！每个箱子都是互相隔离的！\ndocker通过隔离机制，可以将服务器利用到极致\n本质：所有的技术都是因为出现了一些问题，我们需要去解决，才去学习。\ndocker历史\n容器化技术命名就是docker\n刚刚诞生的时候没有引起行业注意！dotcloud，开源\n开源，docker优点\n在容器技术出来之前，我们都是使用虚拟机技术，\n虚拟机：在windows中装一个虚拟机软件vmware，通过这个软件我们可以虚拟出来一台或者多台电脑！笨重！\n虚拟机：也是属于虚拟化技术，docker容器技术，也是一种虚拟化技术\nvm：linux centos 原生镜像（一个电脑） 隔离：需要开启多个虚拟机 几分钟 docker：隔离 镜像机制（最核心的环境 4m +jdk+mysql）十分小巧，运行镜像就可以了 几M 几s docker是基于go语言开发的！开源\ndocker的文档超级详细\n仓库地址：pull push\ndocker能干嘛\n之前的虚拟机技术！\n从内核到库函数到app\n虚拟机技术缺点：\n1.资源占用十分多\n2.冗余步骤多\n3.启动很慢\n容器化技术\n容器化技术不是模拟一个完整的操作系统\n比较docker和虚拟机技术的不同：\n传统虚拟机，虚拟出一个硬件，运行一个完整的操作系统，然后再这个系统上安装和运行软件 容器内的应用直接运行在宿主机的内，容器是没有自己的内核的，也没有虚拟我们的硬件，所以就轻便了 每个容器间互相隔离，每个容器内都有一个属于自己的文件系统，互不影响 devops\n更快速的交付和部署\n传统：一堆帮助文档，安装程序\ndocker：一键运行，打包镜像，发布测试\n更便捷的升级和扩缩容\n使用了docker之后，我们部署应用就和搭积木一样\nspringboot1.5 redis5 tomcat8\n项目打包为一个镜像，扩展，服务器A！开服务器B，做扩展\n更简单的系统运维\n在容器化之后，我们的开发，测试环境高度一致\n更高效的利用计算资源：\n1核 2g的服务器！\ndocker是内核级别的虚拟化，可以在一个物理机上可以运行很多的容器实例，服务器的性能可以运行到极致\ndocker的基本组成\n镜像：image 就是一个类，好比一个模版，可以通过这个模版来创建容器服务，tomcat镜像\u0026ndash;\u0026gt;run\u0026mdash;\u0026ndash;\u0026gt;tomcat01容器（提供服务） 通过这个镜像可以创建多个容器（最终服务或者项目运行就是在容器中）\n容器：container docker利用容器技术，独立运行一个或者一个组应用，通过镜像来创建的。启动、停止、删除、基本命令！目前就可以吧容器理解为就是一个简易的linux系统\n仓库：respository 仓库就是存放镜像的地方 仓库分为公有仓库和私有仓库！ dockerhub 阿里云 都有容器服务器（配置镜像加速）！\n安装docker\n1.需要linux基础\n2.centos7\n3.使用xshell连接远程服务器进行操作\nimage-20210607214021379\rimage-20210607214316440\r查看一下下载的这个hello-world镜像\nimage-20210607214400376\r阿里云镜像加速\n1.登陆阿里云\n2.容器镜像服务\nimage-20210607215031767\r3.配置使用\nsudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://lufuant6.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker 回顾helloworld流程\n开始\u0026ndash;\u0026gt;本地寻找镜像\u0026ndash;\u0026gt;如果有就使用这个镜像运行，如果没有就去仓库下载pull\n底层原理\ndocker怎么工作的\ndocker是一个client\u0026ndash;server结构的系统，docker的守护进程运行在主机上，通过socket从客户端访问\ndockerserver接收到docker-client的指令，就会执行这个命令\ndocker为什么比vm快\n1.docker有着比虚拟机更少的抽象层\n2.docker利用的是宿主机的内核，vm需要guest OS\n所以新建一个容器的时候， docker不需要像虚拟机一样重新加载一个操作系统内核，避免引导。虚拟机是加载guestOS，分钟级别的，而docker是利用宿主；机加的操作系统，省略了这个复杂的过程，妙级的\ndocker的常用命令\n帮助命令\ndocker version\ndocker info\ndocker 命令 \u0026ndash;help\n镜像命令\ndocker images docker search docker pull docker rmi image-20210607222535947\r容器命令\ndocker pull centos 新建容器并启动\ndocker run [] image --name =\u0026#34;\u0026#34; 容器名字 -d 后台方式运行 -i 使用交互方式运行， 进入容器查看内容 -t -p 指定容器的端口-p 8080:8080 主机端口：容器端口 -p 容器端口 -p ip：主机端口：容器端口 exit 从容器中退回主机 docker ps 列出所有运行容器 -a 所有正在运行的容器+运行过的容器 -n=? 显示最近创建的容器 docker ps -q 只显示容器的编号 image-20210608200503679\rimage-20210608200706097\r退出容器\nexit 退出容器，并停止 ctrl+P+Q 删除容器\ndocker rm 容器id\tdocker rm -f $(docker ps -aq) image-20210608201640486\r启动停止容器\ndocker start 容器id docker restart 容器id docker stop 容器id docker kill 容器id image-20210608203048244\r常用其他命令\n后台启动\ndocker run -d centos docker容器使用后台运行，就必须要有一个前台进程，docker发现没有应用，就会自动停止 dockerlogs 查看容器当中的进程信息\ndocker top 命令 docker inspect 容器id 查看容器信息 image-20210609223653271\r进入当前正在进行的容器\n我们通常容器都是使用后台方式运行的，需要进入容器，修改一些配置 docker exec -it 容器id docker attach 容器id 正在执行当前的代码 exec进入容器后开启一个新的终端，可以在里面操作（常用） attach 进入容器正在执行的终端，不会启动新的进程 image-20210609224319430\r从容器内拷贝文件到主机上\ndocker cp 容器id ：容器内路径 目的的主机路径 image-20210609230304773\r当前主机目录 root@yourtreedad:~# cd /home root@yourtreedad:/home# ls kuanshen.java test.java root@yourtreedad:/home# touch kuangshen.java root@yourtreedad:/home# ls kuangshen.java kuanshen.java test.java 进入容器内部 root@yourtreedad:/home# docker attach 3a26ef468c27 [root@3a26ef468c27 /]# cd /home bash: cd: $\u0026#39;\\343/home\u0026#39;: No such file or directory [root@3a26ef468c27 /]# ls bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@3a26ef468c27 /]# cd /home [root@3a26ef468c27 home]# ls 创建文件 [root@3a26ef468c27 home]# touch test1.java [root@3a26ef468c27 home]# ls test1.java 退出容器 [root@3a26ef468c27 home]# exit exit root@yourtreedad:/home# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES root@yourtreedad:/home# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3a26ef468c27 centos \u0026#34;/bin/bash\u0026#34; 20 minutes ago Exited (0) 16 seconds ago suspicious_wilbur cee72dcd9187 centos \u0026#34;-it /bin/bash\u0026#34; 21 minutes ago Created eager_einstein 73d060aad5ac centos \u0026#34;/bin/bash\u0026#34; 27 hours ago Exited (255) About an hour ago optimistic_leakey 从容器内拷贝文件至主机 root@yourtreedad:/home# docker cp 3a26ef468c27:/home/test1.java /home root@yourtreedad:/home# ls kuangshen.java kuanshen.java test.java test1.java 拷贝是一个手动过程，未来我们使用 -v 卷的技术，可以实现自动同步 docker命令很多，以上是最常用的\ndocker安装nginx\n1.搜索镜像\n2.下载镜像\n3.启动镜像\nimage-20210609233757534\r测试\nimage-20210609234211565\r端口映射\n进入容器，查看文件\nimage-20210609234650627\r思考问题：每次改动nignx配置文件，都需要进入容器内部？都十分麻烦，我要是可以在容器外部提供一个映射路径，达到在容器外部修改文件，容器内部就可以自动修改？ -v 数据卷技术\ndocker装一个tomcat\ndocker run -it --rm tomcat:9.0 之前的启动都是后台，停止了容器之后，容器还是可以查到 docker run -it --rm 一般用来测试，用完就删除 进入容器 PS C:\\Users\\Sweetie\u0026gt; docker run -d -p 3355:8080 --name tomcat01 tomcat c42f39b1590834eb3720faa3cee74b79a909550fe02bc2ed383676908c3accf2 PS C:\\Users\\Sweetie\u0026gt; docker exec -it tomcat01 /bin/bash root@c42f39b15908:/usr/local/tomcat# ls linux命令少了 没有webapps 阿里云镜像原因，默认是最小的镜像，所有的不必要的都剔除了。 保证最小可运行的环境 root@c42f39b15908:/usr/local/tomcat/webapps# cd .. root@c42f39b15908:/usr/local/tomcat# ls BUILDING.txt LICENSE README.md RUNNING.txt conf logs temp webapps.dist CONTRIBUTING.md NOTICE RELEASE-NOTES bin lib native-jni-lib webapps work root@c42f39b15908:/usr/local/tomcat# cd webapps.dist root@c42f39b15908:/usr/local/tomcat/webapps.dist# ls ROOT docs examples host-manager manager root@c42f39b15908:/usr/local/tomcat/webapps.dist# cd .. root@c42f39b15908:/usr/local/tomcat# cp -r webapps.dist/* webapps root@c42f39b15908:/usr/local/tomcat# cd webapps root@c42f39b15908:/usr/local/tomcat/webapps# ls ROOT docs examples host-manager manager 以后要部署项目，如果每次都要进入容器是不是十分麻烦，要是可以在容器外部提供一个映射路径，达到在容器修改文件名，容器内部就可以自动修改？ -v 数据卷技术\nwebapps，在外部放置项目，就自动同步到内部就好了！！！\ndocker容器 tomcat+网站 docker+mysql\n部署es+kibana\nes暴露的端口很多 es十分耗内存 es的数据一般需要放置在安全目录！挂载 --net somenetwork ? 网络配置 下载启动 docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \u0026#34;discovery.type=single-node\u0026#34; elasticsearch:7.6.2 一启动就顶不住了，很好内存 docker statuc 查看cpu的状态 赶紧关闭，增加内存的限制，修改配置文件 -e 配置修改 docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \u0026#34;discovery.type=single-node\u0026#34; -e ES_JAVA_OPTS=\u0026#34;-Xms64m -Xmx512m\u0026#34; elasticsearch:7.6.2 环境配置 作业：使用kibana 连接elasticsearch\n因为相互隔离，所以直接localhost来连不现实，可以使用linux内网ip来搞，需要了解docker网络原理，网络的基本知识\n可视化\nportainer先用这个\nrancher（CI、CD再用）\n什么是portainer\ndocker图形化界面管理工具！提供一个后台面板，供我们操作！\ndocker run -d -p 8088:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer 访问测试 外网8088端口 通过它来访问 可视化面板，我们平时不会使用，测试玩玩即可 docker镜像讲解\n镜像是什么\n镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件\n所有的应用，直接打包docker镜像，就可以直接跑起来\n如何得到镜像：\n从远程仓库下载 朋友拷贝给你 自己制作一个镜像 dockerfile unionFS联合文件系统\n我们下载的时候看到的一层层的就是这个\nunionfs联合文件系统，是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改，作为一次提交来一层层叠加，同时可以将不同目录挂在到同一个虚拟文件系统下unite several directories into a single virtual filesystem 。union文件系统是docker 镜像的基础，镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像\n特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录\ndocker镜像加载原理\ndocker的镜像实际上是由一层一层的文件系统组成，这种层级的文件系统UnionFS\nbootfs （boot file system ） 主要包含bootloader 和 kernel ，bootloader 主要是引导加载kernel ， linux 刚启动时会加载 bootfs 文件系统，在docker 镜像的最底层是bootfs。这一层与我们典型的linu/unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs\nrootfs（root file system），在bootfs之上，包含的就是典型linux系统中的 /dev , /proc / bin , /etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如ubuntu，centos等等\n平时我们安装进虚拟机的centos都是好几个G，为什么docker这里才200M\n对于一个精简的OS，rootfs可以很小，只需要包含最基本的命令，工具和程序库就可以了，因为底层直接用host的kernel，自己只需要提供rootfs就可以了，由此可见对于不同的linux发行版，bootfs基本是一致的，rootfs会有差别，因此不同的发行版本可以共用bootfs\n分层理解\nPS C:\\Users\\Sweetie\u0026gt; docker pull redis Using default tag: latest latest: Pulling from library/redis 69692152171a: Already exists a4a46f2fd7e0: Pull complete bcdf6fddc3bd: Pull complete 2902e41faefa: Pull complete df3e1d63cdb1: Pull complete fa57f005a60d: Pull complete 我们可以去下载一个镜像，注意观察下载的日志输出，可以看到是一层一层在下载的！\n思考：为什么docker镜像要采用这种分层的结构呢？\n最大的好处，我觉得莫过于是资源共享！比如有多个镜像都从相同的base镜像构建而来，那么宿主机只需要在磁盘上保留一份base镜像，同时内存中也只需要加载一份base镜像，这样就可以为所有的容器服务了，而且镜像的每一层都可以被共享\n}, \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:02c055ef67f5904019f43a41ea5f099996d8e7633749b6e606c400526b2c4b33\u0026#34;, \u0026#34;sha256:ec5652c3523d96657d66169c0eb71b572ff065711c705a15ec02f60a21c212c3\u0026#34;, \u0026#34;sha256:76d3e24d63f60e6a73af70be15959eb4021dd7a5a09da6925037d3b4a1673fca\u0026#34;, \u0026#34;sha256:f06719b0aa43029f32c821c8f14f9f5941a8be6d3b61dcd9f3f884b39e9a4f23\u0026#34;, \u0026#34;sha256:b896f490f2edc62cc9d190465bbeab871619590d1e9beeffb92e4ca9cc08116d\u0026#34;, \u0026#34;sha256:e3f4077f577bf07c0940d6345ddd17014ff824d3f4f7f3effc9a8c4dae3e527b\u0026#34; ] }, \u0026#34;Metadata\u0026#34;: { \u0026#34;LastTagTime\u0026#34;: \u0026#34;0001-01-01T00:00:00Z\u0026#34; } 理解：\n所有的docker镜像都起始于一个基础镜像层，当进行修改或者增加新的内容时，就会在当前镜像层之上，创建新的镜像层。举一个简单的例子，假如基于ubuntu linux 16.04 创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加python包，该镜像就会在基础镜像层之上创建第二个镜像层，如果继续添加一个安全不定，就会创建第三个镜像层。\n在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。\n这种情况下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像中。docker通过存储引擎（新版本采用快照机制）的方式来实现惊险层堆栈，并保证多镜像层对外展示为统一的文件系统。\nlinux上可用的存储引擎有AUFS、Overlay2、Device Mapper、Btrfs以及ZFS。顾名思义，每种存储引擎都基于Linux中对应的文件系统或者块设备技术，并且每种引擎都有其独有的性能特点。\nDocker在windows上仅支持windowsfilter一种存储引擎，该引擎基于NTFS文件系统之上实现了分层和cow\ndocker镜像都是只读的，一个新的刻写层被加载到镜像的顶部！\n这一层就是我们通常说的容器层，容器之下的都叫镜像\n如何提交一个自己的镜像\ncommit镜像\ndocker commit 提交容器成为一个新的副本 docker commit -m=\u0026#34;提交的描述信息\u0026#34; -a=\u0026#34;作者\u0026#34; 容器id 目标镜像名:[TAG] 测试\n启动默认tomcat 没有文件的webapps root@e7c2f9ef26e4:/usr/local/tomcat# cp -r webapps.dist/* webapps root@e7c2f9ef26e4:/usr/local/tomcat# ls BUILDING.txt LICENSE README.md RUNNING.txt conf logs temp webapps.dist CONTRIBUTING.md NOTICE RELEASE-NOTES bin lib native-jni-lib webapps work root@e7c2f9ef26e4:/usr/local/tomcat# cd webapps root@e7c2f9ef26e4:/usr/local/tomcat/webapps# ls ROOT docs examples host-manager manager cp命令拷贝进webapps image-20210612162156751\r浏览器可以访问 commit提交为一个新的镜像，我们以后就使用我们修改过的镜像即可，这就是我们自己的一个修改过的镜像 PS C:\\Users\\Sweetie\u0026gt; docker commit -m=\u0026#34;add webapps app\u0026#34; -a=\u0026#34;ljs\u0026#34; e7c2f9ef26e4 tomcatupdate1.0 sha256:2a308d5b7f5a2b5b471a193c596369ee1ec2168d04221397ced9c9201a94075e PS C:\\Users\\Sweetie\u0026gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE tomcatupdate1.0 latest 2a308d5b7f5a 8 seconds ago 672MB redis latest fad0ee7e917a 10 days ago 105MB nginx latest d1a364dc548d 2 weeks ago 133MB tomcat latest c43a65faae57 4 weeks ago 667MB portainer/portainer latest 580c0e4e98b0 2 months ago 79.1MB centos latest 300e315adb2f 6 months ago 209MB elasticsearch 7.6.2 f29a1ee41030 14 months ago 791MB elasticsearch latest 5acf0e8da90b 2 years ago 486MB image-20210612162537739\r如果你想要保存当前容器的状态，就可以通过commit来提交，获得一个镜像。\n就好比以前我们学习VM的时候，快照\n到这里才算入门\n容器数据卷、dockerfile、docker网络：docker精髓\n企业实战\ndocker compose\ndocker swarm\nci 、 cd jenkins 流水线\n容器数据卷\n什么是容器数据卷\ndocker的理念回顾：\n将应用和环境打包成一个镜像！\n数据？如果数据都在容器中，那么我们把容器删除，数据就会丢失！\n需求：数据可以持久化\nMYsql，容器删了，删库跑路!\n需求：MYsql的数据可以存储在本地！\n容器之间可以有一个容器共享的技术！docker容器中产生的数据，同步到本地！\n这就是数据卷技术！目录的挂载，将容器内的目录挂载linux上\n总结一句话：容器的持久化和同步操作！容器间也是可以数据共享的！\n使用数据卷\n方式一：直接使用命令挂载 -v docker run -it -v 主机目录地址：容器内目录地址 -p 主机端口：容器端口 root@yourtreedad:~# cd /home root@yourtreedad:/home# ls kuangshen.java kuanshen.java test.java test1.java root@yourtreedad:/home# cd .. root@yourtreedad:/# docker run -it -v /home/ceshi:/home centos /bin/bash image-20210612164241555\r使用 docker inspect 容器id 查看具体信息\n在外面建立文件，可以看到里面也有\n[root@ffb011d1322a /]# cd home [root@ffb011d1322a home]# ls outtoint.txt 在里面见文件，可以看到里面也有\n[root@ffb011d1322a home]# touch intoout.java [root@ffb011d1322a home]# ls intoout.java outtoint.txt [root@ffb011d1322a home]# exit exit root@yourtreedad:/# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ffb011d1322a centos \u0026#34;/bin/bash\u0026#34; 12 minutes ago Up 10 minutes eager_heyrovsky e7c2f9ef26e4 tomcat:latest \u0026#34;catalina.sh run\u0026#34; 34 minutes ago Up 34 minutes 0.0.0.0:5555-\u0026gt;8080/tcp sweet_ramanujan b90d3528ae04 portainer/portainer \u0026#34;/portainer\u0026#34; 6 hours ago Up 37 minutes 0.0.0.0:8088-\u0026gt;9000/tcp, :::8088-\u0026gt;9000/tcp confident_villani root@yourtreedad:/# cd home root@yourtreedad:/home# cd ceshi root@yourtreedad:/home/ceshi# ls intoout.java outtoint.txt root@yourtreedad:/home/ceshi# 容器停止了，但是只要容器还在，就能实现同步数据，类似双向绑定\nimage-20210612165925505\r好处：我们以后修改只需要在本地修改即可，容器内会自动同步！\n实战：安装mysql\n思考：mysql的数据持久化的问题！\n获取镜像 docker pull mysql 运行容器，需要做数据挂载，需要配置密码，这需要注意 官方测试：docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag -d 后台运行 -p 端口映射 -v 数据卷挂在 -e 环境配置 --name docker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7 启动成功之后，我们在本地使用 sqlyog 来测试一下 sqlyog --h -u -p 连接到服务器的3310 ----3310 和容器内的3306进行映射，这个时候我们就可以连接上了 在本地测试创建一个数据库，查看一下映射的路径是否ok 假设我们将容器删除，发现我们挂载到本地的数据卷依旧没有丢失，这就实现了容器数据持久化功能 image-20210612172111412\r具名挂载和匿名挂载\n匿名挂载 -v 容器内路径 相当于不指定主机的地址，直接指定容器地址 root@yourtreedad:/# docker run -d -P --name nginx01 -v /etc/nginx nginx 查看所有卷的情况 docker volume ls 这里发现 DRIVER VOLUME NAME local 0faef3ffc2187555023c9a8e5dca5c11e47f0b436657e48f95e972e33c951c49 这种就是匿名挂载，我们-v的时候只写了容器的路径，没有写容器外的路径！ 通过-v 卷名：容器内路径 这就是具名挂载 root@yourtreedad:/# docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx nginx 11c306e0a80402c0c235042326f5db9da58570e01abac55379414d9d53abc797 root@yourtreedad:/# docker volume ls DRIVER VOLUME NAME local 0faef3ffc2187555023c9a8e5dca5c11e47f0b436657e48f95e972e33c951c49 local 3c63eeef73128b24bbf1830f9cec7d383aae8413e232a857f1216456fb07fedf local 941b4501fa7cefd9a341366fbe18cfeddd0f2d223c1eb87addf1a77a42c2ace8 local 3826373b692739fc44eac10a00d8ddada7b0200c5833963c459d6db001384a70 local 8440372a24dc57f1bcf100c1ef256abbff5713f1c96c2bd65276aea10f54864d local cb64d53be430f816088a1f1bbd1f5aea8885a1be33ddd98a5fb98a9d452fa03c local juming-nginx 查看一下这个卷挂载在主机的哪个位置了呢 root@yourtreedad:/# docker volume inspect juming-nginx [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2021-06-13T02:11:30Z\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: null, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/juming-nginx/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;juming-nginx\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] 所有docker容器内的卷，如果没有指定目录的情况下，都是在/var/lib/docker/volumes/xxxx下 我们通过具名挂载可以方便的找到我们的一个卷，大多数情况下使用的是具名挂载 image-20210613100849422\r如何确定是具名挂载还是匿名挂载 ，还是指定路径挂载 -v 容器内路径 这就是匿名挂载 -v 卷名：容器内路径 这就是具名挂载 -v /宿主机路径：/容器内路径 这就是指定路径挂载 拓展： 通过 -v 容器内路径，ro 、 rw 改变读写权限 docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:ro nginx docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:rw nginx 只读ro readonly 可读可写rw readwrite 一旦设置了ro 容器对我们挂载出来的内容就有限定了！ ro只要看到ro，就说明这个路径只能通过宿主机来操作，容器内部是无法操作的 初识dockerfile\n方式二：\ndockerfile就是用来构建docker镜像的构建文件！命令脚本！先体验一下！\nctrl+U 删除当前命令 mkdir 生成文件夹 rm -rf 文件夹名字 强制删除文件夹名字 pwd 查看当前在那个目录中 进入文件后 esc 再：wq就是保存并退出 vim 使用文本编辑器进入文件 a后就可以编辑 通过脚本可以生成镜像，镜像是一层一层的 touch 创建一个文件 ##创建一个dockerfile文件，名字可以随机，建议 dockerfile ##文件中的内容 指令都是大写 参数 ##这里的每个命令，都是镜像的一层 FROM centos VOLUME[\u0026#34;volume01\u0026#34;,\u0026#34;volume02\u0026#34;] CMD echo \u0026#34;-----end-----\u0026#34; CMD /bin/bash 好像要空行！！！！ 通过dockerfile 去构建镜像 root@yourtreedad:/home/docker-test-volume# docker build -f /home/docker-test-volume/dockerfile1 -t kuangshen/centos:1.0 . 启动一下自己的生成的容器\nroot@yourtreedad:/# docker images REPOSITORY TAG IMAGE ID CREATED SIZE tomcatupdate 1.0 ee149e8cdc20 5 hours ago 672MB portainer/portainer-ce latest 45be17a5903a 2 weeks ago 209MB nginx latest d1a364dc548d 2 weeks ago 133MB tomcat latest c43a65faae57 4 weeks ago 667MB mysql latest c0cdc95609f1 4 weeks ago 556MB portainer/portainer latest 580c0e4e98b0 2 months ago 79.1MB kuangshen/centos 1.0 f75a47123694 6 months ago 209MB root@yourtreedad:/# docker run -it f75a47123694 /bin/bash 但是这个地方报错了，好象是说现在的destination 不能为相对路径 docker: Error response from daemon: OCI runtime create failed: invalid mount {Destination:volume01 Type:bind Source:/var/lib/docker/volumes/67cb8e440bfc475a6b8e0f091779f2c56fed443d1ca4e6edd10ca37f37d09e05/_data Options:[rbind]}: mount destination volume01 not absolute: unknown. ERRO[0000] error waiting for container: context canceled 查看一下卷挂载的路径\nimage-20210613192809990\r测试一下刚才的文件是否同步出去了，可以在卷里写个文件，在宿主机的挂载位置处查看是否有这个文件就可以辣\n这种方式我们未来使用的十分多，因为我们通常会构建自己的镜像！\n假设构建镜像的时候没有挂载卷，要手动镜像挂载 -v卷名：容器内路径\n数据卷容器：多个容器之间同步数据\n两个mysql同步数据！\n主从复制之类的就可能使用这个技术 使用 --volumes-from docker run -it --name docker02 --volumes-from docker01 centos docker run -it --name docker03 --volumes-from docker01 centos 很像继承 启动3个容器，通过我们刚才自己写的镜像启动 启动完了就测试，测试的时候在主docker01中创建文件看看docker0203中会不会有就好了\nroot@yourtreedad:/# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dfb328e8f37f centos \u0026#34;/bin/bash\u0026#34; 3 minutes ago Up 2 minutes docker03 5787d6ea92e4 centos \u0026#34;/bin/bash\u0026#34; 5 minutes ago Up 3 minutes docker02 c8ba46a34155 centos \u0026#34;/bin/bash\u0026#34; 13 minutes ago Up 12 minutes docker01 root@yourtreedad:/# docker attach c8ba46a34155 [root@c8ba46a34155 /]# cd bin [root@c8ba46a34155 bin]# cd bash bash: cd: bash: Not a directory [root@c8ba46a34155 bin]# cd .. [root@c8ba46a34155 /]# ls bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@c8ba46a34155 /]# mkdir ceshi [root@c8ba46a34155 /]# ls bin ceshi dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@c8ba46a34155 /]# cd ceshi [root@c8ba46a34155 ceshi]# ls [root@c8ba46a34155 ceshi]# touch ceshi.java [root@c8ba46a34155 ceshi]# ls ceshi.java [root@c8ba46a34155 ceshi]# cd .. [root@c8ba46a34155 /]# cd .. [root@c8ba46a34155 /]# exit exit 没问题\noot@yourtreedad:/# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dfb328e8f37f centos \u0026#34;/bin/bash\u0026#34; 6 minutes ago Up 6 minutes docker03 5787d6ea92e4 centos \u0026#34;/bin/bash\u0026#34; 8 minutes ago Up 7 minutes docker02 c8ba46a34155 centos \u0026#34;/bin/bash\u0026#34; 17 minutes ago Up 41 seconds docker01 root@yourtreedad:/# docker attach c8ba46a34155 [root@c8ba46a34155 /]# ls bin ceshi dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@c8ba46a34155 /]# cd ceshi [root@c8ba46a34155 ceshi]# ls ceshi.java [root@c8ba46a34155 ceshi]# 问题：如果docker01 删除了，那么数据还有在docker02和docker03上有吗\n有的，它是一种拷贝的概念 ，可能是链接吧\n结论：容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用为止\n但是一旦你持久化到了本地，那么数据就可以持久化保存了，本地的数据是不会删除的\ndockerfile\ndockerfile核心是用来构建docker images 的文件！命令参数脚本！\n构建步骤：\n1.编写一个dockerfile文件\n2.docker build 构建一个镜像\n3.docker run 运行镜像\n4.docker push 发布镜像（dockerhub 、 阿里云镜像仓库）\n查看一下官方是怎么做的\n很多官方镜像都是基础包，很多功能没有，我们通常会自己搭建自己的镜像！\n官方既然可以制作镜像，我们也可以！\ndockerfile构建过程\n很多指令：\n基础知识：\n1.每个保留关键字（指令） 都必须是大写字母\n2.执行从上到下顺序执行\n3.#表示注释\n4.每个指令都会创建提交一个新的镜像层，并提交\ndockerfile 是面向开发的，我们以后要发布项目，做镜像，就需要编写dockerfile文件，这个文件十分简单\ndocker 镜像 例如构建一个springboot 微服务 镜像\ndocker镜像主键成为企业交付的标准，必须要掌握\n步骤：开发运维上线部署\ndockerfile：构建文件，这个文件定义了一切的步骤，源代码\ndockerimages：通过dockerfile构建生成的镜像，这就是最终发布和运行的产品\ndockercontainer：容器就是镜像运行起来提供服务的\ndockerfile的指令：\n以前的话我们都是使用别人的，现在我们知道了这些指令后，我们来练习自己写一个镜像！\nFROM 基础镜像 一切从这里开始构建 MAINTAINER 镜像是谁写的，有你的姓名+邮箱 RUN docker镜像构建的时候需要运行的命令 ADD 步骤：tomcat镜像，这个tomcat压缩包坑定要被添加进去嘛 WORKDIR 镜像的工作目录 VOLUME 容器卷，要挂载的目录 EXPOSE 指定暴露端口 CMD 指定这个容器启动的时候要运行的命令 只有最后一个会生效，可被替代 ENTRYPOINT 指定这个容器启动的时候要运行的命令，可以追加的命令 ONBUILD 当构建一个被继承的dockerfile时候 就会运行onbuild指令，触发指令 COPY 类似ADD,将我们的文件拷贝到镜像中 ENV\t构建的时候设置环境变量 实战测试！\ndocker hub 中 99% 都是从这个基础镜像过来的 FROM scratch ， 然后配置需要的软件和配置来进行的构建\nimage-20210613202655507\r创建一个自己的centos\nimage-20210613203001901\r问题：vim clear 等命令都不支持，我们可以在此镜像的基础上在加一点完善一下\n1.编写dockerdile的文件 root@yourtreedad:/# cd home root@yourtreedad:/home# ls docker-test-volume mysql nginx tomcat root@yourtreedad:/home# mkdir dockerfile root@yourtreedad:/home# ls docker-test-volume dockerfile mysql nginx tomcat root@yourtreedad:/home# cd dockerfile root@yourtreedad:/home/dockerfile# ls root@yourtreedad:/home/dockerfile# vim mydockerfile root@yourtreedad:/home/dockerfile# cat mydockerfile FROM centos MAINTAINER ljs\u0026lt;1018814650@qq.com\u0026gt; ENV MYPATH /uer/local WORKDIR $MYPATH RUN yum -y install vim RUN yum -y install clear RUM yum -y install net-tools EXPOSE 80 CMD echo $MYPATH CMD echo \u0026#34;-----end-----\u0026#34; CMD /bin/bash root@yourtreedad:/home/dockerfile# 2.通过这个文件构建镜像 docker build -f dockerfile文件路径 -t 镜像名：[tag] root@yourtreedad:/home/dockerfile# docker build -f mydockerfile -t mycentos:0.1 . [+] Building 2.2s (8/8) FINISHED =\u0026gt; [internal] load build definition from mydockerfile 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 245B 0.0s =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; [internal] load metadata for docker.io/library/centos:latest 0.0s =\u0026gt; [1/4] FROM docker.io/library/centos 0.0s =\u0026gt; CACHED [2/4] WORKDIR /uer/local 0.0s =\u0026gt; CACHED [3/4] RUN yum -y install vim 0.0s =\u0026gt; [4/4] RUN yum -y install net-tools 1.8s =\u0026gt; exporting to image 0.3s =\u0026gt; =\u0026gt; exporting layers 0.3s =\u0026gt; =\u0026gt; writing image sha256:2734e41a96b14a3e45a820363638a9f62dfd2c7d901757ea5e2a9ba25ababf50 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/mycentos:0.1\t3.测试 root@yourtreedad:/home/dockerfile# docker run -it --name mycentosdemo mycentos:0.1 [root@51e42c44c78d local]# pwd /uer/local [root@51e42c44c78d local]# ifconfig eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 172.17.0.4 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:04 txqueuelen 0 (Ethernet) RX packets 9 bytes 726 (726.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 对比:之前的原生的centos，工作目录默认根目录，没有vim ifconfig 命令\n现在：基于原生centos，添加了这些命令\n我们可以列出本地镜像的变更历史\ndocker history imageId image-20210613204852480\r所以我们平时拿到一个镜像，可以研究一下他是怎么做的了\nCMD 和 ENTRYPOINT 的区别\nCMD 指定这个容器启动的时候需要运行的命令，只有最后一个会生效，可被替代 cmd的情况下 -l 替换了CMD的[\u0026#34;ls\u0026#34;,\u0026#34;-a\u0026#34;]命令，-l 不是命令所以报错 ENTRYPOINT 指定这个容器启动的时候需要运行的命令你，可以追加命令 image-20210613235037903\rimage-20210613235823435\rimage-20210613235940096\r不会替换人家的命令\n我们的追加命令，是直接凭借在我们的ENTRYPOINT 命令的后面！\ndockerfile中很多命令都十分相似，我们需要了解她们的区别，我们最好的学习就是对比她们然后测试效果\n实战：\ntomcat镜像\n1.准备镜像文件 tomcat压缩表，jdk的压缩包！\nimage-20210614104621398\r2.编写dockerfile文件 ， 官方命名Dockerfile ，build会自动寻找这个文件，就不需要-f 指定了\nroot@yourtreedad:/home/kuangshen# cat Dockerfile FROM centos MAINTAINER ljs\u0026lt;1018814650@qq.com\u0026gt; COPY readme.txt /usr/local/readme.txt ADD jdk-8u291-linux-aarch64.tar.gz /usr/local/ ADD apache-tomcat-9.0.46.tar.gz /usr/local/ RUN yum -y install vim ENV MYPATH /usr/local WORKDIR $MYPATH ENV JAVA_HOME /usr/local/jdk1.8.0_291 ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ENV CATALINA_HOME /usr/local/apache-tomcat-9.0.46 ENV CATALINA_BASH /usr/local/apache-tomcat-9.0.46 ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin EXPOSE 8080 CMD /usr/local/apache-tomcat-9.0.46/bin/startup.sh \u0026amp;\u0026amp; tail -F /usr/local/apache-tomcat-9.0.46/bin/logs/catalina.out root@yourtreedad:/home/kuangshen# image-20210614112215796\r3.构建镜像\nimage-20210614110353773\rroot@yourtreedad:/home/kuangshen# docker build -f Dockerfile -t diytomcat . [+] Building 0.1s (11/11) FINISHED =\u0026gt; [internal] load build definition from Dockerfile 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 670B 0.0s =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; [internal] load metadata for docker.io/library/centos:latest 0.0s =\u0026gt; [1/6] FROM docker.io/library/centos 0.0s =\u0026gt; [internal] load build context 0.0s =\u0026gt; =\u0026gt; transferring context: 130B 0.0s =\u0026gt; CACHED [2/6] COPY readme.txt /usr/local/readme.txt 0.0s =\u0026gt; CACHED [3/6] ADD jdk-8u291-linux-aarch64.tar.gz /usr/local/ 0.0s =\u0026gt; CACHED [4/6] ADD apache-tomcat-9.0.46.tar.gz /usr/local/ 0.0s =\u0026gt; CACHED [5/6] RUN yum -y install vim 0.0s =\u0026gt; CACHED [6/6] WORKDIR /usr/local 0.0s =\u0026gt; exporting to image 0.0s =\u0026gt; =\u0026gt; exporting layers 0.0s =\u0026gt; =\u0026gt; writing image sha256:d65fc7234bf254fb93a262a640dcfb543b6f4780fa36ef881bb9992d9705359f 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/diytomcat 启动容器 分配端口 使用挂载 指定镜像 root@yourtreedad:/home/kuangshen# docker run -d -p 9090:8080 --name kuangshendiytomcat -v /home/kuangshen/build/tomcat/test:/usr/local/apache-tomcat-9.0.46/webapps/test -v /home/kuangshen/build/tomcat/tomcatlogs:/usr/local/apache-tomcat-9.0.46/logs diytomcat:1.0 image-20210614110934343\rroot@yourtreedad:/home/kuangshen# docker images REPOSITORY TAG IMAGE ID CREATED SIZE diytomcat latest d65fc7234bf2 4 hours ago 464MB mycentos 0.1 2734e41a96b1 20 hours ago 284MB tomcatupdate 1.0 ee149e8cdc20 28 hours ago 672MB portainer/portainer-ce latest 45be17a5903a 2 weeks ago 209MB nginx latest d1a364dc548d 2 weeks ago 133MB tomcat latest c43a65faae57 4 weeks ago 667MB mysql latest c0cdc95609f1 4 weeks ago 556MB portainer/portainer latest 580c0e4e98b0 2 months ago 79.1MB mycentosentrypointtest 1.0 5198b187e833 6 months ago 209MB mycentostest 1.0 be8cf7de8763 6 months ago 209MB kuangshen/centos 1.0 f75a47123694 6 months ago 209MB centos latest 300e315adb2f 6 months ago 209MB root@yourtreedad:/home/kuangshen# docker run --name diytomcat01 -d -p 9090:8080 -v /home/kuangshen/build/tomcat/test:/usr/local/apache-tomcat-9.0.46/webapps/test -v /home/kuangshen/build/tomcat/tomcatlogs:/usr/local/apache-tomcat-9.0.46/logs diytomcat 174cd08dab23fce852cae1ac5e721c985b377d1ff85a1e769384cb9dd369bde0 进入容器查看\nroot@yourtreedad:/home/kuangshen/build/tomcat# docker exec -it c7cff52b8760 /bin/bash 这里的bin/bash就会自动跳转到我们设定好的usr/local目录之下 image-20210614111326218\r4.启动镜像\n5.访问测试\n6.发布项目（由于做了卷挂载，我们直接在本地编写项目就可以直接发布了！）\n发现项目部署成功，可以直接访问！\n我们以后开发的步骤：需要掌握dockerfile的编写！我们之后的一切都是使用docker镜像来发布运行！！！\n发布镜像\ndockerhub\n1.地址 注册自己的账号\n2.确定这个账号可以登陆\nimage-20210614162522282\r3.在服务器上提交自己的镜像\n在此之前需要打tag\nroot@yourtreedad:/# docker tag --help Usage: docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE root@yourtreedad:/# docker tag tomcatupdate:1.0 yourtreedad/tomcatupdate:2.0 image-20210614165331722\rroot@yourtreedad:/# docker push yourtreedad/tomcateupdatehub:1.0 image-20210614165502602\r提交的时候也是按照镜像的层级一层一层提交的\n可以发布到阿里云镜像服务上嘻嘻\n1.登陆阿里云\n2.找到容器镜像服务\n3.创建命名空间 为了隔离\nimage-20210614170103181\r4.创建容器镜像\nimage-20210614170213918\r5.浏览阿里云\nimage-20210614170251978\rroot@yourtreedad:/# docker login --username=把书掏出来 registry.cn-hangzhou.aliyuncs.com Password: Login Succeeded\t登陆\nroot@yourtreedad:/# docker tag ee149e8cdc20 registry.cn-hangzhou.aliyuncs.com/hfutie/yourtree-test:1.0 image-20210614171742651\r上传\nroot@yourtreedad:/# docker push registry.cn-hangzhou.aliyuncs.com/hfutie/yourtree-test:1.0 image-20210614171949041\rimage-20210614172425553\rdocker小结\ndockerfile build\nimages tag、run/push/pull/save/load\ncontainers stop/kill/start/restart/commit\ndockerrepository\nbackup.tar\nimage-20210614172933295\r精通的话需要学会docker网络（铺垫、容器编排、集群部署）\ndocker网络\n理解docker网络 docker0\n清空所有环境\n测试\nimage-20210614185814918\r好多个网络，docker是如何处理容器网络访问的？\nES之前的问题\nroot@yourtreedad:/# docker run -d -P --name tomcat01 tomcat 查看容器的内部网络地址 ip addr,发现容器启动的时候会得到一个eth0@if22 ip地址，docker分配的 root@yourtreedad:~# docker exec -it tomcat01 ip addr 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: sit0@NONE: \u0026lt;NOARP\u0026gt; mtu 1480 qdisc noop state DOWN group default qlen 1000 link/sit 0.0.0.0 brd 0.0.0.0 21: eth0@if22: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 发现windows好像ping不通啊 linux可以ping通 docker容器内部 原理\n192.168.0.1路由器\n192.168.0.3 同一个网段是能ping通的\n1.我们每安装一个docker容器 ， docker就会给docker容器分配一个ip，我们只要安装了docker，就会有一个网卡docker0，（windows for docker好像咩有） ， 桥接模式，使用的技术是evth-pair技术！\n再次测试 ip addr之后\nimage-20210614190941605\r网课里说的是又多了一个，但windows中没有发现\n2.在启动一个容器测试\n网课里说的是又多了一个，但windows中没有\nimage-20210614191119464\r我们发现这个容器带来的网卡，都是一对一对的 veth-pair 就是一对的虚拟设备接口，她们都是成对出现的，一端连着协议，一端彼此相连 正因为有这个特性 我们就使用veth-pair 充当一个桥梁，连接各种虚拟网络设备的 OpenStac，Docker容器之间的链接，OVS的连接，都是使用 veth-pair技术 3.我们来测试一下tomca01 和 tomcat02 是否可以ping通\nimage-20210614194957533\r在linux中，tomcat01和宿主机和tomcat02可以相互ping通\n在windows for docker中，tomcat01和tomcat02可以通，但是不能和宿主机ping通\n结论：容器和容器之间是可以互相ping通的\n在linux中，tomcat01和tomcat02是共用的一个路由器，即docker0\n所有的容器不指定网络的情况下，都是docker0路由的，docker会给我们的容器分配一个默认的可用IP\n0-255 A B C\n255.255.0.1/16 域\n00000000.00000000.00000000.00000000\n小结\ndocker使用的是linux桥接，宿主机中是一个docker容器的网桥，docker0\ndocker中的所有的网络接口都是虚拟的，虚拟的转发效率高！内网传递文件！\n只要容器删除了，对应的网桥就没了\n\u0026ndash;link\n思考一个场景，我们编写了一个微服务，database url = ip：\n项目不重启，数据库ip换掉了，我们希望可以处理这个问题，可以通过名字来进行访问容器？\n直接ping服务名是不行的 root@yourtreedad:~# docker exec -it tomcat02 ping tomcat01 ping: tomcat01: Name or service not known 解决？ 通过--link 就可以解决了网络连通 root@yourtreedad:~# docker run -d --name tomcat03 --link tomcat02 tomcat 832afb5618b02262a5f9cbe48072941cc4784c009d0f91962b371c218afa31c0 root@yourtreedad:~# docker exec -it tomcat02 ping tomcat03 ping: tomcat03: Name or service not known root@yourtreedad:~# docker exec -it tomcat03 ping tomcat02 image-20210614200734188\r默认网关docker0 ，就是这里的172.17.0.1\nimage-20210614201015974\r探究：inspect 容器id\nimage-20210614201318560\rlink的本质 查看hosts配置，在这里原理发现 root@yourtreedad:~# docker exec -it tomcat03 cat /etc/hosts image-20210614201902916\r\u0026ndash;link 就是我们在hosts配置中，增加了一个172.18.0.3 tomcat02 的映射\nimage-20210614202018329\r由于02没有使用\u0026ndash;link，所以不能直接使用 服务名字来跳转\n实际上就是host映射\n我们现在使用docker已经不建议使用\u0026ndash;link了！\n需要自定义网络！不适用docker0！\ndocker0问题：他不支持容器名连接访问！\n自定义网络\n容器互联：\n查看所有的docker网络 docker network ls image-20210614202322526\r网络模式\nbridge 网络桥接模式 搭桥：（默认，自己创建的推荐使用bridge模式）\nnone ：不配置网络\nhost：和宿主机共享网络\ncontainer：容器内网络连通！（用得少，局限很大）\n测试\n我们直接启动的命令 默认，这个我们看了就是我们的docker0 root@yourtreedad:~# docker run -d -P --name tomcat01 --net bridge tomcat 实际上不写--net也是默认的 docker0 特点，默认，域名不能访问 --link 可以打通连接！ 我们可以自定义一个网络！ image-20210614202926510\rimage-20210614203159484\r创建一个自定义网络 docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet 桥接、子网、网关设置 我们自己的网络就创建好了！ image-20210614203427052\r使用自己构建的网络来创建容器，塞进去 root@yourtreedad:~# docker run -d -P --name tomcat-net-01 --net mynet tomcat 8d24df7fb899de77db6b600aedbfacc32fdd161836dd638b56666ca2014ff5bf root@yourtreedad:~# docker run -d -P --name tomcat-net-02 --net mynet tomcat eee0d29dbed8e780487fcc4bf93f1b3a9ab5ad8ffac194861a3c2ee948d8ea9e 查看网络情况 root@yourtreedad:~# docker inspect mynet image-20210614203821209\r看看能不能ping通\n现在不使用 --link也可以ping名字了！ root@yourtreedad:~# docker exec -it tomcat-net-01 ping 192.168.0.3 root@yourtreedad:~# docker exec -it tomcat-net-01 ping tomcat-net-02 我们自定义的网络docker都已经帮我们维护好了对应的关系，推荐我们平时这样使用网络！\nimage-20210614204033670\r好处：\nredis - 保证不同的集群使用不同的网络，保证集群是安全和健康的\nmysql\n网络连通\n没有确保两个集群网络连通的情况下 ， 两个子网是无法相连的\nimage-20210614204746483\r构建两个tomcat 但是默认是docker0网络下的 root@yourtreedad:~# docker run -d -P --name tomcat01 tomcat 86e292de23f4c821375058608f49f6a5bbdcd0220a5c3e36999cafa86eb25f79 root@yourtreedad:~# docker run -d -P --name tomcat02 tomcat e45223474886d4f490ed66446c2eb1b7809b273c5b104fde27301d9746f4ebf6 而tomcat-net-01是在mynet下的，所以连不通 root@yourtreedad:~# docker exec -it tomcat02 ping 192.168.0.3 不能让docker0和mynet连通，这样不安全，要单独让tomcat01 和mynet连通 如何操作 docker network connect 测试打通 tomcat01 到 mynet image-20210614205014081\rroot@yourtreedad:~# docker network connect mynet tomcat01 root@yourtreedad:~# docker network inspect mynet 连通之后就是将tomcat01 放置到了 mynet 网络下？ 一个容器两个ip地址！ 阿里云服务，公网ip 和 私网ip image-20210614205144180\r再试试\nroot@yourtreedad:~# docker exec -it tomcat01 ping tomcat-net-01 0102好像都可以打通\nimage-20210614205634156\r结论：假设要跨网络操作别人，就需要使用docker network connect 连通！\n实战：部署redis集群\n分片+高可用+负载均衡\nshell脚本建立！\n3主3从\n1.建立网络\nroot@yourtreedad:/# docker network create redisnet --subnet 172.38.0.0/16 root@yourtreedad:/# docker network ls root@yourtreedad:/# docker network inspect redisnet image-20210617192710761\r2.通过脚本创建六个redis配置\nroot@yourtreedad:/# for port in $(seq 1 6); do mkdir -p /mydata/redis/node-${port}/conf touch /mydata/redis/node-${port}/conf/redis.conf cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt;/mydata/redis/node-${port}/conf/redis.conf port 6379 bind 0.0.0.0 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 cluster-announce-ip 172.38.0.1${port} cluster-announce-port 6379 cluster-announce-bus-port 16379 appendonly yes EOF done image-20210617194321734\rimage-20210617194434797\r3.拉取镜像，启动容器，分配端口，数据卷映射\nroot@yourtreedad:/# docker run -p 6371:6379 -p 16371:16379 --name redis-1 -v /mydata/redis/node-1/data:/data -v /mydata/redis/node-1/conf/redis.conf:/etc/redis/redis.conf -d --net redisnet --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf docker run -p 6372:6379 -p 16372:16379 --name redis-2 -v /mydata/redis/node-2/data:/data -v /mydata/redis/node-2/conf/redis.conf:/etc/redis/redis.conf -d --net redisnet --ip 172.38.0.12 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf docker run -p 6373:6379 -p 16373:16379 --name redis-3 -v /mydata/redis/node-3/data:/data -v /mydata/redis/node-3/conf/redis.conf:/etc/redis/redis.conf -d --net redisnet --ip 172.38.0.13 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf docker run -p 6374:6379 -p 16374:16379 --name redis-4 -v /mydata/redis/node-4/data:/data -v /mydata/redis/node-4/conf/redis.conf:/etc/redis/redis.conf -d --net redisnet --ip 172.38.0.14 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf docker run -p 6375:6379 -p 16375:16379 --name redis-5 -v /mydata/redis/node-5/data:/data -v /mydata/redis/node-5/conf/redis.conf:/etc/redis/redis.conf -d --net redisnet --ip 172.38.0.15 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf docker run -p 6376:6379 -p 16376:16379 --name redis-6 -v /mydata/redis/node-6/data:/data -v /mydata/redis/node-6/conf/redis.conf:/etc/redis/redis.conf -d --net redisnet --ip 172.38.0.16 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf image-20210617200000188\r进入容器内部\nroot@yourtreedad:/# docker exec -it redis-1 /bin/sh image-20210617200316068\r建立集群 切片\n/data # redis-cli --cluster create 172.38.0.11:6379 172.38.0.12:6379 172.38.0.13:6379 172.38.0.14:6379 172.38.0.15:6379 172.38.0.16:6379 --clust er-replicas 1 image-20210617200738182\r查看集群信息\n/data # redis-cli -c 127.0.0.1:6379\u0026gt; cluster info 127.0.0.1:6379\u0026gt; cluster nodes 127.0.0.1:6379\u0026gt; set a b image-20210617201019736\r测试，停掉一个master主机redis会不会使用备机来顶替主机\nroot@yourtreedad:/# docker stop redis-3 root@yourtreedad:/# docker exec -it redis-1 /bin/sh /data # redis-cli -c 127.0.0.1:6379\u0026gt; cluster info 127.0.0.1:6379\u0026gt; get a image-20210617201403193\rimage-20210617201528497\rdocker 搭建 redis集群完成！\n我们使用了docker之后，所有的技术都会慢慢变得简单起来\nspringboot 微服务打包docker镜像\n1.架构springboot项目\n2.打包应用\n3.编写dockerfile\n4.构建镜像\n5.发布运行！\nimage-20210617204707930\rimage-20210617204834101\rcmd测试\nimage-20210617204915044\rimage-20210617213140315\r回到idea中编写dockerfile\nimage-20210617224102830\r弄好之后连接linux ， 吧windows上的dockerfile和jar包传到linux服务器上，需要使用filezilla软件传输\nlinux服务器ip地址指令 ifconfig\nimage-20210617213836333\r切换用户\n把文件传到linux上\nimage-20210617221920977\r坑死了 ENTRYPOINT 与[]之间有个打空格\n通过build 构建镜像\nroot@yourtreedad:/home/idea# docker build -f Dockerfile -t kuangshen666 . image-20210617224515040\r测试\nroot@yourtreedad:/home/idea# docker run -d --name kuangshen-springboot-web -P kuangshen666 root@yourtreedad:/home/idea# curl localhost:49158/hello image-20210617225833450\rimage-20210617230044609\r以后我们使用了Docker之后，给别人交付的就是一个镜像即可\n预告：如果我们有很多镜像？100个\n还要学\nDocker Compost\nDocker Swarm\nK8s\nCI/CD 之 Jenkins\n尝试基于ECS快速搭建docker环境\nimage-20210618223452399\rimage-20210618223539027\rimage-20210618223624125\rimage-20210618223650264\rECS云服务器新手上路\nimage-20210619103343896\rimage-20210619103400085\rimage-20210619103431630\r下面尝试部署了一下继恩的vue和nginx\nnginx使用挂载的方式-v 来实现对容器内部nginx配置文件的替换，\n利用docker cp 来把dist文件拷贝进去\n使用-p 的方式替换端口\nroot@yourtreedad:~# docker pull nginx Using default tag: latest latest: Pulling from library/nginx b4d181a07f80: Already exists 66b1c490df3f: Pull complete d0f91ae9b44c: Pull complete baf987068537: Pull complete 6bbc76cbebeb: Pull complete 32b766478bc2: Pull complete Digest: sha256:353c20f74d9b6aee359f30e8e4f69c3d7eaea2f610681c4a95849a2fd7c497f9 Status: Downloaded newer image for nginx:latest docker.io/library/nginx:latest root@yourtreedad:~# root@yourtreedad:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest 4cdc5dd7eaad 10 days ago 133MB yourtreedad/blazordemo latest aa1397c0af05 2 weeks ago 207MB mysql latest 5c62e459e087 3 weeks ago 556MB root@yourtreedad:~# cd .. root@yourtreedad:/# pwd / root@yourtreedad:/# cd home root@yourtreedad:/home# ls blazortest haierDemo ljs mvcwindowstest nginx tomcat consoletest1 kuangshen mvctest mysql nginxdemo webapitest root@yourtreedad:/home# cd nginxdemo root@yourtreedad:/home/nginxdemo# ls nginx-1.14.2 nginx-1.14.2.zip root@yourtreedad:/home/nginxdemo# cd nginx-1.14.2 root@yourtreedad:/home/nginxdemo/nginx-1.14.2# ls conf contrib dist docs html logs nginx.exe temp root@yourtreedad:/home/nginxdemo/nginx-1.14.2/conf# docker run --name nginxdemo2 -p 8889:8765 -v /home/nginxdemo/nginx-1 .14.2/conf/myconf1.conf:/etc/nginx/nginx.conf:ro -d nginx 6bed1ace8c9942f62e61ea18f7f632973fa1d7536ac3a6d1ada11e3d2c093b6e root@yourtreedad:/home/nginxdemo/nginx-1.14.2/conf# docker cp /home/nginxdemo/nginx-1.14.2/dist 6bed1ace8c9942f62e:/etc/nginx root@yourtreedad:/home/nginxdemo/nginx-1.14.2/conf# docker exec -it 6bed1ace8c9942f62e61ea18f7f632973fa1d7536ac3a6d1ada11e3d2c093b6e /bin/bash ls ls root@6bed1ace8c99:/# ls bin docker-entrypoint.d home media proc sbin tmp boot docker-entrypoint.sh lib mnt root srv usr dev etc lib64 opt run sys var root@6bed1ace8c99:/# cd /etc root@6bed1ace8c99:/etc# cd nginx root@6bed1ace8c99:/etc/nginx# ls conf.d dist fastcgi_params mime.types modules nginx.conf scgi_params uwsgi_params root@6bed1ace8c99:/etc/nginx# cat nginx.conf #user nobody; c553c6ba5f13: Pushed #error_log logs/error.log; #error_log logs/error.log notice; Head https://registry-1.docker.io/v2/yourtreedad/nginxcontaindist/blobs/sha256:4d7903a7ce4bdf92461e0dd87d1fb712facb6881df3cbce68f55f4ec54791546: dial tcp: lookup registry-1.docker.io on 192.168.65.5:53: no such host root@yourtreedad:/home/nginxdemo/nginx-1.14.2/conf# events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; # server { # listen 8765; # listen localhost; # location / { # root dist; # index index.html index.htm; # } # } sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 8765; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root dist; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} 67f2e8eb8c87: Pushing [\u0026gt; ] 77.82kB/4.758MB # concurs with nginx\u0026#39;s one # #location ~ /\\.ht { # deny all; #} } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} } root@6bed1ace8c99:/etc/nginx# exit exit root@yourtreedad:/home/nginxdemo/nginx-1.14.2/conf# docker commit -a=\u0026#34;yourtreedad\u0026#34; -m=\u0026#34;jien\u0026#39;s ui add ljs\u0026#39;s deploy new nginx that contains dist\u0026#34; 6bed1ace8c nginx:1.0 sha256:4d7903a7ce4bdf92461e0dd87d1fb712facb6881df3cbce68f55f4ec54791546 root@yourtreedad:/home/nginxdemo/nginx-1.14.2/conf# docker push yourtreedad/nginx:1.0 The push refers to repository [docker.io/yourtreedad/nginx] An image does not exist locally with the tag: yourtreedad/nginx root@yourtreedad:/home/nginxdemo/nginx-1.14.2/conf# docker tag nginx:1.0 yourtreedad/nginxcontaindist:1.0 root@yourtreedad:/home/nginxdemo/nginx-1.14.2/conf# docker push yourtreedad/nginxcontaindist:1.0 The push refers to repository [docker.io/yourtreedad/nginxcontaindist] 67f2e8eb8c87: Preparing 9d1af766c818: Preparing d97733c0a3b6: Preparing c553c6ba5f13: Preparing 48b4a40de359: Preparing ace9ed9bcfaf: Waiting 764055ebc9a7: Waiting 这是部署在本地 ， 现在开始演示部署到云服务器上\nimage-20210718003213326\r通过ssh把配置文件传进去\nimage-20210718003244110\r从dockerhub上拉取镜像\nimage-20210718003546820\rimage-20210718003653954\rhttp://47.106.218.61:8888/\n","date":"2021-07-26T00:23:34+08:00","permalink":"https://linjianshu.github.io/p/docker-learning/","title":"Docker Learning"},{"content":"Git学习文档 学习git之前，我们需要先明白一个概念，版本控制！\n版本控制 什么是版本控制 版本迭代 版本管理器\n版本控制（revision control）是一种在开发的过程中用于管理我们对文件、目录或工程等内容的修改历史，方便查看更改历史记录，备份一遍恢复以前的版本的软件工程技术。\n实现跨区域多人协同开发 追踪和记载一个或者多个文件的历史记录 组织和保护你的源代码和文档 统计工作量 并行开发、提高开发效率 跟踪记录整个软件的开发过程 减轻开发人员的负担，节省时间，同时降低人为错误 简单说就是用于管理多人协同开发项目的技术。\n没有进行版本控制或者版本控制本身缺乏正确的流程管理，在软件开发过程中将引入很多问题，如关键代码的冗余，软件过程的事物性，软件开发过程中的并发性、软件源代码的安全性，以及软件的整合等问题。\n多人开发就必须要使用版本控制，否则代价比较大\n常见的版本控制工具\n主流的版本控制器有如下这些：\nGit SVN(subversion) CVS(concurrent versions system) VSS(Microsoft Visual SourceSafe) TFS(team Foundation Server) Visual Studio Online 版本控制产品非常的多（preforce 、 rational clearcase 、 rcs 、serena dimention 、 svk 、bitkeeper、 monotone 、 bazaar 、 mercurial 、 sourcegear vault），现在影响力最大且使用最广泛的是git和svn\n版本控制分类\n本地版本控制\n记录文件每次的更新，可以对每个版本做一个快照，或者记录补丁文件，适合个人用，如RCS\nimage-20210722211743148\r集中版本控制\n所有的版本数据都保存在服务器上，协同开发者从服务器上同步更新或上传自己的修改\nimage-20210722211927845\r所有的版本数据都存在服务器上，用户的本地只有自己以前所同步的版本，如果不连网的话，用户就看不到历史版本，也无法切换版本验证问题，或在不同分支工作。而且，所有数据都保存在单一的服务器上，有很大风险这个服务器会损坏，这样就会丢失所有的数据，当然可以定期备份。代表产品有：SVN、CVS、VSS\n分布版本控制 “GIT”\n每个人都拥有全部的代码 安全隐患\n所有版本信息仓库全部同步到本地的每个用户，这样就可以在本地查看所有版本历史，可以离线在本地提交，只需在连网时push到相应的服务器或其他用户那里。由于每个用户那里保存的都是所有的版本数据，只要有一个用户的设备没有问题，就可以恢复所有的数据，但这增加了本地存储空间的占用\n不会因为服务器损坏或者网络问题，造成不能工作的情况！\nimage-20210722212449100\rgit和svn最主要区别\nsvn是集中式版本控制系统，版本库是集中放在中央服务器的，而工作的时候，用的都是自己的电脑，所有首先要从中央服务器得到最新的版本，然后工作，完成工作后，需要吧自己做完的推送到中央服务器。集中式版本控制是必须连网才能工作，对网络带宽要求较高。\ngit是分布式版本控制系统，没有中央服务器，每个人的电脑就是一个完整的版本库，工作的时候不需要联网了，因为版本都在自己的电脑上，协同的方法是这样的：比如说自己在电脑上修改了文件A，其他人也在电脑上修改了文件A，这时，你们俩之间只需要吧各自的修改推送给对方，就可以相互看到对方的修改了。git可以直接看到更新了那些代码和文件！！\nGit是目前世界上最先进的分布式版本控制系统。\n聊聊git的历史 同生活中的许多伟大事物一样，git诞生于一个极富纷争大举创新的时代。\nlinux内核开源项目有着为数众多的参与者，绝大多数的linux内核维护工作都花在了提交补丁和保存归档的繁琐事务上1991-2002年，到了2002年，整个项目组开始启用一个专有的分布式版本控制系统bitkeeper来管理和维护代码。\n到了2005年，开发bitkeeper的商业公司通linux内核开源社区的合作关系结束，她们收回了linux内核社区免费使用bitkeeper的权力。这就迫使linux开源社区（特别是linux的缔造者linux torvalds）基于使用bitkeeper时的经验教训，开发出了自己的版本系统。也就是后来的git！\ngit是目前世界上最先进的分布式版本控制系统。\ngit开源、免费，最初git是为了辅助linux内核开发的，来替代bitkeeper。\ngit环境配置 软件下载\n打开git，下载对应操作系统的版本\n所有东西下载慢的话就去找镜像！\n官网下载太慢，我们可以使用淘宝镜像下载\n卸载\n直接反安装、然后清理环境变量\n安装，无脑安装\ngit bash ： unix与linux风格的命令行，使用最多，推荐最多\ngit cmd ： windows风格的命令行\ngit gui ： 图形界面的git ， 不建议初学者使用，尽量先熟悉常用命令\n基本的linux命令学习\ncd： 改变目录 cd .. 回退到上一个目录，直接cd进默认目录 pwd 显示当前所在的目录路径 ls （ll） 列出当前目录中的所有文件，只不过ll列出的内容更为详细 touch 新建一个文件 rm 删除一个文件 mkdir 新建一个目录 ， 就是新建一个文件夹 rm - r 删除一个文件夹 rm-r src 就是删除src目录 mv 移动文件 reset 重新初始化终端、清屏 clear清屏 history查看命令历史 help帮助 exit 退出 #\u0026rsquo;\u0026rsquo; 表示注释 平时一定要多使用这些命令\ngit配置\n所有的配置文件，其实都保存在本地！\n查看配置 git config -l\nimage-20210722223828219\r用户名是必须要有的\ngit相关的配置文件\ngit\\etc\\gitconfig: git 安装目录下的gitconfig \u0026ndash;system系统级 users\\administrator.gitconfig 只适用于当前登陆用户的配置 \u0026ndash;global全局 这里可以直接编辑配置文件，通过命令设置后会响应到这里 设置用户名与邮箱（用户标识、必要）\ngit config \u0026ndash;global user.name \u0026ldquo;linjianshu\u0026rdquo;\ngit config \u0026ndash;global user.email 1018814650@qq.com\nGit基本理论（核心） 工作区域\ngit本地有三个工作区域：工作目录（working directory）、暂存区（stage/index）、资源库（repository或Git Directory）。如果在加上远程的git仓库（Remote Directory）就可以分为四个工作区域。文件在这四个区域质检的转换关系如下：\nimage-20210722235632313\rworkspace：工作区，就是你平时存放项目代码的地方 stage：暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息 history：仓库区（或本地仓库），就是安全存放数据的位置，这里面有你提交的所有版本的数据。其中HEAD指向最新放入的版本 remote：远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换本地的三个区域确切的说应该是git中HEAD指向的版本 master 主分支\nimage-20210723000244325\rdirectory ： 使用git管理的一个目录，也就是一个仓库，包含我们的工作空间和git的管理空间。 workspace：需要通过git进行版本控制的目录和文件，这些目录和文件组成了工作空间 .git： 存放git管理信息的目录，初始化仓库的时候自动创建 index/stage： 暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。 local repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支(branch) Stash：隐藏，是一个工作状态保存栈，用于保存/恢复 WorkSpace中的临时状态。 工作流程\ngit的工作流程一般是这样的:\n在工作目录中添加、修改文件； 将需要进行版本管理的文件放入暂存区域； 将暂存区域的文件提交到git仓库 因此，git管理的文件有三种状态：已修改(modified) , 已暂存(staged) , 已提交(committed)\nimage-20210723000906476\rgit add .\ngit commit\ngit push\ngit项目搭建 创建工作目录与常用指令\n工作目录（workspace）一般就是你希望git帮助你管理的文件夹，可以是你项目的目录，也可以是一个空目录，建议不要有中文。\n日常使用只要记住下图6个命令：\nimage-20210723232353522\r本地仓库搭建\n创建本地仓库的方法有两种：一种是创建全新的仓库，另一种是克隆远程仓库\n1.创建全新的仓库，需要用git管理的项目的根目录执行：\n# 在当前目录新建一个git代码库 $ git init 2.执行后可以看到，仅仅在项目目录多出了一个.git目录，关于版本等的所有信息都在这个目录里面。\n克隆远程仓库\n1.另一种方式是克隆远程目录，由于是将远程服务器上的仓库完全镜像一份至本地！\n# 克隆一个项目和它的整个代码历史（版本信息） git clone [url] 2.去gitee或者github上克隆一个试试看\nimage-20210724000439421\rgit文件操作 文件4种状态\n版本控制就是对文件的版本控制，要对文件进行修改、提交等操作，首先要知道文件当前在什么状态，不然可能会提交了现在还不想提交的文件，或者提交的文件没提交上。\nuntracked：未跟踪，此文件在文件夹中，但并没有加入到git库，不参与版本控制，通过 git add 状态变为staged unmodify：文件已经入库，未修改，即版本库中的文件快照内容与文件夹中完全一致，这种类型的文件有两种去处，如果它被修改，而变为modified ， 如果使用 git rm 移出版本库，则成为untracked文件 modified：文件已修改，仅仅是修改，并没有进行其他的操作，这个文件也有两个去处，通过git add 可进入暂存stagged状态，使用git checkout 则丢弃修改过，返回到unmodifiy状态，这个git checkout即从库中取出文件，覆盖当前修改！ staged：暂存状态， 执行git commit，则将修改同步到数据库中，这时库中的文件和本地文件又变为一致，文件为unmodify状态，执行git reset HEAD filename取消暂存，文件状态为modified image-20210724001457370\rimage-20210724001837514\r查看文件状态\n上面说文件有四种状态，通过如下命令可以查看到文件的状态：\n# 查看指定文件状态 git status [filename] # 查看所有文件状态 git status # git add . 添加所有文件到暂存区 # git commit -m 提交暂存区中的内容到本地仓库 -m 提交信息 忽略文件\n有些时候我们不想吧某些文件纳入进版本控制中，比如数据库文件，临时文件，设计文件等\n在主目录下建立.gitignore文件 ， 此文件有如下规则：\n1.忽略文件中的空行或以#号开始的行将会被忽略\n2.可以使用linux通配符。例如星号*代表任意多个字符，问号？代表一个字符，方括号[abc]代表可选字符范围，大括号({string1},{string2})代表可选的字符串等\n3.如果名称的最前面有一个感叹号！，表示例外规则，将不被忽略\n4.如果名称的最前面是一个路径分隔符/，表示要忽略的此文件在此目录下，而子目录中的文件不忽略。\n5.如果名称的最后面是一个路径分隔符/，表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略）\n# 为注释 *.txt #忽略所有 .txt 结尾的文件，这样的话上传就不会被选中 !llib.txt #但lib.txt除外 /temp #仅忽略项目根目录下的todo文件，不包括其他目录temp build/ #仅忽略build/目录下的所有文件 doc/*.txt #会忽略 doc/notes.txt 但不包括doc/server/arch.txt 使用码云 github是有墙的，比较慢，在国内的话，我们一般使用gitee，公司中有时候会搭建自己的gitlab服务器\n1.注册登陆码云，完善个人信息\n这个其实可以作为大家未来找工作的\n2.设置本机绑定ssh公钥，实现免密码登陆！（免密码登陆，这一步挺重要的，码云是远程仓库，我们是平时工作在本地仓库！）\n# 进入C:\\Users\\Sweetie\\.ssh 目录 # 生成公钥 ssh-keygen image-20210724202958752\r使用ssh-keygen -t rsa 命令\n3.将公钥信息public key 添加到码云账户中即可！\nimage-20210724203418738\r4.使用码云创建一个而自己的仓库\n新建仓库\rimage-20210724203745902\r许可证：开源是否可以随意转载，开源但是不能商业使用，不能转载，\u0026hellip;限制！\n也就是在git上图形化界面上建立仓库，在本地通过git bash 克隆远程仓库\nimage-20210724203950054\rIEDA中集成git 新建项目，绑定git\n将我们远程的git文件目录拷贝到项目中即可！ image-20210724204839883\rimage-20210724204938532\r修改文件，使用IDEA操作git\n一种方式\rimage-20210724205441507\r第二种方式\nimage-20210724205923872\r第三种方式 对于单个文件的add\nimage-20210724210043644\r提交测试\nimage-20210724210212802\rcommit只是添加到本地仓库\npush到远程仓库\ngit push 通过terminal或者可视化来搞\n在log中可以看到每次的操作\nimage-20210724211848407\r说明：git分支 分支在git中相对较难，分支就是科幻电影里的平行宇宙，如果两个平行宇宙互不干扰，哪对现在的你也没有影响。不过在某个时间点，两个平行宇宙合并了，我们就需要处理一下问题了\nimage-20210724212223989\rimage-20210724212233880\rgit分支中常用指令：\n# 列出所有本地分支 git branch # 列出所有远程分支 git branch -r # 新建一个分支，但依然停留在当前分支 git branch [branch-name] # 新建一个分支，并切换到该分支 git checkout -b [branch] # 合并指定分支到当前分支 git merge [branch] # 删除分支 git branch -d [branch-name] # 删除远程分支 git push origin --delete [branch-name] git branch -dr [remote/branch] image-20210724212621289\r新建分支 git branch dev 但是停留在当前分支\nimage-20210724212732716\r多个分支如果并行执行，就会导致我们代码不冲突，也就是同时存在多个版本！\n如果同一个文件在合并分支时被修改了，则会引起冲突：解决的办法是我们可以修改冲突文件后重新提交！选择要保留他的代码还是你的代码！\nmaster主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作，工作一般情况下在新建的dev分支上工作，工作完成后，比如上要发布，或者说dev分支代码稳定后可以合并到朱分支master上来。\n因此可以这样，在dev上做改动，改动完在dev上进行commit和push，这样dev就是相当于一个新的版本\n","date":"2021-07-24T16:18:59+08:00","permalink":"https://linjianshu.github.io/p/git%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"git学习文档"},{"content":"Linux学习 如果是阿里云记得配置安全组!!!\ncss js 静态文件都在wwwroot中,所以如果后台启动或者使用mvcTest.dll 的话会无法找到静态文件 因为静态文件的层级在她们上面一层 , 所以要cp一份wwwroot到存放dll那一层中 , 这样就可以看到样式了!!!\nwindows倾向于GUI操作，windows下的命令到了linux下不一定能用\nwindows有扩展名，linux中可以没有扩展名\nwindows不区分大小写，linux区分大小写\nlinux不同版本使用方法配置文件变化很大，要反复查找和调试\nlinux内核和发行版\nlinux内核是由linus及开源社区维护，内核包含内存管理、存储管理、进程管理、网络通讯等基础模块。很多公司、开元组织基于linux内核打包出很多发行版，不同的发行版的内核版本可能不一致，包含的软件也不一致，界面差别较大，但是命令行操作时互通的，大部分程序也是互通的。\n内核和发行版的关系就像android内核和小米手机系统、华为手机系统的关系一样。常用的发行版有redhat、centos、debian、ubuntu等等。这里我们用ubuntu，因为其内置的软件最适合程序员，其他发行版要自己装。\nlinux常见命令\nwindows有多根目录\nlinux是单根\n常用目录\nboot 存放用于系统引导时的各种文件\nbin 存放二进制可执行文件 例如ls，cat，mkdir等等\nsbin 存放二进制可执行文件，只有root用户才能访问\nusr 用于存放系统应用程序，比较重要的目录/usr/local 本地管理员软件安装目录\nopt 额外安装的可选应用程序包所放置的位置\ndev用于存放设备文件\netc存放系统配置文件\nhome存放所有用户文件的根目录\nlib存放跟文件系统中的程序运行所需要的共享库及内核模块\ntmp 用于存放各种临时文件\nvar 用于存放运行时需要改变数据的文件\nmnt 安装临时文件系统的安装点\n常见命令\npwd 显示当前工作目录 print working directory\nls 目录\ncd 更改目录 cd .. 返回上级目录 cd / 返回根目录 cd 文件夹 进入文件夹\nmkdir 创建目录\nrmdir 目录名 删除非空目录\nrm-r 目录名 删除目录及其下目录与文件（递归删除）\nmv 移动目录 mv test home/test\ncp 复制文件 cp test test1\ncat 查看文件内容\nmore 分页显示文件内容\nfind -name ‘lib*’ 查找文件\nps 查看当前用于运行进程\nps -ef 所有进程\nreboot 重启\nshutdown-now 立即关机\nexit 退出终端\nclear 清屏\nctrl+L清屏\n上下键可以查看历史命令\nctrl+C不要当前输入的指令了\n使用tab可能可以自动补齐\ntar 压缩文件\ntar -c -f name.tar t1 将t1压缩为name.tar的压缩包\ntar -x -C 解压到指定目录 -f 压缩包\nman命令 命令帮助手册\n-r \u0026ndash;recursive 是一样的\nlinux管道指令，链式调用呗\n与图形化界面相比，命令就可以粘合在一起\n例如 ps-ef |more 先查看所有进程，然后分页显示\ngrep 查找\nsudo：基于安全考虑，一般不建议超级用户权限登陆linux，而是平时使用低权限用户访问，需要高权限的操作再用sudo后跟着指令。比如在/下无法创建文件夹，但是sudo mkdir a就可以，当然需要输入密码。su就是super user 的简写，sudo就是用超级用户权限执行命令\nVI编辑器\nesc + w + q\n上下移动的话首先要按esc 然后才能上下移动\nvim是vi的加强版\ni键 插入模式 x就是x ，d就是d ， 上下左右对应着ABCD的字符呢\n按esc 命令模式 按h删掉一个字符，按dd删除一行，按上下左右就控制光标移动\n末行模式 按： 进入末行模式 w写 q退出\nimage-20210626201259638\r在末行模式中输入！指令 可以不离开vi执行指令\nshift+^ 移动到行首\nshift+$ 移动到行尾\n正则表达式 ， 匹配行首就是^ 匹配行尾就是$\nctrl + b 滚屏 ctrl + f 向下滚屏\nu就是撤销 undo\no就是在当前行下新增一行，并且自动进入插入模式\ni和a都是插入模式，就是在前面在后面插入的区别而已\na就是append i就是insert\nnano就是简化版的傻瓜式的文本编辑器\n嘻嘻嘻\nlinux下很多软件都是自己下载源码、自己编译的，有点痛苦。很多发行版都有自己的安装包格式。比如redhat使用*.rpm文件，ubuntu中使用 *.deb文件。\n自己查找、下载安装还是很麻烦的。因此很多发行版中都提供了类似于应用市场、nuget的东西。\nubuntu推荐使用apt进行下载、安装。会从ubuntu官网下载，如果下载速度慢的话，可以设置从其他镜像下载，具体搜索ubuntu atp-get 镜像\n执行某些程序的时候，如果程序没有安装还会提示你，比如执行 vim tree等等\n安装软件需要sudo执行。如：\n1.安装 sudo apt-get install 程序名\n2.卸载 sudo apt-get remove 程序名\n使用ifconfig\n网络问题\n虚拟机和主机之间组件了一个局域网，虚拟机通过主机上网。虚拟机的设置的网络可以设置不同的链接方式。主机可以通过ifconfig看到ip地址连接虚拟机的网络。\n虚拟机的网络连接方式有很多种，最主要的有三种：hostonly、nat、桥接（bridge）。hostonly配置较麻烦，需要懂很多网络工程的东西；NAT是虚拟机借助于主机网卡访问网络，藏在主机后面，网络中其他设备不能连这个虚拟机，连主机都不能，但是虚拟机能连接主机的网络，能上外网；桥接模式则是把虚主机也暴露为网络中的一个设备，主机和虚拟主机在网络内是平等的，可以互相访问，但是要求网络中没有设备访问的限制，如果有限制要修改路由器的配置。因为咱们需要主机和虚拟机相互访问，除非网络有限制，否则最好配置为桥接，配置桥接要选择通过哪个网卡上外网，不能选错了，否则就无法访问外网了。后面我们都配置为桥接（bridge）。\nssh服务\n讲运维人员是怎么远程连接到机房上的服务器的，很少使用图形界面（卡，无法自动化）\n远程登陆有专门的通信协议telnet，telnet就是通过网络进行命令行操作服务器。只有服务器端开始了远程登陆服务，客户端才能通过telnet协议控制服务器端。\n但telnet协议是使用明文传输数据，这会造成严重的安全性问题，所以现在几乎不推荐使用，而是替代协议的是ssh，ssh通讯数据是加密的。\n安装openssh\nubuntu 默认只安装了客户端 openssh-client\n安装服务器\nsudo apt-get install openssh-server\nssh服务默认端口是22，可通过修改配置文件修改端口/etc/ssh/sshd_config\n重启的话就是service ssh restart\nputty下载后直接远程连接linux\n使用mysql\n安装sudo apt-get install mysql-server\n根据提示设置root 用户的密码，测试的时候设置为root\nsudo apt-get install mysql-client 安装管理客户端\nmysql-uroot-proot 通过管理客户端连接mysql 不报错就ok\nmysql 客户端中执行（不要直接在shell中直接执行）show databases; (不要丢了结尾的英文分号) 查看有那些数据库，执行一下 select now(); 正确执行。执行quit； 退出mysql 客户端\nps ： 记得打开服务\nservice mysql start\nimage-20210626211935982\r基于安全考虑，mysql默认只能本机连接，如果想通过其他电脑连接（比如主机访问虚拟机中的mysql），就需要配置，最好不要配置成任意电脑都可以连接，因为危险，要配置成只允许某些ip访问\n配置mysql远程访问（需要网络配置为桥接网络）虚拟机情况的话\n编辑mysql的配置文件mysqld.cnf ， 由于mysql是系统服务，因此需要以su 运行vi , 才有权限，执行sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf ， 由于不同mysql版本配置文件的位置可能不一样，因此最好的找路径的方式就是cd / dir 一级级的看看。linux下不同版本差异性很大，之前查资料都是改/etc/mysql/conf.d/mysql.cnf ，但是使用status；命令查询mysql版本之后搜索mysql5.7 远程访问，就可以找到正确的做法\rimage-20210626212914858\r把bind-address=127.0.0.1注释掉 执行 sudo /etc/init.d/mysql restart 重启 mysql服务 在主机上执行ipconfig，查看ip地址，加入是192.168.0.11，那么就执行grant all privileges on *** . *** to root@\u0026ldquo;192.168.0.11\u0026rdquo; identified by \u0026ldquo;这里换成密码\u0026rdquo; with grant option; 再执行 flush privileges; 外部数据库管理工具navicat连接虚拟机的ip，访问mysql 主机上连接虚拟机内的mysql一定要连接虚拟机的ip，别连错了 主机的ip如果变了就要重新配置 在4之前，由于这个版本的mysql密码是空的，所以没办法呜呜呜，需要改个密码\nimage-20210626220925687\rMySQL 8.0 安装后修改root@localhost的默认空密码 - 汉家羽林郎 - 博客园 (cnblogs.com)\nimage-20210626220955199\r解决mysql8 提示 ERROR 1410 (42000): You are not allowed to create a user with GRANT_zhouzhiwengang的专栏-CSDN博客\n命令有点点不一样\nmysql8.0之后必须要先创建用户，然后才能授权\nimage-20210626232148904\r安装vsftp服务器\nfile transport protol\n什么是ftp 。通过ftp进行文件的上传下载 sudo apt-get install vsftpd 这时候可以用linux用户登陆，能够访问/home/用户名下的文件夹。但是没有上传权限。需要 sudo vi /etc/vsftpd.conf 将write_enable=YES 前面的注释# 取消，然后执行 sudo /etc/init.d/vsftpd restart重启 对于文件数量比较多的，可以先压缩成zip，然后在linux端使用 unzip 文件名 进行解压 对于文件缩量比较多的，可以在linux端使用zip命令压缩，然后再windows端解压 .net core\n历史\n.net 设计之处就是考虑像java一样跨平台的，.net framework 是在windows下运行的，大部分类是可以兼容移植到linux下的，但是没人做这个工作。后来novell公司开发了mono，把大部分.net framework功能移植到了linux下。mono也成为xamarin（使用.net 开发Android、IOS app的技术）和unity3d （使用.Net 开发android /ios 游戏的技术）的基础。\n.net core是微软开发的另一个可以跨linux、windows、mac等平台的.net 。\n微软收购了mono的公司，xamarin。为什么还要搞.net core。因为mono完全兼容.net framework ,架构太陈旧，不利于现在云计算、集群等新的架构历年。因此微软推翻重写了.net core。\n.net framework .net core mono的关系\n.net framework .net core xamarin 有通用的类，也有特有的。为了保证代码通用。微软定义了公共的.net standard library (.net 标准库，像FileStream / List等这些)，按照.net standard library编写的代码可以在几个平台下通用。\n大部分.net framework中的类在.net core中还有，方法也还有，只是namespace可能变了，有些方法也有不一样，部分api缺失（注册表等windows平台特有的api），后面会讲区别。\n之前那些在.net framework 中调用的dll，不一定都能用在.net core (linux)中。如何判断\n在linux下需要安装.net core 的环境\n例如.net core sdk 和 .net core runtimes\nhttps://docs.microsoft.com/zh-cn/dotnet/core/install/linux-ubuntu\n安装完验证一下\n使用linux 来创建.net core 控制台应用程序并运行\n创建控制台项目\ndotnet new console -o test1 在当前目录创建目录 test1 , 并且初始化控制台（console）类型的项目结构（第一次运行dotnet new 比较慢）。使用命令创建项目，是目前很流行的风格。 也可以手动创建test1目录，进入目录，再执行dotnet new console。也就相当于在当前目录下创建控制台项目。 dotnet restore 通过nuget还原安装当前目录的项目用到的包，一定要cd 到项目根目录下执行. restore执行消息里给出了nuget下载目录的路径 改一下项目的代码 dotnet run 编译并运行当前目录的项目,一定要在项目根目录下执行.如果编译报错就会根据报错信息该代码或者是忘了dotnet restore了。 注意.net core 下的控制台程序不是生成exe的,要通过dotnet 入口dll文件名 方式运行 三个步骤:new restore run image-20210627111809617\rimage-20210627112544733\r也可以执行debug里的dll文件，linux没有exe哈，执行dll就可以了\nimage-20210627113402515\raps .net mvc core 项目\ndotnet new mvc -o test2 或者 dotnet new mvc\ndotnet restore\n改一下项目的代码\ndotnet run web项目自带嵌入式服务器，测试阶段不用IIS等单独的服务器，部署阶段再部署到iis、nginx等上\n再linux的服务器上的浏览器中打开http：//127.0.0.1:5000 (只能本机访问，后面讲通过nginx配置远程访问)\nctrl+c 停止服务器\n修改默认端口绑定的方法：再program.cs的build之前加入useurls(\u0026ldquo;http://*.5001\u0026rdquo;);\nimage-20210627121128266\r新版有点区别\nimage-20210627121508698\rhttps://blog.csdn.net/zxy13826134783/article/details/105908201/\nimage-20210627121540245\rECS做到了呜呜呜\nimage-20210627122036170\r插入个知识点，这里我们退出终端后外网就访问不了了，因此需要程序后台运行\nhttps://www.cnblogs.com/bjxxlbm/articles/14790054.html\nnohup dotnet mvctest.dll \u0026amp;\nps -ef |grep dotnet 查看dotnet项目\nkill -9 PID（进程id就行了）\nimage-20210627154748097\rwwwroot底下放的是静态文件\nimage-20210627114214395\r创建其他项目\n.net core目前只支持控制台和aps .net mvc core 不知道winform和webform\n可以创建类库、webapi、解决方案\n新建类库\ndotnet new classlib -o classlibtest\n新建webapi\ndotnet new webapi -o webapitest\n新建解决方案（一个解决方案中包括多个项目）\ndotnet new sln\n还有dotnet new \u0026ndash;help\n历史问题\n旧版本.net core 曾经使用project.json做项目描述文件，后来又改回了project.csproj\n.net core开发的两种方式\n用vi编辑代码没有自动提示，开发麻烦，所以只是进行原理展示。不会真的用vi写代码\n方式1：windows下用vs开发，然后部署到linux下部署运行\n方式2：linux下使用vscode开发，然后linux下部署运行。vscode还是没有vs强大\nwindows下可以直接使用命令行来建立项目，就像linux下操作的一样\nimage-20210627162043186\r发布dotnet publish\nimage-20210627162548407\r找到publish，并压缩成zip格式\n然后通过filezilla 传输到linux上\nlinux通过 unzip 名字 解压缩\n然后dotnet dll文件 就可以运行起来了呜呜呜\n问题：给wsl windows sub子系统 linux\n我们的linux发行版 ubuntu 是wsl\n需要给他安装一个图形化界面\nWSL2 Ubuntu GUI 图形用户界面_哔哩哔哩_bilibili\n远程桌面需要启动一下xrdp服务\nimage-20210627195747795\r使用命令行添加解决方案和引用关系\n如何创建多个项目的解决方案 先创建解决方案文件夹rupengbbs,然后再其中dotnet new sln dotnet new mvc-o rupengbbs.web 说明：创建web项目 dotnet new classlib -o rupengbbs.common 创建common项目 dotnet new sln 说明：解决方案，解决方案名字默认是当前目录的名字 dotnet sln rupengbbs.sln add rupengbbs.common / rupengbbs.common.csproj 说明L吧rupengbbs.common项目中的rupengbbs.common.csproj添加到解决方案文件中。注意最后一个参数在/ 前后不要加空格 这里指的是rupengbbs.common目录下的rupengbbs.common.csproj文件 dotnet sln rupengbbs.sln add rupengbbs.web/rupengbbs.web.csproj 说明：把web项目添加到解决方案中 dotnet add rupengbbs.web/rupengbbs.web.csproj reference rupengbbs.common/rupengbbs.common.csproj 说明：rupengbbs.web.csproj 项目添加对rupengbbs.common.csproj项目的引用 dotnet restore 说明：在解决方案下每个项目中执行dotnet restore 如果是在某个项目下执行 dotnet restore 则只是restore 某个项目 查看一下csproj 和sln文件格式，知道如何手动修改 vscode打开解决方案文件夹即可。在common项目中建一个person.cs，写一个hello方法，然后在web项目中调用 （*）编译整个解决方案的方法，在解决方案文件夹下dotnet build rupengbbs.sln 手动创建三层项目：web项目 、 model项目、dal项目、bll项目 写一个创建三层解决方案的脚本，体现命令行的好处，脚本中的$1$2代表第1.2个参数的值 image-20210627202824466\rimage-20210627203154894\r对着主项目运行\nimage-20210627203449885\r如果某一些操作需要反复执行，那么就可以写成脚本。\nwindows上\n.bat 批处理命令\npowershell\nlinux上\nshell脚本\n写好sh脚本之后，执行bash ./ cjsc.sh RuPeng 会自动把项目和解决方案创建起来了\n因为命令行所有脚本，因为脚本所以自动化。windows下的脚本语言有传统的bat以及新的powershell，windows10安装linux自系统后也可以使用bash\n7.项目添加nugut引用的方法：在项目下执行dotnet add package newtonsoft.json 然后dotnet resotre 一下\ndotnet add package 就等驾驭nuget 的install-package （*）还可以通过dotnet addnew nugetconfig 创建一个nuget配置文件，指定源\ndotnet core 无法在引用里引用自己家的标准程序集，.netframework 可以，.net core统一在nuget里安装\n因此如果涉密的dll还得传到nugut上，通过nuget安装，可以考虑搭建nuget私服\n6.控制台、web应用程序部署到linux等服务器上的统一方式：服务器上先安装.net core，然后再开发环境发布，然后吧发布包上传到服务器上，然后到目录下执行，dotnet 主程序 dll 即可\n注：可以通过发布到FTP、FTPS服务器上的方式，来试试看，端口是21\nimage-20210630110707778\r但是，需要给ljs用户授予777权限，然后给srv/ftp授予777权限\n否则会出现无法发布www.root 和 config的问题\nchmod -R 777 ljs chmod -R 777 srv/ftp\nimage-20210630230743574\rhttpwebrequest、webclient不支持，必须使用异步的httpclient\n反编译工具 JustDecompiler 反编译dll文件\n.net core 中配置文件的解析\n.net coer 的配置文件，不再是配置在web.config中了，而是单独的json配置文件\n只要和合法的json格式，怎么写随意，怎么写就怎么解析\n解析方法：\n1.首先nuget安装：microsoft.extensions.configuration 和 microsoft.extensions.configutation.json\n2.然后引用命名空间\n3.下面的代码就把logging下的loglevel下的default读出来了\nvar builder = new configurationbuilder().setbasepath(directory.getcurrentdirectory()).addJsonfile(\u0026#34;appsettings.json\u0026#34;) ; //设置配置文件所在路径 var configRoot = builder.Build() ; var value = configRoot.GetSection(\u0026#34;Logging\u0026#34;).getSection(\u0026#34;loglevel\u0026#34;).getsection(\u0026#34;default\u0026#34;).value ; sys.console.writeline(value) ; image-20210630235351891\rEFcore的使用\nEfCore 是EF的.net core版本。EF core 对 sqlserver支持很好，也可以在linux下连接sqlserver。不过如果在linux下首选mysql，因此我们主要介绍mysql 中更实用efcore。sqlserver用法几乎一样，只是换一个Ef provider的nuget包而已。\nEFcore的nuget： entityFrameworkcore\n1.官方的mysql ef provider\n2.可以试试第三方的 eF core provider\n3.使用mysql efcore\n​\t把mysql数据库、表创建起来\n​\tinstall-package entityframeworkcore.mysql\n​\t编写person类\n​\n通过usemysql这样的扩展方法来配置连接字符串，这是.net core的风格！可以把连接字符串写到配置文件中，然后再读取。\nEF core 和EF的区别\n要使用 AsNoTracking 、 Include 等要using microsoft.entityframeworkdcore ，不能使用 System.Data.Entity\n目前还不支持lazyload，需要显式的include\n没有内置entitytypeconfiguration（要么手动注册config类，复习一下；要么后续课程会给大家提供一个）\n一对多关系配置从builder.hasrequired(e=\u0026gt;e.author).withmany() ; 改成了：builder.hasone(e=\u0026gt;e.author).withmany().hasforeignkey(e=\u0026gt;e.authorid).isrequired();\n或者builder.hasoptionnal(e=\u0026gt;e.author).withMyan();改成：builder.HasOne(e=\u0026gt;e.author).withmany().hasforeignkey(e=\u0026gt;e.antuorid) ;\n不要中间实体的多对多还不支持，要自己拆成用中间实体的两对一对多\n只要吧配置文件放到ui项目中即可，不再需要在Ui项目中在安装EF\naps.net core mvc\nselfhost\nimage-20210701213916890\rasp.net core ioc\n1.asp.net mvc coer 内置了ioc容器，不在需要autofac等等，当然autofac 也是支持.net core 的 ， 内置ioc是通过构造函数注入，而不是属性注入。\n2.在startup 的configureservices中进行注入的准备工作\n3.在内置的ioc有三种生命周期\ntransient : transient 服务在每次被请求的时候都会被创建。这种生命周期比较适用于轻量级的无状态服务。\nscoped：scoped生命周期的服务是每次web请求被创建\nsingleton：singleton生命周期服务在第一次被请求时创建，在后续的每个请求都会使用同一个实例。如果你的应用需要单例服务，推荐的做法是交给服务容器来负责单例的创建和生命周期管理，而不是自己来走这些事情。\n调用方法 services.addsingleton(typeof(imyservice),new myservice())； 来进行注册\n但是最好 services.addsingleton (typeof(imyservice),typeof(myeservice)) ;\n因为这样的话可以在myservcice中通过构造函数注入其他服务\nimage-20210701215502596\rimage-20210701215509943\rimage-20210701215618664\r4.controller注入\n这里引入一个问题，之前publish的都不行，原因是为什么呢！！！\n就恨他吗离谱 ， 注意运行时 ，不能选择可移植\nimage-20210702000338015\rdotnet test.dll \u0026ndash;urls http://*:5005\n手动指定端口\n单元测试\nimage-20210722203914320\r","date":"2021-06-16T00:25:03+08:00","permalink":"https://linjianshu.github.io/p/csharplinux%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"CSharpLinux环境部署学习文档"},{"content":"小程序组件\nview标签 类比p便签\ntext标签 类比span标签\nselecttable :文档是否可选\nimage-20210404164128223\rdecode标签 :选中＆ｎｂｓｐ；/lt/gt/amp.apos/ensp/emsp这样的可以识别出来\nbutton标签:\n​\ttype: primary / default / warn\nimage-20210404164342281\r​\tform-type=\u0026ldquo;submit\u0026rdquo;/reset\n​\topen-type getuserinfo/getphonenumber/contact\nimage-20210404164741208\rcheckbox image-20210404165141036\r开闭标签,可以在开闭标签内写上复选文字内容\nvalue可以填入真实的值\ncheckboxgroup\nradio单选按钮\n开闭标签 , value可以填入真实的值 , 实现单选需要配合实现radiogroup\nimage-20210404165511648\rblock标签\n​\t标签块 , 其本身不会被渲染到页面中 , 只有内部的标签会被渲染进html页面\nimage-20210404170226484\rimage-20210404171030254\r绑定事件+编写js方法\nimage-20210404183815644\rimage-20210404183822112\rdata的数据绑定以及数据更新\nimage-20210404185119026\rimage-20210404190648374\rimage-20210404190705626\r富文本识别展示\nimage-20210404191510461\rimage-20210404191516120\r可以携带css样式结构\nimage-20210404191528289\r弹出窗体\nimage-20210404193546211\rimage-20210404193554023\r加载窗体 , 等待时间 , 图标 成功的事件\nimage-20210404193628433\r弹出确定/取消按钮\nclick事件判定\n页面跳转事件并且传参\n两种方式\n1.\rimage-20210404195554226\r2.\rimage-20210404195605659\r携带数据\nimage-20210404195614999\rjs中处理\n通过webapi获取后端数据\nimage-20210404212911407\rxy+5x/2+20y/2 = (5+y)(20+x)/2\n100 + 5x + 20 y +xy = 2xy + 5x + 20y\nimage-20210404213731063\rwebapi采用的是.net 5.0 使用efcore , 所以和原来的略有不同呢 亲爱的 , 例如使用依赖诸如, appconnectionstring得写在不同的地方,在静默管道里添加sqlserver服务,并且指定特定的dbcontext,以及重构一下dbcontext的构造函数等等,此外还需要额外添加efsqlserver的nuget包\nvideo标签 以及填充样式\nimage-20210405105945483\rimage标签以及宽度修正样式\nimage-20210405110043711\r数值回传以及样式绑定\n在data里绑定静态数据\nimage-20210405110238337\r在wxml里利用wx:for来遍历data中的静态数据\nimage-20210405110319681\r通过插值判断是否页签被选中,以及页签颜色样式修正\ndata-id传值\nselectbar方法处理\n传值处都要用插值法包裹 实际上很像java的模版引擎\nimage-20210405110458011\r携带id值过来,处理data中的静态typeindex\n使用wx:if wx:else wx:for配合block来进行内容展示\nimage-20210405152741173\rdata中展示新闻的content\nview界面中使用wx：for来遍历newslist\n使用插值法取数据\n使用wx:if和else配合使用\nimage-20210405152813430\r模拟后端接收数据,onload操作\n并且存入data中\n并且在前端将data中的值取出来展示\nimage-20210405154550041\r通过wx：request方法获取，通过success回调函数来将值存入data中\nimage-20210405154625869\r接着就是前端的wxml去取数据啦\nwx:for 需要配合wx:key 使用以提高性能\n否则默认将以index为检索\nimage-20210405162607882\rimage-20210405162912572\r","date":"2021-06-01T00:27:43+08:00","permalink":"https://linjianshu.github.io/p/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"微信小程序学习文档"},{"content":"计算机组成原理学习文档 CPU\n内存\n硬盘\n主板\n计算机硬件识别数据\n高低电平0/1\n通过电信号传递数据\n金属针脚：传递电信号用的通道\n通过很多条电路，可以传递多个二进制数位，每个二进制数位称为1bit比特\n文字、数字、图像如何用二进制表示\n如何存储二进制数\nCPU如何对二进制数字进行加减乘除\n如何从内存中取出想要的数据\nCPU如何识别和执行我们写的程序\n计算机系统 = 硬件 + 软件\n硬件是计算机的实体，软件由具有各类特殊功能的程序组成\n计算机性能的好坏取决于软硬件功能的总和\n软件\n系统软件：用来管理整个计算机系统\n操作系统、DBMS、标准程序库、网络软件、语言处理程序、服务程序 应用软件\n按照任务需要编制成的各种程序 硬件的发展\n第一台电子数字计算机 ENIAC1946 冯诺依曼\n逻辑元件：电子管\n第一代：电子管时代 纸带机编程\n第二代：晶体管 开始出现操作系统 开始出现高级语言\n第三代：中小规模集成电路 高级语言迅速发展 开始出现分时操作系统\n第四代：大规模、超大规模集成电路 出现微处理器、微型计算机、个人计算机PC萌芽 、 操作系统\n微处理器的发展：\n机器字长：计算机一次整数运算所能处理的二进制位数\n摩尔定律：揭示了信息技术进步的速度，集成电路上可容纳的晶体管数目，约每隔18个月就会增加一倍，整体性能也将提升一倍\n软件的发展：\n机器语言010101=\u0026gt;汇编语言=\u0026gt;FORTRAN/PASCAL/C++=\u0026gt;java、python\nDOC操作系统=\u0026gt;windows、android、ios\n目前的发展趋势：\n两极分化：\n1.微型计算机更微型化、网络化、高性能、多用途方向发展\n2.巨型化、超高速、并行处理、智能化方向发展\n计算机硬件的基本组成：\n1.早期冯诺依曼的结构\n2.现代计算机的结构\nENIAC手动接线来控制计算\n冯诺依曼：”存储程序“的概念是指将指令以二进制代码的形式事先输入计算机的主存储器（内存），然后按其在存储器中的首地址执行程序的第一条指令，以后就按该程序的规定顺序执行其他指令，直至程序执行结束。\n早期冯诺依曼机：\n数据/程序：即软件\n硬件：\n输入设备：将信息转换成机器能识别的形式\n存储器：存放数据和程序\n运算器：算术运算和逻辑运算\n控制器：指挥程序运行\n输出设备：将结果转换成人们熟悉的形式\n在计算机系统中，软件和硬件在逻辑上是等效的。\n冯诺依曼计算机的特点：\n计算机由5大部件组成：输入设备、输出设备、存储器、运算器、控制器 指令和数据以同等地位存储于存储器，可按地址寻访 指令和数据用二进制表示 指令由操作码和地址码组成 存储程序 以运算器为中心 输入/输出设备与存储器之间的数据传送通过运算器完成\n现代计算机的结构以存储器为中心\nCPU=运算器+控制器\n计算机组成原理中，主机的概念就是运算器+控制器（cpu）+存储器\n存储器：主存（内存）+辅存（硬盘）\n主机的存储器是内存也就是主存\n辅存是IO设备\n计算机硬件的基本组成：\n五大部分 输入设备：将信息转换成机器能识别的形式 输出设备：将结果转换成人们熟悉的形式 主存储器：存放数据和程序 运算器：算术运算、逻辑运算 控制器：指挥各部件，使程序运行 冯诺依曼结构 首次提出存储程序概念 以运算器为中心 现代计算机结构 以存储器为中心 CPU=运算器+控制器 主存储器的基本组成：\n主存储器：\n存储体 MAR memory address register 存储地址寄存器 MDR memory data register 存储数据寄存器 读和写\n存储器：\n存储单元：每个存储单元存放一串二进制代码 存储字：word 存储单元中二进制代码的组合 存储字长：存储单元中二进制代码的位数 存储元：存储二进制的电子原件，通常为电容，每个存储元可存1bit MAR位数反映存储单元的个数\nMDR位数=存储字长\nMAR4位 = 一共有2的四次方个存储单元\nMDR16位 = 每个存储单元可存放16bit 1个字word = 16bit\n混淆点\n1个字节=8bit\n1B=一个字节\n1b=1bit\n运算器的基本组成：用于实现算术运算和逻辑运算\nACC accumulator 累加器 用于存放操作数或运算结果 MQ multiple-quotient register 乘商寄存器 ， 在乘除运算时，用于存放操作数或运算结果 ALU arithmetic and logic unit 算术逻辑单元， 通过内部复杂的电路实现算术运算、逻辑运算 X 通用的操作数寄存器， 用于存放操作数 控制器的基本组成：\nCU： control unit控制单元，分析指令，给出控制信号 IR： instruction register 指令寄存器，存放当前执行的指令 PC： program counter 程序计数器 ， 存放下一条指令地址， 有自动加1功能 完成一条指令=取指令PC + 分析指令 IR + 执行指令CU\n各硬件部件：\n主存 MAR：内存地址寄存器，用于指明要读/写哪个存储单元。其位数反映存储单元的数量 MDR：内存数据寄存器，用于暂存要读/写的数据。其位数反映存储字长 存储体: 概念：存储元、存储单元、存储字、存储字长、地址 运算器 X 通用寄存器，存放操作数 ACC 累加计数器，存放操作数、运算结果 ALU 算术逻辑单元，用电路实现各种算术运算、逻辑运算 MQ 乘商寄存器，进行乘除法时用到 控制器 IR 指令寄存器，存放当前执行的指令 PC 程序计数器，存放下一条指令的地址 CU 控制单元，分析指令，给出控制信号 工作过程 初始：指令、数据存入主存，PC指向第一条指令 从主存中取指令放入IR、PC自动加1、CU分析指令、CU指挥其他部件执行指令 计算机系统的层次结构\n高级语言机器 用编译程序翻译成汇编语言程序\n汇编语言机器 用汇编程序翻译成机器语言程序\n操作系统机器 向上提供广义指令(系统调用)\n用机器语言的机器 执行二进制机器指令\n微指令系统 由硬件直接执行微指令\n三种级别的语言\n高级语言 汇编语言 机器语言 通常高级语言得翻译成汇编语言，汇编语言翻译成机器语言才可以执行\n但有时候高级语言可以直接通过编译程序直接翻译成机器语言进行执行\n编译程序：编译、汇编、解释程序\n解释程序的语言就是解释性语言\n编译的语言就是编译性语言\n编译程序是一次全部翻译成机器语言的程序，而后再执行机器语言程序，只需要翻译一次\n解释程序是将源程序的一条语句翻译成对应于机器语言的语句并立即执行。紧接着再翻译下一句，每次执行都要翻译\n计算机的性能指标\n存储器的性能指标\nMAR位数反映存储单元的个数（对多支持多少个）\nMDR位数=存储字长=每个存储单元的大小\n总容量=存储单元个数*存储字长 bit = 存储单元个数 * 存储字长/8 byte\n2的十次方 = K\n2的二十次方=M\n2的三十次方=G\n2的四是次方=T\nCPU的性能指标\nCPU主频：CPU内部数字脉冲信号振荡的概率 = 1/CPU时钟周期\nCPI:执行一条指令所需的时钟周期\n执行一条指令的耗时：CPI * CPU 时钟周期\nCPU执行时间：整个程序的耗时\nIPS： instructions per second 每秒执行多少条指令 = 主频/平均CPI\nFLOPS:每秒执行多少次浮点运算\n系统整体的性能指标\n数据通路带宽：数据总线一次所能并行传送信息的位数（各硬件部件通过数据总线传输数据）\n吞吐量：系统在单位时间内处理请求的数量\n响应时间：用户向计算机发送一个请求，到系统对该请求做出响应并获得它所需要的结果的等待时间。\n基准程序：用来测量计算机处理速度的一种实用程序，以便于被测量的计算机性能可以与运行相同程序的其他计算机性能进行比较。\n计算机的性能指标：\n存储器的容量 MAR的位数反映存储单元数量 MDR反映每个存储单元大小 CPU 主频 时钟频率 =1/时钟周期 单位:HZ 时钟周期 CPU中的最小单位，每个动作至少要一个时钟周期 CPU执行时间 运行一个程序所花费的时间 指令条数 * CPI /主频 CPI 执行一条指令所需的时钟周期数 IPS 每秒执行多少条指令 =主频/平均CPI FLOPS：每秒执行多少浮点运算 其他 数据通路宽度、吞吐量、响应时间、基准程序 常用数量单位 描述存储容量、文件大小时：K=2^10 M=2^20 G=2^30 t=2^40 描述频率、速率时：K=10^3 M=10^6 G=10^9 T=10^12 进位计数制\n十进制、二进制、八进制、十六进制 其他进制=\u0026gt;十进制 二进制、八进制、十六进制之间的相互转换 十进制=\u0026gt;其他进制 真值和机器数 基数：每个数码位所用到的不同符号的个数，r进制的基数为r\n二进制：0,1\n八进制：01234567\n十进制：0123456789\n十六进制：0123456789ABCDEF\n二进制优势：\n可以使用两个稳定状态的物理器件表示 01正好对应逻辑值的假真。方便实现逻辑运算 可以很方便地使用逻辑门电路实现算术运算 任意进制=\u0026gt;十进制\n二进制=\u0026gt;八进制、十六进制\n二进制基数为2\n八进制基数为8\n为了保证对应，应该将二进制的3位作为一组，每组转换位对应的八进制符号\n八进制=\u0026gt;二进制\n八进制基数为8\n二进制基数为2\n为了保证对应，应该将八进制的每位都用二进制的三位来代替，每3为转换位对应的二进制符号\n二进制表示 10101010B\n十六进制 349820347H 0x2234623876\n十进制 2134234D\n十进制=\u0026gt;二进制 使用 （整数部分）除基取余法+（小数部分）乘基取整法\n真值：符合人类习惯的数字\n机器数：数字实际存到机器里的形式，正负号需要被数字化\nBCD码：Binary-Coded Decimal ,用二进制编码的十进制\n8421码 余三法 2421码 原理：用4个二进制来表示一个十进制 ， 虽然这样会造成6种冗余，因为2的四次方=16 即能表示从0-15 ， 十进制表示从0-9 ， 所以会造成6个冗余\n8421码对应关系：\nX X X X\n8 4 2 1\n所以如果想表示985 ， 8421码应该这么写 1001 1000 0101 嘻嘻嘻！\n十进制的加法 8+5\n8421码加法 8+5 = 1000 + 0101 = 1101 但是这个落在1010~10010中，也就是8421码不允许或者说没有定义的范围内，为了让他有意义，需要+6，让它进一位，也即1101+0110 = 11011 = 0001 0011 也就是1 3\n余3码：8421码+（0011）B\n2421码：改变权值定义\nX X X X\n2 4 2 1\n如果想表示985 ， 则 1111 1110 1011\n规则：0-4 第一位不能为1 ； 5-9 第一位必须为1\nBCD码\n8421码 每4个二进制位对应一个十进制位（有6个冗余状态） 8、4、2、1分别对应每一位的权值 0000-1011 分别对应 0-9 ，进行加法后若超出该范围，则需要+0110B进行修正（强制向高位进1） 余3码 8421码 + 0011 2421码 2、4、2、1分别对应每一位的权值 表示0~4时最高位为0 ， 表示5~9时最高位为1 字符与字符串\n英文表示\nASCII码\n128位字符 用7位来表示就好 ，但1B=8bit 通常就用1B来表示一个字符\n可印刷字符：32-126 ， 其余为控制、通信字符\n97=01100001B\n122=01110110B\n汉字表示\n为了方便区分 ， 将1980版国标列出了常用的7000多个汉字，对应的是一个93 * 93 的矩阵，用矩阵的行和列来表示，即区码+位码\n区位码：94个区，每区94个位置\n但是前文提到ASCII码的0-32是用于控制和通信，为了防止汉字的编码和英文的编码产生冲突，我们需要在原有的基础上+20H （20H就是十六进制的20 ， 也就是32） 加上32之后就避开了通信和控制区域 ， 但是ASCII码32-125是可印刷字符，为了防止汉字的编码和英文的编码产生冲突，我们需要在原有的基础上+80H（80H就是十六进制的128）这样就可以越开ASCII码产生的冲突，因为ASCII码是1B，并且1B是以0xxx xxxx 表示的，高位不是1，但汉字的区位码，分为区码和位码，加上20H和80H之后，高位必然是1，如果高位是1，就代表他是汉字不是英文字符，所以要读两个B，也就是2B，所以为什么英文符号是1个字节而中文符号是2个字节了。\n汉字的输入：输入编码 例如nei2\n汉字的输出：汉字字形码\n字符串:某计算机按字节编址，编址即每个地址对应1B，从地址为2的单元开始，存储字符串为“abc\u0026quot;,那么，2-5的地址分别存，61H 62H 63H 00H（\\0） 最后一行使用\u0026rsquo;\\0\u0026rsquo;作为字符串结尾标识\n当存放”abc啊“的时候，因为汉字需要占用2B，所以2-6的地址分别存， 61H 62H 63H B0H A1H 00H 或者 61H 62H 63H A1H B0H 00H ，\n大端模式：将数据的最高有效字节存放在低地址单元中\n小端模式：将数据的最高有效字节存放在高地址当中\n字符与字符串\nASCII码 通常用8bit表示一个字符，最高位都为0 共128个字符。0-31为控制/通信字符；32-126为可印刷字符 所有大写字母、所有小写字母、所有数字的编码都连续 汉字 区位码、国标码、汉字内码、输入编码、字形码 国标码=区位码+2020H 机内码=国标码+8080H 字符串 从低地址到高地址逐个字符存储，常采用\u0026rsquo;\\0\u0026rsquo;作为结尾标志 对于多字节的数据（如汉字），可采取大/小端存储模式 大端模式：将数据的最高有效字节存放在低地址单元中 小端模式：将数据的最高有效字节存放在高地址单元中 奇偶校验码\n奇偶校验\n校验原理 奇偶校验 由若干位代码组成的一个字叫码字\n将两个码字逐位进行对比，具有不同的位的个数成为两个码字间的距离\n一种编码方案可能有若干个合法码字，各合法码字间的最小距离成为码距\n当码距=1时，无检错能力 ； 当码距=2时，有检错能力 ； 当码距\u0026gt;=3时，若设计合理，可能具有检错纠错能力\n奇校验码：整个校验码（有效信息位和校验位）中1的个数为奇数\n偶校验码：整个校验码（有效信息位和校验位）中1的个数为偶数\n奇偶校验中，如果偶数个位发生位错误，也就是位跳变的话是检测不出错误的\n如何求校验位：\n求偶校验位：对有效信息位进行异或运算，算的结果就是偶校验位的值\n如何进行校验：对偶校验来说，如果进行的是异或运算得到的结果是1就说明出错了\n海明校验码\n设计思路：将信息位分组进行偶校验=\u0026gt;多个校验位=\u0026gt;多个校验位标注出错位置\n多个校验位能够携带多种状态信息（对/错，错在哪里）\n1.确定海明码的位数：2^k \u0026gt;=n+k+1\nk代表多少位校验码\nn代表有效信息位\n2.确定校验位应该放在哪个位置\n将校验位放在海明位号为2^i-1次方的位置上\n3.确定校验位将和那几个有效位组成一组\n假设信息位：1010\n将一共有多少位从高到低排列，如H7 H6 H5 H4 H3 H2 H1\n将7654321转成二进制的数表示\n即0111 0110 0101 0100 0011 0010 0001\n找出有效位，也就是7653，也就是\nH7: 0111\nH6: 0110\nH5: 0101\nH3: 0011\n从尾巴开始对为1的有效位的实际值进行异或运算，得到每个校验位的值以及和那些有效位作为一组\n即P1=H7异或H5异或H3=D4异或D2异或D1=1异或1异或0=0\n即P2=H7 H6 H3 = D4 D3 D1 = 1 0 0 = 1\n即P3=H7 H6 H5 = D4 D3 D2 = 1 0 1 = 0\nH7 H6 H5 H4 H3 H2 H1 D4 D3 D2 P3 D1 P2 P1 1 0 1 0 分组结果就是：\nP1 D4 D2 D1\nP2 D4 D3 D1\nP3 D4 D3 D2\n4.纠错\n纠错就是对分组进行偶校验，若为1就说明有问题\n异或的结果从高到低排列 010 =\u0026gt;十进制就是2 ，就代表第二位出错了\n海明码的检错、纠错能力:\n纠错能力\u0026ndash;1位\n检错能力\u0026ndash;2位\n为了防止出现2位同时出现位错误判断错误位不对的情况，我们需要在前头加上全校验位，对整体进行偶校验\n1.若S3S2S1为000并且全体偶校验成功=\u0026gt;无错误\n2.若S3S2S1不为0并且全体偶校验失败=\u0026gt;有一位错误，纠正就可以了\n3.若S3S2S1不为0并且全体偶校验码成功=\u0026gt;有两位错误，需要重传\n海明码\n基本思想\n分组偶校验，多个校验位可反映出错位置 求解步骤\n确定校验位个数k个校验位，n个信息为 2^k\u0026gt;=n+k+1 确定校验位分布 P1、P2、P3\u0026hellip;分别在123416 空出来的其他位置一次填入信息位 求校验位 将信息位的位置序号用k位二进制数表示出来 校验位Pi 与位置序号第i位为1的信息为归为一组，进行偶校验 纠错 对P1、P2、P3\u0026hellip;所属各分组进行异或（相当于分组偶校验）求得S1、S2、S3 S3 S2 S1 = 000 说明无错误 S3 S2 S1 不等000 其值反映出错位置 补充\n海明码有1位纠错，2位检错能力 为了区分1位错和2位错，还需添加“全校验位”对整体进行偶校验 循环冗余校验码\n基本思想：数据发送、接受方约定一个“除数”\nK个信息位+R个校验位 作为“被除数” ， 添加校验位后需保证除法的余数为0\n若余数非0 说明出错，则进行重传或纠错\n构造 由生成多项式确定除数。若生成多项式中x的最高次为R，则除数有R+1位 K个信息位+R个0 ， 作为被除数 被除数、除数 进行模二除 ，得到R为余数 K个信息位+R位余数 = CRC码 校验 收到K+R位数据，与生成多项式模二除，计算R为余数 余数为0，说明无错误 余数非0，说明出错 检错、纠错能力 可以检测出所有奇数个错误 可以检测出所有双比特的错误 可以检测出所有小于等于校验位长度的连续错误 若选择合适的生成多项式，且2^R \u0026gt;=K +R +1，则可纠正单比特错 定点数与浮点数\n定点数：小数点的位置固定 \u0026ndash;常规计数法\n浮点数：小数点的位置不固定 \u0026ndash;科学计数法\n定点数的表示\n无符号数 有符号数 原码 反码 补码 移码 无符号数：整个机器字长的全部二进制均为数值位，没有符号位，相当于数的绝对值。\n8位二进制数：2的八次方种不同状态，可以表示的是0到2的八次方-1这么多的十进制数。\nn为的无符号数表示范围为：0到2的n次方-1的十进制\n有符号数的定点表示：\n定点整数+定点小数\n最高位为符号位\n数值部分称为尾数\n注：可用原码、反码、补码三种方式来表示定点整数和定点小数。还可用移码表示定点整数。\n符号位0表示正数1表示负数\n原码：用尾码表示真值的绝对值，符号位0/1 ， 对应正负\n若机器字长为n+1位，则尾数占n位\n若机器字长为n+1位，原码整数的表示范围为：-（2^n-1)到2^n-1\n真值0有+0 和 -0 两种形式\n若机器字长为n+1位，原码小数的表示范围为-（1-2^-n）到1-2^-n\n真值0有+0 和 -0 两种形式\n反码：若符号位为0，则反码与原码相同\n​\t若符号位为1，则数值位全部取反\n补码：正数的补码=原码\n​\t负数的补码=反码+1\n移码：补码的基础上将符号位取反。注意：移码只能用于表示整数\n移码表示的整数很方便对比大小\n各种码的作用\n加减运算：\n无符号数的运算结果没有任何问题\n但是用原码表示有符号数的话，需要先判断符号位是不是负数，如果是负数的话，需要将负数的位改成正数位，然后将加法运算改成减法运算\n也即，使用原码运算：\n加法\u0026ndash;用加法器完成\n减法\u0026ndash;用减法器完成\n但减法器成本很高，所以考虑用加法来代替减法运算\n带余除法\u0026mdash;-设x，m属于z，m\u0026gt;0则存在唯一决定的整数q和r，使得：x=qm+r ， 0\u0026lt;=r\u0026lt;m\n实际上就是将整数分成r类，每类分别为余数从0到r-1\n模数相同的都是同一类，都是等价的\n二者绝对值之和=模的，互为补数\n模-a的绝对值=a的补数\n在mod m 的条件下，若能找到负数的补数，就可以用正数的加法来等价替代减法\n如果模数m为12的话，那么也就是余数0-11\n如果计算机的字长为8bit，也就是表示的范围是0-2^8-1，那么也就是实际上模数就是2^8呗\n所以只要模-a的绝对值=a的补数 =\u0026gt; 2^8-a的绝对值=a的补数 =\u0026gt; a的补码形式的原生定义\n补码\u0026mdash;就是让减法操作转变为加法操作，节省硬件成本 ， 这样ALU中只需要设计加法运算器就可以啦\n补码的作用：使用补码可将减法操作转变为等价的加法，ALU中无需集成减法器。执行加法操作时，符号位一起参与运算。\u0026mdash;-《数论》\n移码的作用：移码表示的整数很方便的对比大小\n定点数的表示和运算\n表示 无符号数 有符号数 原码 补码 反码 移码 运算 移位运算 加减运算 乘法运算 除法运算 移位运算\n算数移位 原码 补码 反码 逻辑移位 循环移位 原码 1 0010100. ==-20\n小数点位置是无法改变的，但是我们可以巧妙的改变数的位置，也就是\n原码 1 0001010. 也就是将尾数，整体右移一位，左边多出来的可以补0 ==-10\n原码的算数移位：符号位保持不变，仅对数值位进行移位\n右移：高位补0，低位舍弃。若舍弃的位=0，则相当于除2；若舍弃的位不等于0，则会丢失精度\n左移：低位补0，高位舍弃。若舍弃的位=0，则相当于乘2；若舍弃的位不等于0，则会出现严重误差\n反码的算数移位\u0026ndash;正数的反码与原码相同，因此对正数反码的移位运算也和原码相同。\n右移：高位补0，低位舍弃。\n左移：低位补0，高位舍弃。\n反码的算数移位\u0026ndash;负数的反码数值位与原码相反，因此负数反码的移位运算规则如下，\n右移：高位补1，低位舍弃\n左移：低位补1，高位舍弃\n补码的算数移位\u0026ndash;正数的补码与原码相同，因此对正数补码的移位运算也和原码相同。\n右移：高位补0，低位舍弃。\n左移：低位补0，高位舍弃。\n补码的算数移位\u0026ndash;负数补码=反码末位+1导致反码最右边几个连续的1都因进位而变为0，直到进位碰到第一个0为止。\n规律\u0026ndash;负数补码中，最右边的1及其右边和原码相同。最右边的1的左边和反码相同\n所以，负数补码的算数移位规则如下：\n右移（同反码）：高位补1，低位舍弃\n左移（同原码）：低位补0，高位舍弃\n牛到家的例子\n-20*7\n可以理解为-20*（4+2+1）\n也就是-20左移两位，左移1位，和不移位三者之和\n逻辑移位：\n逻辑右移：高位补0，低位舍弃\n逻辑左移：低位补0，高位舍弃\n可以把逻辑移位看作是对无符号数的算数移位\n循环移位：\n循环左移和带进位位的循环左移\n应用：汉字的大端模式和小端模式相互转换的时候\n定点数移位运算\n算数移位 左移1位相当于x基数；右移以为相当于/基数 原码：符号位不参与移位。左移右移都补0 反码：符号位不参与移位。左移右移都补1 补码：负数补码的最右边的1及其右边与源码相同，最右边的1的左边与反码相同。符号位不参与移位，左移补0，右移补1。 逻辑移位 左移、右移都补0，移出的位舍弃。 循环移位 不带进位位：用移出的位补上空缺 带进位位：移出的位放到进位位，原进位位补上空缺 注：由于原、反、补码的数位有限，因此某些时候算数移位不能精确等效乘法、除法\n加减运算\n原码的加减法 补码的加减法 溢出判断 符号扩展 原码的加法运算：\n正+正：绝对值做加法，结果为正，可能溢出\n负+负：绝对值做加法，结果为负，可能溢出\n正+负：绝对值大的减绝对值小的，符号同绝对值大的数\n负+正：绝对值大的减绝对值小的，符号同绝对值大的数\n原码的减法运算，“减数”符号取反，转变为加法：\n正-负：正+正\n负-正：负+负\n正-正：正+负\n负+正：负-负\n太难了用减法器\n所以考虑用补码的加减运算\n负数补码=\u0026gt;原码：\n数值位取反+1 负数补码中，最右边的1及其右边同原码。最右边的1的左边同反码 对于补码来说，无论加法还是减法，最后都会转变为加法，由加法器实现运算，符号位也参与运算\n当数太大的时候，可能会发生溢出，所以要进行溢出判断\n溢出判断\n只有正数+正数才会上溢\u0026mdash;\u0026ndash;正+正=负 只有负数+负数才会下溢\u0026mdash;\u0026ndash;负+负=正 方法1：采用一位符号位 设A的符号位As，B的符号位Bs，运算结果的符号为Ss，则溢出逻辑表达式为\nV=AsBs（非Ss）+（非As）（非Bs）Ss\n若V=0，表示无溢出\n若V=1，表示有溢出\n方法2：采用一位符号位，根据数据位进位情况判断溢出，符号位的进位Cs 最高数值位的进位C1\n上溢：Cs=0，C1=1\n下溢：Cs=1，C1=0\n用异或来判断就好\n方法3：采用双符号位\n正数符号为00，负数符号为11\n记两个符号位为Ss1，Ss2，则V=Ss1异或Ss2\n若V=0，则表示无溢出，若V=1，表示有溢出\n双符号位补码称为：模4补码\n单符号位补码称为：模2补码\n符号扩展\n由于可能会出现溢出，所以可以考虑补位，即int-\u0026gt;long ， 如8位=\u0026gt;16位\n定点整数的符号扩展：\n在原符号位和数值位中间添加新位，正数都添0；负数原码添0，负数反、补码添1\n定点小数的符号扩展：\n在原符号位和数值位中间添加新位，正数都添0,；负数原码、补码添0，负数反码添1\n加减运算：\n原码 加法 减法 补码：总是要转变成加法，符号位参与运算 溢出判断（补码） Key：正+正=负（上溢）；负+负=正（下溢） 方法三：采用双符号位，正数符号为00，负数符号为11，加法运算后若双符号位=01则发生上溢错误；若双符号位为10则发生下溢错误，若两个符号位相同，则未发生错误 符号扩展 定点整数符号的扩展：在原符号位和数值位中间添加新位，正数都添0，负数原码添0，反码添1，补码添1 定点小数符号的扩展：在原符号为和数值位后面添加新位，正数都添0，负数原码、补码添0，反码添1 乘法运算\n乘法运算的实现思想 原码的一位乘法 补码的一位乘法 手算乘法：可以考虑用移位来实现，左移就是乘法，右移就是除法\n考虑用机器来实现：\n实际数字有正负，符号位如何处理 乘积的位数扩大一倍如何处理 4个位积都要保存下来最后统一相加吗？ 原码一位乘法\n符号单独处理：符号位=xs和ys进行异或操作\n数值位进行相乘就好了\n运算器：\nALU：算术逻辑单元\nX：通用寄存器（存放被乘数）\nACC：累加、存放乘积高位\nMQ：存放乘数和乘积低位\n机器字长为n+1\n实现方法：先加法再移位，重复n次\n首先，ACC置为0，X存被乘数，MQ存乘数\n当前位=1，则ACC加上被乘数\n当前位=0，则ACC加0\n如此再通过移位运算，达到错位的效果\n补码的乘法运算\n原码的一位乘法：\n进行n轮加法、移位\n每次加法可能是+0、+x的原码\n每次移位是逻辑右移\n符号位不参与运算\n符号位最后由一个异或运算来决定\n补码的一位乘法：\n进行n轮加法、移位，最后再多来一次加法\n每次加法可能+0，+x的补码，+-x的补码\n每次移位是补码的算数右移\n符号位参与运算\n辅助位-MQ中的最低位=1，ACC+x的补码\n辅助位-MQ中的最低位=0，ACC+0\n辅助位-MQ中的最低位=-1，ACC+-x的补码\n除法运算\n除法运算的思想 原码除法：恢复余数法 原码除法：加减交替法（不恢复余数法） 补码除法：加减交替法 恢复余数法：\n实现方法：上商0/1，得到余数，余数末尾补0\n强制类型转换：\n无符号数与有符号数：\n不改变数据内容，改变解释方式\n长整数变短整数：\n高位截断，保留低位\n短整型变长整数：\n符号扩展\n大小端模式：\n大端模式：便于人类阅读\n小段模式：便于机器处理\n边界对齐\n现代计算机通常是按字节编址，每个字节对应1个地址\n通常也支持按字、按半字、按字节寻址\n假设存储字长为32位，则1个字为=32bit ，半字=16bit 每次仿存只能读写1个字\n边界不对齐\n边界对齐访问一个字/半字都只需要一次访存 ， 即空间换时间，舍弃空间，换取最佳时间\n边界不对齐访问一个字/半字可能需要两次访存，即时间换空间，舍弃时间，换取空间密度最佳\n浮点数的表示\n浮点数的表示 浮点数的作用和基本原理 浮点数规格化 浮点数的表示范围 IEEE 754标准 浮点数的加减运算 定点数的局限性：\n定点数可表示的数字范围有限，但我们不能无限制地增加数据的长度\n如何在位数不变的情况下增加数据的表示范围\n阶码+尾数\n阶码=阶符+阶码的数值部分\n尾数=数符+尾数的数值部分\n浮点数的表示\n定点数：如纯小数0.1011和纯整数11110\n浮点数：阶码+尾数\n阶码：常用补码或移码表示的定点整数\n尾数：常用原码或补码表示的定点小数\n浮点数的真值：N=r的E次方*M\n阶码的底通常为2\n阶码E反映浮点数的表示范围及小数点的实际位置；\n尾数M 的数值部分的位数n反映浮点数的精度\n之所以叫做浮点数，正是由于小数点可以通过阶码的值来对尾数进行调整，从而看起来像小数点在尾数中浮动，因此叫浮点数\n浮点数尾数的规格化\n使得尾数的最高位是有效值（左规），以免丢失精度\n规格化浮点数：规定尾数的最高数值位必须是一个有效值\n左规：当浮点数运算的结果为非规格化时要进行规格化处理，将尾数算数左移一位，阶码则要减1\n右规：当浮点数运算的结果尾数出现溢出（双符号位为01或10）时，将尾数算数右移一位，阶码加1\n注：采用双符号位，当溢出发生时，可以挽救。更高的符号位是正确的符号位\n浮点数的表示范围也有极限\n浮点数的表示\n表示\n阶码：阶符+数值部分，尾数：数符+数值部分 阶码+尾数 尾数给出具体数值，阶码指明小数点前移、后移多少位 阶码通常是用补码、移码表示的定点整数 尾数通常是用补码、原码表示的定点小数 真值：N=r的E次方*M 规格化\n尾数的最高数值位必须是一个有效值（类比十进制科学计数法，通常我们会让数值部分最高位为非0） 左规：数值位最高位无效时，通过尾数算数左移、阶码-1的方法处理，直到尾数最高数值位有效时停止 右规：若采用双符号位表示尾数，则当运算后尾数假溢出时，可以通过尾数右移、阶码+1的方法处理 原码表示的尾数规格化：尾数的最高数值位必须是1 补码表示的尾数规格化：尾数的最高数值位必须和尾数符号位相反 表示范围\n浮点数标准\nIEEE754\n移码：补码基础上将符号位取反。注意：移码只能用于表示整数\n移码的定义是：移码=真值+偏置值\n以往的偏置值通常是2的n-1次方\n在IEEE754标准中，偏置值将设定为2的n-1次方-1\n那么移码就会有一点点改变\n分为数符、阶码部分（用移码表示）、尾数（用原码表示，隐藏表示最高位）\n阶码全1、全0用作特殊用途\n浮点数的运算\n加减运算 强制类型转换 1.对阶\n2.尾数加减\n3.规格化\n4.舍入\n5.判溢出\nchar-\u0026gt;int-\u0026gt;long-\u0026gt;double\nfloat-\u0026gt;double\n范围、精度从小到大，转换过程没有损失\n32位\nint：表示整数\nfloat：表示整数及小数\n因此，int-\u0026gt;float:可能损失精度\nfloat-\u0026gt;int:可能溢出及损失精度\n算数逻辑单元\n作用、大致原理 电路基础知识 加法器的实现 ALU:MQ ACC ALU X PSW\n基本逻辑运算：与或非\n优先级：与\u0026gt;或\n分配律结合律都满足的\n复合逻辑：与非、或非、异或、同或\n加法器：\n一位全加器：\nAi+Bi+Ci-1=Si和Ci\nAi是一个输入\nBi是一个输入\nCi-1是来自低位的进位\nSi是本位的输出\nCi是来自本位的进位\n串行加法器：\n只有一个全加器，数据诸位串行送入加法器中进行运算。进位触发器用来寄存进位信号，以便参与下一次运算。\n并行加法器：\n串行进位的并行加法器：把n个全加器串接起来，尽可以进行两个n位数的相加。\n串行进位又称为行波进位，每一级进位直接依赖于前一级的进位，即进位信号是逐级形成的。\n算数逻辑单元：\nALU\n实现算术运算、逻辑运算、辅助功能（移位、求补） 基本结构：输入、输出、控制CU 电路基础知识\n逻辑运算：与或非、与非、或非、异或、同或 门电路：最基础的逻辑元件，用于实现逻辑运算 逻辑表达式就是电路的数学化表示。根据逻辑运算的规则对逻辑表达式进行优化，也就是在优化电路 加法器的实现\n一位全加器的设计 本位和Si=Ai异或Bi异或Ci-1 本位向高位的进位Ci=AiBi+（Ai异或Bi）Ci-1 串行加法器 一位全加器+进位触发器，只能一位一位地加 串行进位的并行加法器 多个全加器简单串联，可多位同时相加 计算速度取决于进位产生和传递的速度 回忆\n各种门电路的图形，全加器的图形和输入输出信号 并新加法器的优化\n并行进位的并行加法器：各级进位信号同时形成，又称为先行进位、同时进位\n串行加法器=\u0026gt;串行进位的并行加法器=\u0026gt;组内并行、组件串行进位的加法器=\u0026gt;组内并行、组件并行进位的加法器\n系统总线\n总线的基本概念\n总线的分类\n总线特性及性能指标\n总线结构\n总线控制\n总线是连接各个部件的信息传输线，是各个部件共享的传输机制。\n总线上信息的传送\n串行\u0026mdash;\u0026ndash;\n并行\u0026mdash;-\n总线结构\n1.单总线结构框图\n缺点：总线会成为瓶颈\n2.面向CPU的双总线结构框图\nCPU和主存之间加入M总线\n3.以存储器为中心的双总线结构框图\n总线的分类\n1.片内总线：芯片内部的总线\n2.系统总线：计算机各部件之间的信息传输线\n数据总线：双向 与机器字长、存储字长有关 地址总线：单向 与存储地址、IO地址有关 控制总线：有出有入 3.通信总线\n用于计算机系统质检或计算机系统与其他系统之间的通信\n传输方式\n串行通信总线 并行通信总线 总线特性及性能指标\n1.总线的物理实现\n实际上就是印刷电路板：主板\n2.总线特性\n机械特性\t尺寸、形状、管脚数、排列顺序 电气特性 传输方向和有效的电平范围 功能特性 每根传输线的功能：地址、数据、控制 时间特性 信号的时序关系 3.总线的性能指标\n1.总线宽度\t数据线的根数\n2.标准传输率 每秒传输的最大字节数（MBps）\n3.时钟同步、异步\t同步、不同步\n4.总线复用\t地址线与数据线复用\n5.信号线数\t地址线、数据线和控制线的总和\n6.总线控制方式\t突发、自动、仲裁、逻辑、计数\n7.其他指标\t负载能力\n4.总线标准\nISA EISA VESA PCI AGP RS-232 USB\n总线结构\n单总线结构 多总线结构 双总线结构 主存总线+通道+IO总线 CPU和主存之间加入M总线 三总线结构 主存总线、IO总线、DMA总线（IO设备和主存直接访问） CPU和cache之间的局部总线+系统总线+扩展总线 四总线结构 局部总线+系统总线+高速总线+扩展总线 多层PCI总线结构 总线控制\n总线判优控制\n主设备：对总线有控制权\n从设备：响应从主设备发来的总线命令\n总线判优控制：\n集中式 链式查询 计数器定时查询 独立请求方式 分布式 链式查询：\nBS\u0026ndash;总线忙\nBR\u0026ndash;总线请求\nBG\u0026ndash;总线同意\nbg的判断是串行的，所以是叫链式查询\n计数器定时查询：\n计数器放在总线控制部件内部，当可以让出总线占用权的时候，轮流向IO接口通过设备地址进行访问，少了BG总线，多了设备地址线，更加灵活设定优先级顺序\n独立请求方式：\n排队控制总线中设有排队器\n发起总线请求的时候，总线控制部件同时对外发起总线占用请求\n总线通信控制：\n1.目的：解决通信双方协调配合的问题\n2.总线传输周期\n申请分配阶段\t主模块申请，总线仲裁决定 寻址阶段 主模块向从模块给出地址和命令 传数阶段 主模块和从模块交换数据 结束阶段 主模块撤销有关信息 总线通信的四种方式\n同步通信 由统一时标控制数据传送 异步通信 采用应答方式，没有公共时钟标准 半同步通信 同步、异步结合 分离式通信 充分挖掘系统总线每个瞬间的潜力 同步式数据输入\n总线传输周期有四个\n在不同时钟周期上升沿给出信号\n在第一个时钟上升沿，给出地址信号\n在第二个时钟上升沿，给出读命令\n在第三个时钟上升沿，给出写数据信号\n在第四个时钟上升沿，撤销读命令以及写数据信号\n在第五个时钟上升沿，撤销地址信号\n同步式数据输出\n适用于总线比较短，不同模块读写速度近似的\n异步通信：\n主设备和从设备的请求和回答\n分为：不互锁、半互锁和全互锁方式\n半同步通信（同步、异步结合）\n同步：发送方用系统时钟前沿发信号，接收方用系统时钟后沿判断、识别\n异步：允许不同速度的模块和谐工作，增加一条“等待”响应信号\nT1 主模块发地址\nT2 主模块发命令\nTw 当WAIT为低电平时，等待一个T\nTw 当WAIT为低电平时，等待一个T\n当WAIT为高电平时，主模块开始向从模块对接\nT3 从模块提供数据\nT4 从模块撤销数据，主模块撤销命令\n以上三种通信的共同点：\n一个总线传输周期中:\n主模块发地址、命令\t占用总线 从模块准备数据 不占用总线 总线空闲 从模块向主模块发送数据 占用总线 第四种则是在总线空闲的时候，充分法诀系统总线每个瞬间的潜力，也就是分离式通信\n一个总线传输周期中，主模块申请占用总线，使用完后即放弃总线的使用权，在从模块准备好数据的时候，申请占用总线，将各种信息送至总线上\n分离式通信特点\n各模块有权申请占用总线 采用同步方式通信，不等对方回答 各模块准备数据时，不占用总线 总线被占用时，无空闲 存储器\n主存储器和高速缓冲存储器很重要\n存储器可分哪些类型 现代存储器的层次结构，为什么要分层 存储器分类\n按照存取方式分类\n存取时间与物理地址无关（随机访问） 随机存储器 在程序的执行过程中可读可写 只读存储器 在程序的执行过程中只读 存取时间与物理地址有关（串行访问） 顺序存取存储器\t磁带 直接存取存储器 磁盘 按在计算机中的作用分类\n主存储器\nRAM 随机存储器 可读可写 静态RAM 动态RAM ROM只读存储器 系统程序 不允许修改 MROM PROM EPROM EEPROM Flash Memory 例如U盘、固态\n高速缓冲存储器（Cache）\n辅助存储器：磁盘、磁带、光盘\n存储介质分类\n半导体存储器\tTTL、MOS 易失 磁表面存储器 磁头、载磁体 不易失 磁芯存储器 硬磁材料、环状元件 不易失 光盘存储器 激光、磁光材料 不易失 存储器的层次结构\n存储器的三个主要特性的关系 速度、容量、价格\n​\t寄存器\tCPU\t主机\t速度快\t容量小\t价格高\n​\t缓存\tCPU\t主机\n​\t主存\t主机\n​\t磁盘\t辅存\n​\t光盘\t辅存\n​\t磁带\t辅存\t速度慢\t容量大\t价格低\n软件、硬件相结合，多种存储器结合的形式，使得某一级的程序员看来，高速、大容量、低价格\n2.缓存\u0026ndash;主存层次和主存\u0026ndash;辅存层次\nCPU 缓存\t主存\t辅存\n10ns 20ns\t200ns\tms\n缓存\u0026ndash;主存 是由硬件绑定在一块儿的（主要为了解决速度问题）\n主存\u0026ndash;辅存 是由软硬件结合的形式弄在一块儿的（主要为了解决容量问题）\n缓存\u0026ndash;主存\n主存储器的地址 实地址 物理地址 主存\u0026ndash;辅存\n虚拟存储器 虚地址 逻辑地址 主存储器\u0026ndash;概述\n主存的基本组成 主存与CPU之间的联系 主存中的存储单元地址的分配 主存的技术指标 基本组成\nMAR地址寄存器\n译码器\n驱动器\n存储体\n读写电路\n控制电路\nMDR数据寄存器\n主存和CPU的联系\nMDR\u0026mdash;-数据总线（双向）\u0026mdash;-主存\nCPU\u0026mdash;-读写\u0026mdash;主存\nMAR\u0026mdash;地址总线（单向）\u0026mdash;主存\n主存中存储单元地址的分配\n高位字节放在前边\u0026mdash;大端模式、大尾模式\n低位字节放在前边\u0026mdash;小端模式、小尾模式\n主存的技术指标\n存储容量\t主存存放二进制代码的总位数 存储速度 存取时间\t存储器的访问时间 读出时间 写入时间 存取周期 连续两次独立的存储器操作（读或写）所需的最小间隔时间 读周期、写周期 存储器的带宽 位/秒 半导体存储芯片简介\n1.半导体存储芯片的基本结构\n译码驱动+存储矩阵+读写电路\n除此之外还有交互的数字线路，例如地址线（单向）、数据线（双向）、片选线、读写控制线\n地址线实际上是地址个数，例如地址线10条，也就是有2的10次方个地址\n数据线实际上是数据的位数，例如数据线有4条，也就是有4位的0101来表示一个数据\n所以芯片容量=地址线*数据线\n片选线 非CS 非CE chipselect chipenable 低电平有效\n读写控制线 非WE 写 非OE 读\n存储芯片片选线的作用\n用16K*1位的存储芯片组成64K * 8位的存储器\n那么就要求同时对8个芯片进行操作，每个芯片凑一个一位，8个同时工作就凑足8位，并且要同时凑足4组，因为1组只有2的16次方个地址，只有凑足4组才能够2的64次方这么多地址\n因此片选线的作用就是让几个存储芯片连接在一起同时工作\n半导体存储芯片的译码驱动方式\n1.线选法 通过输入的地址线，通过地址译码器来判断哪根线有效，然后将有效的线上的数据通过读写控制电路，也就是数据线输出，缺点在于如果地址线位数很多，那么也就是地址线需要很多，每根地址线要和不同的控制电路的块块相连，那么就会导致线很多\n2.重合法\t线选法使用矩阵来布线，而重合法使用二维矩阵来布线，布线的数量大大降低\n随机存取存储器RAM\n静态RAM（SRAM）\n保存0和1的原理是什么 通过触发器来实现存取，这部分涉及到数电的内容 基本单元单元电路的构成是什么 对单元电路如何读出和写入 通过片选信号将不同的芯片分组，通过重合法和地址线以及数据线，对低电平的地址进行选中后进行读写操作 典型芯片的结构是什么样子的 静态RAM芯片如何进行读出和写入操作 动态RAM(DRAM)\n保存0和1的原理是什么\n存在电容中，有电就是1，没电就是0 基本单元单元电路的构成是什么\n对单元电路如何读出和写入\n典型芯片的结构是什么样子的\n单管、三管 静态RAM芯片如何进行读出和写入操作\n动态RAM为什么要进行刷新，刷新方法\n防止电子丢失，刷新与行地址有关 集中刷新（存在死区和死时间率） 分散刷新（刷新过快了，没有死区） 集中刷新与分散刷新相结合（异步刷新） 动态RAM和静态RAM的比较\n​\tDRAM\tSRAM\n存储原理 电容 触发器\n集成度 高 低\n芯片引脚 少 多\n功耗 小 大\n价格\t低\t高\n速度\t慢\t快\n刷新\t有\t无\n​\t用作主存\t用作缓存\n只读存储器ROM\n早起只读存储器\u0026mdash;-不能修改\n改进1\u0026mdash;-用户可以自己写\u0026mdash;\u0026mdash;一次性\n改进2\u0026mdash;\u0026ndash;可以多次写\u0026mdash;\u0026mdash;-要能对信息进行擦除\n改进3\u0026mdash;\u0026mdash;电可擦写\u0026mdash;\u0026mdash;-特定设备\n改进4\u0026mdash;\u0026mdash;电可擦写\u0026mdash;\u0026mdash;-直接连接到计算机\n1.掩模ROM（MROM）\n行列选择线交叉处有MOS管为1\n2.PROM一次性编程\n3.EPROM（多次性编程）\nN型沟道浮动栅MOS电路\n紫外线擦除\n","date":"2021-05-14T00:26:49+08:00","permalink":"https://linjianshu.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"计算机组成原理学习文档"},{"content":"Blazor学习文档 调用webapi\nhttpclient ihttpclientfactory 数据绑定\n单项绑定\n双向绑定\n\u0026lt;input @bind = \u0026#34;CurrentValue\u0026#34; /\u0026gt; \u0026lt;input @bind = \u0026#34;CurrentValue\u0026#34; @bind:event = \u0026#34;oninput\u0026#34; \u0026lt;h1\u0026gt;单向绑定\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;@Apsdetail.ProductBornCode\u0026lt;/h2\u0026gt; \u0026lt;h2\u0026gt;@Apsdetail.ProcedureCode\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3\u0026gt;@Apsdetail.ProductBornCode\u0026lt;/h3\u0026gt; \u0026lt;h3\u0026gt;@Apsdetail.ProcedureCode\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;hr /\u0026gt; \u0026lt;h1\u0026gt;双向绑定\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3\u0026gt;产品出生证\u0026lt;/h3\u0026gt; \u0026lt;input @bind=\u0026#34;@Apsdetail.ProductBornCode\u0026#34; /\u0026gt; \u0026lt;h3\u0026gt;工序编号\u0026lt;/h3\u0026gt; \u0026lt;input @bind=\u0026#34;@Apsdetail.ProcedureCode\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h2\u0026gt;不同的触发event:\u0026lt;/h2\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3\u0026gt;产品出生证\u0026lt;/h3\u0026gt; \u0026lt;input @bind=\u0026#34;@Apsdetail.ProductBornCode\u0026#34; @bind:event=\u0026#34;oninput\u0026#34;/\u0026gt; \u0026lt;h3\u0026gt;工序编号\u0026lt;/h3\u0026gt; \u0026lt;input @bind=\u0026#34;@Apsdetail.ProcedureCode\u0026#34; @bind:event=\u0026#34;oninput\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;button @onclick=\u0026#34;@button_click\u0026#34;\u0026gt;click\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; EditForm\ninput组件 inputtext inputtextarea inputnumber inputselect inputdate inputcheckbox 数据绑定 数据验证 界面携值跳转\n在webapi中\n记得指定route属性\n如果没有fromform的话 post优先为从url传过来的数据\n如果指定了fromform的话 image-20210423163845812\rblazor通过post传过来的东西\nimage-20210423170418068\r在webapi中直接通过实体来接收就好了!!!\n","date":"2021-04-24T00:27:56+08:00","permalink":"https://linjianshu.github.io/p/blazor%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"Blazor学习文档"},{"content":"asp .net core mvc 学习文档 控制器向界面传值 通过viewbag/viewdata 来进行弱传递\ncontroller中:\nimage-20210421230444662\rindex中:\nimage-20210421230455113\r通过model进行强类型传递\ncontroller中:\nimage-20210421230520009\rindex中:\n@model IEnumerable\u0026lt;webmvcdemo.Models.Movie\u0026gt; \u0026lt;form asp-controller=\u0026#34;Movies\u0026#34; asp-action=\u0026#34;Index\u0026#34; \u0026gt; \u0026lt;p\u0026gt; \u0026lt;select name=\u0026#34;prop\u0026#34; required=\u0026#34;\u0026#34;\u0026gt; @foreach (var item in typeof(Movie).GetProperties()) { \u0026lt;option value=@item.Name\u0026gt;@item.Name\u0026lt;/option\u0026gt; } \u0026lt;/select\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;SerachString\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/form\u0026gt; 界面向控制器传参 通过name来准确传递\nindex:\n\u0026lt;select name=\u0026#34;prop\u0026#34; required=\u0026#34;\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;SerachString\u0026#34;/\u0026gt; 控制器中:\nimage-20210421230911623\r通过定位点标记帮助程序\nhttps://docs.microsoft.com/zh-cn/aspnet/core/mvc/views/tag-helpers/built-in/anchor-tag-helper?view=aspnetcore-5.0#asp-route-value\nRazor语法 使用@符号将c#转化为html代码提供展示 显式/隐式razor表达式 razor代码块 ​\tRazor 代码块以开头 @ ，并由括起来 {} 。 代码块内的 C# 代码不会呈现，这点与表达式不同。 一个视图中的代码块和表达式共享相同的作用域并按顺序进行定义\n控制结构@if, else if, else, and @switch 循环结构@for, @foreach, @while, and @do while 复合语句@using, @try, catch, finally @attribute 指令将给定的属性添加到生成的页或视图的类中。 以下示例添加 [Authorize] 属性： @attribute [Authorize] @code和@functions @code块使 Razor 组件可以将 c # 成员添加 () 到组件的字段、属性和方法\n@functions 指令允许将 C# 成员（字段、属性和方法）添加到生成的类中\n在razor组件中,我们使用@code 来代替js所做的操作和运算\n在razor页面中,我们使用@functions 来代替js所做的操作和运算\n@functions { public string GetHello() { return \u0026#34;Hello\u0026#34;; } } \u0026lt;div\u0026gt;From method: @GetHello()\u0026lt;/div\u0026gt; @implements 指令为生成的类实现接口。 @inherits 指令对视图继承的类提供完全控制： image-20210422102054166\r@model 和 @inherits 可在同一视图中使用。\n@inject指令使 Razor 页面可以将服务从服务容器注入到视图。 有关详细信息，请参阅视图中的依赖关系注入。\n@model 指令指定传递到视图或页面的模型类型\n@namespace 指令：\n设置生成的 Razor 页、MVC 视图或组件的类的命名空间 Razor 。 在目录树中最近的导入文件中设置页面、视图或组件类的根派生命名空间， _ViewImports) 或 _Imports razor (组件) (视图或页面。 Razor @page 指令具有不同的效果，具体取决于其所在文件的类型。 指令：\n在 cshtml 文件中，指示该文件是一个 Razor 页面。 有关详细信息，请参阅自定义路由和 ASP.NET Core 中的 Razor Pages 介绍。 指定 Razor 组件应直接处理请求。 有关详细信息，请参阅 ASP.NET Core Blazor 路由。 @using 指令用于向生成的视图添加 C# using 指令：\n@using System.IO @{ var dir = Directory.GetCurrentDirectory(); } \u0026lt;p\u0026gt;@dir\u0026lt;/p\u0026gt; public class Instructor { public int ID { get; set; } [FromQuery(Name = \u0026#34;Note\u0026#34;)] public string NoteFromQueryString { get; set; } 表单标记帮助程序 ","date":"2021-04-16T00:28:25+08:00","permalink":"https://linjianshu.github.io/p/apsdotnetcoremvc%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"ApsDotnetCoreMVC学习文档"},{"content":"C#5.0+学习文档 特点：\n通用性语言 类型安全 面向对象 目标：生产力\n简洁性 表达力 高性能 平台中立，与平台无关\n封装、继承、多态\n统一的类型系统：\n类型 共同的基类 类和接口\nclass interface 属性property、方法method和事件event\n唯一一种函数成员(Function Member):方法(method)\n方法还包括：属性(Property)和事件(Event)还有其他的\n属性\n事件\nC#主要是一种面向对象的语言，但是也借用了不少函数式编程的特性\n函数可以当做值来对待\n委托Delegate 支持纯(purity)模式\n避免使用值可变的变量 类型安全\nc#主要来说是类型安全的 静态类型 static typing 动态类型 dynamic 强类型 strongly typed language 内存管理\n依赖于运行时来执行自动内存管理 CLR:Common Language Runtime (公共语言运行时) GC： Garbage Collector (垃圾收集器) c#没有消灭指针 通常情况下不需要使用指针 unsafe 平台支持\n原来c#主要是在window上面运行\n现在可以在所有的平台上运行\nwindows macs linux ios android \u0026hellip; .Net Core\n.Net/.Net Core 的核心就是CLR: Comman Language Runtime\nCLR和语言无关\nc#是一种托管语言\n会被编译成托管代码(IL : Intermediate Language) CLR把IL转化成机器的原生代码 JIT(Just in time)编译 Ahead-of-time编译 托管代码的容器：Assembly 或portable Executable\n.exe 或dll 包含IL 和类型信息(metadata) IIdasm\n支持c#的框架\n.net framework .net core unity xamarin uwp winrt windows phone xna silverlight .net micro framework mono sql server .net Core\n编译 c#编译器把.cs结尾的源码文件编译成Assembly assembly是.net core里包装和部署的单元 assembly可以是应用程序，也可以是库 .exe .dll 构造函数和实例化 数据是通过实例化一个类型来创建的 预定义的类型直接写literal就可以被实例化了 而自定义类型则通过new操作符来创建实例 实例成员vs静态成员 操作于实例类型的数据成员和函数成员都叫做实例成员 操作于类型而不是类型实例的数据成员和函数成员叫做静态成员 static 静态类static class 的所有成员都是静态的 静态类不可以创建实例。 例如console ，他在整个程序里就一个 public\npublic关键字可以把成员暴露给其他的类 如果没有public关键字的话就是private 无法暴露给其他类 值类型与引用类型 值类型包括所有的内置类型（数值、字符、bool）和自定义的struct和enum\n引用类型包含所有的class，数组，delegate，interface类型。包括字符串\n他们的根本区别在于处理内存的方式\n值类型 值类型变量/常量的内容就是一个值 使用struct关键字就可以自定义创建值类型 Point p = new Point() ; p.x = 7 ; Point p1 = p ; System.Console.WriteLine(p.x); System.Console.WriteLine(p1.x); p1.x = 9 ; System.Console.WriteLine(p1.x); System.Console.WriteLine(p.x); } public struct Point { public int x ; public int y ; } 值类型的赋值\n值类型实例的赋值动作总是复制了该实例 引用类型 引用类型比值类型复杂\n分为两个部分：1.一个对象2.到该对象的引用\n引用类型的变量/常量的内容就是到一个含有值的对象的引用\n引用类型赋值 给引用类型的变量赋值：复制引用， 而不是对象实例\n允许多个变量引用同一个对象（值类型就没有这种可能）\n相当于指向内存里的同一个地址块\nPoint1 p2 = new Point1() ; p2.x = 7 ; Point1 p3 = p2 ; System.Console.WriteLine(p2.x); System.Console.WriteLine(p3.x); p3.x = 9 ; System.Console.WriteLine(p3.x); System.Console.WriteLine(p2.x); } public class Point1 { public int x ; public int y ; } NULL null是一个literal\n可以把null赋值给引用， 表示该引用不指向任何一个对象\nnull.property会抛出nullreferenceException也就是空指针异常\n普通的值类型不可以为null\nc#有一种可空类型（nullable types）来表示值类型的null\n存储开销 值类型的实例所占内存= 他的字段需要内存的总和\nclr会把类型内的字段大小设置为该字段实际大小的整数倍\n引用类型需要为引用和对象单独分配内存\n对象所占内存= 其字段所占内存总和+额外的管理开销（最少8字节）\n每个对象的引用还需要额外的4或8个字节，（根据平台是32位还是64位的）\n内置类型的分类 值类型：sybte /short / int / long / byte / ushort / uint / ulong / folat / double / decimal / bool / char 引用类型：string / object / c#7.0引入了可以使用下划线来增加可读性 使用二进制、十进制、十六进制、指数来表示数\nint a = 1_000_000 ; var b = 0b10101_10101 ; double c = 1.5 ; double million = 1E06 ; int a1 = 0xf00000 ; float e = 1.0f ; decimal d= -1.23m ; 数值literal的类型推断 默认情况下，编译器会推断一个数值literal是double还是整数类型： 如果包含小数点，或以指数形式展现，那么就是double类型 否则literal的类型就是下面列表里的第一个能容纳该数值的类型：int , uint , long , ulong , 数值的后缀 F和M比较有用，当指定float或decimal的literal的时候，应该加上 数值转换 当浮点型转为整型时，小数部分是被截断的，没有舍入。 把一个很大的整数隐式的转换为浮点类型之后，会保证量级不变，但是偶尔会丢失精度。 这是因为浮点类型有很更多的量级，而精度可能不足。 overflowChecked操作符 检查是否会超出类型极限，进而抛出异常\n对++、\u0026ndash;、+、-。*、/起作用\n可以用于表达式或语句\nchecked对float、double不起作用，因为他们有无限值\nint a = 10000000 ; int b = 10000000 ; int c = checked(a*b) ; checked{ int d = a*b ; } float min = float.NegativeInfinity ; double max = double.PositiveInfinity ; int f = unchecked(a*b) ; unchecked{ int e = a*b ; } 按位操作符 ~取反\n\u0026amp;与\n|或\n^异或\n\u0026laquo;左移\n\u0026lt; \u0026raquo;右移\ndouble适用于科学计算，例如计算坐标\ndecimal适用于财务计算，或者是人造数据\ndouble和decimal不能标识循环数据\nbool无法和数值类型进行转换\n||和\u0026amp;\u0026amp;有短路机制，为了避免空指针异常\n\u0026amp;和|没有短路机制\n当使用于数值的时候，\u0026amp;和|执行的是按位操作\n@做前缀，在双引号外边，就不支持转义字符了，且支持多行输出\nimage-20210120192441256\r字符串插值：加上${}就行了\nimage-20210120192847666\rstring的比较，不支持\u0026gt;\u0026lt;等等比较操作符，需要使用comparerto方法\n数组的长度固定不可改变，但是system.collection和其子命名空间提供了更高级的数据结构，包括可变长度的数组和字典\n创建数组时，所有的元素都会被初始化，其值为该类型的默认值\n类型的默认值就是内存按位归零的结果\n值类型和引用类型的性能有区别\n值类型：每个元素都作为数组的一部分进行分配内存\n引用类型：创建数组时就是创建了一堆null引用，因此如果为空的时候可能会抛异常\n建议对元素是引用类型的数组初始化后对元素都进行初始化 边界检查 所有数组的索引都会被运行时检查的\n如果使用了不合理的索引，会抛出indexoutofrangeexception ， 索引越界异常\n通常边界检查对性能的影响很小，jit编译器可执行一些优化，例如在进入循环前预先对所有的索引进行安全检查，避免在迭代中检查\nc#还提供了unsafe代码，可以绕过边界检查\nstack栈和heap堆 stack一块内存存储本地变量和参数 随着函数的进入和退出，stack也会随之增大和缩小 heap一块内存，对象所在的地方（引用类型的实例） 当新的对象被创建之后，他就会被分配在heap上，到该对象的一个引用被返回 程序执行时，随着新对象的不断建立，heap会慢慢被填满。运行时的gc会周期性的把对象从heap上面释放出来，所以不会导致内存耗尽 一旦一个对象不再被任何存活的东西所引用，那么它就可以被释放了 static字段 在heap上，它们会存活到应用程序域停止为止\nimage-20210120195453978\r参数传递：值传递、ref传递、out传递\n值传递：\nimage-20210120195838267\rref传递：复制的是引用而不是值\nimage-20210120200027202\rimage-20210120201653417\r按引用传递out 和ref差不多，除了\n进入函数前不需要被赋值 离开函数前必须被赋值 通常用来从方法中返回多个值\nimage-20210120203541523\r从c#7开始，调用方法适，可以使用out临时声明变量\n当调用的方法有多个out参数时，你不需要其中一些out参数，可以使用下划线_来discard弃用他们\nimage-20210120203948953\rimage-20210120204041448\rparams修饰符 可以在方法的最后一个参数使用params参数修饰符\n可以接受任意数量的该类型的参数\n参数（parameters）类型必须是数组\n也可以使用数组作为arguments\nimage-20210120205539611\r可选参数 从c#4.0开始，方法、构造函数、索引器都可以声明可选参数\n可选参数需要在声明的时候提供默认值\n调用的时候不可以填写可选的parameters\nimage-20210120212044993\r往public方法里添加可选参数，若该方法被其他的assembly调用，那么两个assemblies都需要重新编译，就和添加了一个必填参数是一样的\n可选参数的默认值是常量表达式或拥有无参构造函数的值类型\n可选参数不可以使用ref和out\n必填参数必须在可选参数前面（方法声明时和方法调用时）\n例外是：params的参数仍然放在最后边\nimage-20210120212612888\r定位参数，根据位置来判断，不要求输入的顺序和定位的顺序保持一致 image-20210120212814635\rvar 隐式强类型本地变量\n声明和初始化变量通常一步完成，如果编译器能从初始化表达式推断出类型，就可以使用var\n但是会降低代码的可读性\n右结合的操作符\n赋值、lambda、null合并和条件操作符是右结合的\n从右向左估算\nx=y=3\nnull操作符 c#提供了两种操作符，他们可以更容易的处理null\nnull合并操作符 ？？ 如果操作数不是null，就把左边的给我，如果操作数是null，就把右边的给我 null条件操作符 ？.方法 image-20210120214033193\rimage-20210120214329392\r合在一起用哦哦哦哦\nimage-20210120214520840\rimage-20210120214741402\rswitch语句 当指定常量的时候，只能使用内置的整数类型、bool、char、enum和string类型\n每个case子句的结尾，必须使用跳转语句来表名下一步往哪里执行\nbreak 跳转到switch语句的结尾 goto case x 跳转到其他的case goto default 跳转到default子句 其他的跳转语句 return , throw ,continue , goto label image-20210120215931777\rswitch with patterns c#7 object类型允许任何类型的变量 每个case子句指定一个类型，如果变量的类型与该类型一样，那么就匹配成功 可以使用when来断言一个case case子句的顺序是有关系的 可以是case null image-20210120220321250\rimage-20210120220731178\r复习一下：有用的 ref和out关键字，一个赋值的是引用的地址块，一个是作为不用传入的参数，传出多个参数使用，后者可以使用传入时定义临时变量来，并且不需要传出参数的时候可以使用下划线来discard他们 数字为了区分可读性，可以使用下划线1_000_000这样 @“\u0026hellip;\u0026hellip;.”这样可以不拆解转义字符 parameter格式定义的是数组，且是数量可变的，但必须作为方法的最后一个参数传入 可以构造可选的参数方式，在构造方法的时候预先传入参数默认值，且放在方法的最后边 如int sum (int x =1, int y = 0 ) \u0026hellip; null的合并操作符和条件操作符，防止空指针异常 switch case的新操作:判断类型和使用when进一步判断 以及 goto case , goto default \u0026hellip; 按位操作 ，||和\u0026amp;\u0026amp;的短路机制 ， ${s}插值 checked ， unchecked ， overflowcheck操作符 ， default（int） params修饰符 以及定位修饰符 跳转语句 break ； 结束迭代或switch语句的代码体\ncontinue ; 放弃当前迭代中剩余的语句执行， 直接从下一次迭代开始\ngoto ; 把执行跳转到另一个label的语句块 ， goto语句label ， 当用于switch语句内时，goto case\n3（只能用于常量） ， label相当于是一个代码块的占位符， 放在语句前边，使用冒号：做后缀\nreturn ; 退出方法，并返回一个表达式，类型和方法的返回类型一致，如果是void就return； return可以放在任何地方，除了finally里\nthrow ; 抛出异常 ， 相当于输出了错误\ntyr catch finally\n不可以从finally块里面跳转到外边，除了throw\nimage-20210121093843103\rint i = 1 ; gotoloop: if(i \u0026lt;=5) System.Console.WriteLine(i); i++ ; goto gotoloop ; using static 从c# 6开始， 不仅可以引入命名空间，还可以引入具体的类型，这就需要使用using static\n被引入类型的所有静态成员可被直接使用， 无需使用类名\n所有可访问的静态成员都会被引入，字段、属性、嵌套类型\n也可用于enum ， 这样的话它的成员就被引入了\n如果多个static引入存在歧义的话，将会发生错误\n命名空间 可以使用重复的命名空间，只要类型不相互干扰\n给命名空间起别名，防止他和其他命名空间下的其他类型相互干扰\nusing System; using static System.Console ; using P = System.Reflection ; namespace FirstCSharp { class Program { static void Main(string[] args) { WriteLine(\u0026#34;你搞笑呢\u0026#34;); } class a { private P.PropertyInfo p; } } extern alias 命名空间，解决两个程序集内部命名空间和类型完全一致的问题， 实际上就是给他们在添加一层最外层的用于区分\n命名空间别名限定符\n内层命名空间的类型名会把外层命名空间下的类型名隐藏， 有时即使使用全名也无法解决冲突\n1.使用global命名空间：也就是 ::\nnamespace FirstCSharp { class Program { public class A { public class B { } private static void Main(string[] args) { new global::A.B(); } } } } namespace A { class B { } } 可空值null类型 nullable\n例如 nullable 不仅可以表示 true； false； 还可以表示null ；\nstatic void Main(string[] args) { string str = \u0026#34;sdfhasdfkjsaf\u0026#34;; Nullable\u0026lt;int\u0026gt; indexOf = null; //或者用这种来表达 int? lalala = str.IndexOf(\u0026#39;m\u0026#39;); Nullable\u0026lt;DateTime\u0026gt; lastLogDateTime = null; DateTime? lasTime = null; Console.WriteLine(indexOf?.ToString()); Console.ReadKey(); } null 和 空， 空白 string string name = \u0026ldquo;Nick\u0026rdquo; string name = null string name =\u0026quot;\u0026quot; string name = \u0026quot; \u0026quot; 判断 if(name == null ) \u0026hellip; if(string.isNullOrEmpty(name)) \u0026hellip; if(string.isNullOrWhiteSpace(name)) \u0026hellip; nullable的常用属性和方法 hasvalue .value .getvalueordefault（） .getvalueordefault(默认值) int? num = 3; Console.WriteLine(num.HasValue); Console.WriteLine(num.Value); int? number = null; Console.WriteLine(number.HasValue); Console.WriteLine(number.GetValueOrDefault()); Console.WriteLine(number.GetValueOrDefault(1997)); nullable和T的转换 int? i = 3; int j; j = (int)i; Console.WriteLine(j); int m = 3; int? k; k = m; Console.WriteLine(k); 防止可空索引应该有的做法 string[] a = null; string b = a?[0].Trim(); 第三章 class field：是class和struct的成员，他是一个变量 readonly修饰符 readonly修饰符防止字段在构造之后被改变 readonly字段只能在声明的时候被赋值，或在构造函数里被赋值 字段初始化 字段可以可选初始化\n未初始化的字段有一个默认值\n字段的初始化在构造函数之前运行\n同时声明多个字段，用逗号隔开\n方法 执行某个动作 参数 返回类型 void ref/out作为数据的返回格式 方法的签名 类型内方法的签名必须唯一 签名：方法名、参数类型（含顺序，但与参数名称和返回类型无关） Expression-bodied方法:仅适用于单表达式的方法 void foo() =\u0026gt; Console.WriteLine(\u0026#34;hello world\u0026#34;); foo(); 方法的重载 类型里的方法可以进行重载（允许多个同名的方法同时存在），只要这些方法的签名不同就行\n参数按值传递和按引用传递，也可以进行方法重载\n本地方法 C#7 方法里有方法 void zhendeyoufooma() { void foo() =\u0026gt; Console.WriteLine(\u0026#34;hello world\u0026#34;); foo(); } zhendeyoufooma(); 本地方法适用于其他类呀方法里不需要使用的，也就是这个方法只为这个类服务的，另外可以在构造函数里写， 可以在属性的选择器里写\n不需要写static关键字 构造函数 运行class或struct的初始化代码\n和方法差不多，方法名和类型一致，返回类型也和类型一致，但不写了\nc# 7 ，允许单语句的构造函数写成 expression-bodied成员的形式\npublic class panda { public panda(string n) =\u0026gt; name = n; private string name; } 构造函数重载 在class和struct里可以重载构造函数 调用重载构造函数时使用this 当同一个类型下的构造函数A调用构造函数B的时候，B先执行 public class panda { public panda(string n) =\u0026gt; name = n; public panda(string n, int age):this(n) { this.age = age; } private string name; private int age; } 构造函数和字段的初始化顺序 字段的初始化发生在构造函数执行之前 字段按照声明的先后顺序进行初始化 构造类似单例模式:让类返回最多一个实例\nvar instance = Wine.CreateInstance(); public class Wine{ Wine() { } public static Wine CreateInstance() { return new Wine(); } } 析构函数 c# 7 deconstructor c# 7 引入了deconstructor模式\n作用基本和构造函数相反， 他会把字段反赋给一堆变量\n方法名必须是deconstructor ，有一个或者多个out参数\ndeconstructor可以被重载\ndeconstructor这个方法可以是扩展方法\nvar rectangle = new Rectangle(3,4); rectangle.Deconstruct(out var a , out var b ); var (c, d) = rectangle; rectangle.Deconstruct(out var e,out var f); Extensions.Deconstruct(rectangle,out var k , out var m ); Console.WriteLine(a); Console.WriteLine(b); Console.WriteLine(c); Console.WriteLine(d); public Rectangle(int W, int H) { width = W; height = H; } public void Deconstruct(out int outWidth, out int outHeight) { outWidth = width; outHeight = height; } public void Deconstruct(out int outWidth) { outWidth = width; } public static class Extensions { public static void Deconstruct(this Rectangle rect, out int width, out int height) { width = rect.width; height = rect.height; } } 属性 属性的声明和字段的声明很像，但多了一个get set快 只读和计算的属性 如果属性只有get访问器，那么他就是只读的 如果只有set访问器，那么他就是只写的 属性通常拥有一个专用的幕后字段 ， 这个幕后字段用来存储数据 属性初始化器 从c#6开始，你可以为自动属性添加属性初始化器 只读的自动属性也可以使用（也可以在构造函数里被赋值） public class panda { public panda(string n) =\u0026gt; name = n; public string sex { get =\u0026gt; sex; set =\u0026gt; sex=value; } //相当于 public string sex1 { get; set; } public string sex2 { get; set; } = \u0026#34;linjianshu\u0026#34;; public panda(string n, int age):this(n) { this.age = age; Console.WriteLine(2); } private string name; private int age; } 静态构造函数 静态构造函数，每个类型执行一次 非静态构造函数，每个实例执行一次 一个类型只能定义一个静态构造函数 必须无参 方法名与类型一致 初始化顺序 ​\t静态字段的初始化器在静态都早函数被调用之前的一瞬间运行\n静态类 类也可以是静态的 其成员必须全是静态的 不可以有子类 finalizer终结器 finalizer是class专有的一种方法 在gc回收未引用对象的内存之前运行 其实就是对object的finalize（）方法重写的一种语法 class a { ~class a{ } } partial type 每个分布的类都必须使用partial来声明\n每个分布类的成员不能冲突，不能有同样参数的构造函数\n各分布类完全靠编译器来进行解析：每个分布类在编译时必须可用，且在同一个assembly里\n如果有父类，可以在一个或多个分布类上指明，但必须一致\npartial method 由两部分构成：定义和实现 定义部分通常是生成的 实现部分通常是手动编写的 如果partial method 只有定义，没有实现，那么编译的时候该方法定义就没有了，调用该方法的代码也没有了。这就允许自动生成的代码可以自由的提供钩子，不用担心代码膨胀 partial method 必须是void，并且隐式private的 image-20210124193847516\rnameof 操作符 string name = nameof (count)\n继承 多态 引用是多态的，类型为x的变量可以引用子类的对象 因为子类具有父类的全部功能特性，所以参数可以是子类 反过来则不行 引用转换 一个对象的引用可以隐式的转换到其父类的引用（向上转换） 想转换到子类的引用则需要显示转换（向下转换） 引用转换： 创建了一个新的引用，他也指向同一个对象 向下转换可能会失败，如果失败了就会抛出invalidCastException异常 As操作符 as操作符会执行向下转换，如果转换失败，不会抛出异常，值会变为null\nas操作符无法做自定义转换\nis操作符 is操作符会检验引用的转换是否成功。换句话说，判断对象是否派生于某个类（或者实现了某个接口） 通常用于向下转换前的验证 如果拆箱转换可以成功的话，那么使用is操作符的结果会是true is操作符合模式变量 在c#7 里， 使用is操作符的时候，可以引入一个变量 引入的变量可以立即消费 var person = new Person(); var student = new Student(); //隐式转换 Person p = student; //显示转换 可能会发生类型转换错误 Student s = (Student)p; //如果异常s1就是null Student s1 = p as Student; if (s1 is Student) { //判断 } //判断并引入变量 if (s1 is Student s2) { s2.StuId = \u0026#34;2020170281\u0026#34;; } virtual函数成员 标记为virtual的函数可以被子类重写，包括属性、方法、索引器、事件等等 使用override修饰符，子类可以重写父类的函数 override virtual方法和重写方法的签名、返回类型、可访问程度必须是一样的 重写方法里使用base关键字可以调用父类的实现 var person = new Person(); var student = new Student(); student.jobbb = \u0026#34;student\u0026#34;; Console.WriteLine(person.job); Console.WriteLine(student.job); Person p = student; Console.WriteLine(p.job); } public class Person { public string Name { get; set; } public virtual string job =\u0026gt; \u0026#34;person\u0026#34;; } public class Student : Person { public string StuId { get; set; } public override string job =\u0026gt; jobbb; public string jobbb { get; set; } } 抽象类和抽象成员 使用abstract声明的类是抽象类 抽象类不可以被实例化，只有其具体的子类才可以被实例化 抽象类可以定义抽象成员 抽象成员和virtual成员很像，但是不提供具体的实现。子类必须提供实现，除非子类也是抽象的 public abstract class Person1 { public abstract string Name { get; } } public class Student1:Person1 { public override string Name =\u0026gt; job; public string job { get; set; } } new 和 override的区别 用new的话， 编译时对A的引用就会绑定到A的字段上 //new 和 override 的区别 var b = new B(); A a1 = b; b.lalala(); a1.lalala(); var c = new C(); A a2 = c; c.lalala(); a2.lalala(); } public class A { public virtual void lalala() { Console.WriteLine(\u0026#34;AAAAAA\u0026#34;); } } public class B : A { public override void lalala() { Console.WriteLine(\u0026#34;BBBBBB\u0026#34;); } } public class C:A { public new void lalala() { Console.WriteLine(\u0026#34;CCCCC\u0026#34;); } } sealed 针对重写的成员，可以使用sealed关键字把它密封起来， 防止它被其他子类重写 也可以sealed类本身，就隐式的sealed所有的virtual函数了 public class Student1 : Person1 { //使用sealed的话，就无法在其他子类重写了 public sealed override string Name =\u0026gt; job; public string job { get; set; } } base关键字 base和this很像，base主要用于 从子类访问父类里被重写的函数 调用父类的构造函数 这种写法可以保证，访问的一定是asset的liability属性，无论该属性是呗重写了还是被隐藏了 构造函数和继承 子类必须声明自己的构造函数\n从子类可访问父类的构造函数，但不是自动继承的\n子类必须重新定义他想要暴露的构造函数\n调用父类的构造函数需要使用base关键字\n父类的构造函数肯定会先执行\n如果子类的构造函数里没有使用base关键字，那么父类的无参构造函数就会被隐式的调用\n如果父类没有无参构造函数，那么子类就必须在构造函数里使用base关键字\nnew Tiget( \u0026#34;lalala\u0026#34;); new Tiget(\u0026#34;lalala\u0026#34;, \u0026#34;lulullu\u0026#34;); } public class Animial { public Animial(string @class) { Console.WriteLine(@class); } } public class Tiget : Animial { public Tiget(string @class) : base(@class) { Console.WriteLine(\u0026#34;tiger\u0026#34;); } public Tiget(string @class ,string b):base(@class) { Console.WriteLine(b); } } object object是引用类型 但值类型可以转化为object，反之亦然（类型统一） 在值类型和object之间转换的时候，clr必须执行一些特殊的工作，以弥补值类型和引用类型之间语义上的一些差异，这个过程就叫做装箱和拆箱 装箱 装箱就是把值类型的实例转换为引用类型的实例的动作 目标引用类型可以是object，也可以是某个接口 拆箱 拆箱正好相反，把那个对象转换成原来的值类型\n拆箱需要显示的转换\n数组和泛型只支持引用转换，不支持装箱\n装箱和拆箱的复制 装箱会把值类型的实例复制到一个新的对象 拆箱会把这个对象的内容再赋值给一个值类型的实例 静态和运行时类型检查 C#的程序既会做静态的类型检查（编译时），也会做运行时的类型检查（CLR） 静态检查：不运行程序的情况下，让编译器保证程序的正确性 运行时的类型检查，是由CLR执行，发生在向下的引用转换或拆箱的时候 运行时检查之所以可行是因为：每个在heap上的对象内部都存储了一个类型token 。 这个token可以通过调用object的gettype（）方法来获取 tostring方法 可以在自定义的类型上重写tostring方法 如果你不重写该方法，那就会返回该类型的名称 image-20210124214053490\rstruct struct和class差不多，但是有一些不同 struct是值类型，class是引用类型 struct不支持继承（除了隐式的继承了object） class能有的成员，struct也可以有， 但是一下几个不行 无参构造函数不行 字段初始化器不行 终结器不行 virtual和protected成员不可以 struct的构建 有一个无参构造函数，但是不能对其进行重写，他会对字段进行按位归零操作 当定义struct构造函数的时候，必须显式的为每个字段赋值 不可以有字段初始化器 访问修饰符 public ，完全可访问，enum和interface的成员默认都是这个级别 internal ， 当前assembly或者朋友assembly可访问， 非嵌套类的默认访问级别 private， 本类可以访问， class 和struct 的成员的默认访问级别 protected ， 本类或其子类可以访问 protected internal ， 联合了protected 和internal 的访问级别 朋友程序集assembly 通过添加system.runtime.compilerservices.internalsvisibleto这个assembly的属性 ， 并指定朋友assembly的名字，就可以把internal的成员暴露给朋友assembly [assembyy:internalsvisibleto(\u0026ldquo;friend\u0026rdquo;)]\n如果朋友assembly 有strong name ， 那么就必须指定其完整的160字节的public key [assembyy :internalsvisibleto(\u0026ldquo;strongfriend,publickey=0024f0000448c\u0026hellip;\u0026rdquo;)]\n访问修饰符的限制 当重写父类的函数时，重写后的函数和被重写的函数的访问级别必须一致 有一个例外：当在其他的assembly重写protected internal的方法时， 重写后的方法必须是protected 接口简介 接口只为成员提供规格，没有实现 接口成员都是隐式抽象的 一个class或者struct都可以实现多个接口 接口的实现 接口的成员都是隐式public的，不可以声明访问修饰符 实现接口对她的所有成员进行public的实现 接口和对象的相互转换 接口的扩展 接口可以继承其他接口 显示的接口实现 实现多个接口的时候可能会造成各成员签名的冲突。通过显式实现接口成员可以解决这个问题 枚举 枚举时一个特殊的值类型，它可以让你指定一组命名的数值常量 每个枚举都对应一个底层的整型数值，默认是int类型 也可以指定其他的类型作为枚举的整数类型，例如byte 可以单独指定枚举成员的整数值 也可以指定其中某些成员的数值，未被赋值的成员将接着他前面的已赋值成员的值递增 image-20210124221533924\r枚举可以显式的和其底层的数值相互转换 flags enum 可以对枚举的成员进行组合 为了避免歧义，枚举成员的需要显示的赋值，典型的使用2的乘幂 按约定，如果枚举成员可以组合的话，flags属性就应该引用在枚举类型上 如果声明了这样的枚举却没有使用flags属性，你仍然可以组合枚举的成员，但是调用枚举实例的tostring（）方法时，输出的将是一个数值而不是一组名称 按约定，可以组合枚举的名称应该是复数的 var b = sex.top | sex.bottom | sex.right; Console.WriteLine(b); } [Flags] public enum sex { top = 1 , right = 2 , bottom = 4 , left = 8 } 枚举支持的操作符 = == != \u0026lt; \u0026gt; \u0026lt;= \u0026gt;= + - ^ \u0026amp; | - += -= \u0026ndash; sizeof\n其中按位的、比较的、算术的操作符返回的都是处理底层值后得到的结果 加法操作符只允许一个枚举和一个整型数值相加，两个枚举相加是不可以的 嵌套类型的特性 可访问封闭类型的私有成员，以及任何封闭类型能访问的东西 可以使用所有的访问修饰符来声明，不仅仅是public和internal 嵌套类型的默认访问级别是private而不是internal 从封闭类型外边访问嵌套类型需要使用到封闭类型的名称 复习一下 分部类、命名空间global::、external alias、virtual、override和new的区别、abstract、继承构造函数的base关键字、 goto label 、 using static 、 string.isnullorwhitespace、getvalueordefault、is修饰符、as修饰符、本地方法、deconstructor、 属性自动初始化器、构造函数支持expression body形式、nameof修饰符、分布方法提供钩子、is修饰符提供变量、sealed、子类继承父类构造函数问题、 装箱拆箱是复制、tostring自定义类型得重写不然、deconstructor支持扩展方法 第三章 泛型部分 泛型的作用 跨类型可复用的代码：继承和泛型 继承=\u0026gt;基类 泛型=\u0026gt;带有类型占位符的模板 泛型类型 generic types 泛型会声明类型参数\u0026mdash;泛型的消费者需要提供类型参数（argument）来吧占位符类型填充上 open type \u0026amp; closed type stack open type 开放类型 stack closed type 封闭类型 在运行时，所有的泛型类型实例都是封闭的（占位符类型已经被填充了） 泛型方法 泛型方法在方法的签名内也可以声明类型参数 在泛型类型里面的方法，除非也引入了类型参数，否则是不会归为泛型方法的 只有类型和方法可以引入类型参数，属性、索引器、事件、字段、构造函数、操作符等都不可以声明类型参数、但是他们可以使用他们所在的泛型类型的参数 声明类型参数 在声明class / struct / interface / delegate 的时候可以引入类型参数(type parameters) 其他的例如属性， 就不可以引入类型参数，但是可以使用类型参数 引入就是使用形式， 使用就是直接使用T的形式 泛型类型/泛型方法的名称可以被重载，条件是参数类型的个数不同 typeof 与 未绑定的泛型类型 开方的泛型类型在编译后就变成了封闭的泛型类型 但是如果作为type对象， 那么未绑定的泛型类型在运行时是可以存在的， 只能通过typeof操作符来实现 使用default关键字来获取泛型的默认值 泛型的约束 默认情况下，泛型的类型参数(parameter)可以是任何类型的 如果只允许使用特定的类型参数(argument) ， 就可以指定约束 where T:base-class where T:class where T:interface where T:struct where U:T where T:new () //保证无参构造函数 泛型的约束可以作用于类型或方法的定义 泛型类型的子类 泛型class可以有子类， 在子类里，可以继续让父类的类型参数保持开放 在子类里，也可以使用具体的类型来关闭（封闭）父类的类型参数 子类型也可以引入新的类型参数 静态数据 针对每一个封闭类型， 静态数据都是唯一的 Console.WriteLine(Bob\u0026lt;int\u0026gt;.Count++); //0 Console.WriteLine(Bob\u0026lt;int\u0026gt;.Count++); //1 Console.WriteLine(Bob\u0026lt;object\u0026gt;.Count++); //0 class Bob\u0026lt;T\u0026gt; { public static int Count; } 参数类型和转换 使用 arg as int这样的操作符 或者使用 (int)(object) x 操作符 第四章 委托、事件、lambda表达式 delegate委托 委托是一个对象，他知道如何调用一个方法 委托类型定义了委托实例可以调用的那类方法，具体来说，委托类型定义了方法的返回类型和参数 class Program { static void Main(string[] args) { //第一种推荐 Transformer transformer1 = Square; var i = transformer1(3); //第二种，自己琢磨出来的不推荐 Transformer transformer = new Transformer(Square); var invoke = transformer.Invoke(2); Console.WriteLine(invoke); } delegate int Transformer(int x); static int Square(int x) =\u0026gt; x * x; 委托实例 委托的实例其实就是调用者的委托：调用者调用委托，然后委托调用目标方法 间接的吧调用者和目标方法解耦了 编写插件式的方法 方法是在运行时才赋值给委托变量的 var transformer = new Transformer(Square); var ints = new int[]{1,2,3}; Util.Transform(ints, transformer); foreach (var i in ints) { Console.WriteLine(i); } } public delegate int Transformer(int x); class Util { public static void Transform(int[] values, Transformer t) { for (int i = 0; i \u0026lt; values.Length; i++) { values[i] = t(values[i]); } } } static int Square(int x) =\u0026gt; x * x; } 实现解绑，是在编写程序的时候，才决定我要给这个委托实例一个可供调用的方法，这个方法可以是square平方，也可以是三次方，这取决于需求方，因此解耦之后你可以编写插件式的方法，最后让需求实现者自己来决定要实例化何种方法委托\n多播委托 所有的委托实例都具有多播的能力。一个委托实例可以引用一组目标方法。 使用+和+=操作符可以合并委托实例 delegateDemo1 delegateDemo = null; delegateDemo += Square1; delegateDemo += Cube1; delegateDemo(3); delegateDemo -= Cube1; delegateDemo(3); static void Square1(int x) =\u0026gt; Console.WriteLine(x * x); static void Cube1(int x) =\u0026gt; Console.WriteLine(x *x* x); delegate void delegateDemo1(int i); 调用d就会调用你添加进去的1和2方法，委托的调用顺序与他们定义的顺序是一致的\n用-和-=会把右边的委托从左边的委托里移除\n委托变量使用+或+=操作符时，其操作数可以是null。就相当于把一个新的值赋给了委托变量。\n对于单个目标方法的委托变量使用-=操作符时，就相当于把null值赋给了委托变量\nvar transformer = new Transformer(Square); transformer += Cube; var ints = new int[]{1,2,3}; Util.Transform(ints, transformer); foreach (var i in ints) { Console.WriteLine(i); } } public delegate int Transformer(int x); class Util { public static void Transform(int[] values, Transformer t) { for (int i = 0; i \u0026lt; values.Length; i++) { values[i] = t(values[i]); } } } static int Square(int x) =\u0026gt; x * x; static int Cube(int x) =\u0026gt; x * x * x; 委托是不可变的 使用+=或-=操作符时，实际上是创建了新的委托实例，并把它赋给当前的委托变量 如果多播委托的返回值类型不是void，那么调用者从最后一个被调用的方法来接收返回值。前面的方法仍然会被调用，但是其返回值就被弃用了。 委托 所有的委托类型都派生于system.multicastdelegate，而它又派生于system.delegate c#会把作用于委托的+、-、+=、-+操作编译成使用system.delegate的combine和remove两个静态方法 public static void HardWork(A a) { for (int i = 0; i \u0026lt; 10; i++) { a(i*10+10+\u0026#34;%\u0026#34;); } } public static void WriteFile(string b) { System.IO.File.WriteAllText(\u0026#34;progress.txt\u0026#34;,b); } public static void console(string b) { Console.WriteLine(b); } } public delegate void A(string b); A a = Class1.console; a += Class1.WriteFile; Class1.HardWork(a); 实例方法目标和静态方法目标 target 当一个实例方法被赋值给委托对象的时候，这个委托对象不仅要保留着对方法的引用，还要保留着对方法所属实例的引用 system.delegate的target属性就代表着这个实例 如果引用的是静态方法，那么target属性就是null 泛型委托类型 委托类型可以包含泛型类型参数 public delegate T transformer (T arg) class Program { static void Main(string[] args) { Transformer\u0026lt;int\u0026gt; transformer = Square; int[] a = {1, 2, 3}; Transform(a,transformer); foreach (var i in a) { Console.WriteLine(i); } Transformer\u0026lt;string\u0026gt; transformer1 = Cw; string[] b = {\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;}; Transform(b, transformer1); foreach (var s in b) { Console.WriteLine(s); } } public delegate T Transformer\u0026lt;T\u0026gt;(T t); public static void Transform\u0026lt;T\u0026gt;(T[] values, Transformer\u0026lt;T\u0026gt; t) { for (int i = 0; i \u0026lt; values.Length; i++) { values[i]=t(values[i]); } } static int Square(int a) =\u0026gt; a * a; static string Cw(string a) =\u0026gt; (a+\u0026#34;CW\u0026#34;); } Func和Action委托 使用泛型委托，就可以写出这样一组委托类型，他们可以调用的方法可以拥有任意的返回类型和任意（合理）数量的参数 System命名空间 image-20210127163836922\rimage-20210127163930536\rFunc\u0026lt;\u0026gt;可以有多个输入参数，0个也行，一个输出参数\nclass Program { static void Main(string[] args) { // Transformer\u0026lt;int\u0026gt; transformer = Square; int[] a = {1, 2, 3}; Transform(a, Square); foreach (var i in a) { Console.WriteLine(i); } // Transformer\u0026lt;string\u0026gt; transformer1 = Cw; string[] b = {\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;}; Transform(b, Cw); foreach (var s in b) { Console.WriteLine(s); } } // public delegate T Transformer\u0026lt;T\u0026gt;(T t); public static void Transform\u0026lt;T\u0026gt;(T[] values, Func\u0026lt;T,T\u0026gt; t) { for (int i = 0; i \u0026lt; values.Length; i++) { values[i] = t(values[i]); } } static int Square(int a) =\u0026gt; a * a; static string Cw(string a) =\u0026gt; (a + \u0026#34;CW\u0026#34;); } 个人理解：委托就是把方法作为参数来调用，传来传去呀什么的思密达\nAction\u0026lt;\u0026gt;可以有多个输入参数，0个也行，但是没有输出参数\nclass Program { static void Main(string[] args) { int[] a = new int[] {1, 2, 3}; Transform(a, Square); string[] b = { \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34; , \u0026#34;3\u0026#34;}; Transform(b,Cw); } static void Transform\u0026lt;T\u0026gt;(T[] values, Action\u0026lt;T\u0026gt; tAction) { for (int i = 0; i \u0026lt; values.Length; i++) { tAction(values[i]); } } static void Square(int a) =\u0026gt; Console.WriteLine(a*a); static void Cw(string b) =\u0026gt; Console.WriteLine(b + \u0026#34;CW\u0026#34;); } 委托Vs接口 委托可以解决的问题，接口都可以解决 什么情况下更适合用委托而不是接口呢？当下列条件之一满足时： 接口只能定义一个方法 需要多播能力 订阅者需要多次实现接口 没想到接口居然能作为一个方法的传入参数，我震惊\nclass Util { public static void TransformAll(int[] values, Interface1 a) { for (int i = 0; i \u0026lt; values.Length; i++) { values[i] = a.Transform(values[i]); Console.WriteLine(values[i]); } } } class Cube:Interface1 { public int Transform(int x) =\u0026gt; x * x * x; } public interface Interface1 { int Transform(int x); } Util.TransformAll(new []{1,2,3},new Cube()); 委托的兼容性–委托类型 委托类型之间互不相容，即使方法签名一样 委托的兼容性–委托实例 如果委托实例拥有相同的方法目标，那么委托实例就认为是相等的 委托的兼容性–参数 当你调用一个方法时，你提供的参数argument可以比防范的参数parameter定义更具体 委托可以接受比他的方法目标更具体的参数类型，这个叫contravariance 委托的兼容性–返回类型 调用方法时，你可以得到一个比请求的类型更具体的类型的返回结果 委托的目标方法可以返回比委托描述里更具体的类型的返回结果covariance Event事件 使用委托的时候，通常会出现两个角色，一个广播者，一个订阅者 广播和订阅 使用委托的时候，通常会出现两个角色，一个广播者，一个订阅者 广播者这个类型包含一个委托字段，广播者通过调用委托来决定什么时候进行广播 订阅者是这个方法目标的接收者，订阅者可以决定何时开始或结束监听 一个订阅者不知道和不干扰其他的订阅者 Event事件 事件就是将上述模式正式化的一个语言特性 事件是一种结构，为了实现广播者/订阅者模型，他只暴露了所需的委托特性的部分子集 事件的主要目的就是防止订阅者之间相互干扰 声明事件 最简单的声明事件的方式就是在委托前面加上event关键字 标准的事件模式 为编写事件，.net定义了一个标准的模式 system.eventargs， 一个预定义的框架类，除了静态的empty属性之外，他没有其他成员 eventargs是为事件传递信息的类的基类 为事件选择或定义委托 返回类型是void 接收两个参数，第一个参数类型是object，第二个参数类型是eventagrs的子类。第一个参数表示事件的广播者，第二个参数包含需要传递的信息 名称必须以eventhandler结尾 复习 delegate int D1(int x, int y); static void Main(string[] args) { D1 x = Sum; var i = x(1, 2); Console.WriteLine(i); var operation = Operation(1, 2, Sum); Console.WriteLine(operation); var operation1 = Operation(1, 2, new Func\u0026lt;int, int, int\u0026gt;((i1, i2) =\u0026gt; i1 + i2)); Console.WriteLine(operation1); } static int Sum(int x, int y) =\u0026gt; x + y; static int Multiply(int x, int y) =\u0026gt; x * y; static int Operation(int x, int y, Func\u0026lt;int, int, int\u0026gt; aFunc) { var func = aFunc(x, y); return func; } 针对选择的委托定义事件 在多线程场景下，你需要在测试或调用前，把委托赋给一个临时变量，来避免线程安全相关的错误 var temp = pricechanged ; if(temp!=null) temp (this , e) 在c# 6.0之后，可以这样写： priceChanged?.Invoke(this,e) 非泛型的eventhandler 当事件不携带多余信息的时候，可以使用非泛型的eventhandler委托 eventargs.empty属性 class Program { public class PriceChangedEventArgs : EventArgs { public readonly decimal LastPrice; public readonly decimal NewPrice; public PriceChangedEventArgs(decimal lastPrice, decimal newPrice) { this.LastPrice = lastPrice; this.NewPrice = newPrice; } } public class Stock { private string symbol; private decimal price; public Stock(string symbol) { this.symbol = symbol; } public event EventHandler\u0026lt;PriceChangedEventArgs\u0026gt; PriceChanged; protected virtual void OnPriceChanged(PriceChangedEventArgs e) { PriceChanged?.Invoke(this,e); } public decimal Price { get =\u0026gt; price; set { if (price==value) { return; } decimal oldPrice = price; price = value; OnPriceChanged(new PriceChangedEventArgs(oldPrice , price)); } } } static void Main(string[] args) { var stock = new Stock(\u0026#34;microsoft\u0026#34;); stock.Price = 120; stock.PriceChanged += stock_PriceChanged; stock.Price = 135; } static void stock_PriceChanged(object sender, PriceChangedEventArgs e) { if ((e.NewPrice-e.LastPrice)/e.LastPrice\u0026gt;0.1M) { Console.WriteLine(\u0026#34;Alert , 10% stock price increase ! \u0026#34;); } } } lambda表达式 lambda表达式其实就是一个用来代替委托实例的未命名的方法 编译器会把lambda表达式转化为以下二者之一： 一个委托实例 一个表达式树（expression tree） ， 类型是expression，他表示了可遍历的对象模型中lambda表达式里面的代码。他允许lambda表达式延迟到运行时再被解释 class Program { static void Main(string[] args) { D1 d1 = x=\u0026gt;x*x; var i = d1(3); Console.WriteLine(i); var operation = Operation(3, Multiply); Console.WriteLine(operation); Console.ReadKey(); } static int Operation(int x, Func\u0026lt;int, int\u0026gt; func) =\u0026gt; func(x); delegate int D1(int a); static int Multiply(int x) =\u0026gt; x * x; } lambda表达式的形式 (parameters)=\u0026gt;expression -or- statement -block （参数）=\u0026gt;表达式或语句块 其中如果只有一个参数并且类型可以推断的话，那么参数的小括号可以省略 lambda表达式与委托 每个lambda表达式的参数对应委托的参数 表达式的类型对应委托的返回类型 class Program { static void Main(string[] args) { D1 d1 = x=\u0026gt;x*x; var i = d1(3); Console.WriteLine(i); var operation = Operation(3, Multiply); Console.WriteLine(operation); Func\u0026lt;int, int\u0026gt; func = (a) =\u0026gt; a * a; func(1); Func\u0026lt;string, string, int\u0026gt; function = (str1, str2) =\u0026gt; { return str1.Length + str2.Length; }; Func\u0026lt;string, string, int\u0026gt; function1 = (str1, str2) =\u0026gt; str1.Length + str2.Length; Console.WriteLine( function(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;)); Console.WriteLine( function1(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;)); } static int Operation(int x, Func\u0026lt;int, int\u0026gt; func) =\u0026gt; func(x); delegate int D1(int a); static int Multiply(int x) =\u0026gt; x * x; } 如果不用{}那么就不需要return关键字 ，如果用了{}那么就要使用return关键字，且内部还要加封号；\n显式指定lambda表达式的参数类型 捕获外部变量 lambda表达式可以引用本地的变量和所在方法的参数 被lambda表达式引用的外部变量叫做被捕获的变量（captured variables） 捕获了外部变量的lambda表达式叫做闭包 被捕获的变量是在委托被实际调用的时候才被计算，而不是在捕获的时候 int factor = 2; Func\u0026lt;int, int\u0026gt; func = x =\u0026gt; x * factor; factor = 10; var i = func(3); Console.WriteLine(i); 被捕获的变量的生命周期会被延长到和委托一样 lambda表达式内的本地变量 在lambda表达式内实例化的本地变量对于委托实例的每次调用来说都是唯一的 lambda表达式vs本地方法 本地方式是c#7的新特性 。 他和lambda表达式在功能上有很多重复之处，但他又三个优点： 简单明了进行递归 无需指定委托类型 性能开销略低一点 本地方法效率更高是因为它避免了委托的间接调用。本地方法也可以访问所在方法的本地变量，而且无需编译器把被捕获的变量hoist到隐藏的类 匿名方法vslambda表达式 匿名方法和lambda表达式很像，但是缺少以下三个特性 隐式类型参数 表达式语法（只能是语句块） 编译表达式树的能力，通过赋值给expression 第五章 进阶特性 try-catch-finnally catch可以设置捕获不同类型的异常，如果没有异常类型匹配的，可能就程序报错了 如果你希望有一个兜底的catch可以捕获任何类型的异常，那么你需要把待定类型的异常捕获放在靠前的位置 从c#6 开始，你可以在catch子句中添加一个when子句来指定一个异常过滤器 try { } catch (Exception e)when(e.StackTrace==\u0026#34;\u0026#34;) { Console.WriteLine(e); throw; } finally块 finally块永远都会被执行，无论是否跑出异常 唯一可以让他不执行就是无限执行，或者中断 using语句 很多类都封装了非托管资源，都实现了disposable接口，这个接口定义了一个无参的dispose方法来清理这些资源 using语句提供了一个优雅的语法来在finally块里调用实现了idisposable接口对象上的dispose方法 抛出异常 c# 7 中，throw new Exception 可以作为expression-bodied functions里的一个表达式出现 也可以出现在三元条件表达式里 重新抛出异常 如果使用rhrow ex代替throw的话，程序仍然可以运行 其他常见的情景是抛出一个更为具体的异常类型 如果把原异常的ex传入第二个异常类型作为参数，利于调试，但可能出现信息泄露 System.exception 的关键属性 stacktrace 他是一个字符串，展现了从异常发生地到catch块所有的被调用的方法 message 关于错误的描述信息 innerexception 引起外层异常的内层异常（如果存在的话）而且innerException本身还有可能含有innerexception 常见的异常类型 system.argumentexception system.argumentnullexception system.argumentoutofrangeexception system.invalidoperationexception system.notsuppostedexception system.notimplementedexception system.oubjecdisposedexception nullreferenceexception 你也可以直接throw null ，来抛出此类型异常 try xxx模式 如果解析失败 ， parse方法会抛出异常，而tryparse方法会返回false 枚举器 枚举器是一个只读的，作用于一序列值的、只能向前的游标 枚举器是一个实现了下列任意一个接口的对象： system.collections.ienumrator system.collections.generic.IEnumerator 技术上来说，任何一个含有名为movenext方法和名为current的属性的对象，都会被当做枚举器来对待 foreach语句会迭代可枚举的对象enumerable object 。可枚举的对象是一序列值的逻辑标识。它本身不是游标，它是一个可以基于本身产生的游标的对象。 可枚举对象 enumerable object 一个可枚举对象可以是（下列任意一个） 实现了ienumerable或者ienumerable的对象 有一个名为getenumerator的方法，并且该方法返回一个枚举器emunerator IEumrator和IEnumerable是定义在system.collections命名空间下的 IEnumerator和IEnumerable是定义在system.collections.generic命名空间下的 集合初始化器 要求可枚举对象实现了system.collections.ienumerable接口，并且他还有一个可接受适当参数的add方法 迭代器iterators foreach是枚举器（enumerator）的消费者，而迭代器（iterators）是枚举器的生产者 foreach (var VARIABLE in Foo()) { Console.WriteLine(VARIABLE); } static IEnumerable\u0026lt;string\u0026gt; Foo() { yield return \u0026#34;one\u0026#34;; yield return \u0026#34;two\u0026#34;; yield return \u0026#34;Three\u0026#34;; } yield break yield break 语句表示迭代器块会提前退出，不在返回更多的元素 return语句在迭代器块里面是非法的，你必须使用yield break代替 var enumerable = Foo(false); foreach (var VARIABLE in enumerable) { Console.WriteLine(VARIABLE); } static IEnumerable\u0026lt;string\u0026gt; Foo(bool breakEarly) { yield return \u0026#34;one\u0026#34;; yield return \u0026#34;two\u0026#34;; if (breakEarly) { yield break; } yield return \u0026#34;Three\u0026#34;; } 迭代器和try/catch/finally块 yield return 语句不可以出现在含有catch子句的try里面 yield return 也不能出现在catch或者finally块里面 但是yield return 可以出现在只含有finally块的try块里面 当消费者的枚举器到达序列终点或被disposed的时候，finally块里面的代码会被执行 如果你提前进行了break，那么foreach语句也会dispose掉枚举器，所以用起来很安全 var enumerator = Foo(false).GetEnumerator(); if (enumerator.MoveNext()) { var enumeratorCurrent = enumerator.Current; } while (enumerator.MoveNext()) { Console.WriteLine(enumerator.Current); } static IEnumerable\u0026lt;string\u0026gt; Foo(bool breakEarly) { yield return \u0026#34;one\u0026#34;; yield return \u0026#34;two\u0026#34;; if (breakEarly) { yield break; } yield return \u0026#34;Three\u0026#34;; } 通过movenext的true或false确定是否可以枚举到下一个，如果可以，通过拿到current，进而拿到里面的值，如果用foreach就可以忽略什么current，movenext操作，因为他是一种高阶的写法\n可空值类型 nullable 可空结构体 struct hasvalue getvalueordefault() 和 getvalueordefault(T defaultvalue) object里面定义的equal（object）和gethashcode（）这两个方法也被响应的重写了，首先会比较hasvalue属性的值，如果两个被比较对象的hasvalue属性都是true ， 那么然后就会比较value属性的相等性 可空类型的装箱和拆箱boxing and unboxing nullable values 当T？被装箱后，在堆内存上被装箱的值会包含T，而不是T？ 因为被装箱之后的值本身就是一个引用类型，而引用 类型是可以表示null值的 c#也允许对可空类型进行拆箱操作，这里就需要使用as运算符。如果拆箱转换失败，那么得到的结果就是null，不会抛出异常 null对于可空值类型的定义 null有两种含义 null引用 可空值类型hasvalue为false时的值 下面这两种写法是等价的 运算符提升 就是可以比较两个可空值类型的\u0026gt;\u0026lt;== 前提都是hasvalue为true时才开始判断，否则返回的结果要不是null就是false ？？ 在可空值类型上使用？？运算符，就相当于调用了getvalueordefault方法，并且为这个方法提供了显式的默认值作为参数。当然，有一点不同是：如果变量不是null，那么默认值那部分的表达式就不会被执行\nint? b = null; int a = b ?? 4; Console.WriteLine(a); 可空类型和as运算符 as转化不了的话返回null\n扩展方法 扩展方法允许我们使用新的方法来扩展现有的类型，而且无需修改原有的类型的定义 扩展方法是静态类的一个静态方法，在静态方法里的第一个参数使用this修饰符，第一个参数的类型就是要被扩展的类型 static class StringHelper { public static bool IsCapitalized(this string s) { if (string.IsNullOrEmpty(s)) { return false; } return char.IsUpper(s[0]); } } string stra = \u0026#34;Ok\u0026#34;; var isCapitalized = stra.IsCapitalized(); Console.WriteLine(isCapitalized); 接口也可以被扩展 扩展方法链 扩展方法和实例方法一样，也提供了一种整洁的方式来进行链式调用 前提是他们返回值类型和另一个的传入参数的类型是一致的 歧义和解析 命名空间 只有所在类处于作用范围内的扩展方法才可以被访问， 典型的做法是引入命名空间 如果这里不引入，编译时就会报错 歧义和解析 扩展方法vs实例方法 兼容的实例方法的优先级总是高于扩展方法的 这种情况下，唯一能调用扩展方法的心事就是使用静态调用的语法，也就是类名.方法 歧义和解析 扩展方法vs扩展方法 如果两个扩展方法拥有相同的签名，那么扩展方法必须像常规静态方法那样调用以避免歧义，而如果其中一个扩展方法的参数类型更具体，那么这个方法的优先级就会更高 注意：类和结构体被认为比接口更加具体 什么是匿名类型 匿名类型就是由编译器及时创建的一个class ， 它用来存储一组数据 创建匿名类型：new + object 初始化器，并指定属性及其值 static void Main(string[] args) { string name = \u0026#34;ljs\u0026#34;; int age = 23; string school = \u0026#34;hfut\u0026#34;; var foo = new {name , age , school}; Console.WriteLine(foo.name); } 使用var关键字来引用匿名类，因为匿名类型没有名字 匿名类型的名称可以通过本身就是标识符/以标识符结尾的表达式推断出来 在同一个assembly下声明的两个匿名类实例，如果他们的元素名和类型都完全一致，那么他们的基础类型underlying type 就是一样的 equals方法被重写来进行相等性比较 比较值是否相等 可以创建匿名类型数组 方法不可以返回匿名类型的对象，必须使用dynamic或者object ，调用时依赖动态绑定，并且会损失静态类型的安全性 dynamic foo1 = new[] { new {Name = \u0026#34;ljs\u0026#34; , Age = 23 } , new {Name = \u0026#34;jwt\u0026#34; , Age = 23} , }; 匿名类型主要用来写linq查询 var foo1 = new[] { new {Name = \u0026#34;ljs\u0026#34; , Age = 23 } , new {Name = \u0026#34;jwt\u0026#34; , Age = 23} , }; foreach (var VARIABLE in foo1) { Console.WriteLine(VARIABLE.Name); } Tuple的意义 tuple提供了简单的方式来存储一组数据 使用tuple的主要目的是从方法安全的返回多个值，而且无序使用out参数 c# 7 的tuple主要依赖于一组支撑他的struct 创建tuple 创建tuple字面值最简单的方式就是在小括号里列出所有的值 通过xx.item1和xx.item2来引用tuple里面的未命名元素 static void Main(string[] args) { var tuple = (\u0026#34;ljs\u0026#34;, 20); Console.WriteLine(tuple.Item1); var tuple1 = tuple; tuple1.Item1 = \u0026#34;sbjwt\u0026#34;; Console.WriteLine(tuple); Console.WriteLine(tuple1); } tuple是值类型， 其元素是可变的可读写 你可以明确的指定tuple的类型 只需要在小括号里面列出每个元素的类型即可 可以从方法里返回tuple类型 static void Main(string[] args) { var tuple = (\u0026#34;ljs\u0026#34;, 20); Console.WriteLine(tuple.Item1); var tuple1 = tuple; tuple1.Item1 = \u0026#34;sbjwt\u0026#34;; Console.WriteLine(tuple); Console.WriteLine(tuple1); (int, string) tuple2 = (23, \u0026#34;hfut\u0026#34;); CWtupleByDelegate(23,\u0026#34;hfut\u0026#34;,sum); void CWtupleByDelegate(int a , string b , Action\u0026lt;int ,string \u0026gt; func) =\u0026gt; func(a, b); CWtupleByDelegate1(new Tuple\u0026lt;int, string\u0026gt;(23,\u0026#34;htuf\u0026#34;), sumTuple); void CWtupleByDelegate1(Tuple\u0026lt;int,string\u0026gt; aTuple , Action\u0026lt;Tuple\u0026lt;int,string\u0026gt;\u0026gt; func) =\u0026gt; func(aTuple); } static void sum(int a, string b) =\u0026gt; Console.WriteLine(a + b); static void sumTuple(Tuple\u0026lt;int, string\u0026gt; tuple) =\u0026gt; Console.WriteLine(tuple.Item1+tuple.Item2); } tuple可以和泛型很好的共存\nTask\u0026lt;(string, int)\u0026gt; a; Dictionary\u0026lt;(string, int),bool\u0026gt; b; IEnumerable\u0026lt;(int id, string name)\u0026gt; c; 给tuple元素命名 在创建tuple字面值的时候，你可以给元素起一个有意义的名字 var t1 = (name: \u0026#34;ljs\u0026#34;, age: 23); Console.WriteLine(t1.name); Console.WriteLine(t1.age); (string Name, int Age) t2 = (\u0026#34;jwt\u0026#34;, 12); Console.WriteLine(t2.Name); Console.WriteLine(t2.Age); 在指定tuple类型的时候，也可以给元素起名 仍然可以通过item1，item来引用元素 如果两个tuple元素类型、顺序都一直，那么两个tuple的类型就是兼容的 valuetuple.create 可以使用valueTuple(非泛型)类型上的工厂方法来创建tuple 命名元素不可以通过这种方式创建，因为元素命名依赖于编译器的一些骚操作 var valueTuple = ValueTuple.Create(\u0026#34;Bob\u0026#34;,23); (string,int) bobTuple = ValueTuple.Create(\u0026#34;Bob\u0026#34;,23); Deconstructing Tuples tuple隐式的支持deconstructing模式，你可以很简单的将tuple deconstruct为多个变量 var valueTuple = ValueTuple.Create(\u0026#34;Bob\u0026#34;,23); (string, int) bobTuple = ValueTuple.Create(\u0026#34;Bob\u0026#34;, 23); (string name, int age) = valueTuple; (string name1, int age1) = (\u0026#34;Bob\u0026#34;, 23); Console.WriteLine(name); Console.WriteLine(age); Console.WriteLine(name1); Console.WriteLine(age1); 相等性比较 valuetuple\u0026lt;\u0026gt;也重写了equals方法，让比较更有意义 通过例子可以看出，tuple可以作为dictionary的key tuple也实现了icomparable接口，所以tuple也可以作为排序的key Attribute attribute是一种扩展机制，他可以为代码元素添加自定义的信息 assembly ，类型、成员、返回值、参数、泛型参数 一个很好的应用场景就是序列化 把任意一个对象转化为特定格式/从特定格式转化过来 Attribute Class 一个attribute是通过一个继承了system.attribute的类来定义的 好像就是注解 ，应用于代码元素 按约定，所有的attribute都应该以attribute都应该以attribute这个单词结尾，但是c#会识别这个后缀，并且允许你附加attribute的时候忽略这个后缀 命名和位置attribute参数 attrubute可以有参数 attribute的参数可以分为两类：位置的和命名的 位置参数对应attribute类型的公共构造函数的参数 命名参数对应attribute类型的公共字段或公共属性 当指定attribute的时候，必须包含与attribute相应构造函数所对应的位置参数，而命名参数是可选的 Attribute的目标 没有明确指定的情况下，attribute的目标就是紧随他的代码元素，通常是一个类型或类型的成员 也可以把attribute附加到一个assembly，这就需要显式指定attribute的目标 指定多个attribute 对一个代码元素可以指定多个attribute。每个attribute可以列在同一个中括号内（使用逗号分开） ， 也可以独占一个中括号 Caller Info Attribute 从c# 5.0开始，你可以使用下列三个caller info attributes 之一对可选参数进行标记 [callermembername] 标识调用者成员的名称 [callerfilepath] 表示调用者源代码的路径 [callerLineNumber] 表示调用者在源码文件里面的行号 class Program { static void Main(string[] args) =\u0026gt; Foo(); static void Foo( [CallerMemberName] string memberName = null , [CallerFilePath] string filePath = null , [CallerLineNumber] int lineNumber = 0 ) { Console.WriteLine(memberName); Console.WriteLine(filePath); Console.WriteLine(lineNumber); } } 动态绑定 dynamic binding 静态绑定vs动态绑定 静态绑定：通常来讲，引用在编译时就可以解析出来 动态绑定：把解析类型、成员、操作的过程从编译时延迟到运行时 通常用于：你知道某个函数、成员、操作存在，但是编译器不知道 dynamic类型 dynamic类型使用上下文关键字dynamic来声明 因为d是dynamic的，编译器就会把quack方法绑定到d的这个动作延迟到运行时 静态绑定 编译器在duck上寻找一个名叫quack的无参方法 否则就扩大搜索范围，含有可选参数的quack方法 父类上的方法 扩展方法 dynamic dynamic类型和object类型很像，但是它允许你使用在编译时还不知道的方式来操作 dynamic类型在运行时基于运行时的类型进行绑定，而不是编译时的类型 在运行时： 如果dynamic对象实现了idynamicmetaobjectprovider,那么该接口就用来执行绑定。这叫做自定义绑定 否则，绑定发生的方式和编译器已经知道dynamic对象运行时类型一样，这叫做语言绑定 动态绑定 动态绑定确实规避了静态的类型检查，但是没有规避运行时的类型检查 与反射不一样，使用动态绑定，你无法规避成员的访问规则 动态绑定也会引起心更能问题 但是重复调用同样的动态表达式是有优化的 RunTimeBinderException 如果成员无法进行绑定，那么就会抛出runtimebinderException 动态转换 dynamic类型可以隐式的从其他类型转换过来，也可以隐式的转换到其他类型 var vs dynamic var：让编译器编译时推断出类型 dynamic：让运行时推断出类型 动态表达式 字段、属性、方法、事件、构造函数、索引器、运算符和转换都可以动态的调用 使用void返回类型来消费动态表达式的结果是不可以的，这点和静态的表达式一样 区别是，这个错误会发生在运行时 涉及动态运算对象的表达式就是动态表达式，缺失类型信息是有级联效果的 无法动态调用的函数 有一些函数不可以被动态调用 扩展方法 接口的成员 被子类隐藏的基类成员 因为动态绑定需要两方面的信息 被调用函数的名字 调用函数的对象 这三种情况，都需要额外的类型，并且他只是在编译时知晓了，运行时就丢失了 运算符重载 运算符可以被重载，可以为自定义类型提供更自然的语法 使用implict explicit 关键字 隐式/显式转换 运算符函数 通过声明运算符函数，就可以对运算符进行重载 运算符函数有一下规则 函数名：使用operator关键字，后边跟着运算符的符号 必须是static和public 函数的参数代表着运算符的运算数 函数的结果代表表达式的结果 至少有一个运算数的类型必须是函数所声明的类型 class Program { static void Main(string[] args) { var B = new Note(2); var CShrap = B + 2; Console.WriteLine(CShrap.value); } public struct Note { public int value; public Note(int semitonesFormA) { value = semitonesFormA; } public static Note operator +(Note x, int semitones)=\u0026gt;new Note(x.value+semitones); } } 重载相等性和比较运算符 重载相等性和比较运算符的时候有一些规则 成对重载 equals和gethashcode 大多数情况下，如果你重载了！=和== ， 你通常需要重载equals和gethashcode这两个方法，这样才能得到比较有意义的行为 如果你不这样做，会给一个警告 icomparable和icomparable 如果你重载了\u0026lt;\u0026gt;和\u0026lt;= \u0026gt;=运算符，那么你就应该事先icomparable和icomparable这两个接口 自定义隐式和显式转换 隐式和显示转换是可重载的运算符 自定义转换会被as和is运算符忽略 class Program { static void Main(string[] args) { var B = new Note(2); var CShrap = B + 2; Console.WriteLine(CShrap.value); var cShrap = (double)CShrap; Console.WriteLine(cShrap); int a = 4; var note = (Note)a; Console.WriteLine(note.value); } public struct Note { public int value; public Note(int semitonesFormA) { value = semitonesFormA; } public static Note operator +(Note x, int semitones) =\u0026gt; new Note(x.value + semitones); public static implicit operator double(Note x) =\u0026gt; x.value; public static explicit operator Note (double x)=\u0026gt;new Note((int)x); } } 重载true和false 不安全代码\nfixed语句\n第六章 异步编程 什么是线程 thread 线程是一个可执行路径，他可以独立于其他线程执行 每个线程都在操作系统的进程process内执行，而操作系统进程提供了程序运行的独立环境 单线程应用，在进程的独立环境里只跑一个线程，所以该线程拥有独占权 多线程应用， 单个进程中会跑多个线程，它们会共享当前的执行环境（尤其是内存） 例如，一个线程在后台读取数据，另一个线程在数据到达后进行展示 这个数据就被称作共享的状态 例子\n在单核计算机中 ， 操作系统必须为每个线程分配“时间片”（在windows中通常为20ms）来模拟并发，从而导致重复的x块和y块 在多核或多处理器计算机上，这两个线程可以真正地并行执行（可能受到计算机上其他活动进程的竞争） 在本例中，由于控制台处理并发请求的机制的微妙性，仍然会得到重复的x块和y块 static void Main(string[] args) { Thread t = new Thread(WriteY); //开辟了一个新的线程 thread t.Name = \u0026#34;Y Thread ...\u0026#34;; t.Start(); //运行 writeY //同时主线程也做一些工作 for (int i = 0; i \u0026lt; 1000; i++) { Console.Write(\u0026#34;x\u0026#34;); } } static void WriteY() { for (int i = 0; i \u0026lt; 1000; i++) { Console.Write(\u0026#34;y\u0026#34;); } } } 术语：线程被抢占了 线程在这个时候就可以称之为被抢占了： 他的执行与另一个线程上代码的执行交织的那一点 线程的一些属性 一旦开始执行，isalive就是true，线程结束就是false 线程结束的条件就是：线程构造函数传入的委托结束了执行 线程一旦结束，就无法再重启了 每个线程都有个name属性，通常用于调试 线程name只能设置一次，以后更改就会抛出异常 静态的thread.currentthread属性，会返回当前执行的线程 join and sleep 调用join方法，就可以等待另一个线程结束 例子 private static Thread thread1, thread2; static void Main(string[] args) { thread1 = new Thread(ThreadProc); thread1.Name = \u0026#34;Thread1\u0026#34;; thread1.Start(); thread2 = new Thread(ThreadProc); thread2.Name = \u0026#34;Thread2\u0026#34;; thread2.Start(); } private static void ThreadProc() { Console.WriteLine(\u0026#34;\\n Current thread :{0}\u0026#34; , Thread.CurrentThread.Name); if (Thread.CurrentThread.Name==\u0026#34;Thread1\u0026#34;\u0026amp;\u0026amp;thread2.ThreadState!=ThreadState.Unstarted) { thread2.Join(); } Thread.Sleep(4000); Console.WriteLine(\u0026#34;\\n current Thread :{0}\u0026#34;, Thread.CurrentThread.Name); Console.WriteLine(\u0026#34;Thread1: {0}\u0026#34;,thread1.ThreadState); Console.WriteLine(\u0026#34;Thread2: {0}\\n\u0026#34;,thread2.ThreadState); } 添加超时 调用join的时候，可以设置一个超时，用毫秒或者timespan都可以 如果返回true就是ok了，如果false就是超时了 static TimeSpan waitTime = new TimeSpan(0,0,1); static void Main(string[] args) { var newThread = new Thread(Work); newThread.Start(); if (newThread.Join(waitTime/2)) { Console.WriteLine(\u0026#34;New Thread terminated\u0026#34;); } else { Console.WriteLine(\u0026#34;Join timed out\u0026#34;); } } static void Work() { Thread.Sleep(waitTime); } thread.sleep()方法会暂停当前的线程，并等待一段时间 注意 thread.sleep(0)这样调用会导致线程立即放弃本身当前的时间片，自动将cup移交给其他线程 thread.yield()做同样的事情，但是它只会把执行交给同一个处理器上的其他线程 当等待sleep或join的时候，线程处于阻塞状态 阻塞 如果线程的执行由于某种原因导致暂停，那么就认为该线程被阻塞了。 例如在sleep或者通过join等待其他线程结束 被阻塞的线程会立即将其处理器的时间片生成给其他线程 ，从此就不在消耗处理器时间，直到满足其阻塞线程条件为止 可以通过threadstate这个属性来判断线程是否处于被阻塞的状态 threadstate 但是它大部分的枚举值都没什么用，下面的代码将threadstate剥离成四个最有用的值之一：unstarted / running / waitsleepingjoin / stopped 解除阻塞 unblocking 当遇到下列四种情况的时候，就会解除阻塞 阻塞条件被满足 操作超时（如果设置超时的话） 通过thread.Interrupt()进行打断 通过thread.abort()进行中止 上下文切换 当线程阻塞或解除阻塞的时，操作系统将执行上下文切换。这会产生少量开销，通常为1-2微妙 i/o-bound 和 compute-bound 一个花费大部分时间等待某事发生的操作成为i/o bound i/o绑定操作通常涉及输入或输出， 但这不是硬性要求：thread.sleep()也被视为 i /o -bound 相反，一个花费大部分时间执行cpu密集型工作的操作称为compute-bound 阻塞 vs 忙等待（自旋） blocking vs spinning i/o - bound 操作的工作方式有两种 在当前线程上同步的等待 console.readline() , thread.sleep() , thread.join() 异步的操作， 在稍后操作完成时触发一个回调动作 同步等待的i/o-bound 操作将大部分时间花在阻塞线程上 本地和共享的状态 local本地独立 clr为每个线程分配自己的内存栈，以便使本地变量保持独立 new Thread(Go1).Start(); Go1(); } private static void Go1() { for (int cycle = 0; cycle \u0026lt; 5; cycle++) { Console.WriteLine(\u0026#34;?\u0026#34;); } } shared 共享\n如果多个线程都引用同一个对象的实例，那么他们就共享了数据 var threadTest = new ThreadTest(); var thread = new Thread(threadTest.Go); thread.Name = \u0026#34;new thread\u0026#34;; thread.Start(); Console.WriteLine(Thread.CurrentThread.Name); threadTest.Go(); Console.WriteLine(Thread.CurrentThread.Name); public class ThreadTest { public bool _done=false; public void Go() { if (!_done) { _done = true; Console.WriteLine(\u0026#34;Done\u0026#34;); } } } 被lambda表达式或匿名委托所捕获的本地变量， 会被编译器转化成字段field， 所以也会被共享. bool done = false; //这里是声明了方法 ThreadStart action = () =\u0026gt; { if (!done) { done = true; Console.WriteLine(\u0026#34;Done\u0026#34;); } }; new Thread(action).Start(); action(); 静态字段也会在线程间共享数据field 上述情况就可能导致线程的不安全：即可能相同的操作被执行了多次\n线程安全 thread safety 尽可能避免使用共享状态 锁定与线程安全 简介 locking \u0026amp; thread safety 在读取和写入共享数据的时候，通过使用一个互斥锁exclusive lock，就可以修复前面的问题 c# 使用lock语句来加锁 当两个线程同时竞争一个锁的时候（锁可以基于任何引用类型对象），一个线程会等待或阻塞，直到锁变成可用状态 lock不是线程安全的银弹， 很容易忘记对字段加锁，lock也会引起一些问题（死锁） class ThreadSafe { private static bool _done; static readonly object _locker = new object(); static void Main() { new Thread(Go).Start(); Go(); } static void Go() { lock (_locker) { if (!_done) { Console.WriteLine(\u0026#34;done\u0026#34;); _done = true; } } } } 向线程传递数据 如果你想往线程的启动方法里传递数据，最简单的方式是使用lambda表达式，在里面使用参数调用方法 static void Main(string[] args) { new Thread(() =\u0026gt; Print(\u0026#34;hello asyncprogramming\u0026#34;)).Start(); Print(\u0026#34;hello ljs\u0026#34;); } static void Print(string message) { Console.WriteLine(message); } 甚至可以把整个逻辑都放在lambda里 static void Main(string[] args) { // new Thread(() =\u0026gt; Print(\u0026#34;hello asyncprogramming\u0026#34;)).Start(); // // Print(\u0026#34;hello ljs\u0026#34;); new Thread(() =\u0026gt; { Console.WriteLine(\u0026#34;i am a good man\u0026#34;); var o = new object(); o = \u0026#34;i am a good man\u0026#34;; switch (o) { case string s: Console.WriteLine(\u0026#34;yoo this is a string\u0026#34;); break; case int i: Console.WriteLine(\u0026#34;yoo ! this is an int\u0026#34;); break; default: Console.WriteLine(\u0026#34;yoo i don\u0026#39;t know \u0026#34;); break; } }).Start(); Console.WriteLine(\u0026#34;this is main thread\u0026#34;); } 异常处理 创建线程时在作用范围内的try/catch/finally块，在线程开始执行后就与线程无关了 解决方案，在方法内部设置异常捕获策略 new Thread(()=\u0026gt;Go()).Start(); static void Go() { try { throw null; } catch (Exception e) { Console.WriteLine(e); throw; } } 在wpf、winform里，可以订阅全局异常处理事件 application.dispatcherunhandledException application.threadexception 在通过消息循环调用的程序的任何部分发生未处理的异常（这相当于应用程序处于活动状态时在主线程上运行的所有代码）后，将触发这些异常 但是非ui线程上的未处理异常，并不会触发它 任何线程有任何未处理的异常都会触发 appdomain.currentdomain.unhandledexception 前台线程和后台线程 foreground vs vackground threads 默认情况下，你手动创建的线程就是前台线程 只要有前台线程在运行，那么应用程序就会一直处于活动状态 但是后台线程却不行 一旦所有的前台线程停止，那么应用程序就停止了 任何的后台线程也会突然停止 注意：线程的前台、后台状态与他的优先级无关（所分配的执行时间） var thread = new Thread(() =\u0026gt; { Console.ReadLine(); }); if (args.Length\u0026gt;0) { thread.IsBackground = true; } thread.Start(); 进程以这种形式终止的时候，后台线程执行栈中的finally块就不会被执行了 如果想让她执行，可以在退出程序时使用join来等待后台线程，如果是你自己创建的线程的话，或者使用signal construct ， 如果是线程池的话 应用程序无法正常退出的一个常见原因是还有活跃的前台线程 线程优先级 线程的优先级Thread的priority属性，他决定了相对于操作系统中其他活跃线程所占的执行时间 优先级分为 enum threadpriority {lowest , belownormal , normal , abovenormal , highest} 提升线程优先级 提升线程优先级的时候需要特别注意，因为它可能“饿死”其他线程\n如果想让某线程thread的优先级比其他进程process中的线程thread高的话，那就必须提升进程process的优先级\n使用system.diagnostics下的process类\nusing(process p = process.getcurrentprocess()) p.priorityclass = processpriorityclass.high ; 这可以很好的用于只做少量工作且需要较低延迟的非ui线程\n对于需要大量计算的应用程序，尤其是有ui的应用程序，提高进程优先级可能会使其他进程饿死，从而降低整个计算机的速度\n信号 sinaling 有时候，你需要让某线程一直处于等待状态，直至接收到其他线程发来的通知。这就叫做signaling发送信号 最简单的信号结构就是manualresetevent 调用它上面的waitone方法会阻塞当前的线程，直到另一个线程通过调用set方法开启信号 我们可以调用reset方法将其再次关闭 var signal = new ManualResetEvent(false); new Thread(() =\u0026gt; { Console.WriteLine(\u0026#34;waiting for signal ...\u0026#34;); signal.WaitOne(); Console.WriteLine(\u0026#34;got sinal \u0026#34;); Thread.Sleep(1000); Console.WriteLine(\u0026#34;wo zai xie le\u0026#34;); signal.Dispose(); }).Start(); Thread.Sleep(3000); Console.WriteLine(\u0026#34;准备打开信号了哦\u0026#34;); Thread.Sleep(1000); signal.Set();//打开了信号 Thread.Sleep(500); signal.Reset(); Console.WriteLine(\u0026#34;我有准备打开了\u0026#34;); Thread.Sleep(1000); 富客户端应用程序的线程 在wpf、uwp、winform等类型的程序中，如果在主线程执行耗时的操作，就会导致整个程序无响应。因为主线程同时还要处理消息循环，而渲染和鼠标键盘事件处理等工作都是消息循环来执行的 针对这种耗时的操作，一种流行的做法是启用一个worker线程 执行完操作后，再更新到UI 富客户端应用的线程模型通常是： ui元素和控件只能从创建它们的线程来进行访问（通常是主ui线程） 当想从worker线程更新到ui的时候，你必须把请求交给ui线程 比较底层的实现是： 在wpf，在元素的dispatcher对象上调用begininvoke或invoke 在winform，调用控件的begininvoke或invoke 在uwp中， 调用dispatcher对象上的runasync或invoke 所有这些方法都接收一个委托 begininvoke或runasync通过将委托排队到ui线程的消息队列在执行工作 invoke执行相同的操作，但随后会进行阻塞，直到ui线程读取并处理消息。 因此，invoke允许您从方法中获取返回值 如果不需要返回值，begininvoke/runasync更可取，因为他们不会阻塞调用方，也不会引入死锁的可能性 private void Button_Click(object sender, RoutedEventArgs e) { Work();//这样用直接卡了5s整个界面 // new Thread(Work).Start();//这样用又会直接报错呜呜呜 } void Work() { Thread.Sleep(5000); textbox.Text = \u0026#34;The answer\u0026#34;; } demo wpf\nprivate void Button_Click(object sender, RoutedEventArgs e) { // Work();//这样用直接卡了5s整个界面 new Thread(Work).Start();//这样用又会直接报错呜呜呜 } void Work() { Thread.Sleep(5000);//实际上是为了模拟好多好多奇奇怪怪占用时间的逻辑操作 // textbox.Text = \u0026#34;The answer\u0026#34;; UpdateMessage(\u0026#34;The Answer is me...\u0026#34;); } void UpdateMessage(string message) { Action action = () =\u0026gt; { textbox.Text = message; }; Dispatcher.BeginInvoke(action); } winform demo\nimage-20210126105507084\rprivate void button1_Click(object sender, EventArgs e) { // Work(); //显然，这样做卡死界面了嗷嗷嗷呜呜呜 new Thread(Work).Start(); } void Work() { Thread.Sleep(5000); UpdateUIMessage(\u0026#34;ljs is shuaibi ...\u0026#34;); } void UpdateUIMessage(string message) { Action action = () =\u0026gt; { textBox1.Text = message; }; BeginInvoke(action); } 同步上下文 synchronization contexts 在system.componentmodel 下有一个抽象类：synchronizationcontext ，它使得thread marshaling 的得到泛化 啥意思嘞 就是将一个线程里数据的所有权交给另一个线程，就是把数据移交过去呗还能有啥意思啊\n针对移动、桌面（wpf、uwp、winforms）等富客户端应用的api，他们都定义和实例化了synchronizationcontext的子类\n可以通过静态属性synchronizationcontext.current来获得（当运行在ui线程时） 捕获该属性让你可以在稍后的时候从worker线程向ui线程发送数据 public SynchronizationContext _SynchronizationContext; private void button1_Click(object sender, EventArgs e) { //为当前ui线程捕获 synchronization context _SynchronizationContext =SynchronizationContext.Current; // Work(); //显然，这样做卡死界面了嗷嗷嗷呜呜呜 new Thread(Work).Start(); } void Work() { Thread.Sleep(5000);//模拟耗时操作 UpdateUIMessageMethod1(\u0026#34;ljs is a shuaibi \u0026#34;); // UpdateUIMessage(\u0026#34;ljs is shuaibi ...\u0026#34;); } void UpdateUIMessageMethod1(string message) { //把委托 marshal 给 ui 线程 _SynchronizationContext.Post(s =\u0026gt; textBox1.Text = message, null); //调用post 就相当于 dispatcher或 control 上的 begininvoke 方法 } 调用post方法就相当于调用dispatch或control上面的begininvoke方法 还有一个send方法，就等价于invoke方法 线程池 thread pool 当开始一个线程的时候，将花费几百微妙来组织类似以下内容 一个新的局部变量栈stack 线程池就可以节省这种开销 通过预先创建一个可循环使用线程的池来减少这一开销 线程池对于高效的并行编程和细粒度并发是必不可少的 他允许在不被线程启动的开销淹没的情况下运行短期操作 使用线程池线程需要注意一下几点 不可以设置池线程的名称name 池线程都是后台线程 阻塞池线程可使性能降级 你可以自由的更改池线程的优先级 当他释放回池的时候优先级将还原为正常状态 可以通过thread.currentthread.isthreadpoolthread属性来判断是否执行在池线程上 进入线程池 最简单的、显式的在池线程运行代码的方式就是使用task.run Task.Run(() =\u0026gt; { Thread.Sleep(1000); Console.WriteLine(\u0026#34;this is a threadpool ...\u0026#34;); }); Console.WriteLine(\u0026#34;hey boy! i am a cowboy !\u0026#34;); // Console.ReadKey(); Thread.Sleep(1000); 谁使用了线程池 wcf/remoting / asp.net / asmx web services 应用服务器 system.timers.times / system.threading .timer 并行编程结构 backgroundworkder类 (现在很多余) 异步委托(现在很多余) 线程池中的整洁 线程池提供了另一个功能，即确保临时超出 计算-bound 的工作不会导致cpu超额订阅 cpu超额订阅：活跃的线程超过cpu的核数，操作系统就需要对线程进行时间切片 超额订阅对性能的影响很大，时间切片需要昂贵的上下文切换，并且可能使cpu缓存失效，而cpu缓存对于现代处理器的性能至关重要 clr的策略 clr通过对任务排队并对其启动进行节流限制来避免线程池中的超额订阅 他首先运行尽可能多的并发任务（只要还有cpu核），然后通过爬山算法调整并发级别，并在特定方向上不断调整工作负载 如果吞吐量提高，它将继续朝同一个方向（否则将反转） 这确保他始终追随最佳性能曲线，即时面对计算机上竞争的进程活动时也是如此 如果下面两点能够满足，那么clr的策略将发挥出最佳效果 工作项大多是短时间运行的，（\u0026lt;250ms，或者理想情况下\u0026lt;100ms）因此clr有很多机会可进行测量和调整 大部分时间都被阻塞的工作项不会主宰线程池 thread的问题 线程thread是用来创建并发concurrency的一种低级别工具，他有一些限制，尤其是 虽然开始线程的时候可以方便的传入数据，但是当join的时候，很难从线程获得返回值。 可能需要设置一些共享字段 如果操作抛出异常，捕获和传播改异常都很麻烦 无法告诉线程在结束时开始做另外的工作，你必须进行join操作（在进程中阻塞当前的线程） 很难使用较小的并发concurrent来组建大型的并发 导致了对手动同步的更大依赖以及随之而来的问题 Task class task可以很好的解决上述的问题 task是一个相对高级的抽象，他代表了一个并发的操作concurrent 该操作可能有thread支持，可能不由thread支持 task是可组合的（可使用continuation把他们串成链） task可以使用线程池来减少启动延迟 使用taskcompletionsource，tasks可以利用回调的方式，在等待I/O绑定操作时完全避免线程 开始一个task task.run 开启一个task最简单的办法就是使用task.run这个静态方法 传入一个action委托即可 task默认使用线程池，也就是后台线程 当主线程结束的时候，你创建的所有的tasks都会结束 task.run返回一个task对象，可以使用他来监视其过程 在task.run之后，我们没有调用start，因为该方法创建的是热任务 hot task 可以通过task的构造函数创建冷任务 cold task ， 但是很少这么做 可以通过task的status属性来跟踪task的执行状态 Wait 等待 调用task的wait方法会进行阻塞直到操作完成\n相当于调用thread上的join方法 实际上，task.wait我觉得就是让主线程，或者前台线程等待我们创建出来的这个task后台线程继续执行，在这个过程中，阻塞了线程，直至task完成任务\nAction action = () =\u0026gt; { Thread.Sleep(3000); Console.WriteLine(\u0026#34;Foo\u0026#34;); }; var task = Task.Run(action); Console.WriteLine(task.IsCompleted); task.Wait(); Console.WriteLine(task.IsCompleted); wait也可以让你指定一个超时时间和一个取消令牌来提前结束等待 long-running tasks 长时间运行的任务 默认情况下，clr在线程池中运行task，这非常适合短时间运行的compute-bound类工作 针对长时间运行的任务或者阻塞操作，你可以不采用线程池 var startNew = Task.Factory.StartNew(() =\u0026gt; { Thread.Sleep(3000); Console.WriteLine(\u0026#34;Foo\u0026#34;); },TaskCreationOptions.LongRunning); Console.ReadKey(); Console.WriteLine(startNew.Status); 如果同时运行多个long-running tasks 尤其是其中有处于阻塞状态的，那么性能将会受到很大的影响，这时有比taskcreationoptions.longrunning更好的方法 如果任务是io-bound ，taskcompletionsource和异步函数可以让你用毁掉coninuations代替线程来实现并发 如果任务是compute-bound,生产者/消费者队列允许你对任务的并发性进行限流，避免把其他线程和进程饿死 task的返回值 task有一个泛型子类叫做task，他允许发出一个返回值\n使用func委托或兼容的lambda表达式来调用task.run就可以得到task\n随后，可以通过result属性来获得返回的结果\n如果这个task还没有完成操作，访问result属性会阻塞该线程直到该task完成操作 var task = Task.Run(() =\u0026gt; { Console.WriteLine(\u0026#34;Foo\u0026#34;); return 3; }); int result = task.Result; Console.WriteLine(result); task可以看作是一种所谓的“未来/许诺” future 、promise ，在它里面包裹着一个result ， 在稍后的时候就会变得可用\n在ctp版本，task实际上叫做future\ntask的异常 与thread不一样，task可以很方便的传播异常 如果你的task里面抛出了一个未处理的异常（故障）， 那么该异常就会重新被抛出给 调用了wait的地方 访问了task的result属性的地方 CLR将异常包裹在aggregateException里，以便在并行编程场景中发挥很好的作用 无需重新抛出异常，通过task的isfaulted和iscancled属性也可以检测出task是否发生了故障 如果两个属性都返回了false，那么就是没有错误发生 如果iscancled为true，那就说明一个operationCanceledException为该task抛出了 如果isfaulted为true，那就说明另一个类型的异常被抛出了，而Exception属性也将指明错误 异常与自治的task 自治的，设置完就不管了的task。就是指不通过调用wait（）方法、result属性或者continuation进行会合的任务 针对自治的task，需要像thread一样，显式的处理异常，避免发生“悄无声息”的故障 自治task上未处理的异常称为未观察到的异常 未观察到的异常 可以通过全局的taskscheduler.unobservedtaskexception来订阅未观察到的异常 关于什么是未观察到的异常，有一些细微的差别 Continuation 一个continuation会对task说 ： 当你结束的时候，继续再做点其他的事\ncontinuation通常是通过回调的方式实现的\n当操作一结束，就开始执行 在task上调用getawaiter会返回一个awaiter对象\n他的oncompleted方法会告诉之前的task：当你结束/发生故障的时候要执行委托 可以将continuation附加到已经结束的task上面，此时continuation将会被安排立即执行\nstatic void Main(string[] args) { Task\u0026lt;int\u0026gt; task = Task.Run(() =\u0026gt; Enumerable.Range(2, 3000000) .Count(n =\u0026gt; Enumerable.Range(2, (int)Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0))); var awaiter = task.GetAwaiter(); awaiter.OnCompleted(() =\u0026gt; { Console.WriteLine(awaiter.GetResult()); }); Console.ReadKey(); } 实际上，我们是否可以通过这个方式作为不阻塞主线程并最后为ui更新数据的方式呢\nawaiter 任何可以暴露下列两个方法和一个属性的对象就是awaiter oncompleted getresult iscompleted 的bool属性 没有接口或者父类来统一这些成员 其中oncompleted是inotifycompletion的一部分 private void button1_Click(object sender, EventArgs e) { Task\u0026lt;int\u0026gt; task = Task.Run(() =\u0026gt; Enumerable.Range(2, 3000000) .Count(n =\u0026gt; Enumerable.Range(2, (int)Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0))); var awaiter = task.GetAwaiter(); awaiter.OnCompleted(() =\u0026gt; { textBox1.Text = awaiter.GetResult().ToString(); }); 如果发生故障 如果之前的任务发生故障，那么当continuation代码调用awaiter.getresult的时候，异常就会被重新抛出 无需调用getresult，我们可以直接访问task的result属性 但调用getresult的好处是，如果task是发生故障了，那么异常会被直接抛出，而不是包裹在aggregateexception里面，这样的话catch块就简洁很多了 非泛型 task 针对非泛型的task，getresult方法有一个void返回值，他就是用来重新抛出异常的 同步上下文 如果同步上下文出现了，那么oncompleted会自动捕获它，并将continuation提交到这个上下文中。这一点在富客户端应用中非常有用，因为他会把continuation放回到ui线程中 如果编写的是一个库，则不希望出现上述行为，因为开销较大的ui线程切换应该在程序运行离开库的时候只发生一次，而不是出现在方法调用之间。所以，我们可以使用configureawait方法来避免这种行为 image-20210126170725006\r如果没有同步上下文出现，或者你使用的是configureawait(false)，那么continuation会运行在先前task的同一个线程上，从而避免不必要的开销 ContinueWith 另一种附加continuation的方式是调用task的continuewith方法 Task\u0026lt;int\u0026gt; task = Task.Run(() =\u0026gt; Enumerable.Range(2, 3000000) .Count(n =\u0026gt; Enumerable.Range(2, (int)Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0))); task.ContinueWith(task =\u0026gt; { int? result = task.Result; Console.WriteLine(result); }); Console.ReadKey(); continuewith本身返回一个task，他可以用他来附加更多的continuation\n但是，必须直接处理aggregateexception\n如果task发生故障，需要写额外的代码来吧continuation给封装（marshal）到ui应用上 Task\u0026lt;int\u0026gt; task = Task.Run(() =\u0026gt; Enumerable.Range(2, 3000000) .Count(n =\u0026gt; Enumerable.Range(2, (int)Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0))); task.ContinueWith(a =\u0026gt; { Console.WriteLine(a.Result); UpdateUIMessageMethod1(a.Result.ToString());//marshal过程 } ); 在非ui上下文中，若想让continuation和task执行在同一个线程上，必须指定taskcontinuationoptions.executesynchronously,否则他将弹回线程池 continuewith对于并行编程来说非常有用\ntaskCompletionSource task.run 创建task 另一种方式就是用taskcompletionsource来创建task taskcompletionsource让你在稍后开始和结束的任意操作中创建task 他会为你提供一个可手动执行的从属task 指示操作何时结束或发生故障 他对io-bound类工作比较理想 可以获得所有task的好处（传播值、异常、continuation） 不需要在操作时阻塞线程 使用taskcompletionsource 初始化一个实例即可 他有一个task属性可以返回一个task 该task完全由taskcompletionsource对象控制 调用任意一个方法都会给task发信号： 完成、故障、取消 这些方法只能调用一次，如果再次调用 set会抛出异常 try会返回false static void Main(string[] args) { var taskCompletionSource = new TaskCompletionSource\u0026lt;int\u0026gt;(); new Thread(() =\u0026gt; { Thread.Sleep(5000); taskCompletionSource.SetResult(42); }) { IsBackground = true }.Start(); var task = taskCompletionSource.Task; Console.WriteLine(task.Result); } Taskcompletionsource真正魔力 它创建task，但并不占用线程 task.delay 相当于异步版本的thread.sleep static void Main(string[] args) { Task.Delay(5000).GetAwaiter().OnCompleted(()=\u0026gt;Console.WriteLine(42)); Console.WriteLine(1); Task.Delay(5000).ContinueWith(task =\u0026gt; Console.WriteLine(42)); Console.ReadKey(); } 同步vs异步 同步操作会返回调用者之前完成它的工作 异步操作会返回调用者之后去做他的工作（大部分的） 异步的方法更为少见，会启用并发，因为它的工作会与调用者并行执行 异步方法通常很快就会返回到调用者，因此又叫非阻塞方法 目前见到的大部分的一部方法都是通用目的的 thread.start task.run 可以将continuation 附加到task的方法 异步编程 异步编程的原则是将长时间运行的函数写成异步的 传统的做法是将长时间运行的函数写成同步的，然后从新的线程或task进行调用，从而按需引入并发 上述异步方式的不同之处在于，它是从长时间运行函数的内部启动并发。这有两点好处： io-bound 并发可不使用线程来实现。可提高可扩展性和执行效率 富客户端在worker线程会使用更少的代码，简化了线程安全性 异步编程的两种用途 编写高效处理大量并发io的应用程序（典型的：服务端应用程序） 挑战并不是线程安全（因为共享状态通常是最小化的），而是执行效率 特别的，每个网络请求并不会消耗一个线程 调用图 call graph 在富客户端应用里简化线程安全 如果调用图中任何一个操作都是长时间运行的，那么整个call graph 必须运行在worker线程上，以保证ui的响应 得到一个横跨多个方法的单一并发操作（粗粒度） 需要为call graph 中的每个方法考虑线程安全 异步的call graph，直到需要才开启一个线程，通常较浅（io-bound操作完全不需要） 其他的方法可以在ui线程执行，线程安全得到简化 并发的粒度适中 一连串小的并发操作，操作之间会弹回到ui线程 经验之谈 为了获得上述好处，建议下列操作使用异步编写： io-bound和compute-bound操作 执行超过50ms的操作 另一方面过细的粒度会损害性能，因为异步操作也有开销 异步编程和continuation task非常适合异步编程，因为他们支持continuation（它对异步非常重要） taskcompletionsource是实现底层io-bound异步方法的一种标准方式 对于compute-bound方法，task.run会初始化绑定线程的并发 把task返回调用者，创建异步方法 异步编程的区别：目标是在调用图较低的位置来这样做 富客户端应用中，高级方法可以保留在ui线程和访问控制以及共享状态上，不会出现线程安全问题 // static void Main(string[] args) // { // // DisplayPrimeCounts();//同步写法 // Task.Run(DisplayPrimeCounts);//粗粒度异步写法 // Thread.Sleep(500); // Console.WriteLine(\u0026#34;lalala\u0026#34;); // Console.ReadKey(); // } static void Main(string[] args) { Task.Run(DisplayPrimeCountsAsync); Console.ReadKey(); } static void DisplayPrimeCounts() { for (int i = 0; i \u0026lt; 10; i++) { Console.WriteLine(GetPrimesCount(i * 1000000 + 2, 1000000) + \u0026#34;primes between \u0026#34; + (i + 1000000) + \u0026#34;and\u0026#34;+ ((i+1)*1000000-1)); } Console.WriteLine(\u0026#34;done!\u0026#34;); } static void DisplayPrimeCountsAsync() { for (int i = 0; i \u0026lt; 10; i++) { var taskAwaiter = GetPrimesCountAsync(i * 1000000 + 2, 1000000).GetAwaiter(); taskAwaiter.OnCompleted(() =\u0026gt; { Console.WriteLine(taskAwaiter.GetResult()+ \u0026#34;primes between \u0026#34; + (i + 1000000) + \u0026#34;and\u0026#34; + ((i + 1) * 1000000 - 1)); }); } Console.WriteLine(\u0026#34;done!\u0026#34;); } static int GetPrimesCount(int start, int count) { return ParallelEnumerable.Range(start, count) .Count(n =\u0026gt; Enumerable.Range(2, (int) Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0)); } static Task\u0026lt;int\u0026gt; GetPrimesCountAsync(int start, int count) { return Task.FromResult(ParallelEnumerable.Range(start, count) .Count(n =\u0026gt; Enumerable.Range(2, (int)Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0))); } 语言对异步的支持非常重要 需要对task的执行序列化\n例如task b 依赖于 task a 的执行结果 为此，必须在continuation内部触发下一次循环 很麻烦 因为我们决定引入 async 和await关键字\n对于不想复杂的实现异步非常重要 命令式循环结构不要和continuation混合在一起，因为他们依赖于当前本地状态\n另一个实现，函数式写法（linq查询）, 他也是响应式编程（Rx）的基础\n异步函数 async和await关键字可以让你写出和同步代码一样简洁且结构相同的异步代码 await await关键字简化了附加continuation的过程 他的作用相当于 var awaiter = expression.GetAwaiter() ; awaiter.OnCompleted(()=\u0026gt; { var result = awaiter.GetResult() ; statement(s) ; }) async修饰符 async修饰符会让编译器把await当做关键字而不是标识符（c# 5 以前可能会使用await作为标识符） async修饰符智能应用于方法（包括lambda表达式） 该方法可以返回void / task / task async修饰符对方法的签名或public元数据没有影响（和uisafe一样），他只会影响方法内部 在接口里使用async是没有意义的 使用async来重载非async方法确实合法的 使用async修饰符的方法就是异步函数 static async Task Main(string[] args) { await DisplayPrimeCountsAsync(); } static async Task DisplayPrimeCountsAsync() { for (int i = 0; i \u0026lt; 10; i++) { Console.WriteLine(await GetPrimesCountAsync(i * 1000000 + 2, 1000000) + \u0026#34;primes between \u0026#34; + (i + 1000000) + \u0026#34;and\u0026#34; + ((i + 1) * 1000000 - 1)); } Console.WriteLine(\u0026#34;Done!\u0026#34;); } static async Task\u0026lt;int\u0026gt; GetPrimesCountAsync(int start , int count) { return await Task.FromResult(ParallelEnumerable.Range(start, count) .Count(n =\u0026gt; Enumerable.Range(2, (int)Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0))); } 异步方法如何执行 遇到await表达式，执行（正常情况下）会返回调用者 就像iterator里面的yield return 在返回前，运行时会附加一个continuation到await的task 为保证task结束时，执行会跳回原方法，从停止的地方继续执行 如果发生故障，那么异常会被重新抛出 如果一切正常，那么他的返回值就会赋给await表达式 —实际上就是跟那个awaiter 和 awaiter.oncompleted 是一样的，执行完的得到返回值继续向下执行 可以await什么 await的表达式通常是一个task 也可以满足以下条件的任意对象 有getawaiter方法，返回一个awaiter 返回适当类型的getresult方法 一个bool类型的iscompleted属性 捕获本地状态 await表达式最牛的地方在于他几乎可以出现在任何地方 特别的，在异步方法内，await表达式可以替换任何表达式 除了lock表达式和unsafe上下文 await之后在哪个线程上执行 在await表达式之后，编译器依赖于continuation（通过awaiter模式）来继续执行 如果在富客户端应用的ui线程上，同步上下文会保证后续是在原线程上执行 否则，就会在task结束的线程上继续执行 private void button2_Click(object sender, EventArgs e) { // Go(); GoAsync(); } async void GoAsync() { button2.Enabled = false; for (int i = 1; i \u0026lt; 5; i++) { textBox2.Text += await GetPrimesCountAsync(i * 1000000, 1000000) + \u0026#34; primes between \u0026#34; + \u0026#34; and \u0026#34; + ((i + 1) * 1000000 - 1) + Environment.NewLine; } button2.Enabled = true; } Task\u0026lt;int\u0026gt; GetPrimesCountAsync(int start, int count) { return Task.Run(() =\u0026gt; ParallelEnumerable.Range(start, count) .Count(n =\u0026gt; Enumerable.Range(2, (int) Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0))); } UI 上的await 只有getprimescountasync是在worker线程上运行的 go中的代码会“租用”ui线程上的时间 可以说：Go是在消息循环中伪并发的执行 也就是说：它和ui线程处理的其他时间是穿插执行的 因为这种伪并发，唯一可能发生抢占的时刻就是在await期间 这其实简化了线程安全，防止重新进入即可 这种并发发生在调用栈比较浅的地方（rask.run调用的代码里） 为了从该模型中获益，真正的并发代码要避免访问共享状态或ui控件 private void button2_Click(object sender, EventArgs e) { // Go(); GoAsync(); } async void GoAsync() { button2.Enabled = false; for (int i = 1; i \u0026lt; 5; i++) { textBox2.Text += await GetPrimesCountAsync(i * 1000000, 1000000) + \u0026#34; primes between \u0026#34; + \u0026#34; and \u0026#34; + ((i + 1) * 1000000 - 1) + Environment.NewLine; } button2.Enabled = true; } Task\u0026lt;int\u0026gt; GetPrimesCountAsync(int start, int count) { return Task.Run(() =\u0026gt; ParallelEnumerable.Range(start, count) .Count(n =\u0026gt; Enumerable.Range(2, (int) Math.Sqrt(n) - 1).All(i =\u0026gt; n % i \u0026gt; 0))); } 因为在ui线程上await ， continuation将发送到同步上下文中，该同步上下文通过消息循环执行，来保证整个go方法伪并发的在ui线程上运行 和粗粒度的并发相比 整个同步调用图都在worker线程上 必须在代码中到处使用dispatcher.begininvoke 引入了race condition 循环本省在worker线程上 若实现取消或者过程报告，会使得线程安全问题更容易发生，在方法中新添加任何代码也是同样的效果 编写异步函数 对于任何异步函数，你可以使用task代替void作为返回类型，让该方法称为更有效的异步（可以进行await） static async Task Main(string[] args) { // PrintAnswerToLife(); //如果不使用异步关键字，会导致并行执行 ， 又由于是task线程池，是后台进程，前台进程执行完毕就关了，所以程序还没输出42就停了 await PrintAnswerToLife(); } static async Task PrintAnswerToLife() { await Task.Delay(5000); int answer = 21 * 2; Console.WriteLine(answer); } 并不需要在方法体中显式的返回task。编译器会生成一个task（当方法完成或者发生异常时），这使得创建异步的调用链非常方便啊 编译器会返回task的异步函数来进行扩展，使其成为当发送信号或发生故障时使用taskcompletionsource来创建task代码 因此，当返回task的异步方法结束的时候，执行就会跳回到对它进行await的地方（通过continuation） 编写异步函数在富客户端场景下 富客户端场景下，执行在此刻会跳回到ui线程（如果目前不在ui线程的话） 否则，就在continuation返回的任意线程上继续运行 这意味着，在异步调用图中向上冒泡的时候，不会发生延迟成本，除非是ui线程启动的第一次反弹 返回task 如果方法体返回tresult ， 那么异步方法就可以返回task 其原理就是给taskcompletionsource发送的信号带有值，而不是null 与同步编程很相似，是故意这样设计的 C#中如何设计异步函数 以同步的方式编写函数 使用异步调用来代替同步调用，并且进行await 除了顶层方法外（UI控件的event handler），把你的方法的返回类型升级为task或task,这样他们就可以进行await了 编译器能对异步函数生成task意味着什么 大多数情况下，你只需要在初始化io-bound并发的底层方法里显式的初始化taskcompletionsource，这种情况很少见 针对初始化compute-bound的并发方法，你可以使用task.run来创建task class Program { static async Task Main(string[] args) { await Go(); } static async Task Go() { var printAnswerToLife = PrintAnswerToLife(); await printAnswerToLife; Console.WriteLine(\u0026#34;Done!\u0026#34;); } static async Task PrintAnswerToLife() { var answerToLife = GetAnswerToLife(); var toLife = await answerToLife; Console.WriteLine(toLife); } static async Task\u0026lt;int\u0026gt; GetAnswerToLife() { var delay = Task.Delay(5000); await delay; int answer = 21 * 2; return answer; } } 异步调用图执行 整个执行与同步例子中调用图的顺序一样，因为我们对每个异步函数的调用都进行了await 在调用图中创建了一个没有并行和重叠的连续流 每个await在执行中都创建了一个间隙，在间隙后，程序可以从中断处恢复执行 private void button3_Click(object sender, EventArgs e) { Go1(); } async void Go1() { var printAnswerToLife = PrintAnswerToLife(); await printAnswerToLife; textBox3.Text = \u0026#34;Done!\u0026#34;; } async Task PrintAnswerToLife() { var answerToLife = GetAnswerToLife(); var toLife = await answerToLife; textBox3.Text = toLife.ToString(); } async Task\u0026lt;int\u0026gt; GetAnswerToLife() { var delay = Task.Delay(5000); await delay; int answer = 21 * 2; return answer; } 并行Parallelism 不适用await来调用异步函数会导致并行执行的发生 确实也能满足保持ui响应的并发要求 同样，可以并行跑两个操作 异步lambda表达式 匿名方法（包括lambda表达式），通过使用async也可以变成异步方法 static async Task Main(string[] args) { Func\u0026lt;Task\u0026gt; func = async () =\u0026gt; { await Task.Delay(1000); Console.WriteLine(\u0026#34;Foo\u0026#34;); }; await NamedMethod(); await func(); } static async Task NamedMethod() { await Task.Delay(1000); Console.WriteLine(\u0026#34;Foo1\u0026#34;); } 调用方式也是一样样的 附加 event handler 的时候也可以使用异步lambda表达式 // this.button3.Click += async (sender,args) =\u0026gt; // { // await Task.Delay(1000); // button3.Text = \u0026#34;comeon baby\u0026#34;; // }; 也可以返回task Func\u0026lt;Task\u0026lt;int\u0026gt;\u0026gt; func = async () =\u0026gt; { await Task.Delay(1000); Console.WriteLine(\u0026#34;Foo\u0026#34;); return 123; }; 发布异常 富客户端应用通常依赖于集中的异常处理事件来处理ui线程上未捕获的异常 例如wpf中的application.dispatcherunhandledexception asp.net core 中定制 exceptionfilterattribute也是差不多的效果 其内部原理就是：通过在它们自己的try/catch块来调用ui事件（在asp.net core里就是页面处理方法的管道） 顶层的异步方法会使事情更加复杂 顶层的异步方法由于已经没有方法让他进行await了，所以他会使用void 而不是task作为返回类型 在抛出异常后无法被消息循环中的catch捕获 为了缓解该问题，asyncvoidmethodbuilder会捕获未处理的异常（在返回void的异步方法里） ， 并把他们发布到同步上下文（如果出现的话），以确保全局异常处理事件能够触发 注意 编译器只会把上述逻辑应用于返回类型为void的一部方法\n如果buttonclick的返回类型是task，那么未处理的异常将导致结果task出错，然后task将无处可去（导致为观察到的异常）\n无论在await前面还是后面跑出异常，都没有区别\n如果出现同步上下文，返回值为void的异常会被发布到同步上下文中，如果没有出现，异常将会在线程池上传播，从而导致终止应用程序\noperationstarted 和 operationcompleted 如果存在同步上下文，返回void的异步函数也会进入函数时调用其operationstarted方法，在函数完成时调用其operationcompleted方法 优化同步完成 异步函数可以在await之前就返回 static async Task Main(string[] args) { Console.WriteLine(await GetWebPageAsync(\u0026#34;http://oreilly.com\u0026#34;)); } static Dictionary\u0026lt;string ,string \u0026gt; _cache = new Dictionary\u0026lt;string, string\u0026gt;(); private static async Task\u0026lt;string\u0026gt; GetWebPageAsync(string uri) { string html; if (_cache.TryGetValue(uri,out html)) { return html; } return _cache[uri] = await new WebClient().DownloadStringTaskAsync(uri); } 编译器是通过检查awaiter上的iscompleted属性来实现这个优化的，也就是说，无论何时await收到时候，都会检查\n如果是同步完成了，编译器就会释放可短路的continuation代码\n编写完全没有await的异步方法也是合法的，但是编译器会发出警告\n这类方法可以用于重载virtual/abstract方法\n另一种可以达到相同结果的方式是，使用task.fromresult，他会返回一个已经设置好信号的task\n如果从ui线程上调用，那么getwebpageasync方法是隐式线程安全的。可以连续多次调用它（从而启动多个并发下载），并且不需要lock来保护缓存\n有一种简单的方法可以实现这一点，而不必求助于lock或信令结构。我们创建一个futures （task）的缓存，而不是字符串的缓存，注意并没有async\n取消 cancellationToken 和 cancellationTokenSource 获取cancellationToken 先实例化cancellationtokensource var cancelsource = new cancellationTokensource() ; 这回暴露一个token属性，他会返回一个cancellationtoken ，所以我们可以这样调用 task foo = Foo(cancelsource.token) … … cancelsource.cancel() Delay clr里大部分异步方法都支持cancellationtoken ， 包括delay方法 其他 事实上，可以在构造cancellationtokensource时指定一个时间间隔，以便在一段时间后启动取消。它对于实现超时非常有用，无论是同步还是异步 cancellationtoken这个struct提供了一个register方法，他可以让你注册一个回调委托，这个委托会在取消时触发，它会返回一个对象，这个对象在取消注册时可以被dispose掉 进度报告 异步操作在运行当中反馈实时进度，解决办法是向异步方法中闯入一个action委托，当进度变化时触发方法调用\niprogress 和progress\nprogress的一个构造函数可以接受action类型的委托\nTask组合器 异步函数有一个让其保持一致的协议（可以一致的返回task），让其保持良好的结果，可以使用以及编写task组合器，也就是可以组合task，但是不关心task具体做什么的函数 CLR提供了两个task组合器： task.whenany task.whenall WhenAny 当一组task中任何一个task完成时，task.whenany会返回完成的task 因为task.whenany本身就返回一个task，我们对他进行await，就会返回最先完成的task 事实上，whenany很适合为不支持超时或取消的操作添加这些功能 whenall 当传给他的所有的task都完成后，task.whenall会返回一个task ","date":"2021-01-30T00:17:57+08:00","permalink":"https://linjianshu.github.io/p/%E7%9C%9F%E4%BC%9Acsharp%E5%90%97%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"真会CSharp吗学习文档"},{"content":"RabbiMQ学习文档 rabbitMQ是遵循amqp协议的一个erlang实现。\namqp协议：高级消息队列协议\nhttp协议：request、response\ntelnet协议：经常用来查看某一台ip上的指定端口是否是ping通的【远程登陆协议】\nAMQP 0-9-1 complete Reference Guide rabbitmq 实现的amqp协议的版本号\nconnection =\u0026gt;open , use , close [open-ok , close , une-ok] channel =\u0026gt;open, flow , close , [构建在connection之上，在amqp中常作为长连接] exchange =\u0026gt; queue basic =\u0026gt;发布和获取 message中的一些设置 tx =\u0026gt;事务处理 confirm =\u0026gt;发布确认机制 详细设计书一样\nimage-20201026164558077\rimage-20201026164701153\r延时处理，拉长时间\n以更长的时间来换取堆积的业务逻辑\n异步处理：响应很快，增加服务器承载能力\n流量削峰：\n扩展性：UI和业务的解耦，可以独立演化\n高可用：处理器发生故障以后，不会影响可用性\n缺陷：\n即时性降低，降低了用户体验\u0026mdash;无法避免；业务上来屈服；\n复杂性提高\nvhost：避免命名冲突\nexchange：\ndirect headers topic fanout image-20201026211929666\r在windows上是一个服务\nUI工具可以查看rabbitmq的事实状况，http api的方式也可以查看\nhttp://127.0.0.1:15672/#/\nimage-20201027095638965\rui和命令行的区别：ui只是命令行的子集\nimage-20201026215957380\r应用层序和集群的管理 application and Cluster Management\nstop stop_app start_app reset [格式化的功能] force reset [无条件设置] 集群配置 Cluster management:ram和disk\npurge_queue {queue名} 用于清空某一个队列 用户管理 userManagement\nadd_user {username} {password} [设置users的角色] set_user_tags {username} {tag \u0026hellip;} [设置用户的角色] authenticate_user {username} {password} 验证用户名，密码是否正确 list_users 展示所有users 访问控制 access Control\nset_permissions [-p vhost] {user} {conf} {write} {read} clear_permissions {user} 参数管理 parameter management 【第三方插件比较多】\n政策管理 policy management 对queue 的全局设置用得上这个政策管理，队列镜像也是用的这个命令\n服务器状态\nlist_queues {name} {pid} {durable} list_exchanges [-p vhost] [exchangeinfoitem] list_bindings [-p vhost] [bindinginfoitem] list_connections [connectioninfoitem] list_channels [channelinfoitem] connections =\u0026gt;channels 建立connections是长连接，channels是挂在connection之上的\nstatus environment Miscellaneous 混合命令 erlang和rabbitmq的区别\n一个是语言环境，一个是应用程序\nimage-20201026222139817\rimage-20201026222148175\rimage-20201027091016137\r环境配置文件：measia【erlang的分布式数据库】， config配置文件，log日志的存放路径的设置\nconfig文件。。mongodb , redis\nimage-20201027091602576\r知道端口：5673\nlog信息 默认打出来的是info格式\n{log_levels,[{connection,info},{channel,info}]}\n这样日志特别大，对磁盘的压力就很大\n{vm_memory_high_watermark,0.4}\n指定ram占内存百分比上限，connection达到阀值会阻塞blocked【报警】 让管道流变小\n{disk_free_limit,5000000} 也是会触发报警机制，让管道流变小\n使用C#连接rabbitmq .Net Client\n1.api文档 类似msdn\n2.下载方式有两种： 1）通过官网下载 2）通过nuget下载\nconnectiong to a Broker 服务器配置，guest不可以被外网访问，在生产环境中，默认都是新增用户的\n这是生产者代码：\nusing System; using System.Net.Http; using System.Text; using RabbitMQ.Client; namespace RabbitmqDemo { class Program { static void Main(string[] args) { ConnectionFactory factory = new ConnectionFactory() { HostName = \u0026#34;127.0.0.1\u0026#34;, UserName = \u0026#34;datamip\u0026#34;, Password = \u0026#34;123456\u0026#34; }; //第一步：创建connection var connection = factory.CreateConnection(); //第二步：创建channel var channel = connection.CreateModel(); //第三步：声明交换机（因为rabbitmq已经有了自定义的amqp default exchange ，所以这里不声明也能自动创建） //第四步：创建一个队列（queue） channel.QueueDeclare(\u0026#34;mytest\u0026#34;, true, false, false); var msg = Encoding.UTF8.GetBytes(\u0026#34;你好\u0026#34;); //第五步：发布消息 channel.BasicPublish(string.Empty,\u0026#34;mytest\u0026#34;,basicProperties:null,body:msg); // using... // connection.Dispose(); // channel.Dispose(); Console.WriteLine(\u0026#34;Hello World!\u0026#34;); } } } 这是消费者代码：\nusing System; using System.Text; using RabbitMQ.Client; namespace RabbitmqConsumer { class Program { static void Main(string[] args) { ConnectionFactory factory = new ConnectionFactory() { HostName = \u0026#34;127.0.0.1\u0026#34;, UserName = \u0026#34;datamip\u0026#34;, Password = \u0026#34;123456\u0026#34; }; //第一步：创建connection var connection = factory.CreateConnection(); //第二步：创建channel var channel = connection.CreateModel(); //第三步：声明交换机（因为rabbitmq已经有了自定义的amqp default exchange ，所以这里不声明也能自动创建） //第四步：获取消息 BasicGetResult basicGetResult = channel.BasicGet(\u0026#34;mytest\u0026#34;, true); ReadOnlyMemory\u0026lt;byte\u0026gt; msg = basicGetResult.Body; Console.WriteLine(\u0026#34;Hello World!\u0026#34;); } } } 交换机机制：exchange:direct/fanout/headers/topic image-20201027110100918\rDemo中用到的BasicGet是主动的去拉取，subscribe和publish是发布订阅的模式\nworkqueue方式\nEventingBasicConsumer:多个consumer可以分摊我们的cpu计算压力\n如果申明自定义交换机，一定要手动绑定\n//第三步：声明交换机（因为rabbitmq已经有了自定义的amqp default exchange ，所以这里不声明也能自动创建）可选 channel.ExchangeDeclare(\u0026#34;myexchange\u0026#34;,ExchangeType.Direct,true,false,null); //第四步：创建一个队列（queue） channel.QueueDeclare(\u0026#34;mytest\u0026#34;, true, false, false); channel.QueueBind(\u0026#34;mytest\u0026#34;, \u0026#34;myexchange\u0026#34;, \u0026#34;mytest\u0026#34;, null); for (int i = 0; i \u0026lt; 100; i++) { var msg = Encoding.UTF8.GetBytes(string.Format(\u0026#34;{0}:{1}\u0026#34;,i,\u0026#34;你好\u0026#34;)); //第五步：发布消息 // channel.BasicPublish(string.Empty, \u0026#34;mytest\u0026#34;, basicProperties: null, body: msg); channel.BasicPublish(\u0026#34;myexchange\u0026#34;, \u0026#34;mytest\u0026#34;, basicProperties: null, body: msg); } image-20201027155658033\rRouting模式 做一个日志处理分发，将日志级别不同的存到不同的队列里去，info/debug/warn存到log_else队列中，等待消费者消费；将error存到log_error队列中，等待消费者消费；在这里注意，我们可以在生产者/消费者任意一端构建交换机、队列，因此最合适的方式是，将不同级别队列的构建放在消费者一端，在生产者端，将消息的存进不同的路由中（routekey中）\nimage-20201027163324742\r生产者：\nimage-20201027163944656\r消费者：\nimage-20201027164022728\rimage-20201027164030154\rfanout：exchange多播的现象 应用场景相当多\n1.下订单流程：如果订单提交，同时发送短信和推送\n2.cs软件弹出消息，普通情况下，我们是轮询的方式，我们在cs中绑定fanout exchange，这时候服务器有消息的话，可以及时推送\n3.客户关怀千人千面\n淘宝=\u0026gt;催付、付款后提醒、发货提醒、签收提醒\n​\t=\u0026gt;给用户关联推荐、彩信和邮件、短信给用户推荐关联推荐\n","date":"2020-12-01T00:29:59+08:00","permalink":"https://linjianshu.github.io/p/rabbitmq%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"RabbitMQ学习文档"},{"content":"2020.11.17微服务划分原则 独立运行、独立部署和持续交付 应该通过功能来划分微服务：微服务应该彼此独立，如果不能交付独立的应用程序功能块，那么划分只能增加复杂性。 划分微服务的目标应该是每个微服务可以单独的运行，单独的测试，不依赖其他的微服务，以便在大型项目开发中达到持续交付的目的，否则拆分微服务就失去意义了。 例如：子若姐的设备点检模块部分的微服务，划分为点检项配置和点检计划自动制定两个微服务，两个微服务可以单独的运行，只要无参调用或者给参数调用就能跑。 每个微服务对应一个数据库（也可以没有数据库） 每个微服务有自己的数据库，并与其他微服务完全解耦。 为每个微服务分配数据库，保证该微服务对其下数据库的支配权，数据库中的表应该包括微服务用到的所有表结构和实体，并且在其他微服务出现次数尽可能少（可以出现，如此就需要用MQTT或Rabbitmq保证数据的最终一致性）。 例如：点检项配置微服务有4个表，点检计划自动指定微服务有4个表，有一个表相同，但另外的表只有对应微服务在使用，其他微服务无法干涉。 微服务划分粒度 没有标准定义，个人认为：1.可以按照数据库的独立性来划分微服务（即：被剥离出来的a数据库，理论上只有A微服务可以调用，其他微服务不行）2.可以按照实现的功能层面来划分微服务（根据简单的CRUD构成了一个复杂/简单的功能，即：点检项的配置和点检计划的制定）3.在满足以上的情况下，不建议划分过小的微服务，例如简单的C、R、U、D划分为四个，那么在微服务调用时就会因为进程间调用造成极大的通信成本，另外微服务的搭建也十分繁琐，这是不合适的） 关于DDD原则划分微服务 书中建议我们，并不是所有的微服务都需要使用DDD原则来划分和构建。**每个微服务可以基于不同设计模式具有不同内部架构。并非所有微服务都应使用先进的DDD模式来实现，因为这可能导致过度设计。对于简单的CRUD维护应用程序，设计和实现DDD模式可能没什么意义。但对于核心领域或核心业务，可能需要应用更先进的模式来应对业务规则不断变化的业务复杂性。**我们不可能用“一种架构模式来解决所有问题”。根据优先级，必须为每个微服务选择不同方法。 image-20201116221753802\r个人理解：我们使用的ABP四层框架实际上就是按照DDD原则进行CRUD和构建复杂功能的框架。 image-20201117160828300\r在拆分的过程中，我们还应该考虑，是否有一些被拆分出去的微服务，它用不上DDD，诸如简单的CRUD，以及不涉及聚合数据、提取表中特定数据的Dto构造，我们就可以使用简单的单层或其他形式来进行该微服务的构建，以达到最适合该微服务搭建的目的。 低耦合 重点是构建低耦合的微服务，如果我们发现A微服务在运行的过程中会频繁的调用B微服务，那么我们可能会考虑将A微服务和B微服务进行组合。以解耦提高内聚，降低通信成本，降低出现故障的可能。 微服务间的交互越少越好，核心规则是微服务间的交互需要异步 ","date":"2020-11-17T09:17:59+08:00","permalink":"https://linjianshu.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A12020.11.17%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%92%E5%88%86%E5%8E%9F%E5%88%99/","title":"微服务2020.11.17微服务划分原则"},{"content":"2020.11.16微服务继续学习 Docker数据卷技术 数据卷是指从主机操作系统映射到容器的目录。当容器中的代码访问这些目录时，实际上是在访问主机操作系统中的文件夹。这些目录并没有绑定到容器本身的生命周期中，它们能被直接运行在主机操作系统中的代码访问，或被其他同样映射了该目录的容器访问。因此，数据卷按照设计可独立于容器生命周期来实现数据的持久存储。如果从docker主机删除容器或镜像，数据卷中的数据并不会被删除，其中的数据依然能从主机操作系统访问。\n微服务架构 每个微服务负责实现一个特定的端到端领域，或有着确定边界的业务逻辑，并且每个微服务必须能独立开发和部署。每个微服务应该拥有自己特定的领域数据模型和领域逻辑（自治和去中心化的数据管理），它们是基于不同数据存储技术（SQL、NoSQL）和不同编程语言实现的。\n重点是要创建低耦合的服务，只要它们之间没有太多直接依赖，就应该使它们尽可能地小。\n微服务架构提供了长期的敏捷性，微服务可以基于多个独立部署的服务来创建应用。\n微服务另一个优势在于能够独立地进行横向扩展。而不是一起将本不需要扩展的其他功能区域也进行扩展。难点：如何在多个层级设计并实现安全性：认证、授权、密文密码管理和安全通信等。\n微服务的数据自治 A与B子系统都会调用C实体的属性和数据，而它们是隶属于不同上下文边界的。这样的原则在DDD里也是类似的，每个限界上下文、自治的子系统或服务必须拥有自己的领域模型（数据+逻辑+行为）。\n中心化数据库：同一张地图满足徒步旅行、长途汽车旅行和学习地理知识的需求；都支持ACID原则和SQL语言。\n当业务流程跨越多个微服务时，最终一致性是唯一的办法，这比写一个简单的SQl连接要复杂的多，同理，很多其他关系型数据库功能也不支持跨微服务使用。\n基于微服务的应用通常会混合使用SQL和NoSQL数据库，这种做法有时会被称为混合数据持久化。\n微服务和限界上下文模式的关系 每个BC必须有自己的模型和数据库。\n逻辑架构和物理架构 确定了业务微服务或限界上下文，但不意味这最佳实现方式就是为每个业务微服务创建单独的服务（例如作为一个ASP.NET Web API）或单独的Docker容器。\n业务微服务或限界上下文必须自主地进行代码和状态的独立版本控制、部署和扩展。\n分布式数据管理的挑战和解决方案 定义微服务边界： 关注应用的逻辑领域模型和相关数据\n创建从多个微服务获取数据的查询： 需要一种方式来聚合信息；\nAPI网关、CQRS查询/读取表：此时复杂的查询将变成巨大的挑战，为此可以使用CQRS方案：在不同数据库中创建一个只用作查询的非规范表，这种方式不仅解决了最初的问题（如何跨微服务查询和联接），与复杂的SQL联接语句相比还能进一步提升性能，因为应用所需的数据已经在查询表里了；\n中心数据库的“冷数据”：将“热数据”导出为“冷数据”储存到报表专用的大型数据库中。为了同步数据，可以采用事件驱动通信，如果使用事件驱动通信的方式，整合流程将与上文提到的使用CQRS查询表获取数据的方式相似。\n然而，在设计上需要不断从多个微服务里进行聚合数据并进行复杂查询，那么通常在遇到此类问题后，我们也许会考虑合并微服务。\n在多个微服务之间实现一致性 使用基于异步通信，如集成事件（消息和基于事件的通信）的最终一致性。根据CAP理论，我们需要在可用性和强ACID一致性之间做出选。大多数微服务场景要求高可用性和高扩展性，而非强一致性。开发人员可以使用弱一致性或最终一致性的技术来做到强一致性。这也是大多数基于微服务的架构所采取的方法。\n此外，ACID风格或两步式提交事务违背了微服务原则，跨服务和数据库维护数据的一致性非常重要。需要在微服务之间使用事件驱动通信和发布订阅系统来实现最终一致性。\n在多个微服务之间通信 在多个微服务间创建了长串的同步HTTP调用，应用最终将会碰到问题：阻塞和性能低下。\n因为这可能会产生一种争议：这实际上是一种单体式应用，它的进程间是基于HTTP的，而没有使用进程内通信机制。\n为了促进微服务的自治并获得更高的弹性，应该减少使用跨服务的链式请求/响应通信。建议微服务间的通信只使用异步交互，例如使用基于消息或时间的异步通信。\n识别微服务的领域模型边界 虽然微服务应该尽可能地趋向于小型化，但识别每个微服务的模型边界不是为了尽可能拆成细粒度，而是根据领域知识来进行最有意义的划分。重点不在于大小，而在于业务需要。另外，如果因为存在庞大复杂的依赖关系而要求应用的某个领域有清晰的一致性的需求，这也就表明该领域应该是一个独立的微服务。\n因此，BC会帮助澄清哪里需要特定的领域术语，以及哪里需要把系统拆分成额外的不同领域BC。\n然而也有些具有不同形态但却共用相同标识的实体，它们存在于多个微服务所包含的多个领域模型中。例如会议管理微服务中有一个用户实体，该实体所对应的同一个用户，在订单微服务里被称为买家，在支付微服务里名为付款方，而在客户服务微服务里称作客户。这是因为基于每个领域专家使用的通用语言，会对同一个用户有不同视角，甚至包含不同属性。会议管理微服务里的用户实体应该包含最多的个人数据属性，但是同一个用户在支付微服务里的买家标识和客户服务里的客户标识就不需要那么多属性了。\n每个领域模型里的用户实体可能有不同的补充细节。因此需要某种方式把一个领域的用户实体映射到另一个领域中。\n客户端微服务直连和API网关模式 直连有弊端：如何处理跨界限问题，例如授权、数据传输和动态请求派发：为每个微服务实现安全和界限问题，例如安全性和授权机制，一种可能的方法是把这些服务放进Docker主机或内部集群中，再通过一个中间位置，例如API网关来解决跨界限问题。\n有时要从响应中去掉移动端不需要的数据，还要压缩数据，所以这样的场景下，在移动端和微服务之间使用外观模式或API就变得很方便了。\n使用API网关：\n我们可以使用单一的自定义API网关服务来面对多个不同客户端应用，但这会造成巨大的风险，因为API网关服务会随着客户端应用需求的变化而增长并演化，最终它会因为需求的变化而变得臃肿，在效果上将会等同于单体应用或服务。因此我们极力推荐将API网关拆分成多个服务或者小型的API网关，每个API网关都有自己的形式。\n我们应该创建多个API网关，以便为每种客户端需求实现不同外观，略有差异的API，甚至可能基于客户端展现形式或设备来实现特定的适配代码，这些代码在底层调用多个内部的微服务。\n通常来说，使用一个API网关将应用中所有内部微服务聚合在一起，这种做法并不明智。因此，API网关应该基于业务边界来拆分，而不是作为整个应用的一个聚合器。\n在这单独的一层中，我们也可以过滤内部微服务的API，或者在已发布的API上添加授权。\n网关模式的不足之处：如果API网关包含自定义逻辑和数据集成，就会要求额外的开发成本和未来的维护成本。如果API网关只使用了安全性、日志管理和版本管理功能，这些额外的开发工作便不会发生。\n微服务之间的通信 通信类型 客户端代码或消息发送者通常不需要等待响应，只要把消息发送给RabbitMQ队列或其他消息代理即可。\n例如事件驱动架构里的发布/订阅机制。\n异步整合方式增强微服务自治 微服务间的交互越少越好，核心规则是微服务间的交互需要异步，微服务间通过异步传输来通信，但不要依赖于其他内部微服务作为自己HTTP请求/响应的一部分。\n每个微服务应以自治以及对客户端可用为目标，即使作为端到端应用一部分的其他服务发生故障或不稳定也应如此。如果需要从一个微服务调用其他微服务（如发起HTTP请求来查询数据）为客户端应用提供响应结果，那么这样的架构在其它微服务发生故障时就变得不稳定。\n如果最初的微服务需要原本在别的微服务里拥有的数据，不要依靠同步请求来获取数据。而是通过最终一致性（通常通过集成事件）方式来复制或传输这些数据到最初的微服务的数据库中。\n为了获得最终一致性，可以使用任何协议在微服务之间异步地通信来获取数据。重点在于：不要在微服务间创建同步依赖。\n异步消息通信 跨越多个微服务以及相关领域模型传送变化时，使用异步消息和事件驱动的通信至关重要。一种解决方案是基于异步消息传递和事件驱动的最终一致性。\n尽可能遵循另一个规则：只在内部服务间使用异步消息传递，只在从客户端应用到前端服务（API网关\n加上第一级微服务）间使用同步通信。\n多接受者消息通信\n使用发布/订阅机制；异步事件驱动通信；\n创建、改进和控制微服务API的版本和契约 即便初始版本的契约已经考虑的很周全了，随着时间发展，服务的API也可能需要改变。如果发生了变化，尤其是被多个客户端应用调用的公共API，通常无法强制所有客户端升级到新的API契约。通常这需要增量部署服务的新版本，同时也要让老版本和新版本服务契约同时运行。因此，服务的版本策略很重要。\n有时我们需要对服务API进行不兼容的大版本更新。因为不能强制客户端应用或服务立刻升级到新版，服务端必须支持老版本继续运行一段时间。如果使用基于HTTP的机制，一种方式是把API的版本号嵌入URL或HTTP头部。然后可以决定是在一个服务里同时实现两个版本的API，或是部署不同的服务来各自处理一个版本的API。此时一种较好的方法是采用中介者模式如MediaR库将不同版本的实现用不同的处理器来处理。Hypermedia是用来进行服务版本化和改进的最佳选择。\n微服务的可发现性和服务注册 使用Marathon和Kubernetes和DC/Os处理服务实例的注册和撤销。另一个例子是Service Fabric，它也提供了开箱机用的命名服务来实现服务注册。\n创建基于多个微服务组合界面，其中包括由微服务生成的可视化UI外观和布局 微服务架构通常始于服务端的数据处理和逻辑。但一种更先进的方式是设计基于微服务的应用界面，这以为这我们拥有一个由多个微服务生成的组合界面，而不是由一个单体客户端应用来调用服务器上的微服务。采用这种方式的微服务能够完整地包括逻辑和可视化展现。\n单体客户单调用多个微服务的过程，这些微服务仅仅关注逻辑和数据，而不关注界面展现。\n微服务的适应性和高可用性 意外故障的处理是个大难题。云端系统必须能够接受故障并尝试自动从故障中恢复。通过策略重新发送消息或重新发起请求，使用诸如Polly库的断路器。\n微服务的运行状况管理和诊断 微服务必须报告他的运行状态和诊断信息，采用同意的统一日志格式。使用healthchecks库，以便微服务能向监控服务报告状态来执行合适的操作。\n编排引擎管理运行状况和诊断信息 稳定的协作系统，不仅要创建微服务架构，还需要具备高可用性、可寻址能力、适应性、运行状况和诊断机制等。\n编排高扩展和高可用的多容器微服务 必须使用编排引擎。组合应用的负载均衡、路由和编排。我们需要一个能按需自动启动、挂起或关闭容器的管理平台，理想情况下还要能控制资源的访问（例如网络和数据存储）。\n集群和编排引擎；调度器；Docker Swarm\nimage-20201116212838790\rimage-20201116212959369\r第六章 应该通过功能来划分微服务：微服务应该彼此独立，如果不能交付独立的应用程序功能块，那么划分只能增加复杂性。\n我们可以先创建一个单体应用程序，以后再划分成若干功能，开发并部署成微服务。\n把应用程序划分成多个离散的进程还会带来开销方面的问题。而把功能划分成多个不同进程会进一步增加复杂性，通信协议也会变得更复杂，必须在服务间使用异步通信，事件总线处理、弹性消息和重试，最终一致性等。\nDocker支持 右键项目，点击Add，然后选择docker support即可。这个模版会给项目添加一个dockerfile，同时还会添加一个新的docker-compose项目，它提供了初始的docker-compose.yml文件。\n第七章 将传统的单体.NET Framework应用程序迁移到Windows容器中 开发环境和生产环境 大多数情况下，我们通常希望应用程序依赖的微服务也运行在同一台Docker主机或Swarm上，这样可以让开发工作变得更容易一些，同时可以降低网络延迟。在这样的配置中，微服务实例与用户持久化数据存储的高可用服务器之间的通信成本是唯一的通信成本。\n第八章 应用规范 返回HTML /JSON / XML响应为请求提供服务。应用程序支持各种客户端，包括桌面浏览器、web应用程序、移动web应用程序和原生移动应用程序。该应用程序可能会暴露API供第三方使用，他还能异步集成微服务或外部应用程序，以便在局部故障的情况下让微服务顺利恢复。\n应用程序由下列类型的组件组成：\n展示组件 应用程序业务逻辑 数据库访问逻辑 应用集成逻辑 主要基于消息代理的消息通道 应用程序需要具备较高的可扩展性，同时允许其垂直子系统自动扩展，必须能够部署在多种基础设施环境中，并且最好应该是跨平台的。\n选择架构 尽可能使用异步方式\n微服务开发和部署为彼此独立的容器。这意味着开发团队可以在不影响其他子系统的情况下开发和部署某个微服务。\n每个微服务有自己的数据库，并与其他微服务完全解耦。必要时，使用应用程序级集成事件（通过逻辑事件总线），如命令查询职责分离（CQRS）实现来自不同微服务的数据库间一致性。因此，业务约束必须包含多个微服务和相关数据库之间的最终一致性。\nimage-20201116215344205\r通信架构 客户端与微服务的直接通信 异步事件通信 如果需要，每个微服务可使用不同TCP端口，在生产模式中，该URL将映射到微服务的负载均衡器，负载均衡器将请求分发到可用的微服务实例。\n不打算创建可能影响微服务自动部署的单体API网关，但如果要设计包含数十个微服务的大型微服务应用，强烈将以考虑API网关模式。\n每个微服务的数据主权 每个微服务拥有自己的数据库或数据源，每个数据库或者数据源会部署一个为单独的容器，这种设计只是为了让开发人员能够轻松获取和克隆github代码，使用数据源容器都可以让开发人员在几分钟内构建并部署，数据库应该是基于云端数据库服务器或本地数据库服务器，而不是容器中。\n基于微服务的解决方案的优点 每个微服务相对较小-易于管理和改进 可以扩展应用程序的各个区域 可以将多个团队间的开发工作分开 问题的隔离程度更高 更方便使用最新技术 微服务解决方案的缺点 分布式应用 开发人员必须使用诸如http或amqp等协议实现内部服务通信，这增加了测试和异常处理的复杂性，还增加了系统的延迟 部署的复杂性 需要能为每个服务创建多个实例 原子事务 多个微服务间的原子事务通常是不可能实现的，业务需求必须包含多个微服务间的最终一致性。 全局资源需求增加 客户端与微服务的直连通信问题 在某些情况下，客户端应用程序可能需要通过大量单独的请求来组成用户界面，这在互联网上可能是低效的，客户端应用程序对后端系统的请求应尽可能最少。微服务可能使用了非标的Web协议或者二进制协议或者AMQP消息，这些协议通常会被防火墙屏蔽，因此最好只在内部使用。可能会考虑使用多个细粒度的API网关。 分割微服务 我们需要确定应用程序与其他区域解耦并具有低数量硬依赖的区域。这与应用与类的单一职责原则类似，即：只能处于一个原因更改某个特定的类。最重要的是：微服务必须完全自治、端到端，有自己的数据源。 外部与内部架构和设计模式 每个微服务可以基于不同设计模式具有不同内部架构。并非所有微服务都应使用先进的DDD模式来实现，因为这可能导致过度设计。\n新世界：多种架构模式和多语言微服务 软件架构师和开发人员会使用不同的架构模式，例如混合架构风格和架构模式：\n简单的CRUD，单层 传统N层 领域驱动设计N层 干净架构 命令和查询职责分离（CQRS） 事件驱动架构（EDA） 重点在于：没有任何一种架构模式或风格，以及任何一种特定技术，能够适用于所有情况。\n可以用不同方式实现每个微服务，每个微服务可能具有不同架构模式，并根据应用程序的性质、业务需求和优先级使用不同的语言和数据库。\nimage-20201116221753802\r可以用不同方式实现每个微服务，每个微服务可能具有不同架构模式，并根据应用程序的性质、业务需求和优先级使用不同的语言和数据库。因为每个子系统的上下文边界和要求通常是不同的。\n对于简单的CRUD维护应用程序，设计和实现DDD模式可能没什么意义。但对于核心领域或核心业务，可能需要应用更先进的模式来应对业务规则不断变化的业务复杂性。\n我们不可能用“一种架构模式来解决所有问题”。根据优先级，必须为每个微服务选择不同方法。\nASP.NET Core和Web API控制器中的依赖注入 在ASP.NET Core中，我们可以使用开箱即用的依赖注入DI。此时不需要设置第三方控制反转容器IOC，但如果需要，可以将首选Ioc容器插入到ASP.NET Core基础架构中，在这种情况下，这意味着可以通过控制器的构造函数直接诸如所需的EF DBContext或其他仓储库。\n将DbContext类注册到服务的Ioc容器中，通常可以在startup类中通过configureservices方法调用service.addDbcontext（）方法执行此操作。\n在ASP.NET Web API中实现版本控制 更新webapi以处理新的需求是一个相对简单的过程，但是必须考虑这种更改对调用web api的客户端应用程序产生的影响，虽然设计和实现web api的开发人员可以完全控制该api，但开发人员对可能由第三方组织远程构建的客户端应用程序没有相同程序的控制权。\n版本控制使Web api能够指示其暴露的功能和资源。然后，客户端应用程序便可想特定版本的功能或资源提交请求。实现版本控制有几种方法：\nURi版本控制 查询字符串版本控制 Header版本 因为URL版本是最简单明确的，使用URI版本控制的话，可以向每个资源的URI添加一个版本号。现有URI应该向以前一样继续运行，返回与请求的版本相匹配的模式的资源。\n可以使用web api中的Route属性来设置版本[Route(\u0026ldquo;api/v1/[controller]\u0026rdquo;)]\n在微服务（集成事件）之间实现基于事件的通信 事件总线可以设计为一个接口，包括订阅和取消订阅事件以及发布事件所需的API，还可以具有基于任何进程间或消息通信的一个或多个实现，如消息队列或支持异步通信以及发布/订阅模型的服务总线。\n使用事件来实现跨服务的业务事务，借此在服务间保持最终一致性。\n一旦要决定进行异步和事件驱动的通信，应该选择最符合生产环境需求的服务总线产品。\n集成事件 不建议在多个微服务间共享一个通用的集成事件库，这样做会将这些微服务与单个事件定义数据库相结合。不这样做的原因与不建议在多个微服务中共享通用的领域模型相同：微服务必须完全自治。\n在微服务中共享的应该是：最终的应用程序块，nuget组件共享的工具库，例如json序列化程序。\n在发布到事件总线时设计原子性和弹性 这两个操作一定要以原子性的方式执行，CAP定理任务，我们无法构建同时满足持续可用、强一致，并且能容忍任何分区这三个特征的数据库，此时只能从这三个特征中选择两个来实现。\n如果服务在数据库更新后崩溃，可以使用一下方式来处理此问题：\n使用完整的事件溯源模式 使用事务日志挖掘 使用发件箱模式 可能无法完全实现完整的ES系统，ES意味着只将领域时间存储在事务数据库中，而非存储当前的状态数据。然而实施完整的ES系统需要重新构建系统的大部分内容，并引入很多其他复杂性和要求。但并非最简单的解决方案，除非已经溯溪事件溯源模式。\n使用事务日志挖掘的方案，必须将微服务耦合到RDBMS事务日志。\n一个折中的办法是将事务数据库表和简化的ES模式组合使用。尝试将事件发布到事件总线，如果发布操作成功，将在原始服务中启动另一个事务。\n如果事件总线中的发布事件操作失败，数据在原始微服务中不会不一致。\n如果已经在使用关系型数据库，则可以使用事务表来存储集成时间。要在应用程序中实现原子性，可以使用基于本地事务的两步过程。基本上我们需要在存储领域实体的数据库中有一个integrationevent表，该表用作实现原子性的保证，以便将持久集成事件包括在提交领域数据的相同事务中。\n因此循序渐进的步骤如下：应用程序开始本地数据库事务，然后更新领域实体状态，并将事件插入集成事件表中，最后提交事务，即实现所需的原子性。\n在提交事务后立即发布集成事件，并使用另一个本地事务将表中的事件标记为已发布。\n通过事件总线发布集成事件时实现原子性 事件日志表与原始数据库操作进行原子更新，对同一数据库使用本地事务。如果有任何操作失败，将抛出异常，并对所有已完成的操作执行事务回滚，从而保持领域操作与发送的事件消息间的一致性。\n更新消息事件中的幂等性 幂等性意味着可以多次执行操作而不改变结果。在消息传递环境中传播事件时，如果可以多次传送事件而不改变接收者微服务的结果，则事件是幂等的。\n重要的是，即使同一订单完成事件有重复的消息事件，也只需要在其他系统中更新订单信息一次。\n让每个事件具有某种类型的标识是种方便的做法，我们可以创建强制每个接收者对每个事件只处理一次的逻辑。\n删除重复的集成事件消息 方法之一是使用正在用的消息架构提供的重复数据删除功能，另一种方法是在目标微服务中自定义逻辑。在传输层面和应用层面进行验证是最好的选择。\n使用Rabbitmq时删除重复消息 消息接收者必须准备好处理这些重复的消息。如果可能，接收方应以幂等的方式处理消息，这比用删除重复数据的方式直接处理消息更好。\nRabbitmq会在再次传送时将其设置为“redelivered\u0026quot;标志，因此只有在消息中设置了”redelivered“标志时，接收方才需要以幂等方式对消息进行重复数据删除或处理消息。\n在微服务中运用简化的CQRS和DDD模式 查询：返回结果且不改变系统状态，即查询是没有副作用的 命令：改变系统状态 CQRS例如用一个物理数据库来读取，一个物理数据库用来写入（更新）。\nCQRS的分离是指将查询操作组合在一层，而命令组合到另一层的做法。这两层可以包含在相同物理层级或微服务里，也可以在不同微服务或进程中实现，以便单独优化和独立地横向扩展，避免彼此干扰。\n毕竟我们的目标是让查询来的更灵活，而不是像聚合那样通过DDD模式的约束对查询进行限制。\n将CQRS和CQS方式应用到DDD微服务中 DDD模式不是普遍适用的，它们会为设计引入约束，这些约束提供了诸如随着时间推移进一步提高质量等好处，特别是会改变系统状态的命令和其他代码可以从中获益中。但是这些约束增加了读取和查询数据的复杂性。\n本书建议仅在微服务的事务/更新区域使用DDD模式，查询可以遵循更简单的方法，并且应按照CQRS方法与命令分离。\n为实现查询层，有多种方式可以选择，例如使用EF Core/AutoMapper映射、存储过程、视图、物化视图等全面的ORM，或者使用微型ORM。\n我们使用Dapper这样的微型ORM来实现直接查询。\nCQRS和DDD模式不是顶级架构 值得强调的是，每种情况强行使用相同模式将导致失败，不要在任何地方都使用CQRS和DDD。很多子系统、限界上下文或微服务都比较简单，很容易用简单的CRUD服务或其他方式来实现。\n在CQRS微服务中实现读取/查询 订单微服务的查询是独立于DDD模型和事务实现的。写入执行的事务必须符合领域逻辑，另一方面，查询是幂等的，可从领域规则中分离出来。\n只需简单地查询数据库以获取UI所需数据，然后返回一个动态ViewModel，而不需要在任何位置明确定义，但SQL语句除外。\n实际上，ViewModel类就是Dto呗。\n使用独立于领域模型约束且专为客户端应用创建的ViewModel 因此可以根据查询返回的数据为客户端专门创建返回类型，这些模型或数据传输对象（DTO）成为ViewModel。\n返回的数据（ViewModel）可以是连接数据库中多个实体或表的数据结果，也可以是事务领域模型中定义的多个聚合结果。这种情况下，因为正在创建独立于领域模型的查询，所以聚合的边界和约束可以彻底忽略，我们可以自由的查询需要的任何表和列。这种方法为开发人员创建或更新查询提供了极大的灵活性和生产力。\nViewModel可以是在类中定义的静态类型，或者可根据执行的查询来动态创建，这对开发人员来说非常的灵活。\n动态与静态的ViewModel 大部分情况下，可汇总来自多个领域实体的数据，并根据客户端应用需要的数据精确组合ViewModel。\n优点：敏捷、直截了当快速响应未来变化\n缺点：动态类型会降低清晰度甚至影响服务和客户端应用的兼容性。\n预先定义的DTO类作为ViewModel 经验之谈：起初使用动态ViewModel开发，因为开发非常敏捷。然而一旦开发稳定了，基于前面描述的原因，我们选择重构这个主题，并为ViewModel使用静态的或预先确定的DTO类。\n设计面向DDD的微服务 领域驱动设计（DDD）主张根据和用例相关的实际业务来建模。它也提出了多种技术概念和模式来支持其内部实现，例如丰富模型领域实体、值对象、聚合根规则。\n在实现DDD方法时有陡峭的学习曲线。以便划清业务问题并使用相同的业务术语（统一语言）。此外DDD方式应该只用于实现拥有重要业务规则的复杂微服务。诸如CRUD服务等简单的任务可使用更简单的方法管理。\n如何确定边界是设计和定义微服务的关键任务。DDD模式可以帮助我们理解领域的复杂性。识别和定义用来模型化该领域的实体、值对象和聚合。构建并提炼在一个定义上下文边界的领域模型。\n保持相对较小的微服务上下文边界 最开始需要创建尽可能小的微服务，其次需要避免微服务间无谓的通信。这两个目标相互制约，需要权衡。尽可能将系统拆分成多个小型的微服务，直到尝试拆分新的界限上下文而出现快速增长的边界通信时即可停止拆分。内聚是独立界限上下文的关键。\n如果两个微服务需要很多协作，它们应该成为同一个微服务。\n另一种看待这种情况的方法是自主权。如果一个微服务必须依靠其他服务来直接处理请求，那么就不是真正的自治。\nDDD微服务中的分层 领域实体包含在领域模型层内部，并且不应传送到不属于它的区域，比如表现层。\nViewModel是一个仅为满足表现层需要的数据模型。领域实体不直属于ViewModel，相反，需要在ViewModel和领域实体之间互相转换。\n领域模型层 说白了感觉就是Core，也就是poco。负责表达业务概念、业务状态信息及业务规则。但反映业务情况的状态是由本层控制并使用的，领域模型层是业务软件的核心。\n这意味着一个重要的规则：领域模型实体类应该就是POCO。\n领域实体不应对任何数据访问基础框架如EF有任何直接的依赖。理想情况下，领域实体不应该继承自或实现任何基础框架里的任何类型。\n理解数据的物理模型和如何映射到实体对象模型依然很重要。\n应用层 定义软件要完成的任务，并只会表达领域概念的对象来解决问题。应用层要尽量简单，不包含业务规则或知识，只为下一层中的领域对象协调任务，分配工作，使它们相互协作。即为用户或程序显示某个任务的进度。\n表示应用层必须不包含业务规则或领域知识，这些内容应该有领域模型类库所拥有。应用层必仅协调任务而不能保留或定义任何领域状态（领域模型）。\n应用层将业务规则的执行委托给领域模型类本身，最终在那些领域实体中更新数据。\n基础架构层 基础架构层用于将最初保留在内存中的领域实体汇总的数据持久化到数据库或其他持久存储中。\n在绝对不产生框架强依赖的前提下确保领域模型实体类和用来持久化数据的基础架构无关。即仅有实现软件核心的POCO实现类，并且与基础架构技术完全解耦。\n因此层或类库以及项目应该最终依赖与领域模型层（库）。\nimage-20201117160828300\r每个微服务的基础架构层设计应该是独立的，如前所述，可以按照DDD模式实现复杂微服务，而用更简单的方法实现简单数据驱动微服务（单层的简单CRUD）。\n","date":"2020-11-16T09:17:59+08:00","permalink":"https://linjianshu.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A12020.11.16/","title":"微服务2020.11.16"},{"content":"本周工作情况： 1.Dapper学习及使用（完成） 2.MQTT学习及使用（完成） 3.Dapper\u0026amp;MQTT保证数据一致性Demo（批量增、删、改）（完成） 4.跨服务事务一致性学习（saga)（未完成） 计划下阶段任务： 1.了解oes各个模块业务逻辑，上层：王锐师兄，下层：丽俊师兄，App：子若姐，重点了解流程，不慌搭建微服务 2.继续学习微服务划分原则和示例，根据领域驱动设计（DDD）及师兄师姐的理解划分各模块构建微服务蓝图 3.了解数据池化技术，斟酌数据库选用 Dapper入门及使用 ORM（对象关系映射）轻量级框架：数据库持久化技术，池化技术 EF框架加载树： image-20201113095855356\rDapper加载树： image-20201113092949378\rMQTT学习及使用 image-20201113094906752\rMQTT\u0026amp;Dapper保证跨数据库的数据一致性 image-20201113091711501\r使用EMQ可视化界面作为代理来管理mqTT的客户端及主题、订阅、发布 image-20201113090134383\r批量增加 image-20201113090214669\rimage-20201113090255394\r批量修改 image-20201113090947812\rimage-20201113090956564\rimage-20201113091105493\r批量删除 image-20201113091511010\rimage-20201113091524415\rimage-20201113091600481\r","date":"2020-11-13T09:17:59+08:00","permalink":"https://linjianshu.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A12020.11.13/","title":"微服务2020.11.13"},{"content":"微服务架构学习文档 Netflix流媒体播放平台微服务架构：\nimg\roes目前设想：\nimage-20201013172440573\rimage-20201012210849046\r微服务架构特性： 单一职责 轻量级通信（通过http、rpc协议下的xml、json格式，无关语言、平台） 独立开发、测试、部署（并行工程） preview\r分布式\u0026ndash;集群\u0026ndash;微服务 分布式：不同服务器部署不同业务（应用）\n集群：不同服务器部署同一套业务（应用）\n微服务：同一台服务器可能部署多个微应用\npreview\r问题： 单体应用 优点：便于开发、测试、部署\n缺点：维护成本高、交付周期长、扩展性差\n作业平台、移动端、系统平台有功能相同或者重复的代码，相同业务逻辑的代码，修改维护很不方便 数据有时候通过数据库共享，有时候通过接口调用传输。接口调用关系杂乱。 单个应用为了给其他应用提供接口，渐渐地越改越大，包含了很多本来就不属于它的逻辑。应用边界模糊，功能归属混乱。 加入数据分析、深度学习等相关功能后出现性能瓶颈，影响了其他应用。 数据库表结构被多个应用依赖，无法重构和优化。 所有应用都在一个数据库上操作，数据库出现性能瓶颈。 开发、测试、部署、维护愈发困难。即使只改动一个小功能，也需要整个应用一起发布。有时候发布会不小心带上了一些未经测试的代码，或者修改了一个功能后，另一个意想不到的地方出错了。 团队出现推诿扯皮现象。关于一些公用的功能应该建设在哪个应用上的问题常常要争论很久，最后要么干脆各做各的，或者随便放个地方但是都不维护。 紧迫且繁重的任务容易使人陷入局部、短浅的思维方式，从而做出妥协式的决策。在这种架构中，每个人都只关注在自己的一亩三分地，缺乏全局的、长远的设计。长此以往，系统建设将会越来越困难，甚至陷入不断推翻、重建的循环。\n要做改造，首先你需要有足够的精力和资源。如果你的需求方（业务人员、项目经理、上司等）很强势地一心追求需求进度，以致于你无法挪出额外的精力和资源的话，那么你可能无法做任何事……\n整理了业务逻辑，抽象出公用的业务能力，做成几个公共服务\n各个应用后台只需从这些服务获取所需的数据，从而删去了大量冗余的代码，就剩个轻薄的控制层和前端。这一阶段的架构如下：\nimg\r数据库依然是共用的，所以一些烟囱式系统的缺点仍然存在：\n数据库逐渐成为了性能瓶颈\n可能会有一个服务从数据库中读取另一个服务的现象发生\n数据库表结构可能被多个服务依赖，导致很难调整\n持久化层相互隔离，由各个服务自己负责。另外，为了提高系统的实时性，加入了消息队列机制。架构如下：\nimg\r数据分析和深度学习可以做数据库持久化层，一些常用的访问可以做memcache缓存机制，大文件非结构化文本可以采用nosql非关系型数据库，例如mongodb、redis\n还有一种抽象出公共逻辑的方法是把这些公共逻辑做成公共的框架库。这种方法可以减少服务调用的性能损耗。但是这种方法的管理成本非常高昂，很难保证所有应用版本的一致性。 数据库拆分也有一些问题和挑战：比如说跨库级联的需求，通过服务查询数据颗粒度的粗细问题等。但是这些问题可以通过合理的设计来解决。总体来说，数据库拆分是一个利大于弊的。\n微服务架构的优点还在于其使得整个系统的分工更为明确，责任更加清晰；单体应用公共部分可能大家都实现了一遍，公共的业务功能没有明确的归属 微服务架构的缺点：容易产生雪崩效应，即一个服务挂了，另一个服务直接或者间接地调用该服务，导致这个服务也跟着宕机了；此外，整个应用被拆分为了多个服务，定位故障点也十分困难 问题是解决了，但谁也无法保证不会再发生类似的其他问题。微服务架构虽然逻辑设计上看是完美的，但就像积木搭建的华丽宫殿一样，经不起风吹草动。微服务架构虽然解决了旧问题，也引入了新的问题：\n微服务架构整个应用分散成多个服务，定位故障点非常困难。\n稳定性下降。服务数量变多导致其中一个服务出现故障的概率增大，并且一个服务故障可能导致整个系统挂掉。事实上，在大访问量的生产场景下，故障总是会出现的。\n服务数量非常多，部署、管理的工作量很大。\n开发方面：如何保证各个服务在持续开发的情况下仍然保持协同合作。\n测试方面：服务拆分后，几乎所有功能都会涉及多个服务。原本单个程序的测试变为服务间调用的测试。测试变得更加复杂。\n如何解决：\n引入监控（微服务监控系统）：使用开源组件获取各接口查看各状态，利用指标采集器来做监控界面和告警处理\nredis要监控占用内存值，网络流量；\n数据库要监控磁盘空间、数据库连接数\n业务服务要监控错误率，并发数，响应延迟\rimg\rimg\r定位故障\nDapper\n服务容错\n熔断处理：服务异常或者大量延时就主动熔断，直接返回；不继续调用服务防止雪崩效应导致服务器宕机，隔离一段时间后，允许放行少量请求进入半熔断状态，如果仍然调用失败或超时异常，继续熔断，否则关闭熔断模式 线程隔离（一种隔离模式）不同服务使用不同线程池，即时服务出现故障耗尽线程池资源也不会让其他服务受到影响 回退操作 限流处理：对并发量访问量进行控制，超出部分拒绝请求 动态配置\n动态修改配置参数，解决方案之一是存放在git私有仓库里，通过docker从git服务器中动态读取，本地仓库发生代码变化时，通过push操作推送到git仓库，git服务器通过消息队列通知配置中心刷新对应的配置文件\ndubbo（阿里）\n分布式服务框架，基于java RPC协议，核心组件：有RPC（远程过程调用）、负载均衡、服务发现与注册、容错、服务监控，由于集成了众多功能组件，显得框架较重，但经历了阿里电商的考验，是一个值得研究和使用的框架。Netty（基础通信组件）Zookeeper（服务注册与发现）dubbo-monitor（服务监控中心）\n角色定义：consumer/provider/registry/monitor/container\nspring cloud\n与dubbo不同，其采用http（超文本传输协议）协议restful风格，核心组件：服务发现与注册、服务监控。enruka（服务注册与发现）springboot admin（服务监控中心）\n在高并发环境下，线程数量可能会创建太多，操作系统的任务调度压力大，系统负载也会比较高。那怎么办呢？\nZuul\nspring cloud下微服务api网关，集成ribbon负载均衡、鉴权、限流、熔断、提供动态路由、监控、安全认证、负载卸载等功能。网关就可以对外暴露聚合API，屏蔽内部微服务的微小变动，保持整个系统的稳定性。\nEureka\n服务注册与发现中心\n1.服务注册：生产者（provider）在提供服务实例的时候注册并存进注册表中\n2.提供注册表：消费者（consumer)在调用服务的时候查询注册表里可用的服务，调用其方法，通常会缓存注册表，并定期想注册中心索取注册表信息\n3.信息同步、服务续约：服务实例通过心跳机制定期向注册中心报告该实例的健康状态，注册中心未检测到就将其从注册表上剔除\n4.服务下线：服务实例下线的时候，注册中心将其剔除\n5.负载均衡：内置Ribbon，多个服务实例时，根据ribbion请求请求分法自动进行负载均衡\n6.自我保护：当检测不到心跳机制时，大量服务从注册中心剔除，有可能是网络问题，这时停止剔除，防止误杀服务；在此期间能够进行服务注册和查询，网络稳定将新的服务实例同步到其他节点中\n7.集群部署：所有eureka节点会定时自动同步微服务的注册信息\nNginx\n负载均衡工具（Linux），优秀的反向代理服务器，（正向代理就是替客户端做代理，去请求服务器，例如科学上网，反向代理就是替服务端做代理，将客户端请求分发到真实的服务器上，进而实现负载均衡。）还可以做web服务、web缓存，优点：高并发、低消耗、ip限速、限制连接数、\nimg\rRibbon\n负载均衡工具，被封装在springcloud内，自动将基于http的restful模版转换成客户端的负载均衡的服务调用。负载均衡是对系统的高可用、网络压力的缓解和处理能力扩容的重要手段之一。\nDapper\n谷歌旗下分布式架构跟踪系统，低消耗高拓展，提供链路定位跟踪\nMock\n单元测试、生成数据，对不容易获取、构造的对象，创建一个mock对象来模仿对象的行为\n完美RPC（让远程调用像调用本地方法一样简单，解决分布式系统服务间调用的问题）\n服务注册中心（Zk，负责服务发现、注册与治理）、负载均衡（多种负载均衡算法如轮询、压力最小，请求分发，）、缓存机制（缓存注册表）、异步调用、故障定位、告警和监控、\n轮询、长连接和心跳机制\n轮询耗资源，每次轮询就要建立连接，间隔时间定义，长连接低消耗，心跳更低，轮询和长连接用来请求数据，获取响应，心跳用来保持连接即可\nkubernetes\nDocker\n微服务以镜像的形式，运行在Docker容器中。使用Docker容器技术，我们只需要将所需的基础镜像（jdk等）和微服务生成一个新的镜像，将这个最终的镜像部署在Docker容器中运行，这种方式简单、高效，能够快速部署服务。每个Docker容器中可以运行多个微服务，Docker容器以集群的方式部署，使用Docker Swarm对这些容器进行管理。我们创建一个镜像仓库用来存放所有的基础镜像以及生成的最终交付镜像，在镜像仓库中对所有镜像进行管理。\n自动化测试+发布\n蓝绿发布\n把A组剥离出LB进行升级，升级完了再重新部署进LB中，没问题的话把B组剥离出LB进行升级，升级完了再重新部署进LB中。\nimage-20201012154800884\r优点：发布平滑/有问题及时回滚/出问题影响范围比较大/策略简单\n缺点：将AB分别剥离出LB，就需要两倍数量的服务器提供支持，否则容易导致因请求量过大服务器意外宕机，短时间内浪费一定资源成本，例如云资源或硬件资源\n灰度发布\n升级部分服务，让一部分用户继续使用老版本，一部分使用新版本，当新版本无问题客户无反馈，就逐步扩大服务升级范围，至全部升级完毕。（形似公测和内测）从LB中去掉灰度服务器，对灰度服务器进行升级，升级后进行测试，灰度服务器测试成功就升级剩余服务器。\nimage-20201012154815099\r优点：逐步保证稳定性，一有问题就可以及时发现，影响的范围相对可控，用户无感知，平滑过渡\n缺点：自动化要求比较高\n滚动发布\n一次升级一个或多个服务，直到全部服务都升级；\nimage-20201012155403577\r优点：节约资源/平滑过渡\n缺点：不易回滚/发布策略复杂/自动化要求高\n蓝绿发布：两套环境交替升级，旧版本保留一定时间便于回滚。 灰度发布：根据比例将老版本升级，例如80%用户访问是老版本，20%用户访问是新版本。 滚动发布：按批次停止老版本实例，启动新版本实例。 ","date":"2020-10-23T09:17:59+08:00","permalink":"https://linjianshu.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"微服务架构学习文档"},{"content":"微服务架构设计模式学习文档 微服务不在于“微”，而在于单一职责。\n——引自《微服务架构与实践》王磊 特点： 单一职责 轻量通信（无关平台语言、通过轻量级通信机制互联） image-20201019111933340\r采用xml或json格式达到通用，可以基于http协议或rpc协议达到服务间的轻量级通信\n业务独立（开发、测试、部署） image-20201019112313900\r进程隔离 image-20201019162622677\r持续交付 技术的可扩展性（接口不依赖于特定语言和平台） 劣势： 网络通信：进程内调用比进程间调用用时短，分布式调用严重依赖网络可靠性与稳定性。 自动化测试条件严苛（测试难度大） image-20201019161945662\r分区数据库架构（需要使用基于最终一致性的方法） 跨越多服务变更（服务之间可能有依赖关系） 难点： 性能（跨进程、跨网络、跨数据库）：考虑通信成本、网络延迟、带宽、多服务交互的响应时间 可靠性：服务数量节点增多可能带来潜在故障点，防止单点故障 异步：同步通信造成阻塞，异步通信缺增加功能实现的复杂度，出现故障时的链路追踪、定位、调试有难度。 image-20201019164512498\r数据一致性：保持数据一致性需要使用saga或者什么cqrs视图查询什么的 联表查询： 尝试使用微服务架构改造遗留系统： 改造策略/原则：\n最小修改（停止挖掘） image-20201019165725693\r功能剥离 image-20201019165818362\r数据解耦 image-20201019171523179\r数据同步 image-20201019171657915\r——引自《微服务:从设计到部署》Oposguy翻译与排版 image-20201019174033415\rimage-20201019174056966\rimage-20201019191811111\r每个微服务拥有自己的数据库，这将导致部分数据冗余，但这样可以实现松耦合。\nimage-20201019174508586\rimage-20201019175638779\r进程间通信：\nimage-20201019192425195\r服务中使用了通知、请求/响应和发布/订阅组合。\n必须要加入熔断处理机制（或者设置超时、限制未完成的请求数量或提供回滚操作），否则将会造成线程堵塞无法响应。\nimage-20201019192657830\r使用异步基于消息的通信，例如使用rabbitmq、amqp等等\nimage-20201019193109130\r如何维护多个服务之间的业务事务一致性，传统的两阶段提交2pc已经不能使用\nimage-20201019195112681\r如何从多个服务中检索数据（利用事件驱动架构作为解决方案，首先发布一个事件，让与其相关的数据库所属的微服务订阅该事件，这样就导致：某个微服务内的事件被触发时，订阅该事件的微服务模块进一步触发，导致更多的事件被发布）\n中间层次是消息代理\n事件驱动的架构能够跨越多服务并提供最终一致性事务，另外就是能够生成和维护物化视图。\nimage-20201019195846736\rimage-20201019200203845\rimage-20201019200214661\rimage-20201019201228525\r微服务重构策略：\n停止挖掘 image-20201019202506214\r以上需要两个组件，第一个为api网关，提供负载均衡、请求分发、路由控制；第二个是粘合代码，用于与单体集成，毕竟一个服务很少孤立存在，通常需要访问单体的数据库。这就需要粘合代码来负责数据集成。\n提取服务 image-20201019205850332\rimage-20201019210059948\r——引自《.NET微服务与容器化.NET应用架构指南》Cesar de la Torre,Bill Wagner,Mike Rousos 创建微服务的重点是要创建低耦合的微服务，只要他们之间没有太多的直接依赖，就应该尽可能小，重要的还是要有内部一致性和对其他服务的依赖。\n优势：长期敏捷性、独立部署、细粒度、高扩展、可维护、独立进行横向扩展以便节约成本。\nimage-20201019211612693\r然而，微服务架构的数据访问会变得更加复杂。即使在一个微服务或限界上下文里能够或者应该做到ACID事务一致，但每个微服务的数据是独立的，所以只能通过微服务的API来访问。将数据进行封装确保了微服务是松耦合且能独立变化的。如果多个服务访问相同数据，数据的更新就要求协调同步到所有服务，这会破坏微服务生命周期的自治性。这就表示，当业务流程跨越多个微服务时，最终一致性是唯一的办法。这比写一个简单的SQL连接要复杂得多。同理，很多其他关系型数据库功能也不支持跨微服务使用。\n分布式数据管理的挑战与解决方案 如何定义微服务边界（DDD领域驱动设计及界限上下文）\rimage-20201020151358861\rimage-20201020151420359\r如何创建从多个微服务获取数据的查询（聚合信息提高效率，1.使用api网关，但是可能会成为单点故障或者系统瓶颈，所以要尽可能使用多个细粒度的api网关，2.使用CQRS查询，即使用物化视图模式） image-20201020145820045\rimage-20201020151855677\r如何在多个微服务之间实现一致性（应该使用基于异步通信，或者说是基于事件的通信，即异步事件驱动通信）\rimage-20201020145954765\rimage-20201020154005367\r如何在多个微服务之间通信（http同步本质，会带来http调用链条，造成阻塞和性能低下甚至雪崩式宕机，会有这样一种争议：实际上是一种单体式应用，进程间是基于http的，没有进程内通信机制。因此我们建议，使用基于消息或时间的异步通信，或者使用http轮询方式）\rimage-20201020153126389\r","date":"2020-10-13T09:17:59+08:00","permalink":"https://linjianshu.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"微服务架构设计模式学习文档"},{"content":"Redis学习文档 nosql讲解\n阿里巴巴架构演进\nnosql数据模型\nnosql四大分类\ncap\nbase\nredis入门\nredis安装\n五大基本数据类型\nstring\nlist\nset\nhash\nzset\n三种特殊数据类型\ngeo\nhyperloglog\nbitmap\nRedis配置详解\nredis持久化\nrdb\naof\nredis事务操作\nredis实现订阅发布\nredis主从复制\nredis哨兵模式\n缓存穿透及解决方案\n缓存击穿及解决方案\n缓存雪崩及解决方案\n基础api之jedis详解\nspringboot继承redis操作\nredis的实践分析\nnosql概述\n大数据时代，一般的数据库无法进行分析处理了！\nspringboot+springcloud\n1.单机mysql年代\napp=\u0026gt;dal=\u0026gt;mysql\n90年代静态网页html 服务器没有太大的压力\n1.数据量如果太大，一台机器放不下了\n2.数据的索引 300万条就一定要建立索引，那么一个机器的内存放不下\n3.访问量，读写混合，一个服务器受不了\n2.Memcached（缓存）mysql+垂直拆分（读写分离）\n网站80%都在读，如果每次去查询数据库的话就十分的麻烦！所以说我们希望减轻数据的压力，我们可以使用缓存来保证效率\nimage-20200923185840123\r发展过程：优化数据结构和索引===\u0026gt;文件缓存（IO）===\u0026gt;memchched(当时最热门的技术)===\u0026gt;\n3.分库分表+水平拆分+mysql集群\nimage-20200923190414174\r本质：数据库（读写）\n早些年mysiam：表锁（影响效率），高并发下出现严重的锁问题\n早些年innodb：行锁，慢慢的就开始使用分库分表来解决写的压力！mysql在那个年代推出了表分区，这个并没有多少公司使用！\nmysql的集群，很好的满足了那个年代的所有需求！\n4.如今最近的年代\n技术爆炸：\n2000-2010：十年间，变化太快了（热榜、音乐）\nmysql等关系型数据库就不够用了！数据量很多，变化很快！\nmysql有的使用它来存储一些比较大的文件、播客、图片！数据库表很大，效率就很低了\n如果有一种数据库来专门处理这种数据，mysql的压力就会变得十分小，（研究如何处理这些问题）大数据的io压力下，表几乎没法更改，\n目前一个基本互联网项目！\nimage-20200923191743309\r为什么要用nosql\n用户的个人信息，社交温昂罗，地理位置，用户自己产生的数据，用户日志等等爆发式增长！\n这时候我们就需要使用nosql数据库的，nosql可以很好的处理以上情况\n什么是nosql\nnosql = not only sql(不仅仅是sql)\n关系型数据库：表格，行，列（POI）\n泛指非关系型数据库的， 随着web2.0互联网的诞生，传统的关系型数据库很难对付web2.0时代！尤其是超大规模的高并发的社区！暴露出来很多难以克服的问题，nosql在当今大数据环境下发展的十分迅速，redis是发展最快的，而且是我们当下必须掌握的一个技术！\n很多的数据类型：个人信息，社交网络，地理位置，流媒体，这些数据类型的存储不需要一个固定的格式！不需要多余的操作就可以横向扩展的，Map\u0026lt;String , Object\u0026gt;使用键值对来控制！\nGet Set\nnosql特点\n1.方便扩展（数据之间没有关系，很好扩展）\n解耦\n2.大数据量高性能（Redis 一秒写80000次，读取110000次，nosql的缓存记录级，是一种细粒度的缓存，性能会比较高！）\n3.数据类型是多样型！（不需要事先设计数据库！随取随用！如果数据量十分大的表，很多人就无法设计了！）\n4.传统的rdbms 和nosql的区别\n传统的rdbms -结构化组织 -sql -数据和关系都存在单独的表中 -操作操作，数据定义语言 -严格的一致性 -基础的事务 -.... nosql -不仅仅是数据 -没有固定的查询语言 -键值对存储，列存储，文档存储，图形数据库（社交关系） -最终一致性 -CAP定理 和 BASE（异地多活！） 初级架构师 -高性能，高可用，高可扩 -.... 了解：3V+3高\n大数据时代的3V：主要是描述问题的\n1.海量volume\n2.多样variety\n3.实时velocity\n大数据时代的3高：主要是对程序的要求\n1.高并发\n2.高可拓（随时水平拆分，机器不够了，可以扩展机器来解决）\n3.高性能（保证用户体验和性能）\n真正在公司中的实践一定是：nosql+RDBMS一起使用才是最强的，阿里巴巴的架构演进\n技术没有高低之分，就看你如何使用\n阿里巴巴的演进分析\n这么多东西难道都是在一个数据库中的吗？\nimage-20200923195311367\r敏捷开发、极限编程\n开源才牛\n如果你未来想当一个架构是：没有什么是加一层解决不了的\nimage-20200923200304616\r# 1.商品基本信息 名称、价格、商家信息； 关系型数据库就可以解决了！mysql /oracle(淘宝早年就去IOE!--王坚) 淘宝内部的mysql 不是大家用的mysql #2.商品的描述、评论（文字比较多） 文档型数据库中，mongodb #3.图片 分布式文件系统 FastDFS -淘宝自己的TFS —google自己的GFS -Hadoop HDFS -阿里云的 oss #4.商品的关键字（搜索） -搜索引擎 solr elasticsearch -iseacher 多隆 所有牛逼的人都有一段苦逼的岁月 #5.商品热门的波段信息 -内存数据库 -redis tair、memarche #6.商品的交易，外部的支付接口 -三方应用 要知道，一个简单的网页背后的技术一定不是大家想的那么简单\n大型互联网应用问题：\n数据类型太多了 数据源繁多，经常重构 数据要改造，大面积改造 image-20200923202347841\rimage-20200923202441215\rimage-20200923202455222\r以上都是nosql入门概述\nnosql的四大分类 KV键值对：\n新浪：redis 美团：redis+tair 阿里、百度：redis+tair+meecache 文档型数据库（Bson格式和json一样）：\nMongoDB（一般必须掌握） MongoDB是一个基于分布式文件存储的数据库，C++编写的 主要用来处理大量的文档 MongoDB是一个介于关系型数据库和非关系型数据库中中间的产品，MongoDB是非关系型数据库中功能最丰富的，最像关系型数据库的！ conthDB 列存储数据库\nHBase 分布式文件系统 图形关系数据库\nimage-20200923203416066\r他不是存图形，放的是关系，比如：朋友圈社交网络，广告推荐！ neo4j，infogrid 四者对比\nimage-20200923203555105\rredis入门\n概述\nredis是什么\nremote dictionary server 远程字典服务\n是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。\n免费和开源！是当下最热门的nosql技术之一，也被人们称之为结构化数据库\nredis能干嘛\nredis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。\nimage-20200924092136203\r1.内存存储、持久化，内存中是断电即失，所以说持久化很重要（rdb、aof）\n2.效率高，可以用户高速缓存\n3.发布订阅系统\n4.地图信息分析\n5.计时器、计数器（浏览量！）\n6\u0026hellip;.\n特性\n1.多样的数据类型\n2.持久化\n3.集群\n4.事务\n\u0026hellip;.\n学习中需要用到的东西\n1.公众号\n2.redis.io\n3.windows在github上下载（停更很久了）\nredis推荐都是在linux服务器上搭建的，我们是基于linux学习\nwindows下安装 1.下载安装包\n2.下载完毕得到压缩包\n3.解压\nimage-20200924095526656\r4.开启redis，双击运行服务\nimage-20200924095553184\r默认端口号6379\n5.使用redis客户端来连接redis\nimage-20200924095651464\rimage-20200924095841127\r记住一句话，window下使用确实简单，但是redis推荐我们使用linux去开发使用\nimage-20200924100331170\r测试性能\nredis-benchmark是一个压力测试工具\n官方自带的性能测试工具！\nimage-20200924101324907\r100000并发，50台客户端并发，每次写入3个字节，只有一台服务器来处理这些请求，所有请求在2毫秒内处理完成\n基础知识 redis默认有16个数据库\n默认使用第0个，可以切换数据库\n127.0.0.1:6379\u0026gt; select 3\t#切换数据库 OK 127.0.0.1:6379[3]\u0026gt; dbsize\t#查看大小 (integer) 0 image-20200924102052855\rimage-20200924102123448\r查看当前数据库中所有的key\nimage-20200924102338783\r删除当前数据库中flush\nimage-20200924102622792\r清空全部的数据库flushall\n思考：为什么redis端口号是6379\nredis是单线程的\n明白redis是很快的，官方表示，redis是基于内存操作的，cpu不是redis性能瓶颈，redis的瓶颈是根据机器的内存和网络带宽，既然可以使用单线程来实现，就是用单线程了，所以就使用了单线程了！\nredis为什么单线程还这么快？\nredis是c语言写的，官方提供的数据为100000+的QPS，这个不比同样是使用了key-value的memecache差\nredis为什么单线程还这么快\n1.高性能服务器一定是多线程的？？\n2.多线程（CPU上下文切换）一定是单线程效率高？？\ncpu/memory/硬盘速度要有所了解！\n核心：redis是将所有的数据全部放在内存中的，所以说使用单线程去操作效率就是最高的，多线程（CPU上下文会切换：耗时的操作！！！！），对于内存系统来说，如果没有上下文切换效率就是最高的，多次读写都在一个cpu上的，所以在内存情况下，这个就是最佳的方案！\n五大数据类型 Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件. 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询. Redis 内置了 复制（replication）， LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction）， 事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel） 和自动 分区（Cluster）提供高可用性（high availability）.\n讲解的所有命令，后面使用springboot、jedis，所有的方法都是这些命令\n单点登陆\nredis-key keys * 查看所以的key exists name 判断当前的key是否存在 move name 移除当前的key expire name 10 设置key的过期时间 单位是秒哦 ttl 查看当前key的剩余时间 type name 查看当前key的类型 image-20200924104300213\rimage-20200924104451001\rimage-20200924104806660\rimage-20200924105127099\rstring（字符串） 90%的java程序员使用的都是redis的string类型\nimage-20200924105632891\rappend 追加字符串 ， 如果key不存在 ， 就相当于set key value exists 判断某个key是否存在 strlen 获取字符串的长度 image-20200924110407868\rincr key 自增命令，自增1 decr key 自减命令，自减1 incrby key increment 自增多少步长 decrby key decrement 自减多少步长 image-20200924110748593\r范围 getrange key start end 其实就是截取字符串 从0开始 如果是0到-1 就是截取全部的字符串 替换呢？ setrange key offset value 替换 key 从哪里开始算起，替换多少个字符 setex（set with expire) #设置过期时间 setnx(set if not exist) #不存在设置 image-20200924111131931\rsetex key time value 设置过期时间ttl key 查看多久过期setnx key value 设置原本不存在的key的value值返回值是0代表没有成功 1代表成功 image-20200924111716363\rmset 同时设置多个值 mget 同时获取多个值msetnx 是一个原子性的操作，要么一起成功，要么一起失败 image-20200924112237809\r#对象set user1:1 {name:zhangsan,age:3}#设置user:1对象 值为json字符串来保存一个对象#这里的key是一个巧妙的设置：user：{id}：{filed}，如此设计在redis中是完全ok的 image-20200924112908580\rimage-20200924113631933\rgetset key value 没有就设置设置完了就可以再改 image-20200924150037955\rimage-20200924150059352\rimage-20200924150112188\rstring类似的使用场景：value除了是我们的字符串还可以是我们的数字\n计数器 统计多单位数量 例如 uid:55646541:follow 0 粉丝数 对象缓存存储 list 在redis里，我们可以把list玩成一个栈、队列、阻塞队列！\n所有的list命令都是以L开头的\nlpush 将一个值或多个值，插入到列表头部（左）rpush 将一个值或多个值，插入到列表尾部（右）lrange key start end 获取值 image-20200924151313766\rlpop 移除list的第一个元素rpop 移除list的最后一个元素 image-20200924151853384\rlindex key index 通过下标获取某一个值 image-20200924152048330\rllen list的长度 image-20200924152237266\r移除指定的值！取消关注 uidlrem key count value 移除特定个数的指定值 image-20200924152956569\rtrim 修剪ltrim 截断list集合并获取特定下标的集合ltrim key start end image-20200924153243035\rrpoplpush移除列表右边最后一个元素并且将其加入到一个新的列表中rpoplpush source destination image-20200924153737788\rlset key index value 将列表中指定下标的值替换为另外一个值，更新操作如果不存在指定下标，就会报错 image-20200924154630068\rlist中多用lrrange、lpush、lpop而非lset\nlinsert key before/after 特定的value 要插入的value将某一个具体的value插入到列表中某个特定元素的前面或者后面 image-20200924155744795\r小结\n他实际上是一个链表，before node after left right 都可以插入值 如果key不存在，创建新的链表 如果key存在，新增内容 如果移除了所有的值，空链表，也代表不存在 在两边插入或者改动值，效率最高！中间元素，相对来说效率会低一点！ 消息排队！lpush rpop（消息队列） lpush lpop（栈）\nset（集合） set中的值不能重复\nset通常都是以s开头的sadd key member 向集合中添加元素sismember key member 判断某元素是否在指定的集合中smembers key 查看指定集合的所有元素scard key 查看指定集合的长度 image-20200924162841343\rsrem (s remove缩写) key value 删除指定集合里的指定元素 image-20200924163026477\rset无需不重复集合，可以实现抽随机srandmember key 数量 随机抽取指定数量的元素从某指定集合中 image-20200924163406035\r删除指定的key， 随机删除指定的key0spop key count 随机移除指定集合内指定数量的元素 image-20200924163558641\r将一个指定的集合中的指定元素移除至另一个指定集合中smove source destination value image-20200924163918565\r微博、B站、共同关注（交集）\n差集sdiff(set different) sdiff key1 key2 与 sdiff key2 key1不同，参考系不一样sunion key1 key2 sinter key1 key2 image-20200924164627415\r微博，A用户将所有关注的人，放在一个set集合中，将他的粉丝也放在一个集合中，\n共同关注：A用户和B用户的共同关注，二度好友，推荐好友，六度分割理论\nhash（哈希） 想象成map集合，key-map集合， key -\u0026lt;key,value\u0026gt;集合，只是这个值是一个map集合，其实本质和string类型没有太大区别，还是一个简单的key-value\nhset key field value 设置值hget key field 获取值hmset key field1 value1 field2 value2 批量设置值hget key field1 field2 批量设置值hgetall key 获取所有的值 image-20200924170715011\rset myhash field kuansheng\n所有的hash都是以H开头滴哈宝贝们\nzset\n三种特殊数据类型 geospatial\nhyperloglog\nbitmaps\n","date":"2020-09-19T00:33:33+08:00","permalink":"https://linjianshu.github.io/p/redis%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/","title":"Redis学习文档"},{"content":"从零搭建微服务框架嗷 新建webapi项目\nimage-20201026181939602\r新建student控制器，测试运行\nimage-20201026182245668\rimage-20201026182254921\r添加新项目控制台应用程序，加入model类\nimage-20201026182407678\rimage-20201026182436593\rimage-20201026182536295\r删除program.cs文件，右键属性，修改输出类型为“类库”\nimage-20201026182552213\r继续新建项目，interface，作为服务的接口\nimage-20201026183008099\r删除program.cs文件，继续修改属性为类库\n定义完了接口，接下来应该定义实现接口的具体服务了，新建控制台应用程序\n编写DBhelper类，原生连接数据库\n添加StudentService实现类，继承IStudentService，实现它未实现的方法\nimage-20201026183509062\rimage-20201026183523894\r依然重复上述步骤，右键属性，修改输出类型为类库\n测试，以上依然是个单体结构，只不过分层了，现在我们搭了基层结构如图：\nimage-20201026183657453\r分别为，webapi，接口，模型层，接口实现类\n接下来修改webapi内student控制层里的方法，尝试调用通过接口调用服务，进而获取数据库中的数据\n修改前：\nimage-20201026183803906\r修改后：\n先在startup.cs中进行服务类的依赖注入\nimage-20201026184259317\r在这里，我们对controller进行重新构造：\n定义一个私有只读IStudentService接口 ；\n在构造函数里为它赋值\n在GetAllStu方法里进行调用\nimage-20201026184627518\r启动试试，输入url\nimage-20201026184827682\r不错不错\n接下来我们要添加服务实例，将原来的单体应用程序，模拟拆分成分布式应用程序\n新建项目，新建webapi\nimage-20201026185004596\r新建新的控制器，为了和上面的student控制器区分，且，我们要知道，最后上面将作为客户端，调用我们现在正在搭建的服务实例，这个项目，所以真正会和接口、服务、数据库打交道的应该在我们现在搭建的这个控制器里面，在这里我取名为StuImplController控制器。\nimage-20201026185242569\r在这里面，复制之前的studentcontroller里的内容，作为真正调用的源头\nimage-20201026185405390\r同时，别忘记了，要正常使用，记得在该项目内startup.cs中增加依赖注入\rimage-20201026185548164\r修改启动项目为该服务实例，我们先试试看能不能跑\nimage-20201026190458520\rnice\n接下来我们做分布式应用程序：我们希望LjsMicroServiceReviewDemo通过ServiceInstance去调用，这样子，前者就可以作为客户端，后者就可以作为服务端，因为是进程间通信，虽然在一台电脑上跑，但是可以理解为是利用网络架起的桥梁，进行分布式应用的部署和调用。\n这时候记录一下网址\nhttp://localhost:42464/api/StuImpl/GetAllStu\nimage-20201026190938569\r在客户端，写一个调用方法，调用刚刚的网址嘿嘿\n同时启动两个项目，让他搞去吧\nimage-20201026191036770\rimage-20201026191232782\r爽爆了！\n但是还不够，我们知道，一般情况下，服务器里怎么可能只有一个服务实例在跑呢，那双十一不是炸裂，所以这时候会有很多实例在跑才对，例如两个、三个相同的实例一起运行，同时对外提供服务才对。\n我们要使用命令行运行服务实例，并且赋予相应的端口号\nimage-20201026193900248\rimage-20201026194428606\rimage-20201026194845947\r在地址栏敲cmd\nimage-20201026194856720\rimage-20201026194903514\rimage-20201026194909623\r开启三个服务实例，端口为5726、5727、5728\n为了验证，可以在浏览器试试\nimage-20201026195019372\rnice\n这时候，客户端调用的url就得改成上述网址了\nimage-20201026195131547\r你有种调用我试试\nimage-20201026195809734\r可是我们做不到负载均衡呀，就是我们不晓得怎么调用5726还是5727还是5728嘞，这时候就要引入Nginx啦！\n下载Nginx和环境变量的配置就不过多赘述了\nimage-20201026195315199\r修改conf文件\nimage-20201026195409611\r配置端口侦听\n配置代理端口号\n最后我们打算舍弃传统的调用方式，寄希望于Nginx反向代理工具来帮我们实现一些负载均衡的策略\n启动Nginx.exe\nimage-20201026195704107\r启动客户端程序，跑一跑\nimage-20201026195954175\r问题不大，但是这时候又有个问题了，如果某个服务突然挂了怎么办呢，如果有个服务因为预计可能会有大规模的访问，运维人员又加上了几个服务实例呢，这时候就需要我们手动在conf的配置文件里进行配置，这样十分的低效，假如你在一家超大型的互联网公司，就GG了，所以这时候我们要用consul来替代Nginx\nnuget包必不可少\nimage-20201026200233953\r同样在服务实例项目里也要引入consul包\n在服务实例项目中，加入帮助类，心跳检测控制器，并在startup.cs中配置\n在ReviewDemo中也要注册并使用\n配置完毕后要激活consul，重新生成才行\nimage-20201026202449309\rimage-20201026202508759\r启动成功，接着让三个服务实例上线\nimage-20201026204217548\rimage-20201026204225424\r其实这时候我们不知道如何做负载均衡，如果要做的话，也带在客户端做负载均衡，这样每个客户端都要做一个，就很麻烦，没有什么是加一层不能解决的，所以我们加一层服务网关，Ocelot，用于请求分发、统一负载均衡、熔断、限流、降级\nimage-20201026204426653\r我们继续创建新项目：webapi\nimage-20201026204640378\r引入nuget包，ocelot用于服务网关，consul用于网关和注册中心的集成，polly用于熔断、限流、降级等\n当然，在服务实例层也要加入ocelot.provider.consul，否则ocelot怎么知道服务实例从哪里来呢对吧，好了我们再回到gateway层\n在program.cs文件中添加配置的json文件\nimage-20201026204959449\r在startup.cs文件中把管道换成ocelot自己的\nimage-20201026205138653\r配置文件\nimage-20201026205802408\r给她一个运行端口\nimage-20201026205827534\r跑一跑\nimage-20201026205837308\r结束了嗷，下个阶段的内容应该是，CQRS命令查询职责分离，以及以及以及数据库如何划分，以及以及以及Rabbitmq以及基于事件的驱动。\n","date":"1999-10-10T23:44:44+08:00","permalink":"https://linjianshu.github.io/p/%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%97%B7/","title":"从零搭建微服务框架嗷"},{"content":"windows服务开发备忘 先开个窗体来调试试试看\n再新增一个service服务进来\n修改默认服务名\n添加安装程序 修改为本地\nimage-20210928105412125\r记得引入日志 并将config文件复制到输出目录\n有时候install.bat命令不行可能是系统没有权限\n跑服务的时候记得再program里改成服务,别泡成窗体应用了\n服务的onstart里需要写的是异步方法或者新开一个线程,否则会出现无法服务进程无法连接到服务控制器上的错误\nimage-20210928105853916\rimage-20210928105911601\r接口服务嘛,最好尝试ping一下服务器,服务器畅通才能工作\n另外最好对间隔时间做到可配置\n","date":"1999-10-01T09:17:59+08:00","permalink":"https://linjianshu.github.io/p/windows%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91%E5%A4%87%E5%BF%98/","title":"windows服务开发备忘"}]